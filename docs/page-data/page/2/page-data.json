{"componentChunkName":"component---src-templates-posts-tsx","path":"/page/2","result":{"pageContext":{"group":[{"node":{"number":47,"relative_category":"blog/organization","fields":{"title":"マネジメントとは何か","excerpt":"組織が大きくなってくると自然と自らの手ではどうしようもできなくなり、マネジメント業務を各メンバーに委譲する必要が出てきます。そうは言っても個別のタスク指示はすんなり出来ても、「よしなにやって」つまり「周辺の整理（マネジメント）も含めて上手くタスクを回せるように調整して」と言う指示は一言では伝えきれません。マネジメント職同士のやりとりなら問題ないのですが、これからマネジメント領域に入っていって欲しいメンバーの場合はどう連携すれば良いのでしょうか。未完ではありますが、今回はマネジメントそのものについて整理しました。  > PROBLEMPROBLEM \n\n- チームメンバーにマネジメントを理解して欲しい けれど、マネジメントに関する書籍が多く、一言でこれを読めと伝えるのが難しい 一方、一言では言い表せないが、一目でなら表せるものが自分の中に出来上がっている 昔手にした書籍をヒントにマネジメントの枠組みというのを自分の頭に構築していた ただ、そのことについて書かれた書籍を見たことがない \n- けれど、マネジメントに関する書籍が多く、一言でこれを読めと伝えるのが難しい\n- 一方、一言では言い表せないが、一目でなら表せるものが自分の中に出来上がっている 昔手にした書籍をヒントにマネジメントの枠組みというのを自分の頭に構築していた ただ、そのことについて書かれた書籍を見たことがない \n- 昔手にした書籍をヒントにマネジメントの枠組みというのを自分の頭に構築していた ただ、そのことについて書かれた書籍を見たことがない \n- ただ、そのことについて書かれた書籍を見たことがない  > SOLUTIONSOLUTION \n\nというわけで、自分の頭の中に出来上がったマネジメントのフレームワークについて改めて整理することにしました。 \n\n私はそのフレームワークを「GRPR（グルーパー）マネジメントサイクル」と呼んでいます。GRPRはゴール（G）、リソース（R）、プロセス（P）、ルール（R）の頭文字の組み合わせです。私はこのGRPRを grouper（熱帯や温帯の海域に分布する魚のハタの意）の略字に見立てることで、マネジメントサイクルをハタの形に重ねて覚えています。下記がそのサイクルです。どうです、ハタに見えませんか? \n\n \n\nこのフレームワークはどの職種にも応用ができ、今までいくつかの職種の中でマネジメントを行ってきましたが、どれも無理なく実施できました。そして、これは各種マネジメント関連の書籍を整理する際の枠組みとしても使えます。この当たりを冗長に書こうとすると切りがないのでここでは完結に記す予定です。 \n\nでは、具体的に各要素を見ていきましょう。  > ゴールゴール \n\n計画と意思決定を行います。これはSMARTに則り戦略的かつ具体的に測定可能で達成可能、関連性のある期限あるものが良いです。下記のようなMBOで設定する目標が分かりやすい例です。 \n\n目標例 \n\n- デザインコーディネーション 組織パターン \n- 組織パターン\n- サービスカタログ  > 変化前のリソースとプロセス変化前のリソースとプロセス \n\nゴールを決めた後にその方向に動き出すための現状把握を行います。対象にはリソースとプロセスがありますが、それらは人も含みます。まずリソースについて、人の場合は意志の状態と価値観の確認を行い、人以外の場合は当該リソースのステータスを確認します。 \n\n- マインドフルネス、アンガーマネジメント、心理的安全性\n- キャリアアンカー \n\nプロセスについては各業務フロー、システムフローを確認します。 \n\n- CMMI  > 変化後のリソースとプロセス変化後のリソースとプロセス \n\n現状を把握した後に目指すべきリソースとプロセスが決まったらそちらに変更を促します。所謂 指示と動機付けを元にした「変更管理」を行います。これはリーダーシップという切り口で語られることが多いマネジメント領域です。  > ルールルール \n\n最後にリソースやプロセスの現状や変化を観察し評価します。この評価によってルールを定め、次のゴールへと段階を上げていきます。なお、ルールはリソースやプロセスに制限をかけるものではありますが、長期的に見た際に安全に業務を回すためのガードレールの役割を果たします。 \n\n例えば、ルールには下記のようなものがあります。 \n\n- 業務運用方針\n- 各パブリッククラウドのIAM設定・運用の方針\n- AWS Control Tower  > WRAPUPWRAPUP \n\n最低限の部分をまとめてみました。まずはメンバーからのフィードバックをもらいつつ今後も気になるところを追加していく予定です。"},"name":"[2021-04-01]マネジメントとは何か","tags":["team-building"],"childPublishedDate":{"published_on":"2021-04-01T00:00:00.000Z","published_on_unix":1617235200}}},{"node":{"number":75,"relative_category":"blog/backend","fields":{"title":"CDKで管理する今どきのJenkins","excerpt":"先日のAWS障害で管理していたECSに多少の影響が出たので、そのタイミングで敷設していたJenkinsの構成を改めて整理しました。今回は課題解決というより、既に稼働していたシステム構成の振り返りを行いました。  > PROBLEMPROBLEM \n\n- インフラ系タスクがコード管理されていないので属人化しやすい 可能なら当該タスクはインフラ担当から手離れして欲しい 当該タスクは通常のCIワークフローとは異なるので管理する場所がない そういう意味でJenkinsの出番だけどこれはこれで管理が手間 ヘルスチェックエラーにひっかかったら自動で再起動してほしい \n- 可能なら当該タスクはインフラ担当から手離れして欲しい\n- 当該タスクは通常のCIワークフローとは異なるので管理する場所がない そういう意味でJenkinsの出番だけどこれはこれで管理が手間 ヘルスチェックエラーにひっかかったら自動で再起動してほしい \n- そういう意味でJenkinsの出番だけどこれはこれで管理が手間 ヘルスチェックエラーにひっかかったら自動で再起動してほしい \n- ヘルスチェックエラーにひっかかったら自動で再起動してほしい  > SOLUTIONSOLUTION \n\nというわけで、モダンなJenkins2系をAWS CDKで敷設してみました。  > 1. 構成1. 構成 \n\n大方の構成は「nabinno/jenkins-cdk-on-ec2」のシステム構成図をご覧下さい。元ネタはaws-sampleになりますが、今回はAWS FargateではなくAmazon ECSを採用し、CDKはTypeScriptで実装しています。 \n\n使用技術スタック \n\n- Jenkins\n- Amazon ECS（Amazon EC2）\n- Application Load Balancer\n- Amazon EFS   > 2. CDKによるJenkinsの敷設2. CDKによるJenkinsの敷設 \n\nCDKによるJenkinsの敷設はGitHubレポジトリーを見ていただくとして、ここではCDKのコード上の注意点を2点ほど共有しておきます。  > 2-a. CDKの注意点：リソース名を明示する2-a. CDKの注意点：リソース名を明示する \n\nCDKで各リソース名を明示しないとCloudFormation（CFn）独特の命名規則でリソースが敷設されます。インフラ担当が自分一人の場合は良いですが、インフラ担当を増員する際は、他のIaCツールの運用方針とバッティングする等、後で足かせになるので命名規則にのっとりリソース名を付けていくようにしましょう。 \n\n命名規則は「クラスメソッドさんの記事」を参考に決めるのが定番のようです。下記例になります。    AWSリソース 命名規則     ELB {sysname}-{env}-alb/clb   TargetGroup {sysname}-{env}-tg   EC2 {sysname}-{env}-{type}   SecurityGroup {sysname}-{env}-{type}-sg    \n\nCDKでリソース名を明示するには次のいずれかの方法で対応します。 \n\n- 各クラスのコンストラクトプロパティにある名前を記述する\n- 暗黙的生成されるリソースを明示的に作成する \n\n下記コードでは暗黙的に生成されていたSecurity Groupを明示的に作成している様子等が見て取れます。 ts\n\n// ECS: Service const serviceSecGrp = new ec2.SecurityGroup(this, \"JenkinsMasterServiceSecGrp\", { securityGroupName: \"jenkins-production-master-sg\", vpc: network.vpc, allowAllOutbound: true, }); serviceSecGrp.addIngressRule(worker.workerSecurityGroup, ec2.Port.tcp(50000), \"from JenkinsWorkerSecurityGroup 50000\"); serviceSecGrp.addIngressRule(worker.workerSecurityGroup, ec2.Port.tcp(8080), \"from JenkinsWorkerSecurityGroup 8080\"); const jenkinsMasterService = new ecs.Ec2Service(this, \"EC2MasterService\", { serviceName: 'jenkins-production-master-svc', taskDefinition: jenkinsMasterTask, cloudMapOptions: { name: \"master\", dnsRecordType: sd.DnsRecordType.A }, desiredCount: 1, minHealthyPercent: 0, maxHealthyPercent: 100, enableECSManagedTags: true, cluster: ecsCluster.cluster, securityGroups: [serviceSecGrp] });  \n\nなお、リソース名の明示化について、もちろんCDKのクラスによっては暗黙的なリソースを含んでおり当該リソースに名前を付けることが出来ないケースはあります。今回のケースで言うと、例えば、ECSクラスター（EC2）のIAM RoleやSecurity Group。その場合は、インフラのCDK運用方針としてドキュメントに残しておく等しておくと良いでしょう。  > 2-b. CDKの注意点：cdk.RemovablePolicy.RETAINをつける2-b. CDKの注意点：cdk.RemovablePolicy.RETAINをつける \n\nネットワーク、ストレージ関連のリソースを扱う場合、削除されるとリソース構成が破綻する可能性があるのでcdk.RemovablePolicy.RETAIN、CFnの言うところの \"DeletionPolicy\": \"Retain\" をつけましょう。今回はEFSがその対象になります。 ts\n\nconst efsFilesystem = new efs.CfnFileSystem(this, \"EFSBackend\"); efsFilesystem.applyRemovalPolicy(cdk.RemovalPolicy.RETAIN);  \n\n個人的にはRETAINをつけるとcdk destroy cdk deployを気軽に行えなくなるので、RETAINをつけるならCDK/CFnからはARNで参照する程度に抑えた方が良いと思っています。  > 3. Jenkinsの設定を行う3. Jenkinsの設定を行う \n\nCDKでJenkinsを敷設した終わったらJenkinsの設定を行いましょう。  > 3-a. Jenkinsでつかっているプラグイン3-a. Jenkinsでつかっているプラグイン \n\n昔と違って今のJenkinsは下記プラグインがあれば十分運用できます。 \n\n- github-oauth\n- role-strategy\n- configuration-as-code\n- blueocean \n\nざっと説明するとgithub-oauthでGitHub認証させ、role-strategyでロールごとの権限付与を行い、configuration-as-codeでそれらの管理設定をコード化します。configuration-as-codeは素晴らしく設定情報をコード化することでdockerイメージに当該設定情報を反映させることが出来ます。また、blueoceanはモダンなインターフェイスでジョブ実行します。こちらは次のセクションで詳細を説明します。 \n\nなお、プラグイン管理はIaC化でき下記のようにdockerイメージに反映できます。 sh\n\n$ cat plugins.txt role-strategy:3.1 github-oauth:0.33 thinBackup:1.10 git:4.6.0 authorize-project:1.3.0 configuration-as-code:1.47 blueocean:1.24.4 $ cat Dockerfile [...] COPY plugins.txt /usr/share/jenkins/ref/plugins.txt RUN /usr/local/bin/install-plugins.sh < /usr/share/jenkins/ref/plugins.txt [...]   > 3-b. JenkinsジョブをGitHubで管理する3-b. JenkinsジョブをGitHubで管理する \n\nいよいよJenkinsでジョブの管理設定を行います。具体的には下記手順で実施します。手順が完了すると作ったブランチ分だけJenkinsにジョブが追加されます、とても簡単です。 \n\n1. ジョブを管理させたいGitHubレポジトリでジョブ管理用のブランチを作成し、Jenkinsfile を配置\n2. 「Jenkins - Blue Ocean - New Pipeline」にて下記設定をおこなう Where do you store your code? - GitHub Which organization does the repository belong to? - 任意のuserあるいはorganization Choose a repository - 任意のレポジトリ（1で作成したレポジトリ） \n3. Where do you store your code? - GitHub\n4. Which organization does the repository belong to? - 任意のuserあるいはorganization\n5. Choose a repository - 任意のレポジトリ（1で作成したレポジトリ） \n\nJenkinsfile の作成方法は「ユーザーハンドブック」にありますが、下記例のように直感的に記述することが出来ます。環境変数は「Jenkins - {{レポジトリ}} - 認証情報 - Stores scoped to {{レポジトリ}} - global - Add credential」から追加します。 Jenkinsfile\n\n pipeline { agent any stages { stage('Show env') { steps { sh '''mysql --version ls -al bin env | sort''' } } stage('Run script') { steps { git(url: 'https://github.com/nabinno/jenkins-jobs', branch: 'master', credentialsId: 'github') sh '''git diff sync-db-from-staging-to-integration | patch -p1 -R -f bin/sync_db_from_staging_to_integration''' } } } environment { STAG_DB_DATABASE = credentials('STAG_DB_DATABASE') STAG_DB_HOSTNAME = credentials('STAG_DB_HOSTNAME') STAG_DB_PASSWORD = credentials('STAG_DB_PASSWORD') STAG_DB_USERNAME = credentials('STAG_DB_USERNAME') INTEG_DB_HOSTNAME = credentials('INTEG_DB_HOSTNAME') INTEG_DB_PASSWORD = credentials('INTEG_DB_PASSWORD') INTEG_DB_USERNAME = credentials('INTEG_DB_USERNAME') INTEG_DB_DATABASE = credentials('INTEG_DB_USERNAME') } }   > WRAPUPWRAPUP \n\n今回の振り返りで、2点気づきを得られました。CDKのリソース名の扱いに困っていたのですが、どうにか制御できそうなのでまたしばらくは付き合っていくことになりそうです。 \n\n1. CDKは意外とかゆいところに手が届く。ただ、暗黙的に生成され、CDK側で制御できないリソース名があるので、そういう前提で運用ポリシーを作ると各IaC使いの平穏に繋がる。\n2. Jenkins2は思った以上に手離れが良い。CDK、ECS、EFS、configuration-as-code、Jenkinsfileの組み合わせは保守性、可用性に大きな貢献をしている。"},"name":"[2021-02-24]CDKで管理する今どきのJenkins","tags":["aws-cdk","jenkins","amazon-ecs"],"childPublishedDate":{"published_on":"2021-02-24T00:00:00.000Z","published_on_unix":1614124800}}},{"node":{"number":68,"relative_category":"blog/organization","fields":{"title":"飲み会に参加するための機材","excerpt":"以前チーム内でリモート懇親会を画策したのですが、食材の調達や経費精算など手間が多すぎて断念しました。ただ、その言い訳は実は本質的ではなく、実際に後ろ向きにさせていたのは「しゃべりながら食べるのがつらい」ということにありました。今回はそれを解決した機材を紹介します。  > PROBLEMPROBLEM \n\n- リモート飲みがつらい 何がつらいって、ヘッドホンをしながら飯を食べるのがつらい 有線ヘッドホンだとPCの前に張り付きになりつらい 無線ヘッドホンだと音声が悪すぎて相手のメッセージが聞き取りづらい というか、有線だろうが無線だろうが直接PCにつなげると少量のノイズが乗る場合がありつらい 音声が悪すぎて相手にメッセージが伝わらない 「えっ、今なんて言ったの?」という会話を何度も繰り返す様がいたたまれない 自分の顔を相手に見せつけるのが気持ち的にいたたまれない アバターはPCリソースを消費する上、アバターに気を使うのは飲み会の意義から少しずれている 最初は楽しいがすぐ飽きる \n- 何がつらいって、ヘッドホンをしながら飯を食べるのがつらい 有線ヘッドホンだとPCの前に張り付きになりつらい 無線ヘッドホンだと音声が悪すぎて相手のメッセージが聞き取りづらい というか、有線だろうが無線だろうが直接PCにつなげると少量のノイズが乗る場合がありつらい \n- 有線ヘッドホンだとPCの前に張り付きになりつらい\n- 無線ヘッドホンだと音声が悪すぎて相手のメッセージが聞き取りづらい\n- というか、有線だろうが無線だろうが直接PCにつなげると少量のノイズが乗る場合がありつらい\n- 音声が悪すぎて相手にメッセージが伝わらない\n- 「えっ、今なんて言ったの?」という会話を何度も繰り返す様がいたたまれない\n- 自分の顔を相手に見せつけるのが気持ち的にいたたまれない アバターはPCリソースを消費する上、アバターに気を使うのは飲み会の意義から少しずれている 最初は楽しいがすぐ飽きる \n- アバターはPCリソースを消費する上、アバターに気を使うのは飲み会の意義から少しずれている 最初は楽しいがすぐ飽きる \n- 最初は楽しいがすぐ飽きる  > SOLUTIONSOLUTION \n\nというわけで、自分がこの1年試行錯誤した末に辿り着いた飲み会参加の機材スタックを共有します。  > オーディオインターフェイスオーディオインターフェイス \n\nオーディオインターフェイスはマイクやギターの音をパソコンに取り込むアナログ・デジタル変換と、取り込んだ音を再生するデジタル・アナログ変換の機能を提供します。 \n\nボイスメモ程度なら必要ないですが、フルリモートで頻繁に会議をしている機会が多いと音質とレイテンシーに多分な影響を与えます。オーディオインターフェイスがない場合、入力時にノイズが乗ったり、出力時に音質が劣化します。また、レイテンシーがひどくなったり音がゆがんだり、下手をするとPCに負荷がかかりフリーズします... \n\n会議を頻繁にする人はとりあえず手に入れたい機材。Steinberg UR22Cが人気です。 \n\n- Steinberg UR22C  > マイクマイク \n\n演説やスピーチ用にダイナミックマイクが使われていますが、オンラインミーティングで使う場合は聞き取りづらいので、何はともあれコンデンサーマイクを使うべきです。 \n\nコンデンサーマイクと言っても、いろいろあります。特にマイクの振動板（ダイアフラム）が大型か小型かで音質の印象が変わるので注意が必要です。私は下記の表のように利用シーンごとに使い分けています。    - 説明 利用シーン     スモールダイアフラム 現実主義。色のない、ニュートラルな音色を提供 ファシリテート   ラージダイアフラム 浪漫主義。音源をより大きく、愛らしいものに変換 発表、音楽活動    \n\nなお、HHKB等の打鍵音が大きいキーボードを利用している方や仕事スペースと家庭スペースとの距離が近い方は、いずれにしてもスモールダイアフラムがお薦めです。スモールダイアフラムはマイクから口元を少しでもずらすと音が入力されずらくなくなるため、期待した音質を提供することが出来ます。 \n\n製品としてはShure Beta87Aが人気です。また、購入する際はマイクスタンドとマイクスポンジもセットで検討すると良いです。マイクの位置を固定し風よけを設置した方が安定した音質に繋がります。 \n\n- Shure Beta87A  > ヘッドホンヘッドホン \n\n食事を取りながら相手の話を聞くには通常のヘッドホンだと食べ物を咀嚼するのに苦労します。口を開けたり閉めたりする際、顎とともにヘッドホンが上下に動くため相手の声が聞き取りづらくなります。 \n\n耳の穴に接しない骨伝導ヘッドホンは、食べ物を咀嚼する際の顎の動きに左右されることがないです。テレワークのヘッドホン多用が外耳炎を引き起こしているという話もあるので、そういう意味で骨伝導ヘッドホンは健康を保つ上でも重要な機材となります。 \n\nまた、使用していて分かったのですが、普段の食事の中でも使うことが出来るので、隙間時間に気軽にメディアに接しやすくなります。例えば、家族と一緒の部屋にいる中、食事を取りながらAWSのWebinarを聞くことができます。 \n\n製品としては業界を牽引しているAfterShokzのAeropexが人気です。今回はオーディオインターフェイスを利用しているので、音質をさらに高めるためにトランスリミッターと組み合わせましょう。 \n\n- AfterShokz Aeropex\n- トランスリミッター TaoTronics aptX-LL  > ビデオビデオ \n\nソーシャルメディアでよく登場するビデオ画像は、表情アップの図（ず）が前面に押し出された絵が一般的ですが、地（じ）の表現が薄く解釈余地がないものが多いです。表情が豊かな方は良いのですが、全員がそういうわけではないので地（じ）の生活の部分に焦点を当てた方が実態に合っています。 \n\n例えば、対面での会話の中では身につけている服装や持ち物等のアトリビュートに焦点が当たりますよね。「その身につけているアクセサリーは何?」「机の上に置いてあるその本、面白そうだね」という会話を思い出してください。 \n\nそういう意味で広角レンズを搭載したアクションカムは望ましい選択です。今時のアクションカムは高解像で鮮やかに表現してくれますし、外にいなくても部屋の中で十分面白い絵になります。 \n\nアクションカムは何でも良いのですが、私は普段「撮れラン」で使っているSony HDR-AS3000をミーティングの際に使っています。 \n\n- Sony HDR-AS3000  > WRAPUPWRAPUP \n\n今回紹介した機材に出会うまで紆余曲折ありましたが、揃えてみて満足しています。 \n\n飲み会でなくても良いですが、機材を揃えた方でいろいろ試してみたい方は一緒に雑談してみませんか。60分雑談会というのを開催しているので、いつでもお気軽にお声がけください。"},"name":"[2021-01-30]飲み会に参加するための機材","tags":["drinkup","team-building"],"childPublishedDate":{"published_on":"2021-01-30T00:00:00.000Z","published_on_unix":1611964800}}},{"node":{"number":67,"relative_category":"blog/frontend","fields":{"title":"esaをHeadless CMSとして使う","excerpt":"最近仕事の同僚からHeadless CMS という言葉を聞いていて「自分には関係ないな」と距離を取っていたのですが、なぜか回り回って自分からHeadless CMSを作ることになりました。世の中何が起きるか分からないですね。  > PROBLEMPROBLEM \n\n- ブログを普段書かない人なのだが、よそ向けに情報発信する必要が出てきた とは言っても、今までMarkdownをJekyllで管理していたので画像を貼り付けるのが手間でモチベーションが大きく下がっていた さらにPlantUMLを出力するのも手間、試行錯誤した末にいずれも付け焼き刃で、esaの操作感に勝てるものはなかった \n- とは言っても、今までMarkdownをJekyllで管理していたので画像を貼り付けるのが手間でモチベーションが大きく下がっていた さらにPlantUMLを出力するのも手間、試行錯誤した末にいずれも付け焼き刃で、esaの操作感に勝てるものはなかった \n- さらにPlantUMLを出力するのも手間、試行錯誤した末にいずれも付け焼き刃で、esaの操作感に勝てるものはなかった  > SOLUTIONSOLUTION \n\nというわけで、esaをHeadless CMSとして使うことにしました。 \n\nやってることは昔のMovableTypeそのもので懐かしかったです。コンテンツを別システムで管理しビルドサーバーに当該コンテンツを流し込みリビルド、最後にホストサーバーにアップロードというワークフロー。今はJAMStackの文脈で語られているようです。 \n\nこのHeadless CMSが昔と違うのはコンテンツ作成に集中できること。CI周りが発達したので一度ワークフローを組み立てれば後は自動でコンテンツを生成できます。  > やり方やり方 \n\n- esa.io でゆるふわ情報共有 - Middleman Blog への Export サンプル付き #esa_io - Qiita\n- 技術ブログを支える技術（Gatsby + esaio） - mottox2 blog\n- Next.jsとesaを使った個人サイト構築 | corocn.dev \n\nそれほど時間をかけられなかったので、上記3記事の中で手軽さを考慮しmottox2さんのソースコードを拝借しました。ありがとうございます。 \n\n- 作ったレポジトリ：nabinno/nabinno.github.io: On Blahfe - Nab's Github Pages  > シークエンス図シークエンス図 \n\n私が手を入れたのはコンポーネントを削りGatsby Blog Starterに寄せたのと、デプロイ方法を使い慣れたCircleCIに変えたくらいです。 \n\nGitHub PagesにはVercelのような便利なWebhookがないので、esaで実装されたGitHub Webhook連携を使いそれをトリガーにCircleCIジョブを走らせています。 \n\n  > CircleCIジョブCircleCIジョブ \n\nまた、CircleCIジョブは何の変哲もないもので、NodeJSを叩いてGitプッシュしているくらいです。先ほどのGitHub Webhookと似た感じの泥臭いワークフローは [skip ci] コメントの追加があります。当該コメントを入れないとジョブが再帰的に走り続けるので出口で明示してあります。 yml\n\nversion: 2.1 jobs: build_deploy: docker: - image: circleci/node:12.4 steps: - checkout - run: name: Install NPM command: npm install - run: name: Build command: npm run clean && npm run build - add_ssh_keys: fingerprints: - \"{foo}\" - deploy: name: Deploy command: | git config --global user.email \"nab+circleci@blahfe.com\" git config --global user.name \"nabinno+circleci\" git add . git commit -m \"[skip ci]Run npm run clean && npm run build.\" git push origin master workflows: build_deploy: jobs: - build_deploy: filters: branches: only: master   > WRAPUPWRAPUP \n\nとまあ大した作業内容ではないのですが、久しぶりに昔懐かしのMovableTypeのリビルドを思い出しつつ、副産物として全く縁遠かったNetlifyとVercelの位置づけを薄らと感じ取れました。"},"name":"[2021-01-18]esaをHeadless CMSとして使う","tags":["gatsby","esa","headless-cms","cms"],"childPublishedDate":{"published_on":"2021-01-18T00:00:00.000Z","published_on_unix":1610928000}}},{"node":{"number":44,"relative_category":"blog/organization","fields":{"title":"整理したい私はITILをかぶる、PlantUMLへの愛","excerpt":"現在ネクイノでエンジニアリングマネージャー、バックエンドエンジニア、インフラエンジニアを担当しています。入社後8ヶ月、年の瀬ということで振り返り記事を書くことにしました。テーマを一つに絞らないと記事にならないので今回はPlantUMLに絞ります。断りとして、この記事で書いてあることはITILプラクティスを一部なぞっているに過ぎません。PlantUMLが全知全能のツールということを主張したいわけではないです、ただ愛しています。   > PROBLEMPROBLEM \n\n- 開発人数が増えるにあたり、チームとして機能していない 管理規程はあるものの 業務フローが明示化されておらず、誰が何を何の目的で業務を回しているか分からない 可視化されていないプロセスが問題になるケースが増えてきた \n- 管理規程はあるものの 業務フローが明示化されておらず、誰が何を何の目的で業務を回しているか分からない 可視化されていないプロセスが問題になるケースが増えてきた \n- 可視化されていないプロセスが問題になるケースが増えてきた  > SOLUTIONSOLUTION \n\nと言うわけで、入社早々PlantUMLで業務フローを可視化することを始めました。  > PlantUMLとはPlantUMLとは \n\nPlantUMLはオープンソースのUMLダイアグラム作成用のテキストベースの言語です。シークエンス図、ユースケース図、アクティビティ図、クラス図のようなダイアグラムをシンプルで直感的に書くことができます。 \n\n2009年リリースされており、私が使うようになったのは、Emacsのorg-babelで実装されてからなので2014年くらい1。2016-7年にesa.ioやVS Code等で実装されてから爆発的に普及したと記憶しています。「esa.ioはオンラインのorg-modeになるべくPlantUMLを実装すべき」と要望したのは良い思い出です。  > やったことやったこと \n\nさて、私はネクイノに入社早々既存システムの運用開発と情シス（業務運用）の部長職にアサインされました。既存システムの運用開発は新しく外部のパートナーが入ると言うことで、開発フローが大きく変わる節目にありました。  > 開発フローを整備する開発フローを整備する \n\n話を聞くに新しく入る外部パートナーはプロジェクトマネージャ、ブリッジエンジニア・コミュニケーター、モバイルエンジニア、バックエンドエンジニア、フロントエンジニア、品質チェック含め20名程の体制でした。また、既存システムの運用開発ではプロダクトマネジャー、プロダクトオーナーが各開発者とともに企画策定を行うことが慣習として存在していました。私はまず企画から実装、レビュー、リリースまでの流れを整理します。 Jira上の大まかな流れ \n\n 開発の流れ \n\n  > 要望フローを整備する要望フローを整備する \n\n次に、機能要望、バグ報告、改善要望がSlackチャンネルの至る所に散在している上、チケット化されないケースがありました。突貫ではありますが、GoogleフォームとJira連携を行いました2。 \n\nプロダクトマネジャーの体制が整備されてからは、機能要望のフォームは使われることはなくなりましたが、バグ報告、改善要望は要所要所で使われ、トリアージという形で定期的に活用されています。 \n\n  > デプロイフローを整備するデプロイフローを整備する \n\n開発が進んでいくと、今度は開発環境が足りなくなりました。当時はステージング環境と本番環境しかなく、かつ、ステージング環境がテスト環境兼デモ環境の役割を呈しており、ステージング環境おテストで不具合を起こすとデモに影響が出るという状態が続いておりました。また、外部パートナーが開発するに当たり繊細なステージング環境を使うのが難しいため進捗に影響が出始めておりました。 \n\n急を要する事態のためAWS CDKでステージング環境とは別に結合環境を用意し3、デプロイフローを整備しました。 \n\n  > 障害対応フローを整備する障害対応フローを整備する \n\nさて、運用開発が順調に進んでいくと、今度は障害が頻繁に起きていることに気づきました。いいえ、薄々気づいていたのですが多忙にかまけて蓋をしておりました。ここに関しては本腰を入れてAWSサポートプランをビジネスに変更し原因を突き止めました。協力いただいた各位には感謝です。 \n\nまた、今まで見過ごされていたGoogle Workspace等の業務運用のシステムも含め障害報告の体制を敷くとともに、監視体制も強化しました。 \n\n  > 業務フローを整理する業務フローを整理する \n\nまだまだあります。業務内容に関しては詳細は書けませんが、部内の業務から他部署の業務まで安全に生産性を高めるため整理を行いました。まだまだ行います。  > リモート飲みのフローを整備するリモート飲みのフローを整備する \n\nいよいよ疲れてきたのでお酒が飲みたくなりました。飲み会フローを作ってみましたが思いの外手間がかかることが分かりあまり活用できておりません。その代わり社内でオンラインシャッフルランチという制度ができました。 \n\n  > 分かったこと分かったこと \n\nはい、こうして振り返ると入社時に感じていた雑然さは業務フローが明確でない状態のことでした。開発者なら分かると思いますが、企画段階で思い描く構成図は実装する段になるとあまり意味をなさず、結局は頭の中はシークエンス図でいっぱいになります。それと同じで、登場人物、登場人物間のメッセージ、メッセージの大枠が関係者に共有されていないと、いくらリソースが投下されても不安定で生産性に伸び悩むのです。つまり、雑然とした環境を整理すると言うことはシークエンス図を書くことに他なりません。 \n\nしかしながら、当該環境一つ一つを俯瞰的に見るとITILプラクティスそのものであることにも気づきます。 \n\nITILとはITサービスマネジメントのベストプラクティスフレームワークのこと。何らかの高い技術を持っていても、投資対効果を考えていなければ赤字になりビジネスと成り立ちませんし、顧客のことを考えずに作ったものに価値はありませんし、サービスの評価を落とすことになります。このようなことを防ぐには顧客目線やビジネス的な観点が必要で、そのノウハウがまとまったものがITILです。  > 今回対応したプラクティス今回対応したプラクティス \n\n今回の振り返りでは具体的に次のプラクティスをなぞっておりました。    振り返り ITILプラクティス     開発フローを整備する 継続的サービス改善   要望フローを整備する 要求管理、問題管理   デプロイフローを整備する リリース管理及び展開管理   障害対応フローを整備する インシデント管理   業務フローを整理する CMMI   リモート飲みのフローを整備する 組織変更管理    \n\nCMMIと組織変更管理が分かりづらいの少し補足します。 \n\n- CMMIとは能力成熟度モデル統合のことで、業務フローを評価し5段階で成熟度レベルを出す手法です。現状はレベル1-2（初期段階）のものがほとんどなのでまずはPlantUMLを使い共通認識を作るところから始めました。\n- 組織変更管理とは経営学で言うところのチェンジマネジメントに当たります。ここでは各種フローを整備しメンバー全員に落とし込むことを目指します。『Fearless Change』では今回のリモート飲み以外にも多くのパターンランゲージが紹介されています。  > WRAPUPWRAPUP  > 次にすること次にすること \n\nネクストアクションですが、採用フローを考えています。 \n\n（読者の皆様はどんなシークエンス図を思い浮かべましたか?） \n\nというわけで、ネクイノはPlantUMLを愛している開発者を募集中です。  > PR__colon__ ネクイノとはPR: ネクイノとは \n\n「世界中の医療空間と体験を再定義する」をミッションに、人々と医療の間にICTのチカラで橋をかける遠隔医療ソリューションを手掛けている会社です。医療というと高齢の患者さんをイメージされるかもしれませんが、我らがターゲットとしているのは現役世代の方。病気を治療するというより、現役世代がQOLを高めるためのサポートを目的としています。 \n\nメインサービスは、女性に特化したピルのオンライン診療アプリ「スマルナ」。ピルを飲まれている人だけでなく、受診や服用に抵抗がある方にも気軽に利用していただけたらと思いサービス提供しています。診察室の手前に助産師と薬剤師を配置した相談室を設ける等、受診のハードルを下げる工夫をそこかしこに施しているのが特徴です。 \n\n様々なメディカルコミュニケーションを行っています - 専門家相談 - カスタマーサポート - ユーザーコミュニティ  \n\n妻からは「10年前にサービスがあったら良かったのに」とお墨付きをいただいており、興味をもった方は詳しくはこちらをご覧下さい。 https://smaluna.com/  \n\n1. [B! plantuml] nabinnoのブックマーク ↩ \n2. https://github.com/nabinno/google-forms-to-jira-slack ↩ \n3. CDKはaws-rails-provisionerを参考に ecs_patterns.ApplicationLoadBalancedFargateService を実装しました ↩"},"name":"[2020-12-30]整理したい私はITILをかぶる、PlantUMLへの愛","tags":["team-building"],"childPublishedDate":{"published_on":"2020-12-30T00:00:00.000Z","published_on_unix":1609286400}}},{"node":{"number":64,"relative_category":"blog/backend","fields":{"title":"WSL2時代のDocker開発スタイル","excerpt":"6月13日は狂喜乱舞しました、久しぶりに徹夜するくらい興奮しました。そう、WSL2が出たのですよね。先日やっと私の手元に届いたので早々に検証しました。   > PROBLEMPROBLEM \n\n- あたらしくでたWSL2によって以前書いた記事からだいぶ状況が変わった 主な変更点 WSLのアーキテクチャが2種類になり、WSLはその2つのアーキテクチャを管理する機能に変わった WSL1 Windows Subsystem for Linux上のLinux (LXCore/Lxss) WSL2 軽量Hyper-V上のLinux (Linux Kernel) /procや/sysなどの特殊ファイルもふくめた共有プロトコル「9P」が実装された Win32側の9Pクライアント 9prdr.sys WSL側の9Pクライアント /init \n- 主な変更点 WSLのアーキテクチャが2種類になり、WSLはその2つのアーキテクチャを管理する機能に変わった WSL1 Windows Subsystem for Linux上のLinux (LXCore/Lxss) WSL2 軽量Hyper-V上のLinux (Linux Kernel) /procや/sysなどの特殊ファイルもふくめた共有プロトコル「9P」が実装された Win32側の9Pクライアント 9prdr.sys WSL側の9Pクライアント /init \n- WSLのアーキテクチャが2種類になり、WSLはその2つのアーキテクチャを管理する機能に変わった WSL1 Windows Subsystem for Linux上のLinux (LXCore/Lxss) WSL2 軽量Hyper-V上のLinux (Linux Kernel) \n- WSL1 Windows Subsystem for Linux上のLinux (LXCore/Lxss)\n- WSL2 軽量Hyper-V上のLinux (Linux Kernel)\n- /procや/sysなどの特殊ファイルもふくめた共有プロトコル「9P」が実装された Win32側の9Pクライアント 9prdr.sys WSL側の9Pクライアント /init \n- Win32側の9Pクライアント 9prdr.sys \n- WSL側の9Pクライアント /init    > SOLUTIONSOLUTION \n\nというわけで、前記事で掲げていた目標「WSLでDockerをつかったWebアプリケーション開発ができるかどうか」について再確認します。   > 対象環境対象環境 \n\n- Windows 10 Pro Version 1903 OS Build 18922.1000 Windows Terminal (Preview) Version 0.2.1715.0 WSL2 Ubuntu Version 1804.2019.5210 (Linux 4.19.43-microsoft-standard) Docker version 19.03.0-rc3, build 27fcb77 WSL1 Ubuntu 18.04 LTS Version 1804.2019.522.0 (Linux 4.4.0-18922-Microsoft) \n- Windows Terminal (Preview) Version 0.2.1715.0\n- WSL2 Ubuntu Version 1804.2019.5210 (Linux 4.19.43-microsoft-standard) Docker version 19.03.0-rc3, build 27fcb77 \n- Ubuntu Version 1804.2019.5210 (Linux 4.19.43-microsoft-standard)\n- Docker version 19.03.0-rc3, build 27fcb77\n- WSL1 Ubuntu 18.04 LTS Version 1804.2019.522.0 (Linux 4.4.0-18922-Microsoft) \n- Ubuntu 18.04 LTS Version 1804.2019.522.0 (Linux 4.4.0-18922-Microsoft)   > Windowsの開発環境を構築するWindowsの開発環境を構築する \n\nまず、Windowsの開発環境の構築ですが、既知の情報をふまえつつTIPSを順次紹介します。   > WSLのインストールWSLのインストール \n\n- WSL2を使ってみる (InsiderPreview) \n\nWSLのパッケージ管理は下記2つを押さえておけば問題ないでしょう。 \n\n1. asdf/anyenv プログラミング言語をバージョンごとにわけて使いたい場合はこちらをつかいましょう 関数言語界隈ではasdfが主流になってきてるようです。 \n2. プログラミング言語をバージョンごとにわけて使いたい場合はこちらをつかいましょう\n3. 関数言語界隈ではasdfが主流になってきてるようです。\n4. nix Haskellのようにasdf/anyenvでインストールできない、あるいは、扱われいないパッケージはnixをつかいましょう また、aptのバージョンが古すぎるパッケージもnixが最適です \n5. Haskellのようにasdf/anyenvでインストールできない、あるいは、扱われいないパッケージはnixをつかいましょう\n6. また、aptのバージョンが古すぎるパッケージもnixが最適です   > ターミナルのインストールターミナルのインストール \n\nWSLttyはWSL2に対応しておらずConEmuは描画がくずれやすいため、デフォルトのターミナルかWindows Terminalが選択肢となります。 \n\nWindows TerminalとConEmuとの比較    - Windows Terminal ConEmu     透過対象 backgroundImage ConEmu自体   キーバインド制約 Alt+Shiftが効かない 特になし   WSL2の描画 特になし くずれる   管理者権限で実行 初回のみ タスク実行ごと      > DockerのインストールDockerのインストール \n\nWSL1ではDockerデーモンがつかえないのでWSL2でDockerをつかうようにしましょう。Docker CEをインストールします。 \n\nどうしてもWSL1でということであれば、Win32 (WSL1からみるとdrvfs) 側でDocker For Windowsを用意します。インストールはDockerのダウンロードページから手順通りおこないます。\n 構成等は前回の記事を参照ください。   > さて、WSL2からDockerはどの程度つかえるのかさて、WSL2からDockerはどの程度つかえるのか \n\nWSL2は軽量Hyper-V上にLinuxコンテナを動かしているので、基本Hyper-Vと同様にDockerをつかうことができます。 \n\nただし、WSL1と違いlocalhostにWSL2がバインドできません (2019-07-27追記: Build Version 18945で解決しました )。\n また、WSL1と同様にWin32・WSL間でのファイルの読み書きにパフォーマンスの差が大きく出ています。 \n\nひとつずつ解決方法を見ていきましょう。   > 1. WSL1と違いlocalhostにWSL2がバインドできません1. WSL1と違いlocalhostにWSL2がバインドできません \n\nWSL2がつかっているVirtual Switchはinternal onlyのため、Win32側からlocalhostをつかってWSL2にアクセスすることができません。現在対応中のようです (2019-07-27追記: Build Version 18945で解決しました )。 \n\n対処方法は2つあります。 \n\na. WSL1をつかう \n\nこれが一番楽ですが、WSL1は次項であげるパフォーマンス上の欠点があるので、Web系フロントエンド開発におけるライブリローディング機能をつかうケースに限定するといいでしょう。 \n\nb. Hostsファイルをつかう \n\nWin32のHostsファイルでWSL2のeth0インターフェイスのIPアドレスに適当なホスト名を割り当てます（ポートごとにホストを振り分けたい場合はWSL2側にProxyを用意するといいでしょう）。   shell \n\n# C:\\Windows\\System32\\drivers\\etc\\hosts 172.17.72.217 dashboard.local.me   \n\nWSL2のIPアドレスはコンテナを立ち上げるごとに変わるので、下記のようなコマンドレットをWin32側のPowerShell $PROFILEに用意しておくといいでしょう。WSL2だけで完結したい方はシェル上から powershell.exe -Command 'Sync-HostsToWslIp' と打つだけです。   powershell \n\n# $PROFILE function Sync-HostsToWslIp { $hosts = \"$env:SystemRoot\\System32\\drivers\\etc\\hosts\"; $pattern = \"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\"; $wslip = bash.exe -c \"ifconfig eth0 | grep 'inet '\"; if ($wslip -match $pattern) { $wslip = $matches[0]; } else { echo \"The Script Exited, the ip address of WSL 2 cannot be found\"; exit; } cat $hosts | %{ $_ -match $pattern } $rc = cat $hosts | %{ $_ -replace $matches[0], $wslip } $rc | Out-File $hosts; }     > 2. WSL1と同様にWin32・WSL間でのファイルの読み書きにパフォーマンスの差が大きく出ています2. WSL1と同様にWin32・WSL間でのファイルの読み書きにパフォーマンスの差が大きく出ています \n\nいろんな方がベンチマークを公開してるのでそれを参考にするといいでしょう。 \n\nCf. \n\n- Pythonでファイル操作のベンチマーク\n- dd、git cloneのベンチマーク \n\nわたしは git status -sb をよくつかうので、そのコマンドで簡単なベンチマークとりました。   shell \n\n# WSLx $ cd ~/nabinno.github.io $ \\time -f %e git status -sb # Win32/WSLx $ cd ~/nabinno.github.io $ \\time -f %e powershell.exe -Command 'git status -sb' # Win32 PS> cd ~/nabinno.github.io PS> (Measure-Command { git status -sb }).TotalMilliseconds / 1000 | %{ [math]::Round($_, 2) }      Subject WSL Win32     WSL1 0.47 0.09   WSL2 0.00 0.61   Win32/WSL1 2.66 1.91   Win32/WSL2 2.81 1.79   Win32 0.51 0.12      > Docker以外でWSLの課題はないのかDocker以外でWSLの課題はないのか   > デバイスへのアクセスデバイスへのアクセス \n\n以前から要望があったものだと「デバイスアクセスができない」件があります。 \n\n9P導入前だとこれはElixirのIoTフレームワークNervesのように、WSL UtilitiesでWSLパスをWin32パスに変換してからWin32にあるデバイス関連ツールをつかうのが簡単な解決策でした。   sh \n\n$ fwup.exe -a -i $(wslpath -w -a _build/rpi0_dev/nerves/images/hello_nerves.fw) -t complete -d $(fwup.exe -D | sed 's/,.*//')   \n\nただし9Pを導入したWindows 10 Version 1903以降は、WSL1もWSL2もともにWSLパスを変換せずにWin32にあるデバイス関連ツールをつかうことができます。   sh \n\n$ fwup.exe -a -i _build/rpi0_dev/nerves/images/hello_nerves.fw -t complete -d $(fwup.exe -D | sed 's/,.*//')     > WRAPUPWRAPUP \n\nわたしの観測範囲では課題はほぼ問題ない状態になっていました。 \n\nおすすめ開発環境は下記のとおり    item content     IDE WSLx上のエディタ   Webフロントエンド開発 WSL1   Docker関連開発 WSL2   dotfiles WSLx、Win32を共有管理    \n\nWin32側のIDEをつかっているユーザーはパフォーマンス上の不満がまだあるかもしれませんが、WSLでDockerをつかったWebアプリケーション開発は十分できる、と言えそうです。つまり、Linux・macOS・WindowsによるWebアプリケーション開発は十分共有できる、と。 \n\nいい時代になりました。"},"name":"[2019-07-06]WSL2時代のDocker開発スタイル","tags":["wsl","wsl2","ubuntu"],"childPublishedDate":{"published_on":"2019-07-06T00:00:00.000Z","published_on_unix":1562371200}}},{"node":{"number":63,"relative_category":"blog/frontend","fields":{"title":"イケてるしヤバい言語REBOLの後継Redでクライアントソフトをつくった話","excerpt":"Redという言語はご存じでしょうか。可読性が高いシンタックスを持ち、ワンバイナリーをクロスコンパイルでき、かつ、クライアント用のUIコンポーネントを標準ライブラリに備えたプログラミング言語です。その野心的な挑戦にすぐに虜になりました。新年早々の恋です。   > PROBLEMPROBLEM \n\n- クロスプラットフォーム用のクライアントソフトをつくるにあたり 重たいフレームワークが多い 汎用的な言語をつかってるものが多く、そのためライブラリー等の依存関係が多くなりやすい \n- 重たいフレームワークが多い\n- 汎用的な言語をつかってるものが多く、そのためライブラリー等の依存関係が多くなりやすい   > SOLUTIONSOLUTION \n\nというわけで、年明け見つけたRedがシンプルだったので使ってみました。題材は以前つくったEmacsライブラリ「esa.el」の移植です。 \n\n- 今回作ったコード https://github.com/nabinno/esa.red    > やったことやったこと   > エディターエディター \n\n構文がすなおなので特にエディタは関係なさそうでしたが、慣れ親しんでるEmacsに「Skrylar/red.el」を適用しました。その際、 red-font-lock-keywords と red-indent-line に足りない箇所があったのでオーバーライドしました。   > 糖衣構文の適用糖衣構文の適用 \n\nRedはコマンドラインREPLがつかえるので、 docs.red-lang.org とRed by Exampleをみながらひとつひとつ挙動を確認しました。その中でどうしても慣れない表現が2つあったので糖衣構文を実装しました。 \n\n- 実装した糖衣構文 nabinno/red-elixir  \n\n1. compose \n\nブロック内の変数を評価しブロックとして返す関数 compose は、VIDのフェイス更新によく使われます。HTML/JavaScripでいうところDOM更新にあたるものといえば分かるでしょうか。頻繁に「 compose [foo (bar)] 」のような表現がつづくとほかの変数や関数とまざり可読性がおちるので、Elixirのシジルを参考に compose 関数を省略しました。こんな感じです。 \n\n;-- before compose [foo (bar)] ;-- after ~c[foo (bar)]  \n\n2. 関数の入れ子 \n\n素のRedはイテレーター構文なので、関数の入れ子による可読性低下をおさえるため変数定義をよく使います。個人的には変数は意味のあるものだけ使いたい派なので、パイプを導入しました。といっても、フロントエンドの場合、データ加工はあまりやらないのでつかうケースはほぼありませんでした。あってもこのくらいです。   red \n\n;-- before rejoin collect [ foreach d data [ keep rejoin [d \" \"] ] ] ;-- after data .[ |> Series/map 'd [rejoin [d \" \"]] |> rejoin ]     > タスクランナーの用意タスクランナーの用意 \n\n今回は上で実装したライブラリ「red-elixir」のほかにHTTPリクエスト・JSONパーサーライブラリを使っています。ライブラリパッケージはインストールはgit submodulesで良いですが、呼び出しも考えると実装が冗長的になるのでパッケージ管理とタスクランナーをあわせて用意しました（nabinno/hot、nabinno/mods）。 \n\nタスクランナーインストール後、パッケージのインストールから呼び出しまでの流れ \n\nRedはGoとおなじくワンバイナリーなので、wgetやcurlだけでインストールが完了します。   sh \n\n> mkdir -p ~/.local/bin > wget https://github.com/nabinno/hot/releases/download/0.0.3/hot-linux -O ~/.local/bin/hot > chmod 744 ~/.local/bin/hot   \n\nパッケージ管理はElixirのmixを参考にタスクランナー管理ファイル内に定義します。   sh \n\n> hot cmd/install https://raw.githubusercontent.com/nabinno/mods/master/mods.red > cat hots.red Red [] hots: context [ mods: [ red-elixir #(init: %init.red git: https://github.com/nabinno/red-elixir) json #(init: %json.red git: https://github.com/rebolek/red-tools) http-tools #(init: %http-tools.red git: https://github.com/rebolek/red-tools) ] ] > hot mods/get   \n\nビルド時は #include をつかうのでパッケージ呼び出し機能は使えないですが、コマンドラインREPLで挙動確認している際は do/args %require を使います。   sh \n\n> red >> do/args %require [red-elixir] >> 1 .. 10 .[ |> Series/map 'i [i * 2] |> Series/map 'i [i + 1] ] == [3 5 7 9 11 13 15 17 19 21]     > WRAPUPWRAPUP \n\nクライアントソフトを作る中で感じたことは、この1点です。Redは既存のフレームワークと比べるとまだまだ機能不足感が拭えませんが、それを補えるだけの表現力を持っていました。手触りが本当に良い言語でした。"},"name":"[2019-03-31]イケてるしヤバい言語REBOLの後継Redでクライアントソフトをつくった話","tags":["red","esa"],"childPublishedDate":{"published_on":"2019-03-31T00:00:00.000Z","published_on_unix":1553990400}}},{"node":{"number":62,"relative_category":"blog/backend","fields":{"title":"Elixirではてなブックマーク","excerpt":"紆余曲折合ってはてなブックマークの運用を見直す必要が出てきました。人の興味というのは尽きないもので知りたいことが次々出てきます。にも拘わらず人の時間は有限でそれにあがなうための手段を考えたわけです。   > PROBLEMPROBLEM \n\n- フィードリーダーで記事を読んだ後にはてなブックマーク（ブクマ）するとフィード消化するのに時間がかかる フィードをそのままブクマしていると下記の問題がでてくる あとで確認することができない 読みたくない記事をブクマしてしまう 適切でないURLでブクマしてしまう \n- フィードをそのままブクマしていると下記の問題がでてくる あとで確認することができない 読みたくない記事をブクマしてしまう 適切でないURLでブクマしてしまう \n- あとで確認することができない\n- 読みたくない記事をブクマしてしまう\n- 適切でないURLでブクマしてしまう   > SOLUTIONSOLUTION \n\nというわけで、下記の方針でブクマすることにしました。設置方法の詳細はGitHubレポジトリを参照ください。そして、方針は下記の通りになります。 \n\n方針 \n\n- フィードごとにタグづけする\n- ブクマ対象になる記事をリンクとタイトルで除外判定する\n- ブクマ対象になる記事をリンクから校正すべきものかリダイレクトすべきものか判定する\n- 上記設定はYAMLファイルで簡単に管理できるようにする\n- フィード読込とブクマを非同期処理できるようElixirで実装する   > ブクマの管理方法ブクマの管理方法 \n\nまずブクマの管理ですが、下記5つのYAMLファイルで構成しています、構造はマップとリストのみ。ブクマしたいと思う記事を読みすすめる中で気になるキーワードが出てきたら都度 feed.yaml を更新します。また、記事にノイズが多いようだったら傾向を分析して除外ファイル feed_excluded_link.yaml feed_excluded_title.yaml を更新します。    item description     feed.yaml フィードグループ名に対するリンク、タグのマップ   feed_excluded_link.yaml 除外すべきフィードリンクのリスト   feed_excluded_title.yaml 除外すべきフィードタイトルのリスト   feed_corrected_link.yaml フィードリンクに対するトリミングすべきパラメータのマップ   feed_redirected_link.yaml フィードリンクに対するリダイレクト先リンクのマップ      yaml \n\n# feed.yaml nabinno/sports/feed_group_name: tags: - ski links: - http://rss.example.com/ski_feed.rss - http://rss.example.com/snowboard_feed.rss - http://ski-status.example.com/rss # feed_excluded_link.yaml - anti-ski.example.com - awesome-snowboard.example.com # feed_excluded_title.yaml - queer - two-planker - beaver-tail # feed_corrected_link.yaml amazon.com: - ref - ie # feed_redirected_link.yaml ski-status.example.com: - Floki.find(fst, \".post__body a\")     > Elixirによる非同期処理Elixirによる非同期処理 \n\nElixirで非同期処理を行っているのですが、大きく分けて監視機構のSupervisorと非同期処理のTask.async_streamを使っています。   > 監視機構 Supervisor監視機構 Supervisor \n\nまず、Supervisor。Elixirには監視機構Supervisorがあり、それが各ワーカーを子プロセスとして管理しています。ここではフィード読込とブクマは別々のワーカーで処理しますが、キャッシュが暖気処理を別ワーカーで行っているため再起動戦略は「失敗したイベントの中にあるすべての子プロセスを再起動」（ one_for_all ）にしてあります。再起動戦略の詳細は「OTPスーパバイザ · Elixir School」を参照下さい。 \n\n下記のように Supervisor.start_link を Keshikimi2.Application.start に適用すると、アプリケーション開始（ mix run ）した時点で監視機構が起動されます。   ex \n\nSupervisor.start_link( [ :hackney_pool.child_spec(:hatena_bookmark_pool, timeout: 15_000, max_connections: 100), # @todo 当該ワーカーで暖気処理を行っていないので `one_for_one` にした場合、再起動時にほかに影響する supervisor(Cachex, [:feed, []]), supervisor(Keshikimi2Feed.Registry, [prefix]), # フィード読込処理 (PubSub) supervisor(Keshikimi2Feed.Subscriber, [prefix]), worker(Keshikimi2Feed.Worker, [prefix]), worker(Keshikimi2Feed.Publisher, [[prefix: prefix, poll_interval: 3_000]]), # ブクマ処理 worker(Keshikimi2.HatenaBookmark.AddEntry, [ [prefix: prefix, poll_interval: 3_000] ]) ], strategy: :one_for_all, name: name(prefix) )     > 非同期処理 Task.async_stream非同期処理 Task.async_stream \n\n次に、Task.async_stream。配列を引き回すリクエスト処理は Task.async_stream がうってつけです。下記ではキャッシュからブクマ対象になるフィードリンクを取り出し、除外処理、校正処理を加えて、ブクマのリクエストを出すという流れを組んでいます。Elixirでは、流れをひとまとめにして視覚的にわかりやすく非同期処理してくことができます。   ex \n\nCachex.keys!(:feed) |> Enum.reject(fn key -> key in [ \"excluded_links\", \"excluded_titles\", \"corrected_links\", \"redirected_links\", \"feed_group\", \"archived_links\" ] end) |> Task.async_stream( fn item_link -> with {:ok, [item_title, feed_tags]} <- Cachex.get(:feed, item_link), :ok <- validate_all(item_link, item_title), corrected_link <- correct_all(item_link), {:ok, payload} <- FormData.create( %{ url: corrected_link, comment: feed_tags |> Enum.map_join(fn tag -> \"[#{tag}]\" end), rks: System.get_env(\"HATENA_BOOKMARK_RKS\"), private: 0, keep_original_url: 1, with_status_op: 1, from: \"inplace\", post_twitter: 0, post_evernote: 0 }, :url_encoded, get: false ) do do_add_entries_to_hb(payload) Logger.info(\"add entry: #{item_link}\") end archive_link(item_link) end, timeout: 15_000 ) |> Stream.run()     > WRAPUPWRAPUP \n\nElixirの非同期処理を使うことではてなブックマークの運用がとても快適になりました。はてなブックマークとの今後の付き合い方は下記のように考えています。 \n\n- 手動でブクマ: 気になった記事があるごとに\n- ブクマの確認: 気になるタグごとにまとめて確認 \n\nブクマの確認については、例えば、CIでデプロイしている間に最近のGitHubの動向を確認したい場合は「nabinno/github」をみる、という感じの運用です。 \n\n融通が利かない点で途中運用が難しくなる気もしますが、しばらく回してみます。"},"name":"[2019-01-01]Elixirではてなブックマーク","tags":["elixir","hatena-bookmark"],"childPublishedDate":{"published_on":"2019-01-01T00:00:00.000Z","published_on_unix":1546300800}}},{"node":{"number":61,"relative_category":"blog/health","fields":{"title":"ElixirとRaspberry PiでPM2.5などの環境データを定点観察し、目・喉の痛みに備える","excerpt":"皆さんは体調管理どうされていますか。一度痛い目に遭うと日常の細かい差異が気になってきて、そこをどうにか解決したいというのが人情です。今回は自分の咽頭痛の解消のため一つ実験をしてみました。   > PROBLEMPROBLEM \n\n- 以前からオフィスに行くと目や喉が痛くなることがあったので、自分の体調なのか環境なのか原因を切り分けるために汚染計測器「Dienmern DM106A」を購入 ただ、DM106Aの計測はその時その時のスナップショットなので傾向を読み解きづらい、また、都度実施する手間がかかる \n- ただ、DM106Aの計測はその時その時のスナップショットなので傾向を読み解きづらい、また、都度実施する手間がかかる   > SOLUTIONSOLUTION \n\nというわけで、DM106AのセンサーデータをRaspberry Piで定期取得することにしました。設置方法の詳細はGitHubレポジトリを参照ください。下記、実装概要になります。   > 電子部品の構成電子部品の構成    item description     Raspberry Pi 3 Model B+    Aosong DHT11 気温・湿度センサー、GPIO   Nova SDS021 PM2.5・PM10センサー、UART   ams CCS811 TVOC・CO2eセンサー、I2C    \n\nまず、電子工作は素人ゆえどのセンサーを買えばいいか分からなかったのでDM106Aを分解して各センサーの型番を調べました。DHT011、SDS021はDM106Aとおなじセンサー、HCHOセンサーは信頼性があり手ごろなのがうまく見つけられませんでした。TVOCセンサーはAdafruitが推しているCCS811を採用しました。   > コードの構成コードの構成    item description     AirElixir.Application アプリケーション管理   AirElixir.GoogleSpreadsheets センサーデータ記録   AirElixirSensor.Publisher センサーデータ発行・送信   AirElixirSensor.Subscriber センサーデータ購読・受信    \n\n次に、基本構成はGrovePiを参考にしました。発行処理はElixirでうまくいかないケースがあったのでまずはPython/ErlPortで行いました。後々Elixirに移行できるようにマクロにしました。   > 5日ほど稼働してわかったこと・見立て、今後の課題5日ほど稼働してわかったこと・見立て、今後の課題  \n\n最後に、分かったこと、見立てですが、3点あります。2番目に関しては予想通りだったのですが、1番目、3番目に関しては意外であり、疑り深い私としては特に空気清浄機がきちんと機能していたことに驚きました。 \n\n1. オフィスの空気清浄機「Hitachi EP-LVG110」はPMをきちんとフィルターしていた ただし、空気清浄機はTVOCには効果がなく、これはTroia氏や加藤氏・苅部氏の考察でも言及されている \n2. ただし、空気清浄機はTVOCには効果がなく、これはTroia氏や加藤氏・苅部氏の考察でも言及されている\n3. 人の入りが多い時間帯に空気（TVOCやCO2e）が汚れる 人が「出る」時よりも「入る」際に濃度があがるのは、外のVOCが服などに付着しているためと推察 \n4. 人が「出る」時よりも「入る」際に濃度があがるのは、外のVOCが服などに付着しているためと推察\n5. TVOCやCO2eはPMのうごきに連動している（かも） チャート上はEP-LVG110がPM除去しているためわからないが、日本気象協会のPM2.5分布予測に照らしてみるとPM濃度が高い日にTVOC濃度があがっていた TODO: PMがVOCを運んでいる可能性があるので、IQAirなどのAPIから周辺環境のPMデータも取得したいところ \n6. チャート上はEP-LVG110がPM除去しているためわからないが、日本気象協会のPM2.5分布予測に照らしてみるとPM濃度が高い日にTVOC濃度があがっていた TODO: PMがVOCを運んでいる可能性があるので、IQAirなどのAPIから周辺環境のPMデータも取得したいところ \n7. TODO: PMがVOCを運んでいる可能性があるので、IQAirなどのAPIから周辺環境のPMデータも取得したいところ \n\n課題としてはその性質からして仕方ないのですがTVOCの変動が大きすぎて解読を難しかったです。計測方法等を再度見直す必要がありそうです。 \n\n- TVOCの変動が大きすぎる ポーリング・出力を20分ごとからポーリング3秒ごと・出力20分ごとに変更した、出力データは20分の平均 \n- ポーリング・出力を20分ごとからポーリング3秒ごと・出力20分ごとに変更した、出力データは20分の平均\n- TVOCのスパイクを抑えたい TODO: ファイトレメディエーションによる効果を見ていきたいところ \n- TODO: ファイトレメディエーションによる効果を見ていきたいところ   > WRAPUPWRAPUP \n\n今回の実験はこれが言いたかっただけという指摘をされるとぐうの音も出ませんが、はっきり言わせてください。そう、Elixirは健康管理に向いています。   txt \n\n「なんか体調がすぐれないなあ...」 「Elixirちょうだい!」   \n\nという感じです、はい。"},"name":"[2018-12-22]ElixirとRaspberry PiでPM2.5などの環境データを定点観察し、目・喉の痛みに備える","tags":["elixir","raspberry-pi","particulates","physiology"],"childPublishedDate":{"published_on":"2018-12-22T00:00:00.000Z","published_on_unix":1545436800}}},{"node":{"number":60,"relative_category":"blog/backend","fields":{"title":"連載 Rails2Phoenix 2 認証機能を実装する","excerpt":"連載「Rails2Phoenix」になります、前回は「UmbrellaプロジェクトをHerokuにデプロイする 」でした。今回は前回課題としてあがった認証機能の実装を試みたいと思います。   > PROBLEMPROBLEM \n\n- サービスについて 拡張にともない技術スタックがふえるのを抑えたい スケーラビリティのためのコストを抑えたい パフォーマンスをあげたい \n- 拡張にともない技術スタックがふえるのを抑えたい\n- スケーラビリティのためのコストを抑えたい\n- パフォーマンスをあげたい   > SOLUTIONSOLUTION \n\nというわけで、現在つかっているRailsをPhoenixに変更することにしました。方針は以下の通りで、今回はRails/Deviseの認証機能をPhoenixで実装する流れを取り上げます。 \n\n方針 \n\n- Railsから徐々にPhoenixに移行できるように いままでとおなじPaaS（Heroku） いままでとおなじレポジトリ ブランチ戦略は phoenix/base をベースに 気軽に参照できるようにRails関連ファイルは可能な限りのこしておく いままでとおなじDB 移行完了までDBマイグレーションをしない \n- いままでとおなじPaaS（Heroku）\n- いままでとおなじレポジトリ ブランチ戦略は phoenix/base をベースに 気軽に参照できるようにRails関連ファイルは可能な限りのこしておく \n- ブランチ戦略は phoenix/base をベースに\n- 気軽に参照できるようにRails関連ファイルは可能な限りのこしておく\n- いままでとおなじDB 移行完了までDBマイグレーションをしない \n- 移行完了までDBマイグレーションをしない\n- Phoenixは今後の拡張性をかんがえてUmbrellaプロジェクトで   > Guardianを実装するGuardianを実装する \n\nまず、参考にしたのはBlackodeのguardian_authです。ただ、Guardianのバージョンがふるいので1.0へのマイグレーション記事をもとにアレンジしてあります。認証に関係しそうな構成は下記の通り。 \n\nロジック \n\n- MyApp.Account\n- MyApp.Account.Registration\n- MyApp.Account.User\n- MyApp.Auth.Guardian\n- MyApp.Auth.ErrorHandler\n- MyApp.Auth.Pipeline\n- MyApp.Auth.AfterPipeline\n- MyApp.Auth.Session \n\nコントローラ \n\n- MyAppWeb.RegistrationController\n- MyAppWeb.SessionController   > シリアライザとエラーハンドラの設定シリアライザとエラーハンドラの設定 \n\nGuardian1.0から直接ではなくモジュールを介して参照するようになりました。下記のように各モジュールを用意してコンフィグに割り当てます。   elixir \n\n# apps/my_app/lib/my_app/auth/guardian.ex defmodule MyApp.Auth.Guardian do use Guardian, otp_app: :my_app alias MyApp.Account def subject_for_token(resource, _claims), do: {:ok, to_string(resource.id)} def subject_for_token(_, _), do: {:error, :reason_for_error} def resource_from_claims(claims), do: {:ok, Account.get_user!(claims[\"sub\"])} def resource_from_claims(_claims), do: {:error, :reason_for_error} end     elixir \n\n# apps/my_app/lib/my_app/auth/error_handler.ex defmodule MyApp.Auth.ErrorHandler do import Plug.Conn def auth_error(conn, {type, _reason}, _opts) do body = Poison.encode!(%{message: to_string(type)}) send_resp(conn, 401, body) end end     elixir \n\n# apps/my_app/config/config.exs config :my_app, MyApp.Auth.Guardian, issuer: \"MyApp\", ttl: {30, :days}, allowed_drift: 2000, # optionals allowed_algos: [\"HS512\"], verify_module: MyApp.Auth.Guardian.JWT, verify_issuer: true, secret_key: System.get_env(\"GUARDIAN_SECRET\") || \"secret_key\"     > ルーターの設定ルーターの設定 \n\n認証のパイプラインは、認証中と認証後のものを用意しコンフィグとルーターに割り当てます。 \n\nルータースコープ内のパイプラインくみあわせについて、ここでは未ログインスコープには認証前・認証中パイプライン、ログイン済スコープには認証前・認証中・認証後パイプラインを適用しています。こうすることでどのスコープにも認証リソースをロードすることができ、かつ、認証も担保することができるようになります。具体的にいうと、ルート / などの同一URLで未ログインスコープとログイン済スコープの切り替えができるようになります。   elixir \n\n# apps/my_app/lib/my_app/auth/pipeline.ex defmodule MyApp.Auth.Pipeline do use Guardian.Plug.Pipeline, otp_app: :my_app plug(Guardian.Plug.VerifySession, claims: %{\"typ\" => \"access\"}) plug(Guardian.Plug.VerifyHeader, claims: %{\"typ\" => \"access\"}) plug(Guardian.Plug.LoadResource, allow_blank: true) end     elixir \n\n# apps/my_app/lib/my_app/auth/after_pipeline.ex defmodule MyApp.Auth.AfterPipeline do use Guardian.Plug.Pipeline, otp_app: :my_app plug(Guardian.Plug.EnsureAuthenticated) end     elixir \n\n# apps/my_app/lib/my_app_web/router.ex defmodule MyAppWeb.Router do use MyAppWeb, :router pipeline :browser do plug(:accepts, [\"html\"]) plug(:fetch_session) plug(:fetch_flash) plug(:protect_from_forgery) plug(:put_secure_browser_headers) end pipeline :browser_auth do plug(MyApp.Auth.Pipeline) end pipeline :browser_auth_after do plug(MyApp.Auth.AfterPipeline) end scope \"/\", MyAppWeb do pipe_through([:browser, :browser_auth]) post(\"/registration\", RegistrationController, :create) get(\"/login\", SessionController, :new) post(\"/login\", SessionController, :create) get(\"/logout\", SessionController, :delete) end scope \"/\", MyAppWeb do pipe_through([:browser, :browser_auth, :browser_auth_after]) get(\"/edit\", RegistrationController, :edit) put(\"/edit\", RegistrationController, :update) get(\"/users\", UserController, :index) resources \"/\", UserController, only: [:show, :delete], param: \"username\" end end     elixir \n\n# apps/my_app/config/config.exs config :MyApp, MyApp.Auth.Pipeline, module: MyApp.Auth.Guardian, error_handler: MyApp.Auth.ErrorHandler config :MyApp, MyApp.Auth.AferPipeline, module: MyApp.Auth.Guardian, error_handler: MyApp.Auth.ErrorHandler     > 登録登録 \n\n登録は登録用のロジック（ユーザーモデルと登録サービス）とコントローラを用意します。 \n\nこのあたりはDevise/Railsとあまり変わりません。他のアクション「新規パスワード発行」「メールアドレス確認」等も同様の構成をとろうと思っています。   elixir \n\n# apps/my_app/lib/my_app_web/controller/registration_controller.ex def create(conn, user_params) do changeset = User.registration_changeset(%User{}, user_params) case Registration.create(changeset, Repo) do {:ok, user} -> conn |> MyApp.Auth.login(user) |> put_flash(:info, \"Your account was created successfully\") |> redirect(to: page_path(conn, :home)) {:error, changeset} -> conn |> put_flash(:error, \"Unable to create account: Try again\") |> render(MyAppWeb.PageView, \"home.html\", changeset: changeset) end end     elixir \n\n# apps/my_app/lib/my_app/auth/auth.ex def login(conn, %User{} = user) do conn |> Guardian.Plug.sign_in(user) |> assign(:current_user, user) end     elixir \n\n# apps/my_app/lib/my_app/account/registration.ex def create(changeset, repo) do changeset |> repo.insert() end     > ログイン・ログアウトログイン・ログアウト \n\nログイン・ログアウトはセッション用のサービスとコントローラで実装します。   elixir \n\n# apps/my_app/lib/my_app_web/controller/session_controller.ex @doc \"Logged in [POST /login]\" def create(conn, %{\"email\" => email, \"password\" => password}) do case Session.authenticate_user(email, password) do {:ok, user} -> conn |> Session.login(user) |> put_flash(:info, \"Logged in successfully\") |> redirect(to: page_path(conn, :home)) {:error, _reason} -> conn |> put_flash(:error, \"Wrong username/password\") |> render(\"new.html\") end end @doc \"Logged out [DELETE /logout]\" def delete(conn, _params) do conn |> Session.logout() |> put_flash(:info, \"Logged out successfully.\") |> redirect(to: \"/\") end     elixir \n\n# apps/my_app/lib/my_app/auth/session.ex defmodule MyApp.Auth.Session do import Ecto.Query import Plug.Conn import Comeonin.Bcrypt, only: [checkpw: 2, dummy_checkpw: 0] alias MyApp.Repo alias MyApp.Auth.Guardian alias MyApp.Account.User def login(conn, %User{} = user) do conn |> Guardian.Plug.sign_in(user) |> assign(:current_user, user) end def logout(conn), do: Guardian.Plug.sign_out(conn) def authenticate_user(email, given_password) do query = Ecto.Query.from(u in User, where: u.email == ^email) Repo.one(query) |> check_password(given_password) end def current_user(conn), do: Guardian.Plug.current_resource(conn, []) def logged_in?(conn), do: Guardian.Plug.authenticated?(conn, []) defp check_password(nil, _), do: {:error, \"Incorrect username or password\"} defp check_password(user, given_password) do case Comeonin.Bcrypt.checkpw(given_password, user.encrypted_password) do true -> {:ok, user} false -> {:error, \"Incorrect email or password\"} end end end   \n\nDevise/Railsのビューヘルパーはビューマクロで適用します。   elixir \n\n# apps/my_app/lib/my_app_web.ex def view do quote do # .. import Okuribi.Auth.Session, only: [current_user: 1, logged_in?: 1] end end   \n\nあるいは、put_assigns関数をはやしてコントローラマクロに適用します。   elixir \n\n# apps/my_app/lib/my_app/auth/session.ex def put_assigns(%{private: %{phoenix_action: action}} = conn, settings) do current_resource = Guardian.Plug.current_resource(conn) settings = if current_resource, do: settings[:sign_in][action] || [], else: settings[:sign_out][action] || [] conn |> assign(:current_user, current_resource) |> assign(:page_title, settings[:page_title]) |> assign(:page_description, settings[:page_description]) end     elixir \n\n# apps/my_app/lib/my_app_web.ex def controller do quote do # .. import Okuribi.Auth, only: [put_assigns: 2] end end   \n\nassignsひとつでアクセスできるので、下記のようにコントローラでまとめて指定することでRailsのActionView::Helpers::CaptureHelper#provideの代わりに使えます。   elixir \n\n# apps/my_app/lib/my_app_web/controller/*_controller.ex @page %{ sign_in: %{ new: %{ page_title: dgettext(\"views\", \"pages.home.signed_in.page_title\"), page_description: \"\" } }, sign_out: %{ new: %{ page_title: dgettext(\"views\", \"pages.home.signed_out.page_title\"), page_description: \"\" } } } plug(:put_assigns, @page when action in [:home])     > その他その他 \n\nRailsのビューをPhoenixのテンプレートに移植するには下記の変換を地道に行っていきます。 \n\n- Rails ActionView::Helpers::FormHelper#form_for(record, options={}, &block) ActionView::Helpers::FormHelper#text_field(object_name, method, options={}) ActionView::Helpers::FormHelper#file_field(object_name, method, options={}) ActionView::Helpers::FormHelper#hidden_field(object_name, method, options={}) ActionView::Helpers::FormHelper#password_field(object_name, method, options={}) ActionView::Helpers::FormHelper#radio_button(object_name, method, tag_value, options={}) ActionView::Helpers::FormBuilder#submit(value=nil, options={}) ActionView::Helpers::TranslationHelper#t \n- ActionView::Helpers::FormHelper#form_for(record, options={}, &block)\n- ActionView::Helpers::FormHelper#text_field(object_name, method, options={})\n- ActionView::Helpers::FormHelper#file_field(object_name, method, options={})\n- ActionView::Helpers::FormHelper#hidden_field(object_name, method, options={})\n- ActionView::Helpers::FormHelper#password_field(object_name, method, options={})\n- ActionView::Helpers::FormHelper#radio_button(object_name, method, tag_value, options={})\n- ActionView::Helpers::FormBuilder#submit(value=nil, options={})\n- ActionView::Helpers::TranslationHelper#t\n- Phoenix Phoenix.HTML.Form.form_for(form_data, action, options \\\\ [], fun) Phoenix.HTML.Form.text_input(form, field, opts \\\\ []) Phoenix.HTML.Form.file_input(form, field, opts \\\\ []) Phoenix.HTML.Form.hidden_input(form, field, opts \\\\ []) Phoenix.HTML.Form.password_input(form, field, opts \\\\ []) Phoenix.HTML.Form.radio_button(form, field, value, opts \\\\ []) Phoenix.HTML.Form.submit(opts, opts \\\\ []) Gettext.dgettext(backend, domain, msgid, bindings \\\\ %{}) \n- Phoenix.HTML.Form.form_for(form_data, action, options \\\\ [], fun)\n- Phoenix.HTML.Form.text_input(form, field, opts \\\\ [])\n- Phoenix.HTML.Form.file_input(form, field, opts \\\\ [])\n- Phoenix.HTML.Form.hidden_input(form, field, opts \\\\ [])\n- Phoenix.HTML.Form.password_input(form, field, opts \\\\ [])\n- Phoenix.HTML.Form.radio_button(form, field, value, opts \\\\ [])\n- Phoenix.HTML.Form.submit(opts, opts \\\\ [])\n- Gettext.dgettext(backend, domain, msgid, bindings \\\\ %{})   > WRAPUPWRAPUP \n\n前回もそうですが、コードのマイグレーションはまあ地味な作業ですよね。とまれ、認証機能を実装できたので良しとしましょう。"},"name":"[2018-05-20]連載 Rails2Phoenix 2 認証機能を実装する","tags":["phoenix-framework","elixir","ruby-on-rails","ruby","wercker","heroku","authentication","guardian"],"childPublishedDate":{"published_on":"2018-05-20T00:00:00.000Z","published_on_unix":1526774400}}},{"node":{"number":59,"relative_category":"blog/backend","fields":{"title":"連載 Rails2Phoenix 1 UmbrellaプロジェクトをHerokuにデプロイする","excerpt":"使い慣れたRailsのプロジェクトを拡張したいのですが、その都度技術スタックを増やす必要があり、この点をどうにかクリアしたいと考えています。連載「Rails2Phoenix」になります、今回はフレームワークをElixir製のPhoenix Frameworkへと変更を試みました。   > PROBLEMPROBLEM \n\n- サービスについて 拡張にともない技術スタックがふえるのを抑えたい スケーラビリティのためのコストを抑えたい パフォーマンスをあげたい \n- 拡張にともない技術スタックがふえるのを抑えたい\n- スケーラビリティのためのコストを抑えたい\n- パフォーマンスをあげたい   > SOLUTIONSOLUTION \n\nというわけで、現在つかっているRailsをPhoenixに変更することにしました。方針は以下の通りで、今回はRailsから移行中のPhoenix UmbrellaプロジェクトをHerokuにデプロイする流れをとりあげます。 \n\n方針 \n\n- Railsから徐々にPhoenixに移行できるように いままでとおなじPaaS（Heroku） いままでとおなじレポジトリ ブランチ戦略は phoenix/base をベースに 気軽に参照できるようにRails関連ファイルは可能な限りのこしておく いままでとおなじDB 移行完了までDBマイグレーションをしない \n- いままでとおなじPaaS（Heroku）\n- いままでとおなじレポジトリ ブランチ戦略は phoenix/base をベースに 気軽に参照できるようにRails関連ファイルは可能な限りのこしておく \n- ブランチ戦略は phoenix/base をベースに\n- 気軽に参照できるようにRails関連ファイルは可能な限りのこしておく\n- いままでとおなじDB 移行完了までDBマイグレーションをしない \n- 移行完了までDBマイグレーションをしない\n- Phoenixは今後の拡張性をかんがえてUmbrellaプロジェクトで   > HerokuへのデプロイのながれHerokuへのデプロイのながれ \n\n基本的にドキュメント通り。   > Phoenixアプリケーションを作成Phoenixアプリケーションを作成 \n\nまず、こんな感じでPhoenixの骨組みをつくります。Phoenix関連のファイル apps/, deps/, config/config.exs, mix.exs, mix.lock が追加されます。   sh \n\n> cd rails_project > mix new . --umbrella > (cd ./apps && mix phx.new phoenix_app)   \n\n次に、既存のRailsでつくられたスキーマをPhoenixに移植します。Ripperをつかうとはかどります。ちなみに手動でスキーマをつくりたい場合は、CLI mix phx.gen.schema --no-migration Blog.Post blog_posts title:string で作成します。   rb \n\n# lib/tasks/convert_to_phoenix.rake # こちらはスキーマ移植タスクをPhoenix1.3用に改めたもの require 'ripper' require 'erb' require 'fileutils' namespace :db do namespace :schema do desc 'Convert schema from Rails to Phoenix' task convert_to_phoenix: :environment do ConvertSchemaForPhoenixService.call end end end class ConvertSchemaForPhoenixService class << self def call FileUtils.mkdir_p(File.join('tmp', 'models')) extract_activerecord_define_block( Ripper.sexp( Rails.root .join('db', 'schema.rb') .read ) ).select(&method(:create_table_block?)) .map(&method(:configuration)) .each do |conf| project_name = 'PhoenixApp' table_name = conf[:table_name] table_columns = conf[:table_columns].reject(&method(:reject_condition)) .map do |c| case c[:column_type] when 'text' then c[:column_type] = ':string' when 'datetime' then c[:column_type] = ':naive_datetime' when 'inet' then c[:column_type] = 'EctoNetwork.INET' else c[:column_type] = \":#{c[:column_type]}\" end c end File.write( File.join('tmp', 'models', \"#{conf[:table_name].singularize}.ex\"), template.result(binding) ) end end private def extract_activerecord_define_block(sexp) sexp.dig(1, 0, 2, 2) end def create_table_block?(activerecord_define_block_element_sexp) activerecord_define_block_element_sexp.dig(1, 1, 1) == 'create_table' rescue false end def extract_table_name(create_table_block_sexp) create_table_block_sexp.dig(1, 2, 1, 0, 1, 1, 1) end def extract_table_columns(create_table_block_sexp) create_table_block_sexp.dig(2, 2) end def extract_column_type(table_column_sexp) table_column_sexp.dig(3, 1) end def extract_column_name(table_column_sexp) # Return value of `t.index` is array like ['user_id']. if table_column_sexp.dig(4, 1, 0, 0) == :array return table_column_sexp.dig(4, 1, 0, 1).map { |e| e.dig(1, 1, 1) } end table_column_sexp.dig(4, 1, 0, 1, 1, 1) end def extract_column_option(table_column_sexp) # If is not `column_option`, then `table_column_sexp.dig(4, 1, 1, # 1)` method return nil. Set blank array ([]) for avoiding nil. table_column_sexp.dig(4, 1, 1, 1) || [] end def extract_option_key(column_option_sexp) # Remove colon for avoiding `null:`. column_option_sexp.dig(1, 1).gsub(/:\\z/, '') end def extract_option_value(column_option_sexp) if column_option_sexp.dig(2, 0) == :array return Array(column_option_sexp.dig(2, 1)).map { |e| e.dig(1, 1, 1) } end element = column_option_sexp.dig(2, 1) if element.class != Array return element end case element.dig(0) when :kw then element.dig(1) when :string_content then element.dig(1, 1) || '' end end def template ERB.new(<<'__EOD__', nil, '-') defmodule <%= project_name %>.<%= table_name.classify %> do use Ecto.Schema import Ecto.Changeset alias <%= project_name %>.<%= table_name.classify %> schema \"<%= table_name %>\" do<% table_columns.each do |c| %> field :<%= c[:column_name] -%>, <%= c[:column_type] -%> <% end %> timestamps inserted_at: :created_at end @doc false def changeset(%<%= table_name.classify %>{} = <%= table_name.singularize %>, attrs) do <%= table_name.singularize %> |> cast(attrs, [<%= table_columns.map { |c| \":\" << c[:column_name] }.join(\", \") -%>]) # |> validate_required([<%= table_columns.map { |c| \":\" << c[:column_name] }.join(\", \") -%>]) end end __EOD__ end def configuration(table) { table_name: extract_table_name(table), table_columns: extract_table_columns(table).map do |c| { column_name: extract_column_name(c), column_type: extract_column_type(c), column_option: Hash[extract_column_option(c).map { |o| [extract_option_key(o), extract_option_value(o)] }] } end } end def reject_condition(column) column[:column_name] =~ /\\A(created|updated)_at\\z/ || column[:column_type] == 'index' end end end     sh \n\n> rails db:schema:convert_to_phoenix   \n\n最後に、既存DBへはこんな感じで接続します。   config \n\n# rails_project/apps/phoenix_app/config/dev.exs config :phoenix_app, PhoenixApp.Repo, adapter: Ecto.Adapters.Postgres, url: System.get_env(\"DATABASE_URL\"), pool_size: 10, ssl: true     sh \n\n> (cd ./apps/phoenix_app/assets && npm install) > mix deps.get > mix phx.server     > デプロイのパイプラインを追加デプロイのパイプラインを追加 \n\nさて、既存のCI（Wercker）も更新しましょう。今回はPhoenix関連ブランチが更新された場合にのみ、関連パイプラインを走らせるように下記のように変更しました。 \n\nBEFORE \n\n- build (all branch) deploy.prod (master branch) \n- deploy.prod (master branch) \n\nAFTER \n\n- build (all branch) deploy.prod (master branch) deploy.phoenix.prod (phoenix/base branch) \n- deploy.prod (master branch)\n- deploy.phoenix.prod (phoenix/base branch)   yaml \n\n# wercker.yml deploy-phoenix-prod-heroku: steps: - add-ssh-key: host: github.com keyname: GITHUB - add-to-known_hosts: hostname: github.com fingerprint: 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48 - heroku-deploy: key: $HEROKU_KEY user: $HEROKU_USER app-name: $HEROKU_APP_NAME install-toolbelt: true after-steps: - wantedly/pretty-slack-notify: webhook_url: ${SLACK_WEBHOOK_URL} channel: general     > Herokuアプリケーションを作成Herokuアプリケーションを作成 \n\n基本ドキュメントの説明通りです。Phoenix Umbrellaプロジェクトの注意点としては、ディレクトリの差異くらいでそれ以外は同じです。つまり、これ rails_project/config/prod.exs をこう rails_project/apps/phoenix_app/config/prod.exs 変更します。 \n\n1. Herokuアプリにビルドパックを適用   sh \n\n> heroku create --buildpack https://github.com/HashNuke/heroku-buildpack-elixir.git > heroku buildpacks:add https://github.com/gjaldon/heroku-buildpack-phoenix-static.git   \n\n2. 起動設定を準備   config \n\n# rails_project/elixir_buildpack.config erlang_version=19.1 elixir_version=1.4.2 always_rebuild=false pre_compile=\"pwd\" post_compile=\"pwd\" runtime_path=/app config_vars_to_export=(DATABASE_URL) config_vars_to_export=(DATABASE_POOL_SIZE)     config \n\n# rails_project/phoenix_static_buildpack.config phoenix_relative_path=apps/phoenix_app     config \n\n# rails_project/Procfile web: MIX_ENV=prod mix phx.server   \n\n3. 環境変数を適用 \n\nデータベース関連。   config \n\n# rails_project/apps/phoenix_app/config/prod.exs config :phoenix_app, PhoenixApp.Repo, adapter: Ecto.Adapters.Postgres, url: System.get_env(\"DATABASE_URL\"), pool_size: String.to_integer(System.get_env(\"DATABASE_POOL_SIZE\") || 10), ssl: true     sh \n\nheroku config:set DATABASE_URL=foo heroku config:set DATABASE_POOL_SIZE=bar   \n\nクレデンシャル関連。   sh \n\n> heroku config:set HEROKU_API_KEY=$(heroku auth:token) > heroku config:set SECRET_KEY_BASE=$(mix phx.gen.secret)     > WRAPUPWRAPUP \n\n大枠は想定通りすんなり進めることが出来ましたが、課題もいくつか出てきました。まずは認証機能。こちらは次回のテーマで取り上げようと思いますが、Railsの認証ライブラリほど充実していないので自前でいくつか用意する必要がありそうです。次にビジネスロジック。これは元のRailsの実装が悪かったので致し方ないのですが、移植するのに時間がかかりそうです。先にRails側を整理してから進めた方が良いかもしれません。"},"name":"[2018-01-08]連載 Rails2Phoenix 1 UmbrellaプロジェクトをHerokuにデプロイする","tags":["phoenix-framework","elixir","ruby-on-rails","ruby","wercker","heroku"],"childPublishedDate":{"published_on":"2018-01-08T00:00:00.000Z","published_on_unix":1515369600}}},{"node":{"number":58,"relative_category":"blog/backend","fields":{"title":"WSL（Windows Subsystem for Linux）でDockerをつかったWebアプリケーション開発をおこなう際の注意点","excerpt":"これは無宗教ななびの  が書くDocker Advent Calendar 2017用記事です。前日はinductorさんの「Docker Meetupの中身まとめ」でした  （写真はクリスマスを日本にひろめた明治屋 ）   > PROBLEMPROBLEM \n\n- macOSとWindowsでWebアプリケーション開発をする際に 環境が異なって管理しづらい それならDockerで と思ったが、macOSはBashでWindowsはPowerShellなのか せめてPowerShellではなくBash... となると、いまWindowsでLinux環境をつかうならWSLか ただ、実際どこまで開発ができるかわからんしなあ \n- 環境が異なって管理しづらい それならDockerで と思ったが、macOSはBashでWindowsはPowerShellなのか せめてPowerShellではなくBash... となると、いまWindowsでLinux環境をつかうならWSLか ただ、実際どこまで開発ができるかわからんしなあ \n- それならDockerで と思ったが、macOSはBashでWindowsはPowerShellなのか せめてPowerShellではなくBash... となると、いまWindowsでLinux環境をつかうならWSLか ただ、実際どこまで開発ができるかわからんしなあ \n- と思ったが、macOSはBashでWindowsはPowerShellなのか せめてPowerShellではなくBash... となると、いまWindowsでLinux環境をつかうならWSLか ただ、実際どこまで開発ができるかわからんしなあ \n- せめてPowerShellではなくBash... となると、いまWindowsでLinux環境をつかうならWSLか ただ、実際どこまで開発ができるかわからんしなあ \n- となると、いまWindowsでLinux環境をつかうならWSLか ただ、実際どこまで開発ができるかわからんしなあ \n- ただ、実際どこまで開発ができるかわからんしなあ   > SOLUTIONSOLUTION \n\nというわけで、この記事ではmacOSとWindowsによるWebアプリケーション開発について、どこまで共有できるか書いていきます。 \n\n前提条件として、当該WebアプリケーションはmacOSというより、Bash/Ubuntu14.04~のLinux環境で動くことを想定しています。macOSはHFS+やAPFSのUnicode正規化以外はおおよそLinux環境に適応できているという判断によります。 \n\n要は、WSLでDockerをつかったWebアプリケーション開発ができるかどうかという点に焦点をしぼります。   > 対象環境対象環境 \n\n- Windows 10 Pro 1709 16299.64 Hyper-V 10.0.16299.15 Docker for Windows 17.09.0-ce-win33 Ubuntu 16.04 (Linux 4.4.0-43-Microsoft) Docker Client 1.12.6 \n- Hyper-V 10.0.16299.15\n- Docker for Windows 17.09.0-ce-win33\n- Ubuntu 16.04 (Linux 4.4.0-43-Microsoft) Docker Client 1.12.6 \n- Docker Client 1.12.6   > Windowsの開発環境を構築するWindowsの開発環境を構築する \n\nまず、Windowsの開発環境の構築ですが、既知の情報をふまえつつTIPSを順次紹介します。   > WSLのインストールWSLのインストール \n\n- Windows Subsystem for Linuxをインストールしてみよう！ \n\nWSLのパッケージ管理は下記3つを押さえておけば問題ないでしょう。 \n\n1. apt WSLではデーモンがつかえないのでDockerクライアントを入れましょう、Dockerデーモンの詳細は後ほど言及します \n2. WSLではデーモンがつかえないのでDockerクライアントを入れましょう、Dockerデーモンの詳細は後ほど言及します\n3. anyenv プログラミング言語をバージョンごとにわけて使いたい場合はこちらをつかいましょう exenvがビルドで失敗するためElixirインストールできないほかは、各言語問題なくビルドできます \n4. プログラミング言語をバージョンごとにわけて使いたい場合はこちらをつかいましょう\n5. exenvがビルドで失敗するためElixirインストールできないほかは、各言語問題なくビルドできます\n6. nix ElixirやHaskellのようにanyenvでインストールできない、あるいは、扱われいないパッケージはnixをつかいましょう また、aptのバージョンが古すぎるパッケージもnixが最適です \n7. ElixirやHaskellのようにanyenvでインストールできない、あるいは、扱われいないパッケージはnixをつかいましょう\n8. また、aptのバージョンが古すぎるパッケージもnixが最適です   > ターミナルのインストールターミナルのインストール \n\nWSLttyかConEmuをおすすめします。各々の特徴は下記のとおりですが、通常のWebアプリケーション開発であればWSLttyがいいでしょう。 \n\n- WSLtty Pros ConEmuとくらべてファイルの読込速度が速い (VMよりは遅い) EmacsでCtrl-SPC set-mark が機能する 画面サイズの変更が柔軟 Cons PowerShellなどほかのコンソールの呼び出しが面倒 \n- Pros ConEmuとくらべてファイルの読込速度が速い (VMよりは遅い) EmacsでCtrl-SPC set-mark が機能する 画面サイズの変更が柔軟 \n- ConEmuとくらべてファイルの読込速度が速い (VMよりは遅い)\n- EmacsでCtrl-SPC set-mark が機能する\n- 画面サイズの変更が柔軟\n- Cons PowerShellなどほかのコンソールの呼び出しが面倒 \n- PowerShellなどほかのコンソールの呼び出しが面倒\n- ConEmu Pros PowerShellなどほかのコンソールの呼び出しが楽 Cons ファイルの読込速度がおそい EmacsでCtrl-SPC set-mark が機能しない 画面サイズの変更に制限がある \n- Pros PowerShellなどほかのコンソールの呼び出しが楽 \n- PowerShellなどほかのコンソールの呼び出しが楽\n- Cons ファイルの読込速度がおそい EmacsでCtrl-SPC set-mark が機能しない 画面サイズの変更に制限がある \n- ファイルの読込速度がおそい\n- EmacsでCtrl-SPC set-mark が機能しない\n- 画面サイズの変更に制限がある   > WSLttyWSLtty \n\n- mintty/wsltty \n\nWSL用ターミナルとしてのMinttyです。操作はMinttyとかわらず、元Cygwinづかいにはうれしい操作感です。というわけで、いつものごとく起動用ショートカットのターゲットを準備します。WSLは chsh がつかえないのでログイン時につかいたいシェルを指定します。もし、 screen をつかいたい場合は /run/screen ディレクトリを作成してからコマンド指定します。   bat \n\n%LOCALAPPDATA%\\wsltty\\bin\\mintty.exe --wsl -o Locale=C -o Charset=UTF-8 /bin/wslbridge -t /bin/bash -c 'sudo mkdir /run/screen && sudo chmod 775 $_ && sudo chown root:utmp $_ && SHELL=/usr/bin/zsh screen'   ConEmu \n\n- ConEmu - Handy Windows Terminal \n\nWSL上で日本語を表示するため、また、WSLのLinux環境とWindows環境でターミナルをわけるため、ConEmuをつかいましょう。ConEmuをスマートにしたCmderはWSLとの相性がわるい1のでおすすめしません。 \n\nConEmuの設定「Startup-Tasks」では、WSL用にパラメータ、コマンドを下記のように指定しています。   bash \n\n# task parameters /icon \"C:\\Program Files\\WindowsApps\\CanonicalGroupLimited.UbuntuonWindows_1604.2017.922.0_x64__79rhkp1fndgsc\\images\\icon.ico\" # task command bash -c 'sudo mkdir /run/screen && sudo chmod 775 $_ && sudo chown root:utmp $_ && SHELL=/usr/bin/zsh screen' -new_console:d:%USERPROFILE%     > Docker for WindowsのインストールDocker for Windowsのインストール \n\n- Docker For Windows \n\nWSLではDockerデーモンがつかえないのでNTFS (WSLからみるとdrvfs) 側で用意します。インストールはDockerのダウンロードページから手順通りおこないます。 \n\n構成は下記のようになります。  \n\nDockerクライアントからDockerデーモンにつなぐには、セキュリティリスクはありますが、 DOCKER_HOST をつかうのが簡易的です。Docker for WindowsとDockerクライアント、各々設定します。 \n\n1. Docker for WindowsよりDockerデーモンを「Expose daemon on tcp://localhost:2375 without TLS」として設定\n2. WSL上のDockerクライアントに DOCKER_HOST=tcp://0.0.0.0:2375 を設定 \n\nWSLには下記のようなaliasを用意しておくといいでしょう。   bash \n\nexport DOCKER_HOST=tcp://0.0.0.0:2375 alias docker=\"DOCKER_HOST=${DOCKER_HOST} docker\" alias docker-compose=\"docker-compose -H ${DOCKER_HOST}\"     > さて、WSLからDocker for Windowsはどの程度つかえるのかさて、WSLからDocker for Windowsはどの程度つかえるのか \n\nWSLがlxfs、Docker for WindowsがNTFS (drvfs) 上で動いていることからわかるように、ファイルシステム上の制約があります。具体的には下記4点です。 \n\n1. Docker for WindowsはNTFS (WSLからみるとdrvfs /mnt/) 上のファイルしかVolumeマウントできません\n2. WSLはLinux形式のパスしか扱えません、C:\\Dev のようなドライブ名にコロンをつけたURIスキーマは扱えません\n3. WSL上のdocker-composeはパスを絶対参照しかできません、相対参照できません2 \n4. WSL上のnpm/yarnによるJSビルドをNTFS (drvfs)上でおこなうとエラーになります3  \n\nひとつずつ解決方法を見ていきましょう。   > 1. Docker for WindowsはNTFS (WSLからみるとdrvfs /mnt/) 上のファイルしかVolumeマウントできません1. Docker for WindowsはNTFS (WSLからみるとdrvfs /mnt/) 上のファイルしかVolumeマウントできません \n\n開発用ディレクトリをNTFS上につくりましょう。普段からWindowsで開発されている方はCドライブ直下につくっているとおもいます。   > 2. WSLはLinux形式のパスしか扱えません、ドライブ名にコロンをつけたURIスキーマは扱えません2. WSLはLinux形式のパスしか扱えません、ドライブ名にコロンをつけたURIスキーマは扱えません \n\nNTFSからのパス参照とWSLからのパス参照を共通化するために、WSLに各ドライブのシンボリックリンクをはりましょう。   bash \n\n$ ln -s /mnt/c /C # 開発ディレクトリはこんな感じで参照できます $ ls -al /C/Dev total 0 drwxrwxrwx 0 root root 512 Oct 27 00:54 . drwxrwxrwx 0 root root 512 Dec 8 07:49 .. drwxrwxrwx 0 root root 512 Jul 14 03:06 app-test-1 drwxrwxrwx 0 root root 512 Oct 25 00:38 app-test-2     > 3. WSL上のdocker-composeはパスを絶対参照しかできません、相対参照できません3. WSL上のdocker-composeはパスを絶対参照しかできません、相対参照できません \n\n各OS間での違いを吸収するため、プロジェクトに PRJ_ROOT のような環境変数を用意しましょう。   yaml \n\nservices: app-front: image: 561534604247952616898.dkr.ecr.amazonaws.com/test/front volumes: - ${PRJ_ROOT}/front:/var/www/front     > 4. WSL上のnpm/yarnによるJSビルドをNTFS (drvfs)上でおこなうとエラーになります4. WSL上のnpm/yarnによるJSビルドをNTFS (drvfs)上でおこなうとエラーになります \n\nこちらはFall Creators Updateのデグレですが、更新プログラム (KB4051963) でこの問題が修正されました  \n\nもし更新プログラムが適用できない場合は、シンボリックリンクでNTFS上のnode_modulesディレクトリをWSLに移しましょう。   bash \n\n$ mkdir /home/foo/tmp/app-test-1/front/node_modules $ ln -s /home/foo/tmp/app-test-1/front/node_modules /C/Dev/app-test-1/front/node_modules     > WRAPUPWRAPUP \n\nまだ未検証な部分はのこっていますが、ひととおりmacOSとWindowsによるWebアプリケーション開発は共有できるところまできている、と言えそうです。 \n\n随時、気になる課題が出てきたら追記します。  \n\n1. https://github.com/cmderdev/cmder/issues/901 ↩ \n2. https://github.com/docker/compose/issues/4039#issuecomment-269558432 ↩ \n3. https://github.com/Microsoft/WSL/issues/2448 ↩"},"name":"[2017-12-10]WSL（Windows Subsystem for Linux）でDockerをつかったWebアプリケーション開発をおこなう際の注意点","tags":["wsl","docker","ubuntu"],"childPublishedDate":{"published_on":"2017-12-10T00:00:00.000Z","published_on_unix":1512864000}}}],"pathPrefix":"","first":false,"last":false,"index":2,"pageCount":3,"additionalContext":{}}},"staticQueryHashes":[]}