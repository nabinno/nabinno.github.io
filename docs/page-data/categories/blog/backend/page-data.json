{"componentChunkName":"component---src-templates-posts-tsx","path":"/categories/blog/backend","result":{"pageContext":{"category":"blog/backend","group":[{"node":{"number":75,"relative_category":"blog/backend","fields":{"title":"CDKで管理する今どきのJenkins","excerpt":"先日のAWS障害で管理していたECSに多少の影響が出たので、そのタイミングで敷設していたJenkinsの構成を改めて整理しました。今回は課題解決というより、既に稼働していたシステム構成の振り返りを行いました。   > PROBLEMPROBLEM \n\n- インフラ系タスクがコード管理されていないので属人化しやすい 可能なら当該タスクはインフラ担当から手離れして欲しい 当該タスクは通常のCIワークフローとは異なるので管理する場所がない そういう意味でJenkinsの出番だけどこれはこれで管理が手間 ヘルスチェックエラーにひっかかったら自動で再起動してほしい \n- 可能なら当該タスクはインフラ担当から手離れして欲しい\n- 当該タスクは通常のCIワークフローとは異なるので管理する場所がない そういう意味でJenkinsの出番だけどこれはこれで管理が手間 ヘルスチェックエラーにひっかかったら自動で再起動してほしい \n- そういう意味でJenkinsの出番だけどこれはこれで管理が手間 ヘルスチェックエラーにひっかかったら自動で再起動してほしい \n- ヘルスチェックエラーにひっかかったら自動で再起動してほしい   > SOLUTIONSOLUTION \n\nというわけで、モダンなJenkins2系をAWS CDKで敷設してみました。   > 1. 構成1. 構成 \n\n大方の構成は「nabinno/jenkins-cdk-on-ec2」のシステム構成図をご覧下さい。元ネタはaws-sampleになりますが、今回はAWS FargateではなくAmazon ECSを採用し、CDKはTypeScriptで実装しています。 \n\n使用技術スタック \n\n- Jenkins\n- Amazon ECS（Amazon EC2）\n- Application Load Balancer\n- Amazon EFS    > 2. CDKによるJenkinsの敷設2. CDKによるJenkinsの敷設 \n\nCDKによるJenkinsの敷設はGitHubレポジトリーを見ていただくとして、ここではCDKのコード上の注意点を2点ほど共有しておきます。   > 2-a. CDKの注意点：リソース名を明示する2-a. CDKの注意点：リソース名を明示する \n\nCDKで各リソース名を明示しないとCloudFormation（CFn）独特の命名規則でリソースが敷設されます。インフラ担当が自分一人の場合は良いですが、インフラ担当を増員する際は、他のIaCツールの運用方針とバッティングする等、後で足かせになるので命名規則にのっとりリソース名を付けていくようにしましょう。 \n\n命名規則は「クラスメソッドさんの記事」を参考に決めるのが定番のようです。下記例になります。    AWSリソース 命名規則     ELB {sysname}-{env}-alb/clb   TargetGroup {sysname}-{env}-tg   EC2 {sysname}-{env}-{type}   SecurityGroup {sysname}-{env}-{type}-sg    \n\nCDKでリソース名を明示するには次のいずれかの方法で対応します。 \n\n- 各クラスのコンストラクトプロパティにある名前を記述する\n- 暗黙的生成されるリソースを明示的に作成する \n\n下記コードでは暗黙的に生成されていたSecurity Groupを明示的に作成している様子等が見て取れます。   ts \n\n// ECS: Service const serviceSecGrp = new ec2.SecurityGroup(this, \"JenkinsMasterServiceSecGrp\", { securityGroupName: \"jenkins-production-master-sg\", vpc: network.vpc, allowAllOutbound: true, }); serviceSecGrp.addIngressRule(worker.workerSecurityGroup, ec2.Port.tcp(50000), \"from JenkinsWorkerSecurityGroup 50000\"); serviceSecGrp.addIngressRule(worker.workerSecurityGroup, ec2.Port.tcp(8080), \"from JenkinsWorkerSecurityGroup 8080\"); const jenkinsMasterService = new ecs.Ec2Service(this, \"EC2MasterService\", { serviceName: 'jenkins-production-master-svc', taskDefinition: jenkinsMasterTask, cloudMapOptions: { name: \"master\", dnsRecordType: sd.DnsRecordType.A }, desiredCount: 1, minHealthyPercent: 0, maxHealthyPercent: 100, enableECSManagedTags: true, cluster: ecsCluster.cluster, securityGroups: [serviceSecGrp] });   \n\nなお、リソース名の明示化について、もちろんCDKのクラスによっては暗黙的なリソースを含んでおり当該リソースに名前を付けることが出来ないケースはあります。今回のケースで言うと、例えば、ECSクラスター（EC2）のIAM RoleやSecurity Group。その場合は、インフラのCDK運用方針としてドキュメントに残しておく等しておくと良いでしょう。   > 2-b. CDKの注意点：cdk.RemovablePolicy.RETAINをつける2-b. CDKの注意点：cdk.RemovablePolicy.RETAINをつける \n\nネットワーク、ストレージ関連のリソースを扱う場合、削除されるとリソース構成が破綻する可能性があるのでcdk.RemovablePolicy.RETAIN、CFnの言うところの \"DeletionPolicy\": \"Retain\" をつけましょう。今回はEFSがその対象になります。   ts \n\nconst efsFilesystem = new efs.CfnFileSystem(this, \"EFSBackend\"); efsFilesystem.applyRemovalPolicy(cdk.RemovalPolicy.RETAIN);   \n\n個人的にはRETAINをつけるとcdk destroy cdk deployを気軽に行えなくなるので、RETAINをつけるならCDK/CFnからはARNで参照する程度に抑えた方が良いと思っています。   > 3. Jenkinsの設定を行う3. Jenkinsの設定を行う \n\nCDKでJenkinsを敷設した終わったらJenkinsの設定を行いましょう。   > 3-a. Jenkinsでつかっているプラグイン3-a. Jenkinsでつかっているプラグイン \n\n昔と違って今のJenkinsは下記プラグインがあれば十分運用できます。 \n\n- github-oauth\n- role-strategy\n- configuration-as-code\n- blueocean \n\nざっと説明するとgithub-oauthでGitHub認証させ、role-strategyでロールごとの権限付与を行い、configuration-as-codeでそれらの管理設定をコード化します。configuration-as-codeは素晴らしく設定情報をコード化することでdockerイメージに当該設定情報を反映させることが出来ます。また、blueoceanはモダンなインターフェイスでジョブ実行します。こちらは次のセクションで詳細を説明します。 \n\nなお、プラグイン管理はIaC化でき下記のようにdockerイメージに反映できます。   sh \n\n$ cat plugins.txt role-strategy:3.1 github-oauth:0.33 thinBackup:1.10 git:4.6.0 authorize-project:1.3.0 configuration-as-code:1.47 blueocean:1.24.4 $ cat Dockerfile [...] COPY plugins.txt /usr/share/jenkins/ref/plugins.txt RUN /usr/local/bin/install-plugins.sh < /usr/share/jenkins/ref/plugins.txt [...]     > 3-b. JenkinsジョブをGitHubで管理する3-b. JenkinsジョブをGitHubで管理する \n\nいよいよJenkinsでジョブの管理設定を行います。具体的には下記手順で実施します。手順が完了すると作ったブランチ分だけJenkinsにジョブが追加されます、とても簡単です。 \n\n1. ジョブを管理させたいGitHubレポジトリでジョブ管理用のブランチを作成し、Jenkinsfile を配置\n2. 「Jenkins - Blue Ocean - New Pipeline」にて下記設定をおこなう Where do you store your code? - GitHub Which organization does the repository belong to? - 任意のuserあるいはorganization Choose a repository - 任意のレポジトリ（1で作成したレポジトリ） \n3. Where do you store your code? - GitHub\n4. Which organization does the repository belong to? - 任意のuserあるいはorganization\n5. Choose a repository - 任意のレポジトリ（1で作成したレポジトリ） \n\nJenkinsfile の作成方法は「ユーザーハンドブック」にありますが、下記例のように直感的に記述することが出来ます。環境変数は「Jenkins - {{レポジトリ}} - 認証情報 - Stores scoped to {{レポジトリ}} - global - Add credential」から追加します。   Jenkinsfile \n\n pipeline { agent any stages { stage('Show env') { steps { sh '''mysql --version ls -al bin env | sort''' } } stage('Run script') { steps { git(url: 'https://github.com/nabinno/jenkins-jobs', branch: 'master', credentialsId: 'github') sh '''git diff sync-db-from-staging-to-integration | patch -p1 -R -f bin/sync_db_from_staging_to_integration''' } } } environment { STAG_DB_DATABASE = credentials('STAG_DB_DATABASE') STAG_DB_HOSTNAME = credentials('STAG_DB_HOSTNAME') STAG_DB_PASSWORD = credentials('STAG_DB_PASSWORD') STAG_DB_USERNAME = credentials('STAG_DB_USERNAME') INTEG_DB_HOSTNAME = credentials('INTEG_DB_HOSTNAME') INTEG_DB_PASSWORD = credentials('INTEG_DB_PASSWORD') INTEG_DB_USERNAME = credentials('INTEG_DB_USERNAME') INTEG_DB_DATABASE = credentials('INTEG_DB_USERNAME') } }     > WRAPUPWRAPUP \n\n今回の振り返りで、2点気づきを得られました。CDKのリソース名の扱いに困っていたのですが、どうにか制御できそうなのでまたしばらくは付き合っていくことになりそうです。 \n\n1. CDKは意外とかゆいところに手が届く。ただ、暗黙的に生成され、CDK側で制御できないリソース名があるので、そういう前提で運用ポリシーを作ると各IaC使いの平穏に繋がる。\n2. Jenkins2は思った以上に手離れが良い。CDK、ECS、EFS、configuration-as-code、Jenkinsfileの組み合わせは保守性、可用性に大きな貢献をしている。"},"name":"CDKで管理する今どきのJenkins","tags":["aws-cdk","jenkins","amazon-ecs"],"childPublishedDate":{"published_on":"2021-02-24T02:04:50.000Z","published_on_unix":1614132290}}},{"node":{"number":55,"relative_category":"blog/backend","fields":{"title":"PositiveSSLをHerokuに適用する","excerpt":"年に1回のSSL更新のイベントです。毎年同じことをすれば良いかというとそうでもなく、販社と卸の都合でSSLの購入方法が微妙に変わります。とは言え、毎年一から調べ直すのも手間なので備忘として記しておきます。   > PROBLEMPROBLEM \n\n- HerokuのSSLの期限がきた   > SOLUTIONSOLUTION \n\n- というわけで、いつも使っているSSL販売代理店SSLs.com（NameCheap社）でPositiveSSL（運用Comodo社）を購入しHerokuに適用します。   > HOWTOHOWTO \n\n1. 証明書を購入する SSL販売代理店であればどこでもいいのですが、昔から使っているので \n2. SSL販売代理店であればどこでもいいのですが、昔から使っているので\n3. 秘密鍵と署名リクエストをつくる 秘密鍵 openssl genrsa -des3 -out server.orig.key 2048 秘密鍵パスワードなしopenssl rsa -in server.orig.key -out server.key 署名リクエスト openssl req -new -key server.key -out server.csr \n4. 秘密鍵 openssl genrsa -des3 -out server.orig.key 2048 \n5. 秘密鍵パスワードなしopenssl rsa -in server.orig.key -out server.key \n6. 署名リクエスト openssl req -new -key server.key -out server.csr \n7. 証明書発行を申請する SSL販売代理店より署名リクエストserver.csrと関連情報を送信します \n8. SSL販売代理店より署名リクエストserver.csrと関連情報を送信します\n9. ドメイン保持の証明をする PositiveSSLの運用会社Comodoに対しドメイン保持の証明します 証明方法はメールを受信する、あるいは、Webサイトにプレーンテキストを設置するかの2択になります \n10. PositiveSSLの運用会社Comodoに対しドメイン保持の証明します\n11. 証明方法はメールを受信する、あるいは、Webサイトにプレーンテキストを設置するかの2択になります\n12. Heroku用の証明書をつくる 証明タスクをこなししばらくすると、Comodo社より複数の証明書が送られてきます Heroku用に証明書をつくる cat www_example_com.crt COMODORSADomainValidationSecureServerCA.crt COMODORSAAddTrustCA.crt AddTrustExternalCARoot.crt > server.crt \n13. 証明タスクをこなししばらくすると、Comodo社より複数の証明書が送られてきます\n14. Heroku用に証明書をつくる cat www_example_com.crt COMODORSADomainValidationSecureServerCA.crt COMODORSAAddTrustCA.crt AddTrustExternalCARoot.crt > server.crt \n15. Herokuに証明書を適用する 新規で適用する場合は次のコマンドを実行します heroku addons:add ssl:endpoint heroku certs:add server.crt server.key 更新する場合は次のコマンドを実行します heroku certs:update server.crt server.key \n16. 新規で適用する場合は次のコマンドを実行します heroku addons:add ssl:endpoint heroku certs:add server.crt server.key \n17. heroku addons:add ssl:endpoint\n18. heroku certs:add server.crt server.key\n19. 更新する場合は次のコマンドを実行します heroku certs:update server.crt server.key \n20. heroku certs:update server.crt server.key   > WRAPUPWRAPUP \n\nこのあたりが自動化されれば良いと思いつつ、自動化されたらこのあたりを調べるモチベーションがなくなるので年に一回のリハビリイベントとして位置づけておきます、はい。"},"name":"[2017-04-23]PositiveSSLをHerokuに適用する","tags":[],"childPublishedDate":{"published_on":"2017-04-23T00:00:00.000Z","published_on_unix":1492905600}}},{"node":{"number":60,"relative_category":"blog/backend","fields":{"title":"連載 Rails2Phoenix 2 認証機能を実装する","excerpt":"連載「Rails2Phoenix」になります、前回は「UmbrellaプロジェクトをHerokuにデプロイする 」でした。今回は前回課題としてあがった認証機能の実装を試みたいと思います。   > PROBLEMPROBLEM \n\n- サービスについて 拡張にともない技術スタックがふえるのを抑えたい スケーラビリティのためのコストを抑えたい パフォーマンスをあげたい \n- 拡張にともない技術スタックがふえるのを抑えたい\n- スケーラビリティのためのコストを抑えたい\n- パフォーマンスをあげたい   > SOLUTIONSOLUTION \n\nというわけで、現在つかっているRailsをPhoenixに変更することにしました。方針は以下の通りで、今回はRails/Deviseの認証機能をPhoenixで実装する流れを取り上げます。 \n\n方針 \n\n- Railsから徐々にPhoenixに移行できるように いままでとおなじPaaS（Heroku） いままでとおなじレポジトリ ブランチ戦略は phoenix/base をベースに 気軽に参照できるようにRails関連ファイルは可能な限りのこしておく いままでとおなじDB 移行完了までDBマイグレーションをしない \n- いままでとおなじPaaS（Heroku）\n- いままでとおなじレポジトリ ブランチ戦略は phoenix/base をベースに 気軽に参照できるようにRails関連ファイルは可能な限りのこしておく \n- ブランチ戦略は phoenix/base をベースに\n- 気軽に参照できるようにRails関連ファイルは可能な限りのこしておく\n- いままでとおなじDB 移行完了までDBマイグレーションをしない \n- 移行完了までDBマイグレーションをしない\n- Phoenixは今後の拡張性をかんがえてUmbrellaプロジェクトで   > Guardianを実装するGuardianを実装する \n\nまず、参考にしたのはBlackodeのguardian_authです。ただ、Guardianのバージョンがふるいので1.0へのマイグレーション記事をもとにアレンジしてあります。認証に関係しそうな構成は下記の通り。 \n\nロジック \n\n- MyApp.Account\n- MyApp.Account.Registration\n- MyApp.Account.User\n- MyApp.Auth.Guardian\n- MyApp.Auth.ErrorHandler\n- MyApp.Auth.Pipeline\n- MyApp.Auth.AfterPipeline\n- MyApp.Auth.Session \n\nコントローラ \n\n- MyAppWeb.RegistrationController\n- MyAppWeb.SessionController   > シリアライザとエラーハンドラの設定シリアライザとエラーハンドラの設定 \n\nGuardian1.0から直接ではなくモジュールを介して参照するようになりました。下記のように各モジュールを用意してコンフィグに割り当てます。   elixir \n\n# apps/my_app/lib/my_app/auth/guardian.ex defmodule MyApp.Auth.Guardian do use Guardian, otp_app: :my_app alias MyApp.Account def subject_for_token(resource, _claims), do: {:ok, to_string(resource.id)} def subject_for_token(_, _), do: {:error, :reason_for_error} def resource_from_claims(claims), do: {:ok, Account.get_user!(claims[\"sub\"])} def resource_from_claims(_claims), do: {:error, :reason_for_error} end     elixir \n\n# apps/my_app/lib/my_app/auth/error_handler.ex defmodule MyApp.Auth.ErrorHandler do import Plug.Conn def auth_error(conn, {type, _reason}, _opts) do body = Poison.encode!(%{message: to_string(type)}) send_resp(conn, 401, body) end end     elixir \n\n# apps/my_app/config/config.exs config :my_app, MyApp.Auth.Guardian, issuer: \"MyApp\", ttl: {30, :days}, allowed_drift: 2000, # optionals allowed_algos: [\"HS512\"], verify_module: MyApp.Auth.Guardian.JWT, verify_issuer: true, secret_key: System.get_env(\"GUARDIAN_SECRET\") || \"secret_key\"     > ルーターの設定ルーターの設定 \n\n認証のパイプラインは、認証中と認証後のものを用意しコンフィグとルーターに割り当てます。 \n\nルータースコープ内のパイプラインくみあわせについて、ここでは未ログインスコープには認証前・認証中パイプライン、ログイン済スコープには認証前・認証中・認証後パイプラインを適用しています。こうすることでどのスコープにも認証リソースをロードすることができ、かつ、認証も担保することができるようになります。具体的にいうと、ルート / などの同一URLで未ログインスコープとログイン済スコープの切り替えができるようになります。   elixir \n\n# apps/my_app/lib/my_app/auth/pipeline.ex defmodule MyApp.Auth.Pipeline do use Guardian.Plug.Pipeline, otp_app: :my_app plug(Guardian.Plug.VerifySession, claims: %{\"typ\" => \"access\"}) plug(Guardian.Plug.VerifyHeader, claims: %{\"typ\" => \"access\"}) plug(Guardian.Plug.LoadResource, allow_blank: true) end     elixir \n\n# apps/my_app/lib/my_app/auth/after_pipeline.ex defmodule MyApp.Auth.AfterPipeline do use Guardian.Plug.Pipeline, otp_app: :my_app plug(Guardian.Plug.EnsureAuthenticated) end     elixir \n\n# apps/my_app/lib/my_app_web/router.ex defmodule MyAppWeb.Router do use MyAppWeb, :router pipeline :browser do plug(:accepts, [\"html\"]) plug(:fetch_session) plug(:fetch_flash) plug(:protect_from_forgery) plug(:put_secure_browser_headers) end pipeline :browser_auth do plug(MyApp.Auth.Pipeline) end pipeline :browser_auth_after do plug(MyApp.Auth.AfterPipeline) end scope \"/\", MyAppWeb do pipe_through([:browser, :browser_auth]) post(\"/registration\", RegistrationController, :create) get(\"/login\", SessionController, :new) post(\"/login\", SessionController, :create) get(\"/logout\", SessionController, :delete) end scope \"/\", MyAppWeb do pipe_through([:browser, :browser_auth, :browser_auth_after]) get(\"/edit\", RegistrationController, :edit) put(\"/edit\", RegistrationController, :update) get(\"/users\", UserController, :index) resources \"/\", UserController, only: [:show, :delete], param: \"username\" end end     elixir \n\n# apps/my_app/config/config.exs config :MyApp, MyApp.Auth.Pipeline, module: MyApp.Auth.Guardian, error_handler: MyApp.Auth.ErrorHandler config :MyApp, MyApp.Auth.AferPipeline, module: MyApp.Auth.Guardian, error_handler: MyApp.Auth.ErrorHandler     > 登録登録 \n\n登録は登録用のロジック（ユーザーモデルと登録サービス）とコントローラを用意します。 \n\nこのあたりはDevise/Railsとあまり変わりません。他のアクション「新規パスワード発行」「メールアドレス確認」等も同様の構成をとろうと思っています。   elixir \n\n# apps/my_app/lib/my_app_web/controller/registration_controller.ex def create(conn, user_params) do changeset = User.registration_changeset(%User{}, user_params) case Registration.create(changeset, Repo) do {:ok, user} -> conn |> MyApp.Auth.login(user) |> put_flash(:info, \"Your account was created successfully\") |> redirect(to: page_path(conn, :home)) {:error, changeset} -> conn |> put_flash(:error, \"Unable to create account: Try again\") |> render(MyAppWeb.PageView, \"home.html\", changeset: changeset) end end     elixir \n\n# apps/my_app/lib/my_app/auth/auth.ex def login(conn, %User{} = user) do conn |> Guardian.Plug.sign_in(user) |> assign(:current_user, user) end     elixir \n\n# apps/my_app/lib/my_app/account/registration.ex def create(changeset, repo) do changeset |> repo.insert() end     > ログイン・ログアウトログイン・ログアウト \n\nログイン・ログアウトはセッション用のサービスとコントローラで実装します。   elixir \n\n# apps/my_app/lib/my_app_web/controller/session_controller.ex @doc \"Logged in [POST /login]\" def create(conn, %{\"email\" => email, \"password\" => password}) do case Session.authenticate_user(email, password) do {:ok, user} -> conn |> Session.login(user) |> put_flash(:info, \"Logged in successfully\") |> redirect(to: page_path(conn, :home)) {:error, _reason} -> conn |> put_flash(:error, \"Wrong username/password\") |> render(\"new.html\") end end @doc \"Logged out [DELETE /logout]\" def delete(conn, _params) do conn |> Session.logout() |> put_flash(:info, \"Logged out successfully.\") |> redirect(to: \"/\") end     elixir \n\n# apps/my_app/lib/my_app/auth/session.ex defmodule MyApp.Auth.Session do import Ecto.Query import Plug.Conn import Comeonin.Bcrypt, only: [checkpw: 2, dummy_checkpw: 0] alias MyApp.Repo alias MyApp.Auth.Guardian alias MyApp.Account.User def login(conn, %User{} = user) do conn |> Guardian.Plug.sign_in(user) |> assign(:current_user, user) end def logout(conn), do: Guardian.Plug.sign_out(conn) def authenticate_user(email, given_password) do query = Ecto.Query.from(u in User, where: u.email == ^email) Repo.one(query) |> check_password(given_password) end def current_user(conn), do: Guardian.Plug.current_resource(conn, []) def logged_in?(conn), do: Guardian.Plug.authenticated?(conn, []) defp check_password(nil, _), do: {:error, \"Incorrect username or password\"} defp check_password(user, given_password) do case Comeonin.Bcrypt.checkpw(given_password, user.encrypted_password) do true -> {:ok, user} false -> {:error, \"Incorrect email or password\"} end end end   \n\nDevise/Railsのビューヘルパーはビューマクロで適用します。   elixir \n\n# apps/my_app/lib/my_app_web.ex def view do quote do # .. import Okuribi.Auth.Session, only: [current_user: 1, logged_in?: 1] end end   \n\nあるいは、put_assigns関数をはやしてコントローラマクロに適用します。   elixir \n\n# apps/my_app/lib/my_app/auth/session.ex def put_assigns(%{private: %{phoenix_action: action}} = conn, settings) do current_resource = Guardian.Plug.current_resource(conn) settings = if current_resource, do: settings[:sign_in][action] || [], else: settings[:sign_out][action] || [] conn |> assign(:current_user, current_resource) |> assign(:page_title, settings[:page_title]) |> assign(:page_description, settings[:page_description]) end     elixir \n\n# apps/my_app/lib/my_app_web.ex def controller do quote do # .. import Okuribi.Auth, only: [put_assigns: 2] end end   \n\nassignsひとつでアクセスできるので、下記のようにコントローラでまとめて指定することでRailsのActionView::Helpers::CaptureHelper#provideの代わりに使えます。   elixir \n\n# apps/my_app/lib/my_app_web/controller/*_controller.ex @page %{ sign_in: %{ new: %{ page_title: dgettext(\"views\", \"pages.home.signed_in.page_title\"), page_description: \"\" } }, sign_out: %{ new: %{ page_title: dgettext(\"views\", \"pages.home.signed_out.page_title\"), page_description: \"\" } } } plug(:put_assigns, @page when action in [:home])     > その他その他 \n\nRailsのビューをPhoenixのテンプレートに移植するには下記の変換を地道に行っていきます。 \n\n- Rails ActionView::Helpers::FormHelper#form_for(record, options={}, &block) ActionView::Helpers::FormHelper#text_field(object_name, method, options={}) ActionView::Helpers::FormHelper#file_field(object_name, method, options={}) ActionView::Helpers::FormHelper#hidden_field(object_name, method, options={}) ActionView::Helpers::FormHelper#password_field(object_name, method, options={}) ActionView::Helpers::FormHelper#radio_button(object_name, method, tag_value, options={}) ActionView::Helpers::FormBuilder#submit(value=nil, options={}) ActionView::Helpers::TranslationHelper#t \n- ActionView::Helpers::FormHelper#form_for(record, options={}, &block)\n- ActionView::Helpers::FormHelper#text_field(object_name, method, options={})\n- ActionView::Helpers::FormHelper#file_field(object_name, method, options={})\n- ActionView::Helpers::FormHelper#hidden_field(object_name, method, options={})\n- ActionView::Helpers::FormHelper#password_field(object_name, method, options={})\n- ActionView::Helpers::FormHelper#radio_button(object_name, method, tag_value, options={})\n- ActionView::Helpers::FormBuilder#submit(value=nil, options={})\n- ActionView::Helpers::TranslationHelper#t\n- Phoenix Phoenix.HTML.Form.form_for(form_data, action, options \\\\ [], fun) Phoenix.HTML.Form.text_input(form, field, opts \\\\ []) Phoenix.HTML.Form.file_input(form, field, opts \\\\ []) Phoenix.HTML.Form.hidden_input(form, field, opts \\\\ []) Phoenix.HTML.Form.password_input(form, field, opts \\\\ []) Phoenix.HTML.Form.radio_button(form, field, value, opts \\\\ []) Phoenix.HTML.Form.submit(opts, opts \\\\ []) Gettext.dgettext(backend, domain, msgid, bindings \\\\ %{}) \n- Phoenix.HTML.Form.form_for(form_data, action, options \\\\ [], fun)\n- Phoenix.HTML.Form.text_input(form, field, opts \\\\ [])\n- Phoenix.HTML.Form.file_input(form, field, opts \\\\ [])\n- Phoenix.HTML.Form.hidden_input(form, field, opts \\\\ [])\n- Phoenix.HTML.Form.password_input(form, field, opts \\\\ [])\n- Phoenix.HTML.Form.radio_button(form, field, value, opts \\\\ [])\n- Phoenix.HTML.Form.submit(opts, opts \\\\ [])\n- Gettext.dgettext(backend, domain, msgid, bindings \\\\ %{})   > WRAPUPWRAPUP \n\n前回もそうですが、コードのマイグレーションはまあ地味な作業ですよね。とまれ、認証機能を実装できたので良しとしましょう。"},"name":"[2018-05-20]連載 Rails2Phoenix 2 認証機能を実装する","tags":["phoenix-framework","elixir","ruby-on-rails","ruby","wercker","heroku","authentication","guardian"],"childPublishedDate":{"published_on":"2018-05-20T00:00:00.000Z","published_on_unix":1526774400}}},{"node":{"number":59,"relative_category":"blog/backend","fields":{"title":"連載 Rails2Phoenix 1 UmbrellaプロジェクトをHerokuにデプロイする","excerpt":"使い慣れたRailsのプロジェクトを拡張したいのですが、その都度技術スタックを増やす必要があり、この点をどうにかクリアしたいと考えています。連載「Rails2Phoenix」になります、今回はフレームワークをElixir製のPhoenix Frameworkへと変更を試みました。   > PROBLEMPROBLEM \n\n- サービスについて 拡張にともない技術スタックがふえるのを抑えたい スケーラビリティのためのコストを抑えたい パフォーマンスをあげたい \n- 拡張にともない技術スタックがふえるのを抑えたい\n- スケーラビリティのためのコストを抑えたい\n- パフォーマンスをあげたい   > SOLUTIONSOLUTION \n\nというわけで、現在つかっているRailsをPhoenixに変更することにしました。方針は以下の通りで、今回はRailsから移行中のPhoenix UmbrellaプロジェクトをHerokuにデプロイする流れをとりあげます。 \n\n方針 \n\n- Railsから徐々にPhoenixに移行できるように いままでとおなじPaaS（Heroku） いままでとおなじレポジトリ ブランチ戦略は phoenix/base をベースに 気軽に参照できるようにRails関連ファイルは可能な限りのこしておく いままでとおなじDB 移行完了までDBマイグレーションをしない \n- いままでとおなじPaaS（Heroku）\n- いままでとおなじレポジトリ ブランチ戦略は phoenix/base をベースに 気軽に参照できるようにRails関連ファイルは可能な限りのこしておく \n- ブランチ戦略は phoenix/base をベースに\n- 気軽に参照できるようにRails関連ファイルは可能な限りのこしておく\n- いままでとおなじDB 移行完了までDBマイグレーションをしない \n- 移行完了までDBマイグレーションをしない\n- Phoenixは今後の拡張性をかんがえてUmbrellaプロジェクトで   > HerokuへのデプロイのながれHerokuへのデプロイのながれ \n\n基本的にドキュメント通り。   > Phoenixアプリケーションを作成Phoenixアプリケーションを作成 \n\nまず、こんな感じでPhoenixの骨組みをつくります。Phoenix関連のファイル apps/, deps/, config/config.exs, mix.exs, mix.lock が追加されます。   sh \n\n> cd rails_project > mix new . --umbrella > (cd ./apps && mix phx.new phoenix_app)   \n\n次に、既存のRailsでつくられたスキーマをPhoenixに移植します。Ripperをつかうとはかどります。ちなみに手動でスキーマをつくりたい場合は、CLI mix phx.gen.schema --no-migration Blog.Post blog_posts title:string で作成します。   rb \n\n# lib/tasks/convert_to_phoenix.rake # こちらはスキーマ移植タスクをPhoenix1.3用に改めたもの require 'ripper' require 'erb' require 'fileutils' namespace :db do namespace :schema do desc 'Convert schema from Rails to Phoenix' task convert_to_phoenix: :environment do ConvertSchemaForPhoenixService.call end end end class ConvertSchemaForPhoenixService class << self def call FileUtils.mkdir_p(File.join('tmp', 'models')) extract_activerecord_define_block( Ripper.sexp( Rails.root .join('db', 'schema.rb') .read ) ).select(&method(:create_table_block?)) .map(&method(:configuration)) .each do |conf| project_name = 'PhoenixApp' table_name = conf[:table_name] table_columns = conf[:table_columns].reject(&method(:reject_condition)) .map do |c| case c[:column_type] when 'text' then c[:column_type] = ':string' when 'datetime' then c[:column_type] = ':naive_datetime' when 'inet' then c[:column_type] = 'EctoNetwork.INET' else c[:column_type] = \":#{c[:column_type]}\" end c end File.write( File.join('tmp', 'models', \"#{conf[:table_name].singularize}.ex\"), template.result(binding) ) end end private def extract_activerecord_define_block(sexp) sexp.dig(1, 0, 2, 2) end def create_table_block?(activerecord_define_block_element_sexp) activerecord_define_block_element_sexp.dig(1, 1, 1) == 'create_table' rescue false end def extract_table_name(create_table_block_sexp) create_table_block_sexp.dig(1, 2, 1, 0, 1, 1, 1) end def extract_table_columns(create_table_block_sexp) create_table_block_sexp.dig(2, 2) end def extract_column_type(table_column_sexp) table_column_sexp.dig(3, 1) end def extract_column_name(table_column_sexp) # Return value of `t.index` is array like ['user_id']. if table_column_sexp.dig(4, 1, 0, 0) == :array return table_column_sexp.dig(4, 1, 0, 1).map { |e| e.dig(1, 1, 1) } end table_column_sexp.dig(4, 1, 0, 1, 1, 1) end def extract_column_option(table_column_sexp) # If is not `column_option`, then `table_column_sexp.dig(4, 1, 1, # 1)` method return nil. Set blank array ([]) for avoiding nil. table_column_sexp.dig(4, 1, 1, 1) || [] end def extract_option_key(column_option_sexp) # Remove colon for avoiding `null:`. column_option_sexp.dig(1, 1).gsub(/:\\z/, '') end def extract_option_value(column_option_sexp) if column_option_sexp.dig(2, 0) == :array return Array(column_option_sexp.dig(2, 1)).map { |e| e.dig(1, 1, 1) } end element = column_option_sexp.dig(2, 1) if element.class != Array return element end case element.dig(0) when :kw then element.dig(1) when :string_content then element.dig(1, 1) || '' end end def template ERB.new(<<'__EOD__', nil, '-') defmodule <%= project_name %>.<%= table_name.classify %> do use Ecto.Schema import Ecto.Changeset alias <%= project_name %>.<%= table_name.classify %> schema \"<%= table_name %>\" do<% table_columns.each do |c| %> field :<%= c[:column_name] -%>, <%= c[:column_type] -%> <% end %> timestamps inserted_at: :created_at end @doc false def changeset(%<%= table_name.classify %>{} = <%= table_name.singularize %>, attrs) do <%= table_name.singularize %> |> cast(attrs, [<%= table_columns.map { |c| \":\" << c[:column_name] }.join(\", \") -%>]) # |> validate_required([<%= table_columns.map { |c| \":\" << c[:column_name] }.join(\", \") -%>]) end end __EOD__ end def configuration(table) { table_name: extract_table_name(table), table_columns: extract_table_columns(table).map do |c| { column_name: extract_column_name(c), column_type: extract_column_type(c), column_option: Hash[extract_column_option(c).map { |o| [extract_option_key(o), extract_option_value(o)] }] } end } end def reject_condition(column) column[:column_name] =~ /\\A(created|updated)_at\\z/ || column[:column_type] == 'index' end end end     sh \n\n> rails db:schema:convert_to_phoenix   \n\n最後に、既存DBへはこんな感じで接続します。   config \n\n# rails_project/apps/phoenix_app/config/dev.exs config :phoenix_app, PhoenixApp.Repo, adapter: Ecto.Adapters.Postgres, url: System.get_env(\"DATABASE_URL\"), pool_size: 10, ssl: true     sh \n\n> (cd ./apps/phoenix_app/assets && npm install) > mix deps.get > mix phx.server     > デプロイのパイプラインを追加デプロイのパイプラインを追加 \n\nさて、既存のCI（Wercker）も更新しましょう。今回はPhoenix関連ブランチが更新された場合にのみ、関連パイプラインを走らせるように下記のように変更しました。 \n\nBEFORE \n\n- build (all branch) deploy.prod (master branch) \n- deploy.prod (master branch) \n\nAFTER \n\n- build (all branch) deploy.prod (master branch) deploy.phoenix.prod (phoenix/base branch) \n- deploy.prod (master branch)\n- deploy.phoenix.prod (phoenix/base branch)   yaml \n\n# wercker.yml deploy-phoenix-prod-heroku: steps: - add-ssh-key: host: github.com keyname: GITHUB - add-to-known_hosts: hostname: github.com fingerprint: 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48 - heroku-deploy: key: $HEROKU_KEY user: $HEROKU_USER app-name: $HEROKU_APP_NAME install-toolbelt: true after-steps: - wantedly/pretty-slack-notify: webhook_url: ${SLACK_WEBHOOK_URL} channel: general     > Herokuアプリケーションを作成Herokuアプリケーションを作成 \n\n基本ドキュメントの説明通りです。Phoenix Umbrellaプロジェクトの注意点としては、ディレクトリの差異くらいでそれ以外は同じです。つまり、これ rails_project/config/prod.exs をこう rails_project/apps/phoenix_app/config/prod.exs 変更します。 \n\n1. Herokuアプリにビルドパックを適用   sh \n\n> heroku create --buildpack https://github.com/HashNuke/heroku-buildpack-elixir.git > heroku buildpacks:add https://github.com/gjaldon/heroku-buildpack-phoenix-static.git   \n\n2. 起動設定を準備   config \n\n# rails_project/elixir_buildpack.config erlang_version=19.1 elixir_version=1.4.2 always_rebuild=false pre_compile=\"pwd\" post_compile=\"pwd\" runtime_path=/app config_vars_to_export=(DATABASE_URL) config_vars_to_export=(DATABASE_POOL_SIZE)     config \n\n# rails_project/phoenix_static_buildpack.config phoenix_relative_path=apps/phoenix_app     config \n\n# rails_project/Procfile web: MIX_ENV=prod mix phx.server   \n\n3. 環境変数を適用 \n\nデータベース関連。   config \n\n# rails_project/apps/phoenix_app/config/prod.exs config :phoenix_app, PhoenixApp.Repo, adapter: Ecto.Adapters.Postgres, url: System.get_env(\"DATABASE_URL\"), pool_size: String.to_integer(System.get_env(\"DATABASE_POOL_SIZE\") || 10), ssl: true     sh \n\nheroku config:set DATABASE_URL=foo heroku config:set DATABASE_POOL_SIZE=bar   \n\nクレデンシャル関連。   sh \n\n> heroku config:set HEROKU_API_KEY=$(heroku auth:token) > heroku config:set SECRET_KEY_BASE=$(mix phx.gen.secret)     > WRAPUPWRAPUP \n\n大枠は想定通りすんなり進めることが出来ましたが、課題もいくつか出てきました。まずは認証機能。こちらは次回のテーマで取り上げようと思いますが、Railsの認証ライブラリほど充実していないので自前でいくつか用意する必要がありそうです。次にビジネスロジック。これは元のRailsの実装が悪かったので致し方ないのですが、移植するのに時間がかかりそうです。先にRails側を整理してから進めた方が良いかもしれません。"},"name":"[2018-01-08]連載 Rails2Phoenix 1 UmbrellaプロジェクトをHerokuにデプロイする","tags":["phoenix-framework","elixir","ruby-on-rails","ruby","wercker","heroku"],"childPublishedDate":{"published_on":"2018-01-08T00:00:00.000Z","published_on_unix":1515369600}}},{"node":{"number":65,"relative_category":"blog/backend","fields":{"title":"LYSE本を読む","excerpt":"Elixirの存在を知ったのが2014年7月14日。それからおよそ3年経つというのに一向に理解した気になれないでいます。特にSLAナイン・ナインはなぜその数値なのか腑に落ちないでいました。今回『Learn You Some Erlang for Great Good!（通称LYSE本）』を読むことで積年の謎を解明してみようと臨みました。   > PROBLEMPROBLEM \n\n- Elixirをさわりはじめてしばらく経つけどふかく理解した気になれない\n- Phoenixやほかのフレームワークに頼られないケースが出てきたとき自由な発想ができるようになっておきたい\n- 巷でいわれているSLAナイン・ナイン（99.9999999%）などの実際がどうなのか腹落ちしてない   > TLDRTLDR \n\n- 下記Erlang機能を中心に高いSLAを提供する素地をなしている 分散システム Erlang Port Mapper Daemon（EPMD） 他の言語・フレームワークが「分散コンピューティングの落とし穴」「CAP定理」にどのように対応している比較すると、Erlangの特徴がより見えてくる。 EMPDの特徴 耐障害性（スケーリングはやや弱い） マルチプロセス ネットワークの障害監視 ライフサイクル、再起動戦略を備えたライブラリ（分散OTP） CPシステムでNoSQLデータベース「Mnesia」 \n- 分散システム Erlang Port Mapper Daemon（EPMD） 他の言語・フレームワークが「分散コンピューティングの落とし穴」「CAP定理」にどのように対応している比較すると、Erlangの特徴がより見えてくる。 EMPDの特徴 耐障害性（スケーリングはやや弱い） マルチプロセス ネットワークの障害監視 \n- 他の言語・フレームワークが「分散コンピューティングの落とし穴」「CAP定理」にどのように対応している比較すると、Erlangの特徴がより見えてくる。\n- EMPDの特徴 耐障害性（スケーリングはやや弱い） マルチプロセス ネットワークの障害監視 \n- 耐障害性（スケーリングはやや弱い）\n- マルチプロセス\n- ネットワークの障害監視\n- ライフサイクル、再起動戦略を備えたライブラリ（分散OTP）\n- CPシステムでNoSQLデータベース「Mnesia」   > SOLUTIONSOLUTION \n\nというわけで、「LYSE本」を読むことにしました。各セクションにはElixirに関係ありそうな箇所を抜粋しています。長い長いメモになるので、TLDRだけで済ませて問題ありません。結論、輪郭は見えてきましたがまだその探求の入り口に来たに過ぎないのだということは理解しました。   > 1-3 Erlang概要1-3 Erlang概要   > 1.2 Erlangって何？1.2 Erlangって何？ \n\n- 関数型言語 純粋主義（参照透過性、破壊的データを避けるなど）に従いつつ、実世界で問題が発生した場合はそれを取り払う \n- 純粋主義（参照透過性、破壊的データを避けるなど）に従いつつ、実世界で問題が発生した場合はそれを取り払う\n- アクターモデル 同時並行性 高可用性 Ex: Blue-Green deployment Log management Policy: Let it crash - クラッシュするならさせておけ As bad as anything else let it crashが生んだ誤解 \n- 同時並行性\n- 高可用性\n- Ex: Blue-Green deployment Log management \n- Blue-Green deployment\n- Log management\n- Policy: Let it crash - クラッシュするならさせておけ As bad as anything else let it crashが生んだ誤解 \n- Let it crash - クラッシュするならさせておけ As bad as anything else let it crashが生んだ誤解 \n- As bad as anything else\n- let it crashが生んだ誤解\n- 開発環境 クロスプラットフォーム BEAM 開発ツール コンパイラ デバッガ プロファイラ テストフレームワーク \n- クロスプラットフォーム BEAM \n- BEAM\n- 開発ツール コンパイラ デバッガ プロファイラ テストフレームワーク \n- コンパイラ\n- デバッガ\n- プロファイラ\n- テストフレームワーク\n- ライブラリ OTPフレームワーク Webサーバー パーサジェネレータ Mnesiaデータベース \n- OTPフレームワーク\n- Webサーバー\n- パーサジェネレータ\n- Mnesiaデータベース   > 1.3 Don't drink too much Kool-Aid1.3 Don't drink too much Kool-Aid \n\n- 軽量プロセスによるスケール タスクを細かく分けすぎる＝むやみに並行処理させると処理速度に影響がでる \n- タスクを細かく分けすぎる＝むやみに並行処理させると処理速度に影響がでる\n- CPUコア数によるスケール すべてを同時に稼働させることができない \n- すべてを同時に稼働させることができない\n- 技術領域 適切でない技術領域 画像処理 信号処理 OSのデバイスドライバ 適切な技術領域 巨大なサーバソフトウェア - QMS, MapReduce 多言語との接続 高レベルプロトコルの実装 Ex: IANOというUNICTチームが作成したロボット Wings 3D \n- 適切でない技術領域 画像処理 信号処理 OSのデバイスドライバ \n- 画像処理\n- 信号処理\n- OSのデバイスドライバ\n- 適切な技術領域 巨大なサーバソフトウェア - QMS, MapReduce 多言語との接続 高レベルプロトコルの実装 Ex: IANOというUNICTチームが作成したロボット Wings 3D \n- 巨大なサーバソフトウェア - QMS, MapReduce\n- 多言語との接続\n- 高レベルプロトコルの実装\n- Ex: IANOというUNICTチームが作成したロボット Wings 3D \n- IANOというUNICTチームが作成したロボット\n- Wings 3D   > 3.2. 変化できない変数3.2. 変化できない変数 \n\n- パターンマッチング（= 演算子） 比較の役割も果たしている 値が違っていたらエラーを出す 値が同じだったら当該の値を返す \n- 比較の役割も果たしている 値が違っていたらエラーを出す 値が同じだったら当該の値を返す \n- 値が違っていたらエラーを出す\n- 値が同じだったら当該の値を返す   erlang \n\n> 47 = 45 + 2. > 47 = 45 + 3. ** exception error: no match of right hand side value 48   \n\n- アンダースコア変数（_） 使用はできるが値の格納はできない \n- 使用はできるが値の格納はできない   erlang \n\n> _ = 14+3. 17 > _. * 1: variable '_' is unbound     > 3.3. アトム3.3. アトム \n\n- アトムと予約語 いくつかのアトムは予約語 after and andalso band begin bnot bor bsl bsr bxor case catch cond div end fun if let not of or orelse query receive rem try when xor false true \n- いくつかのアトムは予約語 after and andalso band begin bnot bor bsl bsr bxor case catch cond div end fun if let not of or orelse query receive rem try when xor false true \n- after and andalso band begin bnot bor bsl bsr bxor case catch cond div end fun if let not of or orelse query receive rem try when xor false true   > 3.4. ブール代数と比較演算子3.4. ブール代数と比較演算子 \n\n- false trueはアトムなので数値の代替にはならない\n- アトムなどのほかの型も比較対象になる number < atom < reference < fun < port < pid < tuple < list < bit string \n- number < atom < reference < fun < port < pid < tuple < list < bit string   erlang \n\n> 0 == false. false > 1 < false. true     > 3.8. ビット構文!3.8. ビット構文! \n\n- Erlangはおもいデータを数値処理するにはむいてない\n- 一方、数値処理が必要ないアプリケーションの中では速い 次のような処理にむいている イベントに反応する イベントをミリ秒単位でしょりできリアルタイムアプリケーションに適している メッセージングパッシング アトムをつかうと軽く処理できる \n- 次のような処理にむいている イベントに反応する イベントをミリ秒単位でしょりできリアルタイムアプリケーションに適している メッセージングパッシング アトムをつかうと軽く処理できる \n- イベントに反応する イベントをミリ秒単位でしょりできリアルタイムアプリケーションに適している \n- イベントをミリ秒単位でしょりできリアルタイムアプリケーションに適している\n- メッセージングパッシング アトムをつかうと軽く処理できる \n- アトムをつかうと軽く処理できる\n- 軽量なビット文字列 Pros リストで表現する文字列は1文字につき1ノード ビット文字列はC言語の配列のようなもの - <<\"this is a bit string!\">> Cons パターンマッチなどの捜査の際に単純さが失われる \n- Pros リストで表現する文字列は1文字につき1ノード ビット文字列はC言語の配列のようなもの - <<\"this is a bit string!\">> \n- リストで表現する文字列は1文字につき1ノード\n- ビット文字列はC言語の配列のようなもの - <<\"this is a bit string!\">> \n- Cons パターンマッチなどの捜査の際に単純さが失われる \n- パターンマッチなどの捜査の際に単純さが失われる   > 4-5 パターンマッチング4-5 パターンマッチング \n\n4-5章からIDEがないとreplなどに時間がとられるので整備しておこう。Emacsならerlang.elがある。インデント、フィルコメント、コメントアウト、OTPなどのscafold、Eshell、コンパイル等ひととおりそろっている。   > 5.5. 関数呼び出しによるパターンマッチガードはcase文よりも優れているのか？5.5. 関数呼び出しによるパターンマッチガードはcase文よりも優れているのか？ \n\nまず、パフォーマンス上かわらない。 \n\nつぎに、引数が複数あるときは関数をつかう。   erlang \n\nbeach(Temperature) -> case Temperature of {celsius, N} when N > 20 andalso N =< 45 -> 'favorable'; {kelvin, N} when N >= 293 andalso N =< 318 -> 'scientifically favorable'; {fahrenheit, N} when N >= 68 andalso N =< 113 -> 'favorable in the US'; _ -> 'avoid beach' end.   \n\n上記のようだと可読性がさがる、冗長的。以下のように関数でまとめる。   erlang \n\nbeachf({celsius, N}) when N >= 20 andalso N =< 45 -> 'favorable'; beachf({kelvin, N}) when N >=293 andalso N =< 318 -> 'scientifically favorable'; beachf({fahrenheit, N}) when N >= 68 andalso N =< 113 -> 'favorable in the US'; beachf(_) -> 'avoid beach'.   \n\nただし、引数が評価関数の対象の場合はcase文が向いている。   erlang \n\nprepend(X, []) -> [X]; prepend(X, Set) -> case lists:member(X, Set) of true -> Set; false -> [X | Set] end.     > 6-11 文法6-11 文法 \n\n- 今回は標準文法について Erlangの特徴はざっと次の通り 型変換の関数が素朴 erlang:<type>_to_<type> という形式をとっているため、型が追加されるたびに変換用関数を BIF (built-in function) に追加しなければいけない 再帰、無名関数、エラーは普通、Ruby, JSっぽい レコードによってインターフェイスを定義できる データ構造にキーバリューストア、セット、配列、有効グラフ、キューがある ただ配列は、他の手続き型言語の配列とは逆に、一定時間での挿入や検索ができない Erlangでなされるプログラミングスタイルでは配列や行列と結びつける必要がなく、実際にはめったに使われないため \n- Erlangの特徴はざっと次の通り 型変換の関数が素朴 erlang:<type>_to_<type> という形式をとっているため、型が追加されるたびに変換用関数を BIF (built-in function) に追加しなければいけない 再帰、無名関数、エラーは普通、Ruby, JSっぽい レコードによってインターフェイスを定義できる データ構造にキーバリューストア、セット、配列、有効グラフ、キューがある ただ配列は、他の手続き型言語の配列とは逆に、一定時間での挿入や検索ができない Erlangでなされるプログラミングスタイルでは配列や行列と結びつける必要がなく、実際にはめったに使われないため \n- 型変換の関数が素朴 erlang:<type>_to_<type> という形式をとっているため、型が追加されるたびに変換用関数を BIF (built-in function) に追加しなければいけない \n- erlang:<type>_to_<type> という形式をとっているため、型が追加されるたびに変換用関数を BIF (built-in function) に追加しなければいけない\n- 再帰、無名関数、エラーは普通、Ruby, JSっぽい\n- レコードによってインターフェイスを定義できる\n- データ構造にキーバリューストア、セット、配列、有効グラフ、キューがある ただ配列は、他の手続き型言語の配列とは逆に、一定時間での挿入や検索ができない Erlangでなされるプログラミングスタイルでは配列や行列と結びつける必要がなく、実際にはめったに使われないため \n- ただ配列は、他の手続き型言語の配列とは逆に、一定時間での挿入や検索ができない Erlangでなされるプログラミングスタイルでは配列や行列と結びつける必要がなく、実際にはめったに使われないため \n- Erlangでなされるプログラミングスタイルでは配列や行列と結びつける必要がなく、実際にはめったに使われないため   > 7. 再帰7. 再帰 \n\n- lists モジュール sort/1 join/2 last/1 flatten/1 all/1 reverse/1 map/2 filter/2 \n- sort/1\n- join/2\n- last/1\n- flatten/1\n- all/1\n- reverse/1\n- map/2\n- filter/2\n- gb_tree モジュール lookup/2 map/2 \n- lookup/2\n- map/2   > 8.2. 無名関数8.2. 無名関数   erlang \n\n> (fun() -> a end)(). a > lists:filter(fun(X) -> X rem 2 == 0 end, lists:seq(1, 10)). [2,4,6,8,10]     > 9. エラー9. エラー コンパイル時エラー    type error description     Module Module name 'madule' does not match file name 'module'  -module 属性内に書いたモジュール名がファイル名と一致していない   Function Warning: function somefunction/0 is unused 関数を公開していない、あるいはその関数が使われている場所が間違った関数名やアリティになっている   Function function somefunction/1 undefined 関数が存在していない:  -export 属性内あるいは関数を宣言するときに間違った関数名やアリティを書いてる   Function head mismatch 関数定義を他の関数での先頭の節の間に差し込んでいる   Syntax syntax error before: 'SomeCharacterOrWord' Ex: 括弧の閉じ忘れやタプルやおかしな式接尾辞、予約語・おかしな文字コードにエンコードされたUnicode文字の使用   Syntax syntax error before: 行末がおかしい   Variable Warning: this expression will fail with a 'badarith' exception Ex: llama + 5    Variable Warning: a term is constructed, but never used 関数の中に、リス作成、タプル宣言、どんな変数にも束縛されていない無名関数・自身を返す無名関数の宣言がある   Variable Warning: variable 'Var' is unused 使わない変数を宣言している   Variable Warning: this clause cannot match because a previous clause at line 4 always matches モジュール内で定義された関数が catch-all 節のあとに特定の節を持っている   Variable variable 'A' unsafe in 'case'  case ... of の中で宣言されている変数を、その外側で使っている    ランタイムエラー (exception error)    type error description     function clause no function clause matching somefunction 関数内のすべてのガード節で失敗、あるいはすべてのパターンマッチで失敗   case clause no case clause matching 'value' 条件の書き忘れ、誤った種類のデータ送信、 catch-all 節が必要な場合   if clause no true branch found when evaluating an if expression 条件の書き忘れ、 catch-all 節が必要な場合   badmatch no match of right hand side value 無理なパターンマッチ、変数束縛の繰り返し   badarg bad argument 誤った引数の呼び出し   undef undefined function somefunction 未定義関数の呼び出し   badarith bad argument in an arithmetic expression 誤った算術演算   badfun bad function 変数を関数として呼び出した場合   badarity interpreted function with arity 1 called with two arguments 誤ったアリティ    例外処理   erlang \n\n1> erlang:error(badarith). ** exception error: bad argument in an arithmetic expression 2> erlang:error(custom_error). ** exception error: custom_error     > 11.2 レコード11.2 レコード   erlang \n\n-record(robot, {name, type=industrial, hobbies, details=[]}).     erlang \n\n5> Crusher = #robot{name=\"Crusher\", hobbies=[\"Crushing people\",\"petting cats\"]}. #robot{name = \"Crusher\",type = industrial, hobbies = [\"Crushing people\",\"petting cats\"], details = []} 6> Crusher#robot.hobbies. %% 参照 [\"Crushing people\",\"petting cats\"] 7> NestedBot = #robot{details=#robot{name=\"erNest\"}}. #robot{name = undefined,type = industrial, hobbies = undefined, details = #robot{name = \"erNest\",type = industrial, hobbies = undefined,details = []}} 8> NestedBot#robot.details#robot.name. %% ネスト参照 \"erNest\"     > 11.3. キーバリューストア11.3. キーバリューストア \n\nキーバリューストアは4つのモジュールで提供されている。    module methods description     proplist  get_value/2, get_all_values/2, lookup/2, lookup_all/2  少量データ向け, 緩いデータ構造   orddict  store/3, find/2, fetch/2, erase/2  少量データ向け（75要素くらい）   dict  store/3, find/2, fetch/2, erase/2, map/2, fold/2  大量データ向け、ordict と同じインターフェイス   gb_trees  enter/2, lookup/2, delete_any/2, insert/3, get/2, update/3, delete/2  大量データ向け、データ構造の入出力がわかるスマートモードとわからないネイティブモードがあるため状況に応じて安全性とパフォーマンスのバランスを取ることができる      > 11.5.セット11.5.セット \n\nセット（集合）は4つのモジュールで提供されている。    module methods description     ordsets  new/0, is_element/2, add_element/2, del_element/2, union/1, intersection/1  少量セット向け、遅いが可読性が高い   sets - 大量セット向け、ordsets と同じインターフェイス   gb_sets - 大量セット向け、スマートモード・ネイティブモードがあるため状況に応じ安全性とパフォーマンスのバランスを取ることができる   sofs - 一意な要素の集合だけではなく、数学的な概念として集合が必要な場合      > 11.6. 有効グラフ11.6. 有効グラフ \n\n有効グラフは2つのモジュールで提供されている。    module description     digraph 生成、変更、エッジ・辺の操作、経路・周の検索   digraph_utils グラフの誘導、木のテスト、隣接ノードの検索      > 11.7. キュー11.7. キュー \n\nqueue モジュール    api methods description     Original API  new/0, in/2, out/1  キューの作成・削除   Extended API  get/1, peek/1, drop/1  キューの中身の確認   Okasaki API - 関数型データ構造にもとづく      > 12-13 並列性について12-13 並列性について   > 12.2.1. 並列性の概念12.2.1. 並列性の概念 \n\n- Erlangの開発の背景 大抵の人は並行ソフトウェアを書くことにうんざりしてる 並行の解決策のほとんどがロックやミューテックスと呼ばれる小さな理論を扱うことに終始する 通信業界では並行性・並列性をめざす文化があった PLEX AXE \n- 大抵の人は並行ソフトウェアを書くことにうんざりしてる 並行の解決策のほとんどがロックやミューテックスと呼ばれる小さな理論を扱うことに終始する \n- 並行の解決策のほとんどがロックやミューテックスと呼ばれる小さな理論を扱うことに終始する\n- 通信業界では並行性・並列性をめざす文化があった PLEX AXE \n- PLEX\n- AXE\n- 満たすべき要求 スケーラビリティ リニアスケールが可能 実装方針 小さなプロセス プロセスに共有メモリの使用を禁じる フォールトレランス (交換機上の何千ものユーザをサポートすること) クラッシュが可能 クラッシュ後リスタートが可能 実装方針 分散 非同期メッセージングパッシング \n- スケーラビリティ リニアスケールが可能 実装方針 小さなプロセス プロセスに共有メモリの使用を禁じる \n- リニアスケールが可能\n- 実装方針 小さなプロセス プロセスに共有メモリの使用を禁じる \n- 小さなプロセス\n- プロセスに共有メモリの使用を禁じる\n- フォールトレランス (交換機上の何千ものユーザをサポートすること) クラッシュが可能 クラッシュ後リスタートが可能 実装方針 分散 非同期メッセージングパッシング \n- クラッシュが可能\n- クラッシュ後リスタートが可能\n- 実装方針 分散 非同期メッセージングパッシング \n- 分散\n- 非同期メッセージングパッシング\n- 実装 並列・並行に最適化されたVM コア1つに対してスケジューラとして1つのスケジューラを起動 実行キューにあるタスクが多すぎた場合、他スレッドのスケジューラに移される 過負荷なプロセスに対して送れるメッセージ量を制御 \n- 並列・並行に最適化されたVM コア1つに対してスケジューラとして1つのスケジューラを起動 実行キューにあるタスクが多すぎた場合、他スレッドのスケジューラに移される 過負荷なプロセスに対して送れるメッセージ量を制御 \n- コア1つに対してスケジューラとして1つのスケジューラを起動\n- 実行キューにあるタスクが多すぎた場合、他スレッドのスケジューラに移される\n- 過負荷なプロセスに対して送れるメッセージ量を制御   > 12.3. すべてが線形にスケールするわけではない12.3. すべてが線形にスケールするわけではない \n\n- アムダールの法則 50%並行にしたコードは2倍ほど速くなる 95%並行にしたコードは20倍ほど速くなる \n- 50%並行にしたコードは2倍ほど速くなる\n- 95%並行にしたコードは20倍ほど速くなる   > 14 プロセス間通信14 プロセス間通信 \n\n- 今回は2つのプロセス間通信のプロセス管理について 片方のプロセスがエラーになっても、もう片方のプロセスが死なないようにする プロセスがエラーになったものはクラッシュさせる クラッシュしたプロセスをリスタートさせる また、そのクラッシュ情報をもう片方にメッセージとして送る \n- 片方のプロセスがエラーになっても、もう片方のプロセスが死なないようにする プロセスがエラーになったものはクラッシュさせる クラッシュしたプロセスをリスタートさせる また、そのクラッシュ情報をもう片方にメッセージとして送る \n- プロセスがエラーになったものはクラッシュさせる クラッシュしたプロセスをリスタートさせる \n- クラッシュしたプロセスをリスタートさせる\n- また、そのクラッシュ情報をもう片方にメッセージとして送る   > エラーとプロセスエラーとプロセス \n\n以下、3つの関数をつかい実装する。 \n\n1. erlang:exit(Pid, Why) - Pid に対して自分が異常終了で死んだとつたえる。自身は死なない。\n2. erlang:process_flag(trap_exit, Value) - Value が true ならシステムプロセスとなり、 false ならシステムプロセスでなくなる。デフォルトは false。この関数によりクラッシュしたプロセスをリスタートさせる\n3. erlang:register(Atom, Pid) と erlang:make_ref() - register/2 で予測不可能な Pid を Atom として登録し、make_ref/0 で生成された Reference をもとにメッセージ送信をおこなう。なお、ここで生成される Reference は同一Erlang VM上、あるいはクラスタリングしたVM上のみでユニークになる。   erlang \n\nstart_critic2() -> spawn(?MODULE, restarter, []). restarter() -> process_flag(trap_exit, true), Pid = spawn_link(?MODULE, critic2, []), register(critic2, Pid), receive {'EXIT', Pid, normal} -> % not a crash  ok; {'EXIT', Pid, shutdown} -> % manual termination, not a crash  ok; {'EXIT', Pid, _} -> restarter() end. judge2(Band, Album) -> Ref = make_ref(), critic2 ! {self(), Ref, {Band, Album}}, receive {Ref, Criticism} -> Criticism after 2000 -> timeout end. critic2() -> receive {From, Ref, {\"Rage Against the Turing Machine\", \"Unit Testify\"}} -> From ! {Ref, \"They are great!\"}; {From, Ref, {\"System of a Downtime\", \"Memoize\"}} -> From ! {Ref, \"They're not Johnny Crash but they're good.\"}; {From, Ref, {\"Johnny Crash\", \"The Token Ring of Fire\"}} -> From ! {Ref, \"Simply incredible.\"}; {From, Ref, {_Band, _Album}} -> From ! {Ref, \"They are terrible!\"} end, critic2().     erlang \n\n27> functions:start_critic2(). <0.125.0> 28> functions:judge2(\"The Doors\", \"Light my Firewall\"). \"They are terrible!\" 29> exit(whereis(critic2), kill). true 30> whereis(critic2). <0.129.0> 31> functions:judge2(\"The Doors\", \"Light my Firewall\"). \"They are terrible!\"     > 15 アプリケーションを作成する15 アプリケーションを作成する   > リマインダーアプリケーションリマインダーアプリケーション \n\n- 仕様 イベントを追加 イベントには締切り（警告する時間）、イベント名、詳細が含まれます イベントの時間が来たら警告 イベント名でイベントをキャンセル 永続的なディスク保存先を持たない 注 これは今回見ようとしているのアーキテクチャの概念を示すのに必要ありません これは実際のアプリケーションを作るなら全然ダメなことですが、代わりにもし実装したくなったらその機能はどこに挿入されるかを示して、ちょっとだけその実装の手助けになる関数も示します 永続化保存先がないとした場合、実行中にコードを更新しなければいけません ソフトウェアとのやりとりはコマンドライン経由で あとでこれは拡張できる たとえばGUI、Webページアクセス、IMソフト、メールなど \n- イベントを追加 イベントには締切り（警告する時間）、イベント名、詳細が含まれます \n- イベントには締切り（警告する時間）、イベント名、詳細が含まれます\n- イベントの時間が来たら警告\n- イベント名でイベントをキャンセル\n- 永続的なディスク保存先を持たない 注 これは今回見ようとしているのアーキテクチャの概念を示すのに必要ありません これは実際のアプリケーションを作るなら全然ダメなことですが、代わりにもし実装したくなったらその機能はどこに挿入されるかを示して、ちょっとだけその実装の手助けになる関数も示します 永続化保存先がないとした場合、実行中にコードを更新しなければいけません \n- 注 これは今回見ようとしているのアーキテクチャの概念を示すのに必要ありません これは実際のアプリケーションを作るなら全然ダメなことですが、代わりにもし実装したくなったらその機能はどこに挿入されるかを示して、ちょっとだけその実装の手助けになる関数も示します \n- これは今回見ようとしているのアーキテクチャの概念を示すのに必要ありません\n- これは実際のアプリケーションを作るなら全然ダメなことですが、代わりにもし実装したくなったらその機能はどこに挿入されるかを示して、ちょっとだけその実装の手助けになる関数も示します\n- 永続化保存先がないとした場合、実行中にコードを更新しなければいけません\n- ソフトウェアとのやりとりはコマンドライン経由で あとでこれは拡張できる たとえばGUI、Webページアクセス、IMソフト、メールなど \n- あとでこれは拡張できる たとえばGUI、Webページアクセス、IMソフト、メールなど \n- たとえばGUI、Webページアクセス、IMソフト、メールなど\n- ユースケース Client イベントサーバをサブスクライブして、メッセージとして通知を受ける こうすることで、すべてイベントサーバをサブスクライブしている多くのクライアントを設計するのが簡単になる 各クライアントは潜在的に、前述した異なるゲートウェイとなる GUI、Webページ、IMソフト、メールなど サーバにイベントを詳細情報とともに追加するように依頼 サーバにイベントをキャンセルするように依頼 サーバを（落ちたかどうか知る為に）監視 必要があればイベントサーバを終了 Event Server メソッド クライアントからのサブスクライブを受取 イベントプロセスから出された通知を各サブスクライバに転送 イベントを追加するためにメッセージを受取 必要なX, Y, Zプロセスを起動 イベントキャンセルのメッセージを受取 イベントプロセスを殺す クライアントから終了できる シェルから自分自身のコードを再読込出来る Process X, Y, Z 発報が待たれる通知を表す 天気にはイベントサーバにリンクされたタイマーに過ぎない 時間が来たらイベントサーバにメッセージを送る キャンセルのメッセージを受け取って死ぬ \n- Client イベントサーバをサブスクライブして、メッセージとして通知を受ける こうすることで、すべてイベントサーバをサブスクライブしている多くのクライアントを設計するのが簡単になる 各クライアントは潜在的に、前述した異なるゲートウェイとなる GUI、Webページ、IMソフト、メールなど サーバにイベントを詳細情報とともに追加するように依頼 サーバにイベントをキャンセルするように依頼 サーバを（落ちたかどうか知る為に）監視 必要があればイベントサーバを終了 \n- イベントサーバをサブスクライブして、メッセージとして通知を受ける こうすることで、すべてイベントサーバをサブスクライブしている多くのクライアントを設計するのが簡単になる 各クライアントは潜在的に、前述した異なるゲートウェイとなる GUI、Webページ、IMソフト、メールなど \n- こうすることで、すべてイベントサーバをサブスクライブしている多くのクライアントを設計するのが簡単になる\n- 各クライアントは潜在的に、前述した異なるゲートウェイとなる GUI、Webページ、IMソフト、メールなど \n- GUI、Webページ、IMソフト、メールなど\n- サーバにイベントを詳細情報とともに追加するように依頼\n- サーバにイベントをキャンセルするように依頼\n- サーバを（落ちたかどうか知る為に）監視\n- 必要があればイベントサーバを終了\n- Event Server メソッド クライアントからのサブスクライブを受取 イベントプロセスから出された通知を各サブスクライバに転送 イベントを追加するためにメッセージを受取 必要なX, Y, Zプロセスを起動 イベントキャンセルのメッセージを受取 イベントプロセスを殺す クライアントから終了できる シェルから自分自身のコードを再読込出来る Process X, Y, Z 発報が待たれる通知を表す 天気にはイベントサーバにリンクされたタイマーに過ぎない 時間が来たらイベントサーバにメッセージを送る キャンセルのメッセージを受け取って死ぬ \n- メソッド クライアントからのサブスクライブを受取 イベントプロセスから出された通知を各サブスクライバに転送 イベントを追加するためにメッセージを受取 必要なX, Y, Zプロセスを起動 イベントキャンセルのメッセージを受取 イベントプロセスを殺す クライアントから終了できる シェルから自分自身のコードを再読込出来る \n- クライアントからのサブスクライブを受取\n- イベントプロセスから出された通知を各サブスクライバに転送\n- イベントを追加するためにメッセージを受取 必要なX, Y, Zプロセスを起動 \n- 必要なX, Y, Zプロセスを起動\n- イベントキャンセルのメッセージを受取 イベントプロセスを殺す \n- イベントプロセスを殺す\n- クライアントから終了できる\n- シェルから自分自身のコードを再読込出来る\n- Process X, Y, Z 発報が待たれる通知を表す 天気にはイベントサーバにリンクされたタイマーに過ぎない 時間が来たらイベントサーバにメッセージを送る キャンセルのメッセージを受け取って死ぬ \n- 発報が待たれる通知を表す 天気にはイベントサーバにリンクされたタイマーに過ぎない \n- 天気にはイベントサーバにリンクされたタイマーに過ぎない\n- 時間が来たらイベントサーバにメッセージを送る\n- キャンセルのメッセージを受け取って死ぬ\n- 実装 ディレクトリ構成 ebin/ include/ priv/ src/ event.erl - event module loop/1 normalize/1 start/2 start_link/2 cancel/1 time_to_go/1 init/3 evserv.erl - event server loop/1 valid_datetime/1 valid_time/1 valid_time/3 send_to_clients/2 start/0 start_link/0 terminate/0 subscribe/1 add_event/3 add_event2/3 cancel/1 listen/1 init/0 sup.erl - supervisor start/2 start_link/2 init/1 loop/1 Emakefile{'src/*', [debug_info, {i, \"src\"}, {i, \"include\"}, {outdir, \"ebin\"}]}. \n- ディレクトリ構成 ebin/ include/ priv/ src/ event.erl - event module loop/1 normalize/1 start/2 start_link/2 cancel/1 time_to_go/1 init/3 evserv.erl - event server loop/1 valid_datetime/1 valid_time/1 valid_time/3 send_to_clients/2 start/0 start_link/0 terminate/0 subscribe/1 add_event/3 add_event2/3 cancel/1 listen/1 init/0 sup.erl - supervisor start/2 start_link/2 init/1 loop/1 Emakefile{'src/*', [debug_info, {i, \"src\"}, {i, \"include\"}, {outdir, \"ebin\"}]}. \n- ebin/\n- include/\n- priv/\n- src/ event.erl - event module loop/1 normalize/1 start/2 start_link/2 cancel/1 time_to_go/1 init/3 evserv.erl - event server loop/1 valid_datetime/1 valid_time/1 valid_time/3 send_to_clients/2 start/0 start_link/0 terminate/0 subscribe/1 add_event/3 add_event2/3 cancel/1 listen/1 init/0 sup.erl - supervisor start/2 start_link/2 init/1 loop/1 \n- event.erl - event module loop/1 normalize/1 start/2 start_link/2 cancel/1 time_to_go/1 init/3 \n- loop/1\n- normalize/1\n- start/2\n- start_link/2\n- cancel/1\n- time_to_go/1\n- init/3\n- evserv.erl - event server loop/1 valid_datetime/1 valid_time/1 valid_time/3 send_to_clients/2 start/0 start_link/0 terminate/0 subscribe/1 add_event/3 add_event2/3 cancel/1 listen/1 init/0 \n- loop/1\n- valid_datetime/1\n- valid_time/1\n- valid_time/3\n- send_to_clients/2\n- start/0\n- start_link/0\n- terminate/0\n- subscribe/1\n- add_event/3\n- add_event2/3\n- cancel/1\n- listen/1\n- init/0\n- sup.erl - supervisor start/2 start_link/2 init/1 loop/1 \n- start/2\n- start_link/2\n- init/1\n- loop/1\n- Emakefile{'src/*', [debug_info, {i, \"src\"}, {i, \"include\"}, {outdir, \"ebin\"}]}.    sh \n\n$ erl -make && erl -pa ebin/ Erlang/OTP 19 [erts-8.1] [source] [64-bit] [smp:2:2] [async-threads:10] [kernel-poll:false] Eshell V8.1 (abort with ^G) 1> evserv:start(). <0.59.0> 2> evserv:subscribe(self()). {ok,#Ref<0.0.2.84>} 3> evserv:add_event(\"Hey there3\", \"test\", { {2017, 7, 9}, {1, 23, 59} }). ok 4> evserv:listen(2000). [{done,\"Hey there3\",\"test\"}]     > TIPSTIPS \n\n- Erlangのタイムアウト値はミリ秒でおよそ50日に制限されている   > 16 OTP16 OTP   > OTPとはなにかOTPとはなにか \n\n- Erlangの特徴 並列・分散 エラー処理 \n- 並列・分散\n- エラー処理\n- 組込関数 リンク モニター タイムアウト 終了の補足 \n- リンク\n- モニター\n- タイムアウト\n- 終了の補足\n- OTP 下記のようなバグになりやすい箇所をモジュールとして吸収 プロセスの順番 競合条件をどのように避けるか プロセスはいつでも死ぬ可能性があること ホットコードローディング 名前付きプロセス Supervisor Pros バグを解決するための時間を大幅に減らせる 個々のモジュールのテストが行いやすい 個々のモジュールの最適化が利用者全員の恩恵となる \n- 下記のようなバグになりやすい箇所をモジュールとして吸収 プロセスの順番 競合条件をどのように避けるか プロセスはいつでも死ぬ可能性があること ホットコードローディング 名前付きプロセス Supervisor \n- プロセスの順番\n- 競合条件をどのように避けるか プロセスはいつでも死ぬ可能性があること \n- プロセスはいつでも死ぬ可能性があること\n- ホットコードローディング\n- 名前付きプロセス\n- Supervisor\n- Pros バグを解決するための時間を大幅に減らせる 個々のモジュールのテストが行いやすい 個々のモジュールの最適化が利用者全員の恩恵となる \n- バグを解決するための時間を大幅に減らせる\n- 個々のモジュールのテストが行いやすい\n- 個々のモジュールの最適化が利用者全員の恩恵となる   > 17 gen_server17 gen_server \n\n今回はよくつかわれるビヘイビア gen_server 。この汎用化によって、メンテナンス、コードの単純化、テストの簡易化へとつながる。下記に gen_server のコールバックの概要を記す。   > クライアントとサーバクライアントとサーバ \n\n- gen_server init/1 Return {ok, State} {ok, State, TimeOut} {ok, State, hibernate} {stop, Reason} ignore handle_call/3 Params Request, From, State Return {reply, Reply, NewState} {reply, Reply, NewState, Timeout} {reply, Reply, NewState, hibernate} {noreply, NewState} {noreply, NewState, Timeout} {noreply, NewState, hibernate} {stop, Reason, Reply, NewState} {stop, Reason, NewState} handle_cast/2 Params Message, State Return {noreply, NewState} {noreply, NewState, Timeout} {noreply, NewState, hibernate} {stop, Reason, NewState} handle_info/2 Callback case bang operator (!) TimeOut モニター通知 'EXIT' シグナル Params Message, State Return {noreply, NewState} {noreply, NewState, Timeout} {noreply, NewState, hibernate} {stop, Reason, NewState} terminate/2 Callback case handle_* 関数の返値 {stop, Reason, NewState} {stop, Reason, Reply, NewState} 親が死んで、gen_serverが終了を補足していた場合 Params Reason, State Return init/1 の反対 VMがETS (erlang term storage) を削除 code_change/3 Params PreviousVersion {down, Version} State {ok, NewState} Extra \n- init/1 Return {ok, State} {ok, State, TimeOut} {ok, State, hibernate} {stop, Reason} ignore \n- Return {ok, State} {ok, State, TimeOut} {ok, State, hibernate} {stop, Reason} ignore \n- {ok, State}\n- {ok, State, TimeOut}\n- {ok, State, hibernate}\n- {stop, Reason}\n- ignore\n- handle_call/3 Params Request, From, State Return {reply, Reply, NewState} {reply, Reply, NewState, Timeout} {reply, Reply, NewState, hibernate} {noreply, NewState} {noreply, NewState, Timeout} {noreply, NewState, hibernate} {stop, Reason, Reply, NewState} {stop, Reason, NewState} \n- Params Request, From, State \n- Request, From, State\n- Return {reply, Reply, NewState} {reply, Reply, NewState, Timeout} {reply, Reply, NewState, hibernate} {noreply, NewState} {noreply, NewState, Timeout} {noreply, NewState, hibernate} {stop, Reason, Reply, NewState} {stop, Reason, NewState} \n- {reply, Reply, NewState}\n- {reply, Reply, NewState, Timeout}\n- {reply, Reply, NewState, hibernate}\n- {noreply, NewState}\n- {noreply, NewState, Timeout}\n- {noreply, NewState, hibernate}\n- {stop, Reason, Reply, NewState}\n- {stop, Reason, NewState}\n- handle_cast/2 Params Message, State Return {noreply, NewState} {noreply, NewState, Timeout} {noreply, NewState, hibernate} {stop, Reason, NewState} \n- Params Message, State \n- Message, State\n- Return {noreply, NewState} {noreply, NewState, Timeout} {noreply, NewState, hibernate} {stop, Reason, NewState} \n- {noreply, NewState}\n- {noreply, NewState, Timeout}\n- {noreply, NewState, hibernate}\n- {stop, Reason, NewState}\n- handle_info/2 Callback case bang operator (!) TimeOut モニター通知 'EXIT' シグナル Params Message, State Return {noreply, NewState} {noreply, NewState, Timeout} {noreply, NewState, hibernate} {stop, Reason, NewState} \n- Callback case bang operator (!) TimeOut モニター通知 'EXIT' シグナル \n- bang operator (!)\n- TimeOut\n- モニター通知\n- 'EXIT' シグナル\n- Params Message, State \n- Message, State\n- Return {noreply, NewState} {noreply, NewState, Timeout} {noreply, NewState, hibernate} {stop, Reason, NewState} \n- {noreply, NewState}\n- {noreply, NewState, Timeout}\n- {noreply, NewState, hibernate}\n- {stop, Reason, NewState}\n- terminate/2 Callback case handle_* 関数の返値 {stop, Reason, NewState} {stop, Reason, Reply, NewState} 親が死んで、gen_serverが終了を補足していた場合 Params Reason, State Return init/1 の反対 VMがETS (erlang term storage) を削除 \n- Callback case handle_* 関数の返値 {stop, Reason, NewState} {stop, Reason, Reply, NewState} 親が死んで、gen_serverが終了を補足していた場合 \n- handle_* 関数の返値 {stop, Reason, NewState} {stop, Reason, Reply, NewState} \n- {stop, Reason, NewState}\n- {stop, Reason, Reply, NewState}\n- 親が死んで、gen_serverが終了を補足していた場合\n- Params Reason, State \n- Reason, State\n- Return init/1 の反対 VMがETS (erlang term storage) を削除 \n- init/1 の反対\n- VMがETS (erlang term storage) を削除\n- code_change/3 Params PreviousVersion {down, Version} State {ok, NewState} Extra \n- Params PreviousVersion {down, Version} State {ok, NewState} Extra \n- PreviousVersion {down, Version} \n- {down, Version}\n- State {ok, NewState} \n- {ok, NewState}\n- Extra   > 18 gen_fsm18 gen_fsm \n\n今回は有限ステートマシン (finite state machine)。ビヘイビア gen_fsm をとりあげる。このビヘイビアは gen_server に基本似た挙動をするが、呼び出しやメッセージ投入をあつかうのではなく同期や非同期のイベントをあつう。   > 18.1. 有限ステートマシン18.1. 有限ステートマシン \n\n- 状態遷移図 (state diagram) による記述\n- シーケンス図による記述\n- gen_fsm init/1 Return {ok, StateName, Data} {ok, StateName, Data, Timeout} {ok, StateName, Data, hibernate} {stop, Reason} StateName/2 非同期イベント Params Event, StateData Return {next_state, NextStateName, NewData} {next_state, NextStateName, NewData, Timeout} {next_state, NextStateName, hibernate} {stop, Reason, Data} StateName/3 同期イベント Params Event, From, StateData Return {reply, Reply, NextStateName, NewStateData} {reply, Reply, NextStateName, NewStateData, Timeout} {reply, Reply, NextStateName, NewStateData, hibernate} {next_state, NextStateName, NewStateData} {next_state, NextStateName, NewStateData, Timeout} {next_state, NextStateName, NewStateData, hibernate} {stop, Reason, Reply, NewStateData} {stop, Reason, NewStateData} handle_event/3 非同期イベント、グローバルイベント Params Event, StateData Return {next_state, NextStateName, NewData} {next_state, NextStateName, NewData, Timeout} {next_state, NextStateName, hibernate} {stop, Reason, Data} handle_sync_event/4 同期イベント、グローバルイベント Params Event, From, StateData Return {reply, Reply, NextStateName, NewStateData} {reply, Reply, NextStateName, NewStateData, Timeout} {reply, Reply, NextStateName, NewStateData, hibernate} {next_state, NextStateName, NewStateData} {next_state, NextStateName, NewStateData, Timeout} {next_state, NextStateName, NewStateData, hibernate} {stop, Reason, Reply, NewStateData} {stop, Reason, NewStateData} code_change/4 Params OldVersion, StateName, Data, Extra Return {ok, NextStateName, NewStateData} terminate/3 init/1 と逆の挙動をする \n- init/1 Return {ok, StateName, Data} {ok, StateName, Data, Timeout} {ok, StateName, Data, hibernate} {stop, Reason} \n- Return {ok, StateName, Data} {ok, StateName, Data, Timeout} {ok, StateName, Data, hibernate} {stop, Reason} \n- {ok, StateName, Data}\n- {ok, StateName, Data, Timeout}\n- {ok, StateName, Data, hibernate}\n- {stop, Reason}\n- StateName/2 非同期イベント Params Event, StateData Return {next_state, NextStateName, NewData} {next_state, NextStateName, NewData, Timeout} {next_state, NextStateName, hibernate} {stop, Reason, Data} \n- 非同期イベント\n- Params Event, StateData \n- Event, StateData\n- Return {next_state, NextStateName, NewData} {next_state, NextStateName, NewData, Timeout} {next_state, NextStateName, hibernate} {stop, Reason, Data} \n- {next_state, NextStateName, NewData}\n- {next_state, NextStateName, NewData, Timeout}\n- {next_state, NextStateName, hibernate}\n- {stop, Reason, Data}\n- StateName/3 同期イベント Params Event, From, StateData Return {reply, Reply, NextStateName, NewStateData} {reply, Reply, NextStateName, NewStateData, Timeout} {reply, Reply, NextStateName, NewStateData, hibernate} {next_state, NextStateName, NewStateData} {next_state, NextStateName, NewStateData, Timeout} {next_state, NextStateName, NewStateData, hibernate} {stop, Reason, Reply, NewStateData} {stop, Reason, NewStateData} \n- 同期イベント\n- Params Event, From, StateData \n- Event, From, StateData\n- Return {reply, Reply, NextStateName, NewStateData} {reply, Reply, NextStateName, NewStateData, Timeout} {reply, Reply, NextStateName, NewStateData, hibernate} {next_state, NextStateName, NewStateData} {next_state, NextStateName, NewStateData, Timeout} {next_state, NextStateName, NewStateData, hibernate} {stop, Reason, Reply, NewStateData} {stop, Reason, NewStateData} \n- {reply, Reply, NextStateName, NewStateData}\n- {reply, Reply, NextStateName, NewStateData, Timeout}\n- {reply, Reply, NextStateName, NewStateData, hibernate}\n- {next_state, NextStateName, NewStateData}\n- {next_state, NextStateName, NewStateData, Timeout}\n- {next_state, NextStateName, NewStateData, hibernate}\n- {stop, Reason, Reply, NewStateData}\n- {stop, Reason, NewStateData}\n- handle_event/3 非同期イベント、グローバルイベント Params Event, StateData Return {next_state, NextStateName, NewData} {next_state, NextStateName, NewData, Timeout} {next_state, NextStateName, hibernate} {stop, Reason, Data} \n- 非同期イベント、グローバルイベント\n- Params Event, StateData \n- Event, StateData\n- Return {next_state, NextStateName, NewData} {next_state, NextStateName, NewData, Timeout} {next_state, NextStateName, hibernate} {stop, Reason, Data} \n- {next_state, NextStateName, NewData}\n- {next_state, NextStateName, NewData, Timeout}\n- {next_state, NextStateName, hibernate}\n- {stop, Reason, Data}\n- handle_sync_event/4 同期イベント、グローバルイベント Params Event, From, StateData Return {reply, Reply, NextStateName, NewStateData} {reply, Reply, NextStateName, NewStateData, Timeout} {reply, Reply, NextStateName, NewStateData, hibernate} {next_state, NextStateName, NewStateData} {next_state, NextStateName, NewStateData, Timeout} {next_state, NextStateName, NewStateData, hibernate} {stop, Reason, Reply, NewStateData} {stop, Reason, NewStateData} \n- 同期イベント、グローバルイベント\n- Params Event, From, StateData \n- Event, From, StateData\n- Return {reply, Reply, NextStateName, NewStateData} {reply, Reply, NextStateName, NewStateData, Timeout} {reply, Reply, NextStateName, NewStateData, hibernate} {next_state, NextStateName, NewStateData} {next_state, NextStateName, NewStateData, Timeout} {next_state, NextStateName, NewStateData, hibernate} {stop, Reason, Reply, NewStateData} {stop, Reason, NewStateData} \n- {reply, Reply, NextStateName, NewStateData}\n- {reply, Reply, NextStateName, NewStateData, Timeout}\n- {reply, Reply, NextStateName, NewStateData, hibernate}\n- {next_state, NextStateName, NewStateData}\n- {next_state, NextStateName, NewStateData, Timeout}\n- {next_state, NextStateName, NewStateData, hibernate}\n- {stop, Reason, Reply, NewStateData}\n- {stop, Reason, NewStateData}\n- code_change/4 Params OldVersion, StateName, Data, Extra Return {ok, NextStateName, NewStateData} \n- Params OldVersion, StateName, Data, Extra \n- OldVersion, StateName, Data, Extra\n- Return {ok, NextStateName, NewStateData} \n- {ok, NextStateName, NewStateData}\n- terminate/3 init/1 と逆の挙動をする \n- init/1 と逆の挙動をする\n- イベント送信関数 ローカル send_event/2 sync_send_event/2-3 グローバル send_all_state_event/2-3 sync_send_event/2-3 \n- ローカル send_event/2 sync_send_event/2-3 \n- send_event/2\n- sync_send_event/2-3\n- グローバル send_all_state_event/2-3 sync_send_event/2-3 \n- send_all_state_event/2-3\n- sync_send_event/2-3   > 18.2. ユーザー同士の取引システム例18.2. ユーザー同士の取引システム例 \n\n- \n-    > 19 gen_event19 gen_event \n\n今回はイベントハンドラ。ビヘイビアは gen_event をつかう。 \n\n- 人々（あるいは、あるプロセスやアプリケーション）にイベントが起きたことを知らせる機能の実装方法 単純出力方式 結果を出力するのみ 単純サブスクライバ方式 メッセージ送信前にサブスクライバのPidを取得 Cons コールバックのために待機プロセスが必要 イベントマネージャ方式 関数をうけとるプロセスをたて、すべてのイベントに対して当該関数をはしらせる Pros サーバのサブスクライバがたくさんあっても稼働し続けられる すべてのコールバックは同じインスタンスで操作される 短命なタスクに対して新しいプロセスを生成する必要がない Cons 関数が長時間動作する必要があった場合、お互いブロックしあう イベントマネージャをイベントフォワーダにすれば防ぐことができる 無限ループする関数はクラッシュするまで新規イベントをブロックする \n- 単純出力方式 結果を出力するのみ \n- 結果を出力するのみ\n- 単純サブスクライバ方式 メッセージ送信前にサブスクライバのPidを取得 Cons コールバックのために待機プロセスが必要 \n- メッセージ送信前にサブスクライバのPidを取得\n- Cons コールバックのために待機プロセスが必要 \n- コールバックのために待機プロセスが必要\n- イベントマネージャ方式 関数をうけとるプロセスをたて、すべてのイベントに対して当該関数をはしらせる Pros サーバのサブスクライバがたくさんあっても稼働し続けられる すべてのコールバックは同じインスタンスで操作される 短命なタスクに対して新しいプロセスを生成する必要がない Cons 関数が長時間動作する必要があった場合、お互いブロックしあう イベントマネージャをイベントフォワーダにすれば防ぐことができる 無限ループする関数はクラッシュするまで新規イベントをブロックする \n- 関数をうけとるプロセスをたて、すべてのイベントに対して当該関数をはしらせる\n- Pros サーバのサブスクライバがたくさんあっても稼働し続けられる すべてのコールバックは同じインスタンスで操作される 短命なタスクに対して新しいプロセスを生成する必要がない \n- サーバのサブスクライバがたくさんあっても稼働し続けられる\n- すべてのコールバックは同じインスタンスで操作される\n- 短命なタスクに対して新しいプロセスを生成する必要がない\n- Cons 関数が長時間動作する必要があった場合、お互いブロックしあう イベントマネージャをイベントフォワーダにすれば防ぐことができる 無限ループする関数はクラッシュするまで新規イベントをブロックする \n- 関数が長時間動作する必要があった場合、お互いブロックしあう イベントマネージャをイベントフォワーダにすれば防ぐことができる \n- イベントマネージャをイベントフォワーダにすれば防ぐことができる\n- 無限ループする関数はクラッシュするまで新規イベントをブロックする   > 19.2. 汎用イベントハンドラ gen_event19.2. 汎用イベントハンドラ gen_event  \n\n- gen_event の各関数 init/1 Response {ok, State} terminate/2 handle_event/2 非同期 すべてのイベントマネージャは戻り値を返さないことで呼び出しプロセスをブロックする Params Event, State Response {ok, NewState} gen_server:handle_cast/2 と似た動作 {ok, NewState, hibernate} {remove_handler} イベントマネージャからハンドラを削除する {swap_handler, Args1, NewState, NewHandler, Args2} 今あるイベントハンドラを削除して新しいものに置き換える notify/2 すべての流入イベントを通知する (非同期) sync_notify/2 すべての流入イベントを通知する (同期) cast/2 非同期 handle_call gen_server:handle_call コールバックに似ているがレスポンスが異なる gen_server:call/3-4 が呼び出しに使われている Response {ok, Reply, NewState} {ok, Reply, NewState, hibernate} {remove_handler, Reply} {swap_handler, Reply, Args1, NewState, Handle_Call} handle_info/2 hendle_event と同じレスポンスだが、終了シグナルや ! 演算子でイベントマネージャに贈られたメッセージのみを扱う点で異なる code_change/3 gen_server:code_change と同じ動作をする Params OldVsn バージョン番号, State ハンドラの状態, Extra Response {ok, NewState} \n- init/1 Response {ok, State} \n- Response {ok, State} \n- {ok, State}\n- terminate/2\n- handle_event/2 非同期 すべてのイベントマネージャは戻り値を返さないことで呼び出しプロセスをブロックする Params Event, State Response {ok, NewState} gen_server:handle_cast/2 と似た動作 {ok, NewState, hibernate} {remove_handler} イベントマネージャからハンドラを削除する {swap_handler, Args1, NewState, NewHandler, Args2} 今あるイベントハンドラを削除して新しいものに置き換える \n- 非同期 すべてのイベントマネージャは戻り値を返さないことで呼び出しプロセスをブロックする \n- すべてのイベントマネージャは戻り値を返さないことで呼び出しプロセスをブロックする\n- Params Event, State \n- Event, State\n- Response {ok, NewState} gen_server:handle_cast/2 と似た動作 {ok, NewState, hibernate} {remove_handler} イベントマネージャからハンドラを削除する {swap_handler, Args1, NewState, NewHandler, Args2} 今あるイベントハンドラを削除して新しいものに置き換える \n- {ok, NewState} gen_server:handle_cast/2 と似た動作 \n- gen_server:handle_cast/2 と似た動作\n- {ok, NewState, hibernate}\n- {remove_handler} イベントマネージャからハンドラを削除する \n- イベントマネージャからハンドラを削除する\n- {swap_handler, Args1, NewState, NewHandler, Args2} 今あるイベントハンドラを削除して新しいものに置き換える \n- 今あるイベントハンドラを削除して新しいものに置き換える\n- notify/2 すべての流入イベントを通知する (非同期) \n- すべての流入イベントを通知する (非同期)\n- sync_notify/2 すべての流入イベントを通知する (同期) \n- すべての流入イベントを通知する (同期)\n- cast/2 非同期 \n- 非同期\n- handle_call gen_server:handle_call コールバックに似ているがレスポンスが異なる gen_server:call/3-4 が呼び出しに使われている Response {ok, Reply, NewState} {ok, Reply, NewState, hibernate} {remove_handler, Reply} {swap_handler, Reply, Args1, NewState, Handle_Call} \n- gen_server:handle_call コールバックに似ているがレスポンスが異なる\n- gen_server:call/3-4 が呼び出しに使われている\n- Response {ok, Reply, NewState} {ok, Reply, NewState, hibernate} {remove_handler, Reply} {swap_handler, Reply, Args1, NewState, Handle_Call} \n- {ok, Reply, NewState}\n- {ok, Reply, NewState, hibernate}\n- {remove_handler, Reply}\n- {swap_handler, Reply, Args1, NewState, Handle_Call}\n- handle_info/2 hendle_event と同じレスポンスだが、終了シグナルや ! 演算子でイベントマネージャに贈られたメッセージのみを扱う点で異なる \n- hendle_event と同じレスポンスだが、終了シグナルや ! 演算子でイベントマネージャに贈られたメッセージのみを扱う点で異なる\n- code_change/3 gen_server:code_change と同じ動作をする Params OldVsn バージョン番号, State ハンドラの状態, Extra Response {ok, NewState} \n- gen_server:code_change と同じ動作をする\n- Params OldVsn バージョン番号, State ハンドラの状態, Extra \n- OldVsn バージョン番号, State ハンドラの状態, Extra\n- Response {ok, NewState} \n- {ok, NewState}   > 20 supervisor20 supervisor \n\n今回のビヘイビアはスーパバイザ supervisor。 監視戦略の概要にふれてみる。 \n\n- init/1 レスポンス {ok, { {RestartStrategy, MaxRestart, MaxTime}, [{ChildId, StartFunc, Restart, Shutdown, Type, Modules}] } }. 例 {ok, { {one_for_all, 5, 60}, [ {fake_id, {fake_mod, start_link, [SomeArg]}, permanent, 5000, worker, [fake_mod]}, {other_id, {event_manager_mod, start_link, []}, transient, infinity, worker, dynamic} ] } }. 再起動戦略 one_for_one 1つのワーカがクラッシュしたら当該ワーカを再起動する 各々のワーカが独立している、互いが関係していない、あるいは、ワーカが再起動して状態が消えても隣のワーカに影響を与えない場合につかう one_for_all 1つのワーカがクラッシュしたらすべてのワーカをクラッシュさせて再起動する 各々のワーカが互いに強く依存している場合につかう rest_for_one 1つのワーカがクラッシュした当該ワーカのら子ワーカたちをクラッシュさせて再起動する 各々のワーカがチェーン状態に依存している場合につかう simple_one_for_one one_for_one はワーカのリストを起動した順で保持している一方 、simple_one_for_one はワーカへの定義を dict で保持している 再起動制限 MaxTime 秒以内に MaxRestart 回起動したら、スーパバイザは再起動をやめて自身をシャットダウンする ワーカ (子プロセス) 構成要素 ChildId StartFunc スーパバイザの起動方法をつたえるためのタプル {M, F, A} Restart 再起動戦略 permanent 常に再起動 temporary 再起動しない transient 正常終了の場合は再起動しない 異常終了の場合は再起動する Shutdown 終了期限 Type 子プロセスの種類 ワーカ スーパバイザ Modules コールバックモジュールのリスト \n- レスポンス {ok, { {RestartStrategy, MaxRestart, MaxTime}, [{ChildId, StartFunc, Restart, Shutdown, Type, Modules}] } }. 例 {ok, { {one_for_all, 5, 60}, [ {fake_id, {fake_mod, start_link, [SomeArg]}, permanent, 5000, worker, [fake_mod]}, {other_id, {event_manager_mod, start_link, []}, transient, infinity, worker, dynamic} ] } }. 再起動戦略 one_for_one 1つのワーカがクラッシュしたら当該ワーカを再起動する 各々のワーカが独立している、互いが関係していない、あるいは、ワーカが再起動して状態が消えても隣のワーカに影響を与えない場合につかう one_for_all 1つのワーカがクラッシュしたらすべてのワーカをクラッシュさせて再起動する 各々のワーカが互いに強く依存している場合につかう rest_for_one 1つのワーカがクラッシュした当該ワーカのら子ワーカたちをクラッシュさせて再起動する 各々のワーカがチェーン状態に依存している場合につかう simple_one_for_one one_for_one はワーカのリストを起動した順で保持している一方 、simple_one_for_one はワーカへの定義を dict で保持している 再起動制限 MaxTime 秒以内に MaxRestart 回起動したら、スーパバイザは再起動をやめて自身をシャットダウンする ワーカ (子プロセス) 構成要素 ChildId StartFunc スーパバイザの起動方法をつたえるためのタプル {M, F, A} Restart 再起動戦略 permanent 常に再起動 temporary 再起動しない transient 正常終了の場合は再起動しない 異常終了の場合は再起動する Shutdown 終了期限 Type 子プロセスの種類 ワーカ スーパバイザ Modules コールバックモジュールのリスト \n- {ok, { {RestartStrategy, MaxRestart, MaxTime}, [{ChildId, StartFunc, Restart, Shutdown, Type, Modules}] } }. 例 {ok, { {one_for_all, 5, 60}, [ {fake_id, {fake_mod, start_link, [SomeArg]}, permanent, 5000, worker, [fake_mod]}, {other_id, {event_manager_mod, start_link, []}, transient, infinity, worker, dynamic} ] } }. 再起動戦略 one_for_one 1つのワーカがクラッシュしたら当該ワーカを再起動する 各々のワーカが独立している、互いが関係していない、あるいは、ワーカが再起動して状態が消えても隣のワーカに影響を与えない場合につかう one_for_all 1つのワーカがクラッシュしたらすべてのワーカをクラッシュさせて再起動する 各々のワーカが互いに強く依存している場合につかう rest_for_one 1つのワーカがクラッシュした当該ワーカのら子ワーカたちをクラッシュさせて再起動する 各々のワーカがチェーン状態に依存している場合につかう simple_one_for_one one_for_one はワーカのリストを起動した順で保持している一方 、simple_one_for_one はワーカへの定義を dict で保持している 再起動制限 MaxTime 秒以内に MaxRestart 回起動したら、スーパバイザは再起動をやめて自身をシャットダウンする ワーカ (子プロセス) 構成要素 ChildId StartFunc スーパバイザの起動方法をつたえるためのタプル {M, F, A} Restart 再起動戦略 permanent 常に再起動 temporary 再起動しない transient 正常終了の場合は再起動しない 異常終了の場合は再起動する Shutdown 終了期限 Type 子プロセスの種類 ワーカ スーパバイザ Modules コールバックモジュールのリスト \n- 例 {ok, { {one_for_all, 5, 60}, [ {fake_id, {fake_mod, start_link, [SomeArg]}, permanent, 5000, worker, [fake_mod]}, {other_id, {event_manager_mod, start_link, []}, transient, infinity, worker, dynamic} ] } }. \n- {ok, { {one_for_all, 5, 60}, [ {fake_id, {fake_mod, start_link, [SomeArg]}, permanent, 5000, worker, [fake_mod]}, {other_id, {event_manager_mod, start_link, []}, transient, infinity, worker, dynamic} ] } }.\n- 再起動戦略 one_for_one 1つのワーカがクラッシュしたら当該ワーカを再起動する 各々のワーカが独立している、互いが関係していない、あるいは、ワーカが再起動して状態が消えても隣のワーカに影響を与えない場合につかう one_for_all 1つのワーカがクラッシュしたらすべてのワーカをクラッシュさせて再起動する 各々のワーカが互いに強く依存している場合につかう rest_for_one 1つのワーカがクラッシュした当該ワーカのら子ワーカたちをクラッシュさせて再起動する 各々のワーカがチェーン状態に依存している場合につかう simple_one_for_one one_for_one はワーカのリストを起動した順で保持している一方 、simple_one_for_one はワーカへの定義を dict で保持している \n- one_for_one 1つのワーカがクラッシュしたら当該ワーカを再起動する 各々のワーカが独立している、互いが関係していない、あるいは、ワーカが再起動して状態が消えても隣のワーカに影響を与えない場合につかう \n- 1つのワーカがクラッシュしたら当該ワーカを再起動する\n- 各々のワーカが独立している、互いが関係していない、あるいは、ワーカが再起動して状態が消えても隣のワーカに影響を与えない場合につかう\n- one_for_all 1つのワーカがクラッシュしたらすべてのワーカをクラッシュさせて再起動する 各々のワーカが互いに強く依存している場合につかう \n- 1つのワーカがクラッシュしたらすべてのワーカをクラッシュさせて再起動する\n- 各々のワーカが互いに強く依存している場合につかう\n- rest_for_one 1つのワーカがクラッシュした当該ワーカのら子ワーカたちをクラッシュさせて再起動する 各々のワーカがチェーン状態に依存している場合につかう \n- 1つのワーカがクラッシュした当該ワーカのら子ワーカたちをクラッシュさせて再起動する\n- 各々のワーカがチェーン状態に依存している場合につかう\n- simple_one_for_one one_for_one はワーカのリストを起動した順で保持している一方 、simple_one_for_one はワーカへの定義を dict で保持している \n- one_for_one はワーカのリストを起動した順で保持している一方 、simple_one_for_one はワーカへの定義を dict で保持している\n- 再起動制限 MaxTime 秒以内に MaxRestart 回起動したら、スーパバイザは再起動をやめて自身をシャットダウンする \n- MaxTime 秒以内に MaxRestart 回起動したら、スーパバイザは再起動をやめて自身をシャットダウンする\n- ワーカ (子プロセス) 構成要素 ChildId StartFunc スーパバイザの起動方法をつたえるためのタプル {M, F, A} Restart 再起動戦略 permanent 常に再起動 temporary 再起動しない transient 正常終了の場合は再起動しない 異常終了の場合は再起動する Shutdown 終了期限 Type 子プロセスの種類 ワーカ スーパバイザ Modules コールバックモジュールのリスト \n- 構成要素 ChildId StartFunc スーパバイザの起動方法をつたえるためのタプル {M, F, A} Restart 再起動戦略 permanent 常に再起動 temporary 再起動しない transient 正常終了の場合は再起動しない 異常終了の場合は再起動する Shutdown 終了期限 Type 子プロセスの種類 ワーカ スーパバイザ Modules コールバックモジュールのリスト \n- ChildId\n- StartFunc スーパバイザの起動方法をつたえるためのタプル {M, F, A} \n- スーパバイザの起動方法をつたえるためのタプル {M, F, A}\n- Restart 再起動戦略 permanent 常に再起動 temporary 再起動しない transient 正常終了の場合は再起動しない 異常終了の場合は再起動する \n- 再起動戦略 permanent 常に再起動 temporary 再起動しない transient 正常終了の場合は再起動しない 異常終了の場合は再起動する \n- permanent 常に再起動 \n- 常に再起動\n- temporary 再起動しない \n- 再起動しない\n- transient 正常終了の場合は再起動しない 異常終了の場合は再起動する \n- 正常終了の場合は再起動しない\n- 異常終了の場合は再起動する\n- Shutdown 終了期限 \n- 終了期限\n- Type 子プロセスの種類 ワーカ スーパバイザ \n- 子プロセスの種類 ワーカ スーパバイザ \n- ワーカ\n- スーパバイザ\n- Modules コールバックモジュールのリスト \n- コールバックモジュールのリスト   > 21 プロセスプールをつくる21 プロセスプールをつくる \n\n今回はプロセスプール管理アプリケーションをOTPを使ってつくる。   > 要件要件 \n\n- サーバを最大でN個の並列接続に制限\n- アプリケーションによって開かれるファイルの数を制限\n- サブシステムに優先順位を与える\n- 不定期なアクセス負荷に対してキューにタスクを貯めることで、可用性を高める   > 実装実装 \n\n機能 \n\n- アプリケーション 起動 停止 \n- 起動\n- 停止\n- 特定のプロセスプール 起動 停止 \n- 起動\n- 停止\n- プール内のタスク プールに余裕がある場合 実行 タスクが実行されたら呼び出し元は解放 できる限りタスクを非同期に実行 プールに余裕がない場合 起動できないと告げる タスクがキューの中にある間は呼び出し元のプロセスを待たせておく タスクをキューに貯める \n- プールに余裕がある場合 実行 タスクが実行されたら呼び出し元は解放 できる限りタスクを非同期に実行 \n- 実行\n- タスクが実行されたら呼び出し元は解放\n- できる限りタスクを非同期に実行\n- プールに余裕がない場合 起動できないと告げる タスクがキューの中にある間は呼び出し元のプロセスを待たせておく タスクをキューに貯める \n- 起動できないと告げる\n- タスクがキューの中にある間は呼び出し元のプロセスを待たせておく\n- タスクをキューに貯める \n\n状態 \n\n- 静的な状態 下記から容易に取得 設定ファイル 他のプロセス アプリケーションを再起動しているスーパーバイザ \n- 下記から容易に取得 設定ファイル 他のプロセス アプリケーションを再起動しているスーパーバイザ \n- 設定ファイル\n- 他のプロセス\n- アプリケーションを再起動しているスーパーバイザ\n- 動的な状態 再計算できるデータから取得 状態の種類 初期からの状態 現在までの状態 変換すべき状態 \n- 再計算できるデータから取得\n- 状態の種類 初期からの状態 現在までの状態 変換すべき状態 \n- 初期からの状態\n- 現在までの状態\n- 変換すべき状態\n- 再計算できない動的なデータ 下記から取得 ユーザの入力 生のデータ 逐次的な外部イベント など 保存方法 データベースに登録 \n- 下記から取得 ユーザの入力 生のデータ 逐次的な外部イベント など \n- ユーザの入力\n- 生のデータ\n- 逐次的な外部イベント\n- など\n- 保存方法 データベースに登録 \n- データベースに登録    > 25 ホットコードローディング25 ホットコードローディング \n\n- 今回はホットコードローディング（更新）についてかんがえる。\n- ホットコードローディングはホットスワップの1種でElixir/Erlangの信頼性につながっている。\n- ホットコードローディングは systools により複数の appup から relup として構成されている。   > リリースの更新リリースの更新 \n\nバージョンがあがるほどリリースの更新は煩雑になっていく。 \n\n- OTPアプリケーションを書く (ver. 1.0.0) それらをリリースにする \n- それらをリリースにする\n- 1つ以上のOTPアプリケーションのバージョンを更新する (ver. 1.1.0) そのアプリケーションの古いバージョンから新しいバージョンへの遷移を行うために、何を変更すべきかを説明した appup ファイルを作成する \n- そのアプリケーションの古いバージョンから新しいバージョンへの遷移を行うために、何を変更すべきかを説明した appup ファイルを作成する\n- 新しいアプリケーションで新しいリリースを作る (ver. 1.2.0) appup ファイルをこれらのリリースから生成する 新しいアプリケーションを稼働しているErlangシェルにインストールする \n- appup ファイルをこれらのリリースから生成する\n- 新しいアプリケーションを稼働しているErlangシェルにインストールする \n\nリリース作業として以下の通り。relup 構成ツールとして、Erlangは relx 、Elixirは distillery がある。 \n\n- 巻き戻しできるようアップグレードとダウングレード双方を appup ファイルに記述\n- モジュールによるリリース構成を config ファイルに記述\n- systools:make_relup で relup を作成\n- release_hanlder によって更新   appup \n\n%% {NewVersion, %% [{VersionUpgradingFrom, [Instructions]}] %% [{VersionDownGradingTo, [Instructions]}]}. {\"1.1.0\", [{\"1.0.0\", [{add_module, pq_quest}, {load_module, pq_enemy}, {load_module, pq_events}, {update, pq_player, {advanced, []}, [pq_quest, pq_events]}]}], [{\"1.0.0\", [{update, pq_player, {advanced, []}}, {delete_module, pq_quest}, {load_module, pq_enemy}, {load_module, pq_events}]}]}. {\"1.0.1\", [{\"1.0.0\", [{load_module, sockserv_serv}]}], [{\"1.0.0\", [{load_module, sockserv_serv}]}]}.     > 27 EUnit27 EUnit \n\n- 今回は単体テストEUnitについてかんがえる。   > EUnitの特徴EUnitの特徴 \n\n- eunit:test(モジュール名, [verbose]) で実行\n- postfixがtestの関数 _test() に対してテストをおこなう\n- モジュールの内外ともにテストコードをかける\n- モジュール外に書いた場合プライベート関数に対するテストはできなくなる\n- テスト用モジュールはpostfixがtestsとなる _tests.erl    > EUnitの関数EUnitの関数 \n\n- 表現系 テスト foo_test -> ?assert(is_number(ops:add(1, 2))), ?assertEqual(4, ops:add(2, 2)). テストジェネレータ foo_test_ -> [test_them_1(), test_them_2, ?_assertError(badarith, 1/0)]. フィクスチャー setup {setup, Setup, Instantiator} {setup, Setup, Cleanup, Instantiator} {setup, Where, Setup, Instantiator} {setup, Where, Setup, Cleanup, Instantiator} foreach {foreach, Setup, [Instantiator]} {foreach, Setup, Cleanup, [Instantiator]} {foreach, Where, Setup, [Instantiator]} {foreach, Where, Setup, Cleanup, [Instantiator]} instantiator制御 {spawn, TestSet} - 並行処理 {timeout, (時間 秒), TestSet} - 時間指定処理 {inorder, TestSet} - 逐次処理 {inparallel, TestSet} - 並列処理 コメント {Comment, Fixture} \n- テスト foo_test -> ?assert(is_number(ops:add(1, 2))), ?assertEqual(4, ops:add(2, 2)). \n- foo_test -> ?assert(is_number(ops:add(1, 2))), ?assertEqual(4, ops:add(2, 2)).\n- テストジェネレータ foo_test_ -> [test_them_1(), test_them_2, ?_assertError(badarith, 1/0)]. \n- foo_test_ -> [test_them_1(), test_them_2, ?_assertError(badarith, 1/0)].\n- フィクスチャー setup {setup, Setup, Instantiator} {setup, Setup, Cleanup, Instantiator} {setup, Where, Setup, Instantiator} {setup, Where, Setup, Cleanup, Instantiator} foreach {foreach, Setup, [Instantiator]} {foreach, Setup, Cleanup, [Instantiator]} {foreach, Where, Setup, [Instantiator]} {foreach, Where, Setup, Cleanup, [Instantiator]} instantiator制御 {spawn, TestSet} - 並行処理 {timeout, (時間 秒), TestSet} - 時間指定処理 {inorder, TestSet} - 逐次処理 {inparallel, TestSet} - 並列処理 コメント {Comment, Fixture} \n- setup {setup, Setup, Instantiator} {setup, Setup, Cleanup, Instantiator} {setup, Where, Setup, Instantiator} {setup, Where, Setup, Cleanup, Instantiator} \n- {setup, Setup, Instantiator}\n- {setup, Setup, Cleanup, Instantiator}\n- {setup, Where, Setup, Instantiator}\n- {setup, Where, Setup, Cleanup, Instantiator}\n- foreach {foreach, Setup, [Instantiator]} {foreach, Setup, Cleanup, [Instantiator]} {foreach, Where, Setup, [Instantiator]} {foreach, Where, Setup, Cleanup, [Instantiator]} \n- {foreach, Setup, [Instantiator]}\n- {foreach, Setup, Cleanup, [Instantiator]}\n- {foreach, Where, Setup, [Instantiator]}\n- {foreach, Where, Setup, Cleanup, [Instantiator]}\n- instantiator制御 {spawn, TestSet} - 並行処理 {timeout, (時間 秒), TestSet} - 時間指定処理 {inorder, TestSet} - 逐次処理 {inparallel, TestSet} - 並列処理 \n- {spawn, TestSet} - 並行処理\n- {timeout, (時間 秒), TestSet} - 時間指定処理\n- {inorder, TestSet} - 逐次処理\n- {inparallel, TestSet} - 並列処理\n- コメント {Comment, Fixture} \n- {Comment, Fixture}\n- アサーション系 ?assert(expression) ?assertNot(expression) ?assertEqual(A, B) ?assertMatch(Pattern, Expression) ?assertError(Pattern, Expression) ?assertThrow(Pattern, Expression) ?assertExit(Pattern, Expression) ?assertException(Class, Pattern, Expression) \n- ?assert(expression)\n- ?assertNot(expression)\n- ?assertEqual(A, B)\n- ?assertMatch(Pattern, Expression)\n- ?assertError(Pattern, Expression)\n- ?assertThrow(Pattern, Expression)\n- ?assertExit(Pattern, Expression)\n- ?assertException(Class, Pattern, Expression) \n\nフィクスチャー (foreach) をつかったテストジェネレータ   erlang \n\n-define(setup(F), {setup, fun start/0, fun stop/1, F}). %% 関数some2について some2_test_() -> [{\"SetupData1を適切に評価できること\", {foreach, ?setup(fun (SetupData1) -> [some_instantiator1(SetupData1), some_instantiator2(SetupData1), ... some_instantiatorN(SetupData1)] end}}, {\"SetupData2を並列処理で適切に評価できること\", {foreach, ?setup(fun (SetupData2) -> {inparallel, [some_instantiator1(SetupData2), some_instantiator2(SetupData2), ... some_instantiatorN(SetupData2)]} end)}}].   \n\n並列・並行でテストする際の注意点 \n\n- 名前をa、b、cのようにハードコードすると、並列で走らせている際、名前の衝突が起きる可能性がある。可能な限り名前はハードコードせずに make_ref() によって一意の値をつかうこと。   > 28 インメモリーデータベース ETS28 インメモリーデータベース ETS   > ETSの特徴ETSの特徴 \n\n- データへの並列平行なアクセスが可能 ただし、安全性と並行性が低下する可能性がある ETSのデフォルト使用数は1400 erl -env ERL_MAX_ETS_TABLES Number で設定 \n- ただし、安全性と並行性が低下する可能性がある\n- ETSのデフォルト使用数は1400 erl -env ERL_MAX_ETS_TABLES Number で設定 \n- erl -env ERL_MAX_ETS_TABLES Number で設定   > ETSのテーブル種類ETSのテーブル種類 \n\n- set 標準 \n- 標準\n- ordered_set テーブルデータのソート機能あり ユースケース: 範囲指定してデータ取得する (ただし、アクセス時間が遅くなる O(log N)) \n- テーブルデータのソート機能あり\n- ユースケース: 範囲指定してデータ取得する (ただし、アクセス時間が遅くなる O(log N))\n- bag 同一キーのタプル（レコード）を保持可能 \n- 同一キーのタプル（レコード）を保持可能\n- duplicate_bag 同一内容のタプル（レコード）を保持可能 \n- 同一内容のタプル（レコード）を保持可能\n- 共通機能 テーブル所有権 ETSテーブル起動関数であらたにコールしたプロセスがそのテーブルの所有者 権限 protected level 所有者 read, write その他 read public level 所有者 read, write その他 read, write private level 所有者 read, write その他 n/a テーブルの移譲 ETSテーブルはプロセスが死ぬと消滅する 移譲の種類 都度指定する移譲 プロセスが死んだ場合の自動移譲 \n- テーブル所有権 ETSテーブル起動関数であらたにコールしたプロセスがそのテーブルの所有者 権限 protected level 所有者 read, write その他 read public level 所有者 read, write その他 read, write private level 所有者 read, write その他 n/a \n- ETSテーブル起動関数であらたにコールしたプロセスがそのテーブルの所有者\n- 権限 protected level 所有者 read, write その他 read public level 所有者 read, write その他 read, write private level 所有者 read, write その他 n/a \n- protected level 所有者 read, write その他 read \n- 所有者 read, write\n- その他 read\n- public level 所有者 read, write その他 read, write \n- 所有者 read, write\n- その他 read, write\n- private level 所有者 read, write その他 n/a \n- 所有者 read, write\n- その他 n/a\n- テーブルの移譲 ETSテーブルはプロセスが死ぬと消滅する 移譲の種類 都度指定する移譲 プロセスが死んだ場合の自動移譲 \n- ETSテーブルはプロセスが死ぬと消滅する\n- 移譲の種類 都度指定する移譲 プロセスが死んだ場合の自動移譲 \n- 都度指定する移譲\n- プロセスが死んだ場合の自動移譲   > ETSの関数ETSの関数 \n\n- テーブル作成・削除 ets:new/2 \n- ets:new/2\n- データ挿入・参照 ets:insert(Table, ObjectOrObjects) ets:lookup(Table, Key) \n- ets:insert(Table, ObjectOrObjects)\n- ets:lookup(Table, Key)\n- その他 ets:delete(Table, Key) ets:match(Table, MatchClause) ets:match_object(Table, MatchClause) ets:fun2ms(MatchSpecClause) \n- ets:delete(Table, Key)\n- ets:match(Table, MatchClause)\n- ets:match_object(Table, MatchClause)\n- ets:fun2ms(MatchSpecClause) \n\nsetテーブルでnamed_tableオプションをつける場合   erlang \n\n21> ets:new(ingredients, [set, named_table]). ingredients 22> ets:insert(ingredients, {bacon, great}). true 23> ets:lookup(ingredients, bacon). [{bacon,great}] 24> ets:insert(ingredients, [{bacon, awesome}, {cabbage, alright}]). true 25> ets:lookup(ingredients, bacon). [{bacon,awesome}] 26> ets:lookup(ingredients, cabbage). [{cabbage,alright}] 27> ets:delete(ingredients, cabbage). true 28> ets:delete(ingredients, cabbage). true 29> ets:lookup(ingredients, cabbage). [] 32> ets:insert_new(ingredients, {tomato, hey}). true 33> ets:insert_new(ingredients, {tomato, hey}). false   \n\nbagテーブルでnamed_tableオプションをつけない場合   erlang \n\n34> TabId = ets:new(ingredients, [bag]). 16401 35> ets:insert(TabId, {bacon, delicious}). true 36> ets:insert(TabId, {bacon, fat}). true 37> ets:insert(TabId, {bacon, fat}). true 38> ets:lookup(TabId, bacon). [{bacon,delicious},{bacon,fat}]   \n\nordered_setターブルで、named_tableオプションをつける場合   erlang \n\n42> ets:new(ingredients, [ordered_set, named_table]). ingredients 43> ets:insert(ingredients, [{ketchup, \"not much\"}, {mustard, \"a lot\"}, {cheese, \"yes\", \"goat\"}, {patty, \"moose\"}, {onions, \"a lot\", \"caramelized\"}]). true 44> Res1 = ets:first(ingredients). cheese 45> Res2 = ets:next(ingredients, Res1). ketchup 46> Res3 = ets:next(ingredients, Res2). mustard 47> ets:last(ingredients). patty 48> ets:prev(ingredients, ets:last(ingredients)). onions   \n\nnamed_tableオプションつきbagテーブルでパターンマッチをする   erlang \n\n53> ets:new(table, [named_table, bag]). table 54> ets:insert(table, [{items, a, b, c, d}, {items, a, b, c, a}, {cat, brown, soft, loveable, selfish}, {friends, [jem, jeff, etc]}, {items, 1, 2, 3, 1}]). true 55> ets:match(table, {items, '$1', '$2', '_', '$1'}). [[a,b],[1,2]] 56> ets:match(table, {items, '$114', '$212', '_', '$6'}). [[d,a,b],[a,a,b],[1,1,2]] 57> ets:match_object(table, {items, '$1', '$2', '_', '$1'}). [{items,a,b,c,a},{items,1,2,3,1}] 58> ets:delete(table). true     > 29 分散システム EPMD29 分散システム EPMD \n\n- 今回は分散システム Erlang Port Mapper Daemon (EPMD) についてかんがえる。今回の章がSLAにもっとも関係しているといえそうである。ほかの言語・フレームワークが「分散コンピューティングの落とし穴」「CAP定理」にどのように対応している比較すると、Erlangの特徴がより見えてくるだろう。   > 分散システムEPMDの特徴分散システムEPMDの特徴 \n\n前提 \n\n- 分散システムによるFault toleranceについて ソフトウェアの稼働状況と対ハードウェア障害リスク マシン1台 リスク対策できない マシン複数台 アプリケーションが正しく構築されない場合、リスク対策できない \n- ソフトウェアの稼働状況と対ハードウェア障害リスク マシン1台 リスク対策できない マシン複数台 アプリケーションが正しく構築されない場合、リスク対策できない \n- マシン1台 リスク対策できない \n- リスク対策できない\n- マシン複数台 アプリケーションが正しく構築されない場合、リスク対策できない \n- アプリケーションが正しく構築されない場合、リスク対策できない\n- 「分散コンピューティングの落とし穴」へのErlangの対応 ネットワークは信頼できる Erlangの対応 非同期通信モード（リンクやモニタ）により、メッセージを送信に正常な場合に必ず返信するように設計 ただし、ノード間でリンクやモニタを張った際にネットワーク障害起きた場合、リンクやモニタが一斉にトリガーされシステムに予期しない負荷をかけることになる レイテンシはゼロである Erlangの対応 タイムアウト、リンク、モニタ、非同期パターンにより遅延を想定し設計 帯域幅は無限である Erlangの対応 大きなメッセージを送らない ネットワークはセキュアである Erlangの対応 Erlangはネットワークの安全性を確認しないため 異なるデータセンター間で自動的にクラスタ化しない あるいは、SSLに切り替える 安全なチャンネル越しにトンネルする ノード間の通信プロトコルを再実装する ネットワーク構成は変化せず一定である Erlangの対応 アプリケーションでネットワーク構成（トポロジー）を管理しない 管理者は1人である Erlangの対応 デバッグツールによる個別障害対応 ノード監視ツールによるシステム運用状況の共有 実装プロトコルやAPIのバージョン管理 転送コストはゼロである Erlangの対応 Erlangはほかのノードに渡されるメッセージを圧縮しないため 送るメッセージを小さくする あるいは、独自の通信レイヤを実装する ネットワークは均質である Erlangの対応 Erlangノードと同じプロトコル形式にして通信 Cノード BERT BERT-RPC \n- ネットワークは信頼できる Erlangの対応 非同期通信モード（リンクやモニタ）により、メッセージを送信に正常な場合に必ず返信するように設計 ただし、ノード間でリンクやモニタを張った際にネットワーク障害起きた場合、リンクやモニタが一斉にトリガーされシステムに予期しない負荷をかけることになる \n- Erlangの対応 非同期通信モード（リンクやモニタ）により、メッセージを送信に正常な場合に必ず返信するように設計 ただし、ノード間でリンクやモニタを張った際にネットワーク障害起きた場合、リンクやモニタが一斉にトリガーされシステムに予期しない負荷をかけることになる \n- 非同期通信モード（リンクやモニタ）により、メッセージを送信に正常な場合に必ず返信するように設計\n- ただし、ノード間でリンクやモニタを張った際にネットワーク障害起きた場合、リンクやモニタが一斉にトリガーされシステムに予期しない負荷をかけることになる\n- レイテンシはゼロである Erlangの対応 タイムアウト、リンク、モニタ、非同期パターンにより遅延を想定し設計 \n- Erlangの対応 タイムアウト、リンク、モニタ、非同期パターンにより遅延を想定し設計 \n- タイムアウト、リンク、モニタ、非同期パターンにより遅延を想定し設計\n- 帯域幅は無限である Erlangの対応 大きなメッセージを送らない \n- Erlangの対応 大きなメッセージを送らない \n- 大きなメッセージを送らない\n- ネットワークはセキュアである Erlangの対応 Erlangはネットワークの安全性を確認しないため 異なるデータセンター間で自動的にクラスタ化しない あるいは、SSLに切り替える 安全なチャンネル越しにトンネルする ノード間の通信プロトコルを再実装する \n- Erlangの対応 Erlangはネットワークの安全性を確認しないため 異なるデータセンター間で自動的にクラスタ化しない あるいは、SSLに切り替える 安全なチャンネル越しにトンネルする ノード間の通信プロトコルを再実装する \n- Erlangはネットワークの安全性を確認しないため 異なるデータセンター間で自動的にクラスタ化しない あるいは、SSLに切り替える 安全なチャンネル越しにトンネルする ノード間の通信プロトコルを再実装する \n- 異なるデータセンター間で自動的にクラスタ化しない\n- あるいは、SSLに切り替える\n- 安全なチャンネル越しにトンネルする\n- ノード間の通信プロトコルを再実装する\n- ネットワーク構成は変化せず一定である Erlangの対応 アプリケーションでネットワーク構成（トポロジー）を管理しない \n- Erlangの対応 アプリケーションでネットワーク構成（トポロジー）を管理しない \n- アプリケーションでネットワーク構成（トポロジー）を管理しない\n- 管理者は1人である Erlangの対応 デバッグツールによる個別障害対応 ノード監視ツールによるシステム運用状況の共有 実装プロトコルやAPIのバージョン管理 \n- Erlangの対応 デバッグツールによる個別障害対応 ノード監視ツールによるシステム運用状況の共有 実装プロトコルやAPIのバージョン管理 \n- デバッグツールによる個別障害対応\n- ノード監視ツールによるシステム運用状況の共有\n- 実装プロトコルやAPIのバージョン管理\n- 転送コストはゼロである Erlangの対応 Erlangはほかのノードに渡されるメッセージを圧縮しないため 送るメッセージを小さくする あるいは、独自の通信レイヤを実装する \n- Erlangの対応 Erlangはほかのノードに渡されるメッセージを圧縮しないため 送るメッセージを小さくする あるいは、独自の通信レイヤを実装する \n- Erlangはほかのノードに渡されるメッセージを圧縮しないため 送るメッセージを小さくする あるいは、独自の通信レイヤを実装する \n- 送るメッセージを小さくする\n- あるいは、独自の通信レイヤを実装する\n- ネットワークは均質である Erlangの対応 Erlangノードと同じプロトコル形式にして通信 Cノード BERT BERT-RPC \n- Erlangの対応 Erlangノードと同じプロトコル形式にして通信 Cノード BERT BERT-RPC \n- Erlangノードと同じプロトコル形式にして通信 Cノード BERT BERT-RPC \n- Cノード\n- BERT\n- BERT-RPC\n- 障害（ノードの応答不能）への対応 下記の中から原因を特定するが確実には対応できない ハードウェア障害 アプリケーションクラッシュ ネットワーク分断 輻輳 遮断 ゾンビ化するということ ネットワーク分断が起きている間アプリケーションが生きていた場合 当該ノードで保持していたデータがクラスタ間で保持していたデータと整合性がとれず、欠損扱いになる（一貫性の欠如） 当該ノードからレスポンスが返ってこないため生きているか死んでいるかわからない（可用性の欠如） CAP（Consistency, Availability, Partition Tolerance）定理 ノード間において、同時に下記3つの要素を保証することはできない 一貫性 Consistency すべてのデータ読み込みにおいて、最新の書き込みデータもしくはエラーのどちらかを受け取れること 可用性 Availability システム要求に応答できること（SPOFがない） 分断耐性 Partition tolerance ネットワーク分断時でもシステムを継続して運用できること 組合せ、採用条件、採用ケース CA 採用条件 ネットワークが絶対に落ちない場合 ネットワークが1つの塊として動作している場合 データの読み書きが多い場合 採用ケース RDBMS NFS AP 採用条件 ネットワーク分断が起きやすい場合 SPOFがない場合 ネットワーク分断時データ変更不可だと問題がある場合 結果整合性を適用可能な場合 時間ベース 個別にコンフリクト解消 全ノードによる合意 合意割合による調整 問い合わせ対象による調整 採用ケース Amazon SimpleDB Apache Cassandra DNS HTTPキャッシュ CP 採用条件 ネットワーク分断が起きやすい場合 SPOFがある場合 ネットワーク分断時データ変更不可でも問題ない場合 採用ケース Mnesia Apache HBase \n- 下記の中から原因を特定するが確実には対応できない ハードウェア障害 アプリケーションクラッシュ ネットワーク分断 輻輳 遮断 \n- ハードウェア障害\n- アプリケーションクラッシュ\n- ネットワーク分断 輻輳 遮断 \n- 輻輳\n- 遮断\n- ゾンビ化するということ ネットワーク分断が起きている間アプリケーションが生きていた場合 当該ノードで保持していたデータがクラスタ間で保持していたデータと整合性がとれず、欠損扱いになる（一貫性の欠如） 当該ノードからレスポンスが返ってこないため生きているか死んでいるかわからない（可用性の欠如） \n- ネットワーク分断が起きている間アプリケーションが生きていた場合 当該ノードで保持していたデータがクラスタ間で保持していたデータと整合性がとれず、欠損扱いになる（一貫性の欠如） 当該ノードからレスポンスが返ってこないため生きているか死んでいるかわからない（可用性の欠如） \n- 当該ノードで保持していたデータがクラスタ間で保持していたデータと整合性がとれず、欠損扱いになる（一貫性の欠如）\n- 当該ノードからレスポンスが返ってこないため生きているか死んでいるかわからない（可用性の欠如）\n- CAP（Consistency, Availability, Partition Tolerance）定理 ノード間において、同時に下記3つの要素を保証することはできない 一貫性 Consistency すべてのデータ読み込みにおいて、最新の書き込みデータもしくはエラーのどちらかを受け取れること 可用性 Availability システム要求に応答できること（SPOFがない） 分断耐性 Partition tolerance ネットワーク分断時でもシステムを継続して運用できること 組合せ、採用条件、採用ケース CA 採用条件 ネットワークが絶対に落ちない場合 ネットワークが1つの塊として動作している場合 データの読み書きが多い場合 採用ケース RDBMS NFS AP 採用条件 ネットワーク分断が起きやすい場合 SPOFがない場合 ネットワーク分断時データ変更不可だと問題がある場合 結果整合性を適用可能な場合 時間ベース 個別にコンフリクト解消 全ノードによる合意 合意割合による調整 問い合わせ対象による調整 採用ケース Amazon SimpleDB Apache Cassandra DNS HTTPキャッシュ CP 採用条件 ネットワーク分断が起きやすい場合 SPOFがある場合 ネットワーク分断時データ変更不可でも問題ない場合 採用ケース Mnesia Apache HBase \n- ノード間において、同時に下記3つの要素を保証することはできない 一貫性 Consistency すべてのデータ読み込みにおいて、最新の書き込みデータもしくはエラーのどちらかを受け取れること 可用性 Availability システム要求に応答できること（SPOFがない） 分断耐性 Partition tolerance ネットワーク分断時でもシステムを継続して運用できること \n- 一貫性 Consistency すべてのデータ読み込みにおいて、最新の書き込みデータもしくはエラーのどちらかを受け取れること \n- すべてのデータ読み込みにおいて、最新の書き込みデータもしくはエラーのどちらかを受け取れること\n- 可用性 Availability システム要求に応答できること（SPOFがない） \n- システム要求に応答できること（SPOFがない）\n- 分断耐性 Partition tolerance ネットワーク分断時でもシステムを継続して運用できること \n- ネットワーク分断時でもシステムを継続して運用できること\n- 組合せ、採用条件、採用ケース CA 採用条件 ネットワークが絶対に落ちない場合 ネットワークが1つの塊として動作している場合 データの読み書きが多い場合 採用ケース RDBMS NFS AP 採用条件 ネットワーク分断が起きやすい場合 SPOFがない場合 ネットワーク分断時データ変更不可だと問題がある場合 結果整合性を適用可能な場合 時間ベース 個別にコンフリクト解消 全ノードによる合意 合意割合による調整 問い合わせ対象による調整 採用ケース Amazon SimpleDB Apache Cassandra DNS HTTPキャッシュ CP 採用条件 ネットワーク分断が起きやすい場合 SPOFがある場合 ネットワーク分断時データ変更不可でも問題ない場合 採用ケース Mnesia Apache HBase \n- CA 採用条件 ネットワークが絶対に落ちない場合 ネットワークが1つの塊として動作している場合 データの読み書きが多い場合 採用ケース RDBMS NFS \n- 採用条件 ネットワークが絶対に落ちない場合 ネットワークが1つの塊として動作している場合 データの読み書きが多い場合 \n- ネットワークが絶対に落ちない場合\n- ネットワークが1つの塊として動作している場合\n- データの読み書きが多い場合\n- 採用ケース RDBMS NFS \n- RDBMS\n- NFS\n- AP 採用条件 ネットワーク分断が起きやすい場合 SPOFがない場合 ネットワーク分断時データ変更不可だと問題がある場合 結果整合性を適用可能な場合 時間ベース 個別にコンフリクト解消 全ノードによる合意 合意割合による調整 問い合わせ対象による調整 採用ケース Amazon SimpleDB Apache Cassandra DNS HTTPキャッシュ \n- 採用条件 ネットワーク分断が起きやすい場合 SPOFがない場合 ネットワーク分断時データ変更不可だと問題がある場合 結果整合性を適用可能な場合 時間ベース 個別にコンフリクト解消 全ノードによる合意 合意割合による調整 問い合わせ対象による調整 \n- ネットワーク分断が起きやすい場合\n- SPOFがない場合\n- ネットワーク分断時データ変更不可だと問題がある場合\n- 結果整合性を適用可能な場合 時間ベース 個別にコンフリクト解消 全ノードによる合意 合意割合による調整 問い合わせ対象による調整 \n- 時間ベース\n- 個別にコンフリクト解消\n- 全ノードによる合意 合意割合による調整 問い合わせ対象による調整 \n- 合意割合による調整\n- 問い合わせ対象による調整\n- 採用ケース Amazon SimpleDB Apache Cassandra DNS HTTPキャッシュ \n- Amazon SimpleDB\n- Apache Cassandra\n- DNS\n- HTTPキャッシュ\n- CP 採用条件 ネットワーク分断が起きやすい場合 SPOFがある場合 ネットワーク分断時データ変更不可でも問題ない場合 採用ケース Mnesia Apache HBase \n- 採用条件 ネットワーク分断が起きやすい場合 SPOFがある場合 ネットワーク分断時データ変更不可でも問題ない場合 \n- ネットワーク分断が起きやすい場合\n- SPOFがある場合\n- ネットワーク分断時データ変更不可でも問題ない場合\n- 採用ケース Mnesia Apache HBase \n- Mnesia\n- Apache HBase \n\nErlangが提供する道具 \n\n- ノードとEPMD 特徴 ノードとはErlang VMのインスタンスのこと 各ノードはEPMDに接続されている 新しいノードは自動的にErlangクラスタに接続され、各ノードに接続される 接続されているノードでも完全に独立している 各ノードが固有に保持しているもの プロセスレジストリ ETSテーブル 読み込んだモジュール EPMDはErlangクラスタの一部として、各コンピューター上で稼働する EPMDは名前サーバとして機能する Pros Fault tolerance Cons 1ノードにつき1エフェメラルポートが必要になるため、Scalingに制限がある 対処として、ノードのグループを小さなクラスタに分割 \n- 特徴 ノードとはErlang VMのインスタンスのこと 各ノードはEPMDに接続されている 新しいノードは自動的にErlangクラスタに接続され、各ノードに接続される 接続されているノードでも完全に独立している 各ノードが固有に保持しているもの プロセスレジストリ ETSテーブル 読み込んだモジュール EPMDはErlangクラスタの一部として、各コンピューター上で稼働する EPMDは名前サーバとして機能する \n- ノードとはErlang VMのインスタンスのこと\n- 各ノードはEPMDに接続されている 新しいノードは自動的にErlangクラスタに接続され、各ノードに接続される \n- 新しいノードは自動的にErlangクラスタに接続され、各ノードに接続される\n- 接続されているノードでも完全に独立している 各ノードが固有に保持しているもの プロセスレジストリ ETSテーブル 読み込んだモジュール \n- 各ノードが固有に保持しているもの プロセスレジストリ ETSテーブル 読み込んだモジュール \n- プロセスレジストリ\n- ETSテーブル\n- 読み込んだモジュール\n- EPMDはErlangクラスタの一部として、各コンピューター上で稼働する\n- EPMDは名前サーバとして機能する\n- Pros Fault tolerance \n- Fault tolerance\n- Cons 1ノードにつき1エフェメラルポートが必要になるため、Scalingに制限がある 対処として、ノードのグループを小さなクラスタに分割 \n- 1ノードにつき1エフェメラルポートが必要になるため、Scalingに制限がある 対処として、ノードのグループを小さなクラスタに分割 \n- 対処として、ノードのグループを小さなクラスタに分割\n- シリアライズ、デシリアライズ\n- マルチプロセス\n- ネットワークの障害監視 \n\nErlangクラスタを設定する \n\n- ノードの名前解決 長い名前 aaa.bbb.cccのような完全修飾ドメイン名 DNSリゾルバによって解決 erl -name LongName 短い名前 ピリオドがないホスト名 ホストファイルやDNSエントリによって解決 erl -sname ShortName 注意点 1台のコンピューター上でErlangノードを設定する際は通常短い名前をつかう 長い名前と短い名前、双方でのやり取りはできない \n- 長い名前 aaa.bbb.cccのような完全修飾ドメイン名 DNSリゾルバによって解決 erl -name LongName \n- aaa.bbb.cccのような完全修飾ドメイン名\n- DNSリゾルバによって解決\n- erl -name LongName\n- 短い名前 ピリオドがないホスト名 ホストファイルやDNSエントリによって解決 erl -sname ShortName \n- ピリオドがないホスト名\n- ホストファイルやDNSエントリによって解決\n- erl -sname ShortName\n- 注意点 1台のコンピューター上でErlangノードを設定する際は通常短い名前をつかう 長い名前と短い名前、双方でのやり取りはできない \n- 1台のコンピューター上でErlangノードを設定する際は通常短い名前をつかう\n- 長い名前と短い名前、双方でのやり取りはできない\n- 関数 net_kernel:connect_node/1 - ノード接続 ノード名参照 node/0 - 現在のノード名を参照 nodes/0 - 接続ノード参照 リンクとモニタ link - ノードをまたいだリンク erlang:monitor/2 - ノードをまたいだモニタ（ネットワーク分断時に一斉に活性化し負荷が増加する可能性あり） erlang:monitor_node/2 - ノードを指定したモニタ 遠隔操作 spawn/2 spawn/4 spawn_link/2 spawn_link/4 \n- net_kernel:connect_node/1 - ノード接続\n- ノード名参照 node/0 - 現在のノード名を参照 nodes/0 - 接続ノード参照 \n- node/0 - 現在のノード名を参照\n- nodes/0 - 接続ノード参照\n- リンクとモニタ link - ノードをまたいだリンク erlang:monitor/2 - ノードをまたいだモニタ（ネットワーク分断時に一斉に活性化し負荷が増加する可能性あり） erlang:monitor_node/2 - ノードを指定したモニタ \n- link - ノードをまたいだリンク\n- erlang:monitor/2 - ノードをまたいだモニタ（ネットワーク分断時に一斉に活性化し負荷が増加する可能性あり）\n- erlang:monitor_node/2 - ノードを指定したモニタ\n- 遠隔操作 spawn/2 spawn/4 spawn_link/2 spawn_link/4 \n- spawn/2\n- spawn/4\n- spawn_link/2\n- spawn_link/4\n- クラスタのUIDトークンとしてのCookie 関数 erl -sname ShortName -setcookie CookieName erlang:get_cookei/0 erlang:set_cookei/2 \n- 関数 erl -sname ShortName -setcookie CookieName erlang:get_cookei/0 erlang:set_cookei/2 \n- erl -sname ShortName -setcookie CookieName\n- erlang:get_cookei/0\n- erlang:set_cookei/2\n- 隠しノード クラスタを介してノード接続すると、クラスタ間で予期しないメッセージ通信がおこなわれる可能性があるため、それを防止する策としてクラスタを介さず接続可能な隠しノード機能がある 関数 erlang:send(Dest, Message, [noconnect]) - クラスタを介さずにノードに接続 erl -sname ShortName -hidden - クラスタを介さずに隠しノードに接続 nodes(hidden) - 隠しノードを参照 \n- クラスタを介してノード接続すると、クラスタ間で予期しないメッセージ通信がおこなわれる可能性があるため、それを防止する策としてクラスタを介さず接続可能な隠しノード機能がある\n- 関数 erlang:send(Dest, Message, [noconnect]) - クラスタを介さずにノードに接続 erl -sname ShortName -hidden - クラスタを介さずに隠しノードに接続 nodes(hidden) - 隠しノードを参照 \n- erlang:send(Dest, Message, [noconnect]) - クラスタを介さずにノードに接続\n- erl -sname ShortName -hidden - クラスタを介さずに隠しノードに接続\n- nodes(hidden) - 隠しノードを参照\n- ポート範囲指定 EPMDのポート番号は 4369 設定方法 erl -name LongName -kernel inet_dist_listen_min 9100 -kernel inet_dist_listen_max 9115 erl -name LongName -config ports ports.config: [{kernel, [{inet_dist_listen_min, 9100}, {inet_dist_listen_max, 9115}]}]. \n- EPMDのポート番号は 4369 \n- 設定方法 erl -name LongName -kernel inet_dist_listen_min 9100 -kernel inet_dist_listen_max 9115 erl -name LongName -config ports ports.config: [{kernel, [{inet_dist_listen_min, 9100}, {inet_dist_listen_max, 9115}]}]. \n- erl -name LongName -kernel inet_dist_listen_min 9100 -kernel inet_dist_listen_max 9115\n- erl -name LongName -config ports ports.config: [{kernel, [{inet_dist_listen_min, 9100}, {inet_dist_listen_max, 9115}]}]. \n- ports.config: [{kernel, [{inet_dist_listen_min, 9100}, {inet_dist_listen_max, 9115}]}]. \n- 分散用モジュール net_kernel start([Name, Type, HeartbeatInMilliseconds]) - インスタンスを一時的にノード化 set_net_ticktime(Milliseconds) - Ticktime（ハートビートを4倍した時間、ノードの死亡判定時間）を設定変更 global - プロセスレジストリの代替 register_name(Name, Pid) - gloabl登録し名前変更 unregister_name(Name, Pid) - globalから名前解除 re_register_name(Name, Pid) - 参照先の喪失を防ぎながらglobal登録し名前変更 whereis_name(Name) - PID探索 send(Name, Message) - メッセージ送信 random_exit_name/3 - ランダムにプロセスをkillする random_notify_name/3 - 2つのプロセスのうちいかすプロセスをランダムに1つ選び、globalから解除されるプロセスに {global_name_conflict, Name} というメッセージを送信 notify_all_name/3 - 指定したPIDプロセスをglobalから解除し、 {global_name_conflict, Name, OtherPid} というメッセージを送信、コンフリクト解消を促す rpc call(Node, Module, Function, Args[, Timout]) async_call(Node, Mod, Fun, Args[, Timout]) yield(AsyncPid) nb_yield(AsyncPid[, Timeout]) - ポーリング、ロングポーリング cast(Node, Mod, Fun, Args) - 返値なしのコール multicall(Nodes, Mod, Fun, Args) - 複数ノードへのコール eval_everywhere(Nodes, Mod, Fun, Args) - 複数ノードへの命令（コールとほぼ同じ） \n- net_kernel start([Name, Type, HeartbeatInMilliseconds]) - インスタンスを一時的にノード化 set_net_ticktime(Milliseconds) - Ticktime（ハートビートを4倍した時間、ノードの死亡判定時間）を設定変更 \n- start([Name, Type, HeartbeatInMilliseconds]) - インスタンスを一時的にノード化\n- set_net_ticktime(Milliseconds) - Ticktime（ハートビートを4倍した時間、ノードの死亡判定時間）を設定変更\n- global - プロセスレジストリの代替 register_name(Name, Pid) - gloabl登録し名前変更 unregister_name(Name, Pid) - globalから名前解除 re_register_name(Name, Pid) - 参照先の喪失を防ぎながらglobal登録し名前変更 whereis_name(Name) - PID探索 send(Name, Message) - メッセージ送信 random_exit_name/3 - ランダムにプロセスをkillする random_notify_name/3 - 2つのプロセスのうちいかすプロセスをランダムに1つ選び、globalから解除されるプロセスに {global_name_conflict, Name} というメッセージを送信 notify_all_name/3 - 指定したPIDプロセスをglobalから解除し、 {global_name_conflict, Name, OtherPid} というメッセージを送信、コンフリクト解消を促す \n- register_name(Name, Pid) - gloabl登録し名前変更\n- unregister_name(Name, Pid) - globalから名前解除\n- re_register_name(Name, Pid) - 参照先の喪失を防ぎながらglobal登録し名前変更\n- whereis_name(Name) - PID探索\n- send(Name, Message) - メッセージ送信\n- random_exit_name/3 - ランダムにプロセスをkillする\n- random_notify_name/3 - 2つのプロセスのうちいかすプロセスをランダムに1つ選び、globalから解除されるプロセスに {global_name_conflict, Name} というメッセージを送信\n- notify_all_name/3 - 指定したPIDプロセスをglobalから解除し、 {global_name_conflict, Name, OtherPid} というメッセージを送信、コンフリクト解消を促す\n- rpc call(Node, Module, Function, Args[, Timout]) async_call(Node, Mod, Fun, Args[, Timout]) yield(AsyncPid) nb_yield(AsyncPid[, Timeout]) - ポーリング、ロングポーリング cast(Node, Mod, Fun, Args) - 返値なしのコール multicall(Nodes, Mod, Fun, Args) - 複数ノードへのコール eval_everywhere(Nodes, Mod, Fun, Args) - 複数ノードへの命令（コールとほぼ同じ） \n- call(Node, Module, Function, Args[, Timout])\n- async_call(Node, Mod, Fun, Args[, Timout])\n- yield(AsyncPid)\n- nb_yield(AsyncPid[, Timeout]) - ポーリング、ロングポーリング\n- cast(Node, Mod, Fun, Args) - 返値なしのコール\n- multicall(Nodes, Mod, Fun, Args) - 複数ノードへのコール\n- eval_everywhere(Nodes, Mod, Fun, Args) - 複数ノードへの命令（コールとほぼ同じ）   > 30 分散OTP30 分散OTP \n\n- 前回の分散の章でnine ninesのなぞが見えてきた。今回はそれを補完する分散OTPについてかんがえる。   > 分散アプリケーションの特徴分散アプリケーションの特徴 \n\n構成 \n\n- 標準アプリケーション アプリケーションコントローラ（ノード） アプリケーションマスタ スーパーバイザ \n- アプリケーションコントローラ（ノード） アプリケーションマスタ スーパーバイザ \n- アプリケーションマスタ スーパーバイザ \n- スーパーバイザ\n- 分散アプリケーション アプリケーションコントローラ（ノード） アプリケーションマスタ スーパーバイザ \n- アプリケーションコントローラ（ノード） アプリケーションマスタ スーパーバイザ \n- アプリケーションマスタ スーパーバイザ \n- スーパーバイザ \n\nライフサイクル \n\n- 標準アプリケーション 1. 読込中2. 起動中3. 停止中4. 解放中 \n- 分散アプリケーション 1. 読込中2. 起動中 稼働中の分散ノードが死んだら稼働中ステータスに移行 3. 稼働中の分散ノードが死んだら稼働中ステータスに移行4. 稼働中 稼働中ステータスは1つのノードのみ 5. 稼働中ステータスは1つのノードのみ6. 停止中7. 解放中  \n\n再起動戦略 \n\n- 特徴 ハードウェア障害を前提にしたCAシステムでよくとられます ネットワーク分断を前提にしたCPシステムの場合は採用を熟慮すること \n- ハードウェア障害を前提にしたCAシステムでよくとられます\n- ネットワーク分断を前提にしたCPシステムの場合は採用を熟慮すること\n- 2つの戦略 フェイルオーバー アプリケーション停止後、別の場所で再起動する戦略 メインとバックアップを入れ替える方法 複数台サーバを立ち上げて相互に負荷を補完しあう方法 テイクオーバー アプリケーション復活後、バックアップからメインに移行する戦略 \n- フェイルオーバー アプリケーション停止後、別の場所で再起動する戦略 メインとバックアップを入れ替える方法 複数台サーバを立ち上げて相互に負荷を補完しあう方法 \n- アプリケーション停止後、別の場所で再起動する戦略 メインとバックアップを入れ替える方法 複数台サーバを立ち上げて相互に負荷を補完しあう方法 \n- メインとバックアップを入れ替える方法\n- 複数台サーバを立ち上げて相互に負荷を補完しあう方法\n- テイクオーバー アプリケーション復活後、バックアップからメインに移行する戦略 \n- アプリケーション復活後、バックアップからメインに移行する戦略   > 32 Mnesia32 Mnesia   > Mnesiaの特徴Mnesiaの特徴 \n\n- Pros CPシステム（NoSQL） トランザクション機能 (ACID) ネットワーク分断につよい ただし、10ノード前後が実用上の限界と考えられている \n- CPシステム（NoSQL） トランザクション機能 (ACID) ネットワーク分断につよい ただし、10ノード前後が実用上の限界と考えられている \n- トランザクション機能 (ACID)\n- ネットワーク分断につよい ただし、10ノード前後が実用上の限界と考えられている \n- ただし、10ノード前後が実用上の限界と考えられている\n- Cons 各テーブルにつき2Gの容量制限 Table Frangmentation機能で回避可能 厳密なシステム要求に応答することはむずかしい 数テラバイトの大きなデータをあつかうのに向いていない 組込型制限がない \n- 各テーブルにつき2Gの容量制限 Table Frangmentation機能で回避可能 \n- Table Frangmentation機能で回避可能\n- 厳密なシステム要求に応答することはむずかしい\n- 数テラバイトの大きなデータをあつかうのに向いていない\n- 組込型制限がない \n\n適切なユースケース \n\n- 下記条件をみたした場合 ノード数、データ量双方を見積もることが可能 ETS/DETS（タプル）形式でアクセス可能 \n- ノード数、データ量双方を見積もることが可能\n- ETS/DETS（タプル）形式でアクセス可能 \n\nテーブルオプション \n\n- 保存方法 ram_copies - データをETS（メモリ）にのみ保存、32ビットマシンで4Gの容量制限 disc_only_copies - データをDETSにのみ保存、2Gの容量制限 disc_copies - データをETSとDETS双方に保存、DETSの2G容量制限はない、通常はこちらはつかう \n- ram_copies - データをETS（メモリ）にのみ保存、32ビットマシンで4Gの容量制限\n- disc_only_copies - データをDETSにのみ保存、2Gの容量制限\n- disc_copies - データをETSとDETS双方に保存、DETSの2G容量制限はない、通常はこちらはつかう\n- テーブル種類 set bag ordered_set \n- set\n- bag\n- ordered_set \n\nCLI \n\n- erl -name LongName -mnesia dir path/to/db - dir 変数でスキーマ保存場所を指定 \n\n関数 \n\n- mnesia create_schema(ListOfNodes) create_table(TableName, Option) オプション {attributes, List} - テーブルのカラム名 {disc_copies, NodeList} {disc_only_copies, NodeList} {ram_copies, NodeList} - テーブルの保存場所 {index, ListOfIntegers} - インデックスをはる {record_name, Atom} - テーブルの別名（非推奨） {type, Type} - テーブル種類 (set, ordered_set, bag) {local_content, Boolean} - デフォルト false。true にすると、多数のノード上に共有されない固有のローカルテーブルを作成する wait_for_tables - テーブル読込完了まで待機 activity(AccessContext, Fun[, Args]) - クエリの実行方法を指定 AccessContextの種類 transaction - 非同期トランザクション、トランザクションの完了を待つわけではないので正確ではない sync_transaction - 同期トランザクション async_dirty - 非同期のロックなし処理 sync_dirty - 同期のロックなし処理 ets - MnesiaをつかわずETSテーブルで処理 write delete read match_object select \n- create_schema(ListOfNodes)\n- create_table(TableName, Option) オプション {attributes, List} - テーブルのカラム名 {disc_copies, NodeList} {disc_only_copies, NodeList} {ram_copies, NodeList} - テーブルの保存場所 {index, ListOfIntegers} - インデックスをはる {record_name, Atom} - テーブルの別名（非推奨） {type, Type} - テーブル種類 (set, ordered_set, bag) {local_content, Boolean} - デフォルト false。true にすると、多数のノード上に共有されない固有のローカルテーブルを作成する \n- オプション {attributes, List} - テーブルのカラム名 {disc_copies, NodeList} {disc_only_copies, NodeList} {ram_copies, NodeList} - テーブルの保存場所 {index, ListOfIntegers} - インデックスをはる {record_name, Atom} - テーブルの別名（非推奨） {type, Type} - テーブル種類 (set, ordered_set, bag) {local_content, Boolean} - デフォルト false。true にすると、多数のノード上に共有されない固有のローカルテーブルを作成する \n- {attributes, List} - テーブルのカラム名\n- {disc_copies, NodeList} {disc_only_copies, NodeList} {ram_copies, NodeList} - テーブルの保存場所\n- {index, ListOfIntegers} - インデックスをはる\n- {record_name, Atom} - テーブルの別名（非推奨）\n- {type, Type} - テーブル種類 (set, ordered_set, bag)\n- {local_content, Boolean} - デフォルト false。true にすると、多数のノード上に共有されない固有のローカルテーブルを作成する\n- wait_for_tables - テーブル読込完了まで待機\n- activity(AccessContext, Fun[, Args]) - クエリの実行方法を指定 AccessContextの種類 transaction - 非同期トランザクション、トランザクションの完了を待つわけではないので正確ではない sync_transaction - 同期トランザクション async_dirty - 非同期のロックなし処理 sync_dirty - 同期のロックなし処理 ets - MnesiaをつかわずETSテーブルで処理 \n- AccessContextの種類 transaction - 非同期トランザクション、トランザクションの完了を待つわけではないので正確ではない sync_transaction - 同期トランザクション async_dirty - 非同期のロックなし処理 sync_dirty - 同期のロックなし処理 ets - MnesiaをつかわずETSテーブルで処理 \n- transaction - 非同期トランザクション、トランザクションの完了を待つわけではないので正確ではない\n- sync_transaction - 同期トランザクション\n- async_dirty - 非同期のロックなし処理\n- sync_dirty - 同期のロックなし処理\n- ets - MnesiaをつかわずETSテーブルで処理\n- write\n- delete\n- read\n- match_object\n- select\n- application set_env(mnesia, dir, \"path/to/db\") - スキーマ保存場所を指定 \n- set_env(mnesia, dir, \"path/to/db\") - スキーマ保存場所を指定 \n\nクエリリスト内包表記 \n\n- qlc q(Fun, Generator) - クエリハンドル eval(QueryHandle) - 評価 fold(Fun, Dict, QueryHandle) \n- q(Fun, Generator) - クエリハンドル\n- eval(QueryHandle) - 評価\n- fold(Fun, Dict, QueryHandle)   > 33 Dialyzer33 Dialyzer \n\n今回は静的型チェッカーDialyzerについてかんがえる。   > Dialyzerの特徴Dialyzerの特徴 \n\nCLI \n\n- PLT (Persistent Lookup Table 永続的探索表) dialyzer --build_plt --apps erts kernel stdlib mnesia sasl common_test eunit - PLT作成 dialyzer --add_to_plt --apps reltool - PLT追加 \n- dialyzer --build_plt --apps erts kernel stdlib mnesia sasl common_test eunit - PLT作成\n- dialyzer --add_to_plt --apps reltool - PLT追加\n- 型チェック dialyzer foo/src/bar.erl - ファイルを解析 dialyzer -r foo/src bar/src --src - ディレクトリ指定してerlファイルを解析 \n- dialyzer foo/src/bar.erl - ファイルを解析\n- dialyzer -r foo/src bar/src --src - ディレクトリ指定してerlファイルを解析 \n\nErlangの型 \n\n- シングルトン型 - それ自体が型を示すオブジェクト 'some atom - アトム 42 - 整数 [] - 空リスト {} - 空タプル <<>> - 空バイナリ \n- 'some atom - アトム\n- 42 - 整数\n- [] - 空リスト\n- {} - 空タプル\n- <<>> - 空バイナリ\n- BIF型 any() none() pid() port() reference() atom() atom() binary() <<_:Integer>> - 特定サイズのバイナリ <<_:*Integer>> - 特定のユニットサイズで長さは指定されていないバイナリ <<_:Integer, _:_*OtherInteger>> - 上記2つの組み合わせ、バイナリの最小の長さを指定する形式 integer() N..M - 整数の範囲 non_neg_integer() pos_integer() - ゼロより大きい自然数 neg_integer() - 負の整数 float() fun() - あらゆる種類の関数 fun((...) -> Type) - 引数のアリティが決まっていない、特定の肩を返す無名関数 fun(() -> Type) fun((Type1, Type2, ..., TypeN) -> Type) [Type()] - 特定の型を持つリスト [Type(), ...] - 特定の型を持つリスト、またリストが空でないことを示す tuple() {Type1, Type2, ..., TypeN} - 全要素の型とサイズがわかっているタプル \n- any()\n- none()\n- pid()\n- port()\n- reference()\n- atom()\n- atom()\n- binary()\n- <<_:Integer>> - 特定サイズのバイナリ\n- <<_:*Integer>> - 特定のユニットサイズで長さは指定されていないバイナリ\n- <<_:Integer, _:_*OtherInteger>> - 上記2つの組み合わせ、バイナリの最小の長さを指定する形式\n- integer()\n- N..M - 整数の範囲\n- non_neg_integer()\n- pos_integer() - ゼロより大きい自然数\n- neg_integer() - 負の整数\n- float()\n- fun() - あらゆる種類の関数\n- fun((...) -> Type) - 引数のアリティが決まっていない、特定の肩を返す無名関数\n- fun(() -> Type)\n- fun((Type1, Type2, ..., TypeN) -> Type)\n- [Type()] - 特定の型を持つリスト\n- [Type(), ...] - 特定の型を持つリスト、またリストが空でないことを示す\n- tuple()\n- {Type1, Type2, ..., TypeN} - 全要素の型とサイズがわかっているタプル\n- エイリアス型 term() boolean() - 'true' | 'false' byte() - 0..255 char() - 0..16#10ffff number() - integer() | float() maybe_improper_list() - maybe_improper_list(any(), any()) maybe_improper_list(T) - maybe_improper_list(T, any()) string() - [char()] iolist() - maybe_improper_list(char() | binary() | iolist(), binary() | []) module() - atom() timeout() - non_neg_integer() node() - アトム no_return() - none() \n- term()\n- boolean() - 'true' | 'false' \n- byte() - 0..255 \n- char() - 0..16#10ffff \n- number() - integer() | float() \n- maybe_improper_list() - maybe_improper_list(any(), any()) \n- maybe_improper_list(T) - maybe_improper_list(T, any()) \n- string() - [char()] \n- iolist() - maybe_improper_list(char() | binary() | iolist(), binary() | []) \n- module() - atom() \n- timeout() - non_neg_integer() \n- node() - アトム\n- no_return() - none()  \n\n判定できない例と対策   erlang \n\n-module(cards). -export([kind/1, main/0]). -type suit() :: spades | clubs | hearts | diamonds. -type value() :: 1..10 | j | q | k. -type card() :: {suit(), value()}. -spec kind(card()) -> 'face' | 'number'. % 注釈をくわえることでdialyzerに警告させる kind({_, A}) when A >= 1, A =< 10 -> number; kind(_) -> face. main() -> number = kind({spades, 7}), face = kind({hearts, k}), number = kind({rubies, 4}), % タプルの中の型が違う  face = kind({clubs, q}).     erlang \n\n-module(convert). -export([main/0]). %% 注釈をつけないとdialyzerは下記のように判定する % -spec convert(list() | tuple()) -> list() | tuple(). -spec convert(tuple()) -> list(); (list()) -> tuple(). main() -> [_, _] = convert({a, b}), {_, _} = convert([a, b]), [_, _] = convert([a, b]), {_, _} = convert({a, b}). %% private convert(Tup) when is_tuple(Tup) -> tuple_to_list(Tup); convert(L=[_|_]) -> list_to_tuple(L)."},"name":"[2017-04-29]LYSE本を読む","tags":["erlang","elixir"],"childPublishedDate":{"published_on":"2017-04-29T00:00:00.000Z","published_on_unix":1493424000}}},{"node":{"number":49,"relative_category":"blog/backend","fields":{"title":"HydeをつかってEmacsをJekyllクライアントにする","excerpt":"Emacianとしてその殻の中に閉じこもっていたいです。だけど、世間がそれを許さず次々と無理難題を押しつけてくるのです。今回はタスク等から出てきた備忘禄をGitHub Pages（Jekyll）で管理しようと重い腰を上げました。   > PROBLEMPROBLEM \n\n- タスクメモがAsanaなどのタスク管理ツールに散在している\n- ブラウザをつかって文章を書くのがつらい\n- Gist/Yagist等でもいいのだけど編集がめんどうとか個人だとオーバースペックとか   > SOLUTIONSOLUTION \n\nというわけで、GitHub Pages（Jekyll）をEmacsで楽に管理できないかと以前から考えていたのですが、いい塩梅のライブラリを発見しました。JekyllだからHydeと言います。名前が jekyll doctor (hyde)とかぶっていますがここでは気にしません。 \n\nHydeのPros/Consは以下の通りです。 \n\nPros \n\n- gitの自動コメント\n- jekyll build、jekyll serveのショートカット \n\nCons \n\n- キーバインドが既存のものとかぶる\n- hyde-homeがカスタム変数ではない\n- add-hookが効かない   > Hydeの設定Hydeの設定 \n\nHydeの設定は基本いじることもなくJekyllを使うことが出来ます。下記記載するのはConsつぶしですが、ここはお好みです。 \n\nまず、キーバインド操作。Hyde本体がキーバインドをdefvarで割り当てているので、init.elの設定でrequire前に割り込みevalして、hyde関数にhyde-home引数をわたすことで解決します。あと、折り返し回りは別設定になっているのでadaptive-wrapやtruncate-linesを設定しています。   emacs-lisp \n\n;;; Hyde (Jekyll client) (require-package 'adaptive-wrap) (defun hyde/open-post-maybe-into-other-window (pos) \"Opens the post under cursor in the editor (POS).\" (interactive \"d\") (let ((post-file-name (nth 1 (split-string (strip-string (thing-at-point 'line)) \" : \"))) (dir (get-text-property pos 'dir))) (let ((hyde-buffer (current-buffer))) (find-file-other-window (strip-string (concat hyde-home \"/\" dir \"/\" post-file-name))) (hyde-markdown-activate-mode hyde-buffer) (adaptive-wrap-prefix-mode t) (set-default 'truncate-lines nil)))) (defun hyde/quit-wrap () \"Quits hyde.\" (interactive) (progn (delete-other-windows) (kill-buffer (current-buffer)))) (defun create-markdown-scratch () \"Create a markdown scratch buffer.\" (interactive) (switch-to-buffer (get-buffer-create \"*markdown*\")) (markdown-mode)) (defun hyde/nabinno () \"Run hyde-wrap with home parameter.\" (interactive) (progn (delete-other-windows) (create-markdown-scratch) (split-window-horizontally) (other-window 1) (hyde \"~/nabinno.github.io/\"))) (defvar hyde-mode-map (let ((hyde-mode-map (make-sparse-keymap))) (define-key hyde-mode-map (kbd \"N\") 'hyde/new-post) (define-key hyde-mode-map (kbd \"G\") 'hyde/load-posts) (define-key hyde-mode-map (kbd \"C\") 'hyde/hyde-commit-post) (define-key hyde-mode-map (kbd \"P\") 'hyde/hyde-push) (define-key hyde-mode-map (kbd \"J\") 'hyde/run-jekyll) (define-key hyde-mode-map (kbd \"S\") 'hyde/serve) (define-key hyde-mode-map (kbd \"K\") 'hyde/stop-serve) (define-key hyde-mode-map (kbd \"d\") 'hyde/deploy) (define-key hyde-mode-map (kbd \"D\") 'hyde/delete-post) (define-key hyde-mode-map (kbd \"U\") 'hyde/promote-to-post) (define-key hyde-mode-map (kbd \"X\") 'hyde/quit-wrap) (define-key hyde-mode-map (kbd \"O\") 'hyde/open-post-maybe-into-other-window) hyde-mode-map) \"Keymap for Hyde\") (global-set-key (kbd \"C-c ; j\") 'hyde/nabinno) (require-package 'hyde) (require 'hyde)   \n\n次に、ホストIPの操作。Jekyllのルートにおく.hyde.elの中身です。JekyllはWebrickを使っているので、VMなどでホストをいじっている場合はhyde/serve-commandにホストIPを0.0.0.0（jekyll s -H 0.0.0.0）に変更する必要があります。   emacs-lisp \n\n(setq hyde-deploy-dir \"_site\" hyde-posts-dir \"_posts\" hyde-drafts-dir \"_drafts\" hyde-images-dir \"images\" hyde/git/remote \"upstream\" ; The name of the remote to which we should push hyde/git/branch \"master\" ; The name of the branch on which your blog resides hyde/jekyll-command \"jekyll b\" ; Command to build hyde/serve-command \"jekyll s -H 0.0.0.0 --force_polling\" ; Command to serve hyde-custom-params '((\"category\" \"personal\") (\"tags\" \"\") (\"cover\" \"false\") (\"cover-image\" \"\")))     > WRAPUPWRAPUP \n\nHydeを介してEmacsでJekyllを操作できるのは、やはり快適です。特にorg-modeとMarkdownの相性が良く。org-modeで管理していた備忘をMarkdownに変換し、Jekyll（GitHub Pages）にパブリッシュというワークフローが引けたのが良かったです。数年間はお世話になると思います。"},"name":"[2017-02-01]HydeをつかってEmacsをJekyllクライアントにする","tags":["emacs","jekyll","hyde","github-pages"],"childPublishedDate":{"published_on":"2017-02-01T00:00:00.000Z","published_on_unix":1485907200}}},{"node":{"number":52,"relative_category":"blog/backend","fields":{"title":"HerokuとGAEのCIをDockerとパイプラインから構成されたWerckerで管理する","excerpt":"Continuous Integration (CI) が徐々にDockerに対応し始める機運です。先行してWerckerがDocker対応を始めたので、その流れに乗るべくWerckerをDocker化してみました。   > PROBLEMPROBLEM \n\n- パフォーマンス改善のための開発環境がいけてない\n- 別PaaSへ移行するための開発環境が汎用化できてない、つらい   > SOLUTIONSOLUTION \n\nというわけで、まずはCI上のDockerに載せてから次の手（GAEあたり）を考えることにしました。CIはWerckerを使用。以前から使っていたのですが、今回はボックスがDockerになったのでそちらに対応しました。 \n\nまず、Werckerは「Docker」「環境変数」による環境管理、「パイプライン」によるワークフロー管理を行っています。 \n\n1. Dockerで環境を管理。 今回は対応していないですが、GAEのコンテナ（gcr.io/google_appengine/ruby:xxx）と共通化することもできます。ただし、HerokuのHobby Dynosはプロセス数に制限があるのでコンテナ運用は工夫が必要です。\n2. 異なるサービス間のネットワークをWerckerが生成する環境変数で管理。 Dockerのネットワーク設定の煩雑さを解消します。\n3. タスクをワークフローとしてパイプラインで条件付け管理。 パイプラインごとにコンテナを立ち上げているので、同じDocker環境でもパイプラインごとに環境変数を分けることが可能です。Herokuのパイプラインでもいいですが、今後別PaaSに移行する可能性を考えてCI管理にbetしました。 \n\n次に、Werckerのふるまいを定義するwercker.ymlは、下記シークエンス図のようにパイプラインごとに記述されています。今回は各パイプラインの詳細を見ていくことにします。    > devパイプラインdevパイプライン \n\ndevパイプラインは wercker dev コマンドをローカルでたたく際に使います。下記の例だとRSpec走らせているだけなのでおまけ程度。ただ、ローカル開発でDockerを使うことになったらこういう提案もありだと思います。プロジェクトレポジトリすべてをDockerにしてローカル開発するペイン、所謂git-dockerのバージョン管理問題があるので代替案として。   yaml \n\nbox: ruby:2.3.1 services: - postgres:9.6.1 - redis:3.0.3 dev: steps: - bundle-install - script: name: Install ImageMagick code: | apt-get update apt-get install -y nodejs imagemagick - script: name: Setup database code: | RAILS_ENV=test bundle exec rake db:create db:migrate - internal/watch: name: Run rspec code: | RAILS_ENV=test bundle exec rake spec reload: true     > buildパイプラインbuildパイプライン \n\nbuildパイプラインもdevパイプラインと同じDockerボックスを使っています。やっていることはdevパイプラインと変わらず、すべてのブランチで走ります。   yaml \n\nbuild: steps: - bundle-install - script: name: Install ImageMagick code: | apt-get update apt-get install -y nodejs imagemagick - script: name: Echo Ruby information code: | env echo \"ruby version $(ruby --version) running!\" echo \"from location $(which ruby)\" echo -p \"gem list: $(gem list)\" - script: name: Setup database code: | RAILS_ENV=test bundle exec rake db:create db:migrate - script: name: Run rspec code: | RAILS_ENV=test bundle exec rake spec     > deploy-stageパイプラインdeploy-stageパイプライン \n\ndeploy-stageパイプラインはステージング環境用。現在Herokuを本番環境で利用しているので、デプロイごとにそれをフォークして環境構築しています。また、Railsのアセットプリコンパイルの時間短縮はほかのCIと同様にキャッシュを利用しています。 \n\n他のPaaSに移った場合に現在行っている本番環境のフォークをどうするかが検討課題となります。   yaml \n\ndeploy-stage-heroku: steps: - bundle-install - script: name: Install NodeJS code: | apt-get update apt-get install -y nodejs - nabinno/heroku-install: key: $HEROKU_KEY user: $HEROKU_USER app-name: $HEROKU_APP_NAME - script: name: Fork Application - destroy application code: | heroku apps:destroy --app $HEROKU_APP_NAME --confirm $HEROKU_APP_NAME - script: name: Fork Application - fork code: | heroku fork --from $FROM_HEROKU_APP_NAME --to $HEROKU_APP_NAME - script: name: Fork Application - setup addons of rediscloud code: | heroku addons:create rediscloud:30 --app $HEROKU_APP_NAME - script: name: Fork Application -change dynos code: | heroku ps:scale web=1:Free worker=1:Free --app $HEROKU_APP_NAME - script: name: Fork Application - change environment variables code: | _rediscloud_url=$(heroku run 'env | grep -e REDISCLOUD_.*_URL' --app $HEROKU_APP_NAME | awk -F= '{print $2}') heroku config:set \\ S3_BUCKET=$S3_BUCKET \\ HEROKU_APP=$HEROKU_APP_NAME \\ REDISCLOUD_URL=$_rediscloud_url \\ --app $HEROKU_APP_NAME - script: name: Assets Precompile - restore assets cache code: | [ -e $WERCKER_CACHE_DIR/public/assets ] && cp -fr $WERCKER_CACHE_DIR/public/assets $WERCKER_SOURCE_DIR/public || true mkdir -p $WERCKER_SOURCE_DIR/tmp/cache [ -e $WERCKER_CACHE_DIR/tmp/cache/assets ] && cp -fr $WERCKER_CACHE_DIR/tmp/cache/assets $WERCKER_SOURCE_DIR/tmp/cache || true - script: name: Assets Precompile - main process code: | RAILS_ENV=production bundle exec rake assets:precompile --trace - script: name: Assets Precompile - store assets cache code: | mkdir -p $WERCKER_CACHE_DIR/public/assets cp -fr $WERCKER_SOURCE_DIR/public/assets $WERCKER_CACHE_DIR/public mkdir -p $WERCKER_CACHE_DIR/tmp/cache/assets cp -fr $WERCKER_SOURCE_DIR/tmp/cache/assets $WERCKER_CACHE_DIR/tmp/cache - add-ssh-key: host: github.com keyname: GITHUB - add-to-known_hosts: hostname: github.com fingerprint: 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48 - script: name: Assets Precompile - git commit code: | { git add public/assets/.sprockets-manifest-*.json git commit -m 'Run `rake assets:precompile` on Wercker.' } || { echo 'Skip: keep precompiled assets manifest.' } - heroku-deploy: key: $HEROKU_KEY user: $HEROKU_USER app-name: $HEROKU_APP_NAME - script: name: DB Migrate code: | heroku run 'bundle exec rake db:migrate --trace' --app $HEROKU_APP_NAME after-steps: - wantedly/pretty-slack-notify: webhook_url: ${SLACK_WEBHOOK_URL} channel: general     > deploy-prod-herokuパイプラインdeploy-prod-herokuパイプライン \n\ndeploy-prod-herokuパイプラインは本番環境へのリリース用。環境変数以外はdeploy-stageパイプラインと同じものです。   yaml \n\ndeploy-prod-heroku: steps: - bundle-install - script: name: Install NodeJS code: | apt-get update apt-get install -y nodejs - script: name: Assets Precompile - restore assets cache code: | [ -e $WERCKER_CACHE_DIR/public/assets ] && cp -fr $WERCKER_CACHE_DIR/public/assets $WERCKER_SOURCE_DIR/public || true mkdir -p $WERCKER_SOURCE_DIR/tmp/cache [ -e $WERCKER_CACHE_DIR/tmp/cache/assets ] && cp -fr $WERCKER_CACHE_DIR/tmp/cache/assets $WERCKER_SOURCE_DIR/tmp/cache || true - script: name: Assets Precompile - main process code: | RAILS_ENV=production bundle exec rake assets:precompile --trace - script: name: Assets Precompile - store assets cache code: | mkdir -p $WERCKER_CACHE_DIR/public/assets cp -fr $WERCKER_SOURCE_DIR/public/assets $WERCKER_CACHE_DIR/public mkdir -p $WERCKER_CACHE_DIR/tmp/cache/assets cp -fr $WERCKER_SOURCE_DIR/tmp/cache/assets $WERCKER_CACHE_DIR/tmp/cache - add-ssh-key: host: github.com keyname: GITHUB - add-to-known_hosts: hostname: github.com fingerprint: 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48 - script: name: Assets Precompile - git commit code: | { git add public/assets/.sprockets-manifest-*.json git commit -m 'Run `rake assets:precompile` on Wercker.' } || { echo 'Skip: keep precompiled assets manifest.' } - script: name: Add git-tag code: | _tag=$(date -u -d '9 hours' +%Y-%m-%d-%H-%M-%S) git config --global user.email 'wercker@blahfe.com' git config --global user.name 'Wercker Bot' git tag -a $_tag master -m 'wercker deploy' git push origin $_tag - heroku-deploy: key: $HEROKU_KEY user: $HEROKU_USER app-name: $HEROKU_APP_NAME install-toolbelt: true - script: name: DB Migrate code: | heroku run 'bundle exec rake db:migrate --trace' --app $HEROKU_APP_NAME after-steps: - wantedly/pretty-slack-notify: webhook_url: ${SLACK_WEBHOOK_URL} channel: general     > deploy-prod-gaeパイプラインdeploy-prod-gaeパイプライン \n\ndeploy-prod-gaeパイプラインはdeploy-prod-herokuパイプラインと同じく本番環境へのリリース用。GAEにいつでも移行できるように走らせています。 \n\nGAEのデプロイは癖があって、gcloud app deployコマンドをつかってDockerビルドを走らせますが、その時にDocker内に外部から環境変数を設定することができません。そのため、アセットプリコンパイルのビルドの際、asset_syncを使っていると別サーバーへ同期に失敗します。また、パイプライン上の別ステップに環境変数を当てて行うことはできるが、gcloudのデプロイステップとアセットプリコンパイルが重複して適切なダイジェストを発行できません。従って、GAEをつかう場合は ./public ディレクトリをつかうのが現状の正解です。HerokuのSlugの取り扱い方針と違うので注意が必要です。 \n\nGAEのコンテナの中身は、gcloud beta app gen-config --runtime=ruby --custom で出力されるDockerfileを参照ください。   yaml \n\ndeploy-prod-gae: steps: - bundle-install - script: name: Install ImageMagick code: | apt-get update apt-get install -y nodejs imagemagick - script: name: Echo Ruby information code: | env echo \"ruby version $(ruby --version) running!\" echo \"from location $(which ruby)\" echo -p \"gem list: $(gem list)\" - script: name: DB Migrate code: | RAILS_ENV=production \\ DATABASE_URL=${DATABASE_URL} \\ bundle exec rake db:create db:migrate --trace - script: name: Install gcloud code: | curl https://sdk.cloud.google.com | bash source ~/.bashrc - script: name: Authenticate gcloud code: | gcloud config set project utagaki-v2 openssl aes-256-cbc -k ${DECRYPT_KEY} -d -in ./gcloud.json.encrypted -out ./gcloud.json gcloud auth activate-service-account --key-file ./gcloud.json - script: name: Deploy app to Google App Engine code: | gcloud app deploy ./app.yaml --promote --stop-previous-version after-steps: - wantedly/pretty-slack-notify: webhook_url: ${SLACK_WEBHOOK_URL} channel: general     > post-deployパイプラインpost-deployパイプライン \n\npost-deployパイプラインは本番環境にデプロイした後の後処理用です。参考程度に git tag をつけています。   yaml \n\npost-deploy: steps: - add-ssh-key: host: github.com keyname: GITHUB - add-to-known_hosts: hostname: github.com fingerprint: 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48 - script: name: Add git-tag code: | _tag=$(date -u -d '9 hours' +%Y-%m-%d-%H-%M-%S) git remote add origin git@github.com:nabinno/utagaki.git git config --global user.email 'wercker@blahfe.com' git config --global user.name 'Wercker Bot' git tag -a $_tag master -m 'wercker deploy' git push origin $_tag after-steps: - wantedly/pretty-slack-notify: webhook_url: ${SLACK_WEBHOOK_URL} channel: general     > WRAPUPWRAPUP \n\nこうしてWerckerの設定ファイルを書いてみるに、どのCI、どの仮想環境も同じ書き味ということが分かります。当処懸念していたDocker化することによる嵌まり事はなく、すんなり移行することができました。 \n\n手軽さ、管理のしやすさから、今後はすべてのCIがDockerに移行するでしょう。"},"name":"[2017-02-07]HerokuとGAEのCIをDockerとパイプラインから構成されたWerckerで管理する","tags":["wercker","docker","heroku","google-app-engine"],"childPublishedDate":{"published_on":"2017-02-07T00:00:00.000Z","published_on_unix":1486425600}}},{"node":{"number":56,"relative_category":"blog/backend","fields":{"title":"RubyのCSVパースをPyCallで実行する（ベンチマーク）","excerpt":"先日RubyからPythonにアクセスできるPyCallというライブラリの存在を知り、ぜひともベンチマークを取りたいと思った次第です。現状RubyのCSVの読み込みに不満を持っており、そこをどうにか解消したいと考えています。   > PROBLEMPROBLEM \n\n- 大量のCSVを読み込む際、毎回時間がかかる   > SOLUTIONSOLUTION \n\nというわけで、「Dalibor Nasevicのベンチマーク記事」にPyCallのベンチマークをくわえて比較してみることにしました。記事では下記の通り CSV.foreach が速いとの結論でした。    kind_of_parse time (real) memory (MB)     1. CSV.read  39.13 866.6   2. CSV.parse  36.16 936.87   3. line by line from String Object 23.39 73.42   4. line by line from IO Object 24.55 0.0   5. CSV.foreach  24.04 0.0      > PyCallのベンチマークPyCallのベンチマーク \n\nそれでは、PyCallのベンチマークを計りましょう。コードは下記のようになります。   ruby \n\nrequire_relative './helpers' require 'pycall/import' include PyCall::Import pyimport :pandas, as: :pd print_memory_usage do print_time_spent do csv = pd.read_csv.('data.csv') sum = csv['id'].sum.() puts \"Sum: #{sum}\" end end   \n\nPyCallは pyenv との相性が悪いのでSystemインストールしたPythonでたたきます。   sh \n\n$ PYTHON=/usr/bin/python3.4 ruby parse_6_pycall.rb Sum: 499999500000 Time: 1.49 Memory: 54.99 MB   \n\n結果    kind_of_parse time (real) memory (MB)     1. CSV.read  39.13 866.6   2. CSV.parse  36.16 936.87   3. line by line from String Object 23.39 73.42   4. line by line from IO Object 24.55 0.0   5. CSV.foreach  24.04 0.0   6. PyCall 1.49 54.99    \n\nはい、結果が出ました。Daliborのベンチマーク記事で一番速かった CSV.foreach より16倍の実行速度となりました。   > WRAPUPWRAPUP \n\nPyCallのオブジェクトが PyObjectとActiveRecordと相性が悪そうなのと、PythonとRuby双方のメモリー管理が運用を難しくすることから、安易に本番環境のRailsに導入するのは厳しいと思います。 \n\nただし、実行回数が限定されたスクリプトなら積極的に使って良いでしょう。"},"name":"[2017-06-05]RubyのCSVパースをPyCallで実行する（ベンチマーク）","tags":["ruby","benchmark","pycall"],"childPublishedDate":{"published_on":"2017-06-05T00:00:00.000Z","published_on_unix":1496620800}}},{"node":{"number":62,"relative_category":"blog/backend","fields":{"title":"Elixirではてなブックマーク","excerpt":"紆余曲折合ってはてなブックマークの運用を見直す必要が出てきました。人の興味というのは尽きないもので知りたいことが次々出てきます。にも拘わらず人の時間は有限でそれにあがなうための手段を考えたわけです。   > PROBLEMPROBLEM \n\n- フィードリーダーで記事を読んだ後にはてなブックマーク（ブクマ）するとフィード消化するのに時間がかかる フィードをそのままブクマしていると下記の問題がでてくる あとで確認することができない 読みたくない記事をブクマしてしまう 適切でないURLでブクマしてしまう \n- フィードをそのままブクマしていると下記の問題がでてくる あとで確認することができない 読みたくない記事をブクマしてしまう 適切でないURLでブクマしてしまう \n- あとで確認することができない\n- 読みたくない記事をブクマしてしまう\n- 適切でないURLでブクマしてしまう   > SOLUTIONSOLUTION \n\nというわけで、下記の方針でブクマすることにしました。設置方法の詳細はGitHubレポジトリを参照ください。そして、方針は下記の通りになります。 \n\n方針 \n\n- フィードごとにタグづけする\n- ブクマ対象になる記事をリンクとタイトルで除外判定する\n- ブクマ対象になる記事をリンクから校正すべきものかリダイレクトすべきものか判定する\n- 上記設定はYAMLファイルで簡単に管理できるようにする\n- フィード読込とブクマを非同期処理できるようElixirで実装する   > ブクマの管理方法ブクマの管理方法 \n\nまずブクマの管理ですが、下記5つのYAMLファイルで構成しています、構造はマップとリストのみ。ブクマしたいと思う記事を読みすすめる中で気になるキーワードが出てきたら都度 feed.yaml を更新します。また、記事にノイズが多いようだったら傾向を分析して除外ファイル feed_excluded_link.yaml feed_excluded_title.yaml を更新します。    item description     feed.yaml フィードグループ名に対するリンク、タグのマップ   feed_excluded_link.yaml 除外すべきフィードリンクのリスト   feed_excluded_title.yaml 除外すべきフィードタイトルのリスト   feed_corrected_link.yaml フィードリンクに対するトリミングすべきパラメータのマップ   feed_redirected_link.yaml フィードリンクに対するリダイレクト先リンクのマップ      yaml \n\n# feed.yaml nabinno/sports/feed_group_name: tags: - ski links: - http://rss.example.com/ski_feed.rss - http://rss.example.com/snowboard_feed.rss - http://ski-status.example.com/rss # feed_excluded_link.yaml - anti-ski.example.com - awesome-snowboard.example.com # feed_excluded_title.yaml - queer - two-planker - beaver-tail # feed_corrected_link.yaml amazon.com: - ref - ie # feed_redirected_link.yaml ski-status.example.com: - Floki.find(fst, \".post__body a\")     > Elixirによる非同期処理Elixirによる非同期処理 \n\nElixirで非同期処理を行っているのですが、大きく分けて監視機構のSupervisorと非同期処理のTask.async_streamを使っています。   > 監視機構 Supervisor監視機構 Supervisor \n\nまず、Supervisor。Elixirには監視機構Supervisorがあり、それが各ワーカーを子プロセスとして管理しています。ここではフィード読込とブクマは別々のワーカーで処理しますが、キャッシュが暖気処理を別ワーカーで行っているため再起動戦略は「失敗したイベントの中にあるすべての子プロセスを再起動」（ one_for_all ）にしてあります。再起動戦略の詳細は「OTPスーパバイザ · Elixir School」を参照下さい。 \n\n下記のように Supervisor.start_link を Keshikimi2.Application.start に適用すると、アプリケーション開始（ mix run ）した時点で監視機構が起動されます。   ex \n\nSupervisor.start_link( [ :hackney_pool.child_spec(:hatena_bookmark_pool, timeout: 15_000, max_connections: 100), # @todo 当該ワーカーで暖気処理を行っていないので `one_for_one` にした場合、再起動時にほかに影響する supervisor(Cachex, [:feed, []]), supervisor(Keshikimi2Feed.Registry, [prefix]), # フィード読込処理 (PubSub) supervisor(Keshikimi2Feed.Subscriber, [prefix]), worker(Keshikimi2Feed.Worker, [prefix]), worker(Keshikimi2Feed.Publisher, [[prefix: prefix, poll_interval: 3_000]]), # ブクマ処理 worker(Keshikimi2.HatenaBookmark.AddEntry, [ [prefix: prefix, poll_interval: 3_000] ]) ], strategy: :one_for_all, name: name(prefix) )     > 非同期処理 Task.async_stream非同期処理 Task.async_stream \n\n次に、Task.async_stream。配列を引き回すリクエスト処理は Task.async_stream がうってつけです。下記ではキャッシュからブクマ対象になるフィードリンクを取り出し、除外処理、校正処理を加えて、ブクマのリクエストを出すという流れを組んでいます。Elixirでは、流れをひとまとめにして視覚的にわかりやすく非同期処理してくことができます。   ex \n\nCachex.keys!(:feed) |> Enum.reject(fn key -> key in [ \"excluded_links\", \"excluded_titles\", \"corrected_links\", \"redirected_links\", \"feed_group\", \"archived_links\" ] end) |> Task.async_stream( fn item_link -> with {:ok, [item_title, feed_tags]} <- Cachex.get(:feed, item_link), :ok <- validate_all(item_link, item_title), corrected_link <- correct_all(item_link), {:ok, payload} <- FormData.create( %{ url: corrected_link, comment: feed_tags |> Enum.map_join(fn tag -> \"[#{tag}]\" end), rks: System.get_env(\"HATENA_BOOKMARK_RKS\"), private: 0, keep_original_url: 1, with_status_op: 1, from: \"inplace\", post_twitter: 0, post_evernote: 0 }, :url_encoded, get: false ) do do_add_entries_to_hb(payload) Logger.info(\"add entry: #{item_link}\") end archive_link(item_link) end, timeout: 15_000 ) |> Stream.run()     > WRAPUPWRAPUP \n\nElixirの非同期処理を使うことではてなブックマークの運用がとても快適になりました。はてなブックマークとの今後の付き合い方は下記のように考えています。 \n\n- 手動でブクマ: 気になった記事があるごとに\n- ブクマの確認: 気になるタグごとにまとめて確認 \n\nブクマの確認については、例えば、CIでデプロイしている間に最近のGitHubの動向を確認したい場合は「nabinno/github」をみる、という感じの運用です。 \n\n融通が利かない点で途中運用が難しくなる気もしますが、しばらく回してみます。"},"name":"[2019-01-01]Elixirではてなブックマーク","tags":["elixir","hatena-bookmark"],"childPublishedDate":{"published_on":"2019-01-01T00:00:00.000Z","published_on_unix":1546300800}}},{"node":{"number":64,"relative_category":"blog/backend","fields":{"title":"WSL2時代のDocker開発スタイル","excerpt":"6月13日は狂喜乱舞しました、久しぶりに徹夜するくらい興奮しました。そう、WSL2が出たのですよね。先日やっと私の手元に届いたので早々に検証しました。   > PROBLEMPROBLEM \n\n- あたらしくでたWSL2によって以前書いた記事からだいぶ状況が変わった 主な変更点 WSLのアーキテクチャが2種類になり、WSLはその2つのアーキテクチャを管理する機能に変わった WSL1 Windows Subsystem for Linux上のLinux (LXCore/Lxss) WSL2 軽量Hyper-V上のLinux (Linux Kernel) /procや/sysなどの特殊ファイルもふくめた共有プロトコル「9P」が実装された Win32側の9Pクライアント 9prdr.sys WSL側の9Pクライアント /init \n- 主な変更点 WSLのアーキテクチャが2種類になり、WSLはその2つのアーキテクチャを管理する機能に変わった WSL1 Windows Subsystem for Linux上のLinux (LXCore/Lxss) WSL2 軽量Hyper-V上のLinux (Linux Kernel) /procや/sysなどの特殊ファイルもふくめた共有プロトコル「9P」が実装された Win32側の9Pクライアント 9prdr.sys WSL側の9Pクライアント /init \n- WSLのアーキテクチャが2種類になり、WSLはその2つのアーキテクチャを管理する機能に変わった WSL1 Windows Subsystem for Linux上のLinux (LXCore/Lxss) WSL2 軽量Hyper-V上のLinux (Linux Kernel) \n- WSL1 Windows Subsystem for Linux上のLinux (LXCore/Lxss)\n- WSL2 軽量Hyper-V上のLinux (Linux Kernel)\n- /procや/sysなどの特殊ファイルもふくめた共有プロトコル「9P」が実装された Win32側の9Pクライアント 9prdr.sys WSL側の9Pクライアント /init \n- Win32側の9Pクライアント 9prdr.sys \n- WSL側の9Pクライアント /init    > SOLUTIONSOLUTION \n\nというわけで、前記事で掲げていた目標「WSLでDockerをつかったWebアプリケーション開発ができるかどうか」について再確認します。   > 対象環境対象環境 \n\n- Windows 10 Pro Version 1903 OS Build 18922.1000 Windows Terminal (Preview) Version 0.2.1715.0 WSL2 Ubuntu Version 1804.2019.5210 (Linux 4.19.43-microsoft-standard) Docker version 19.03.0-rc3, build 27fcb77 WSL1 Ubuntu 18.04 LTS Version 1804.2019.522.0 (Linux 4.4.0-18922-Microsoft) \n- Windows Terminal (Preview) Version 0.2.1715.0\n- WSL2 Ubuntu Version 1804.2019.5210 (Linux 4.19.43-microsoft-standard) Docker version 19.03.0-rc3, build 27fcb77 \n- Ubuntu Version 1804.2019.5210 (Linux 4.19.43-microsoft-standard)\n- Docker version 19.03.0-rc3, build 27fcb77\n- WSL1 Ubuntu 18.04 LTS Version 1804.2019.522.0 (Linux 4.4.0-18922-Microsoft) \n- Ubuntu 18.04 LTS Version 1804.2019.522.0 (Linux 4.4.0-18922-Microsoft)   > Windowsの開発環境を構築するWindowsの開発環境を構築する \n\nまず、Windowsの開発環境の構築ですが、既知の情報をふまえつつTIPSを順次紹介します。   > WSLのインストールWSLのインストール \n\n- WSL2を使ってみる (InsiderPreview) \n\nWSLのパッケージ管理は下記2つを押さえておけば問題ないでしょう。 \n\n1. asdf/anyenv プログラミング言語をバージョンごとにわけて使いたい場合はこちらをつかいましょう 関数言語界隈ではasdfが主流になってきてるようです。 \n2. プログラミング言語をバージョンごとにわけて使いたい場合はこちらをつかいましょう\n3. 関数言語界隈ではasdfが主流になってきてるようです。\n4. nix Haskellのようにasdf/anyenvでインストールできない、あるいは、扱われいないパッケージはnixをつかいましょう また、aptのバージョンが古すぎるパッケージもnixが最適です \n5. Haskellのようにasdf/anyenvでインストールできない、あるいは、扱われいないパッケージはnixをつかいましょう\n6. また、aptのバージョンが古すぎるパッケージもnixが最適です   > ターミナルのインストールターミナルのインストール \n\nWSLttyはWSL2に対応しておらずConEmuは描画がくずれやすいため、デフォルトのターミナルかWindows Terminalが選択肢となります。 \n\nWindows TerminalとConEmuとの比較    - Windows Terminal ConEmu     透過対象 backgroundImage ConEmu自体   キーバインド制約 Alt+Shiftが効かない 特になし   WSL2の描画 特になし くずれる   管理者権限で実行 初回のみ タスク実行ごと      > DockerのインストールDockerのインストール \n\nWSL1ではDockerデーモンがつかえないのでWSL2でDockerをつかうようにしましょう。Docker CEをインストールします。 \n\nどうしてもWSL1でということであれば、Win32 (WSL1からみるとdrvfs) 側でDocker For Windowsを用意します。インストールはDockerのダウンロードページから手順通りおこないます。\n 構成等は前回の記事を参照ください。   > さて、WSL2からDockerはどの程度つかえるのかさて、WSL2からDockerはどの程度つかえるのか \n\nWSL2は軽量Hyper-V上にLinuxコンテナを動かしているので、基本Hyper-Vと同様にDockerをつかうことができます。 \n\nただし、WSL1と違いlocalhostにWSL2がバインドできません (2019-07-27追記: Build Version 18945で解決しました )。\n また、WSL1と同様にWin32・WSL間でのファイルの読み書きにパフォーマンスの差が大きく出ています。 \n\nひとつずつ解決方法を見ていきましょう。   > 1. WSL1と違いlocalhostにWSL2がバインドできません1. WSL1と違いlocalhostにWSL2がバインドできません \n\nWSL2がつかっているVirtual Switchはinternal onlyのため、Win32側からlocalhostをつかってWSL2にアクセスすることができません。現在対応中のようです (2019-07-27追記: Build Version 18945で解決しました )。 \n\n対処方法は2つあります。 \n\na. WSL1をつかう \n\nこれが一番楽ですが、WSL1は次項であげるパフォーマンス上の欠点があるので、Web系フロントエンド開発におけるライブリローディング機能をつかうケースに限定するといいでしょう。 \n\nb. Hostsファイルをつかう \n\nWin32のHostsファイルでWSL2のeth0インターフェイスのIPアドレスに適当なホスト名を割り当てます（ポートごとにホストを振り分けたい場合はWSL2側にProxyを用意するといいでしょう）。   shell \n\n# C:\\Windows\\System32\\drivers\\etc\\hosts 172.17.72.217 dashboard.local.me   \n\nWSL2のIPアドレスはコンテナを立ち上げるごとに変わるので、下記のようなコマンドレットをWin32側のPowerShell $PROFILEに用意しておくといいでしょう。WSL2だけで完結したい方はシェル上から powershell.exe -Command 'Sync-HostsToWslIp' と打つだけです。   powershell \n\n# $PROFILE function Sync-HostsToWslIp { $hosts = \"$env:SystemRoot\\System32\\drivers\\etc\\hosts\"; $pattern = \"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\"; $wslip = bash.exe -c \"ifconfig eth0 | grep 'inet '\"; if ($wslip -match $pattern) { $wslip = $matches[0]; } else { echo \"The Script Exited, the ip address of WSL 2 cannot be found\"; exit; } cat $hosts | %{ $_ -match $pattern } $rc = cat $hosts | %{ $_ -replace $matches[0], $wslip } $rc | Out-File $hosts; }     > 2. WSL1と同様にWin32・WSL間でのファイルの読み書きにパフォーマンスの差が大きく出ています2. WSL1と同様にWin32・WSL間でのファイルの読み書きにパフォーマンスの差が大きく出ています \n\nいろんな方がベンチマークを公開してるのでそれを参考にするといいでしょう。 \n\nCf. \n\n- Pythonでファイル操作のベンチマーク\n- dd、git cloneのベンチマーク \n\nわたしは git status -sb をよくつかうので、そのコマンドで簡単なベンチマークとりました。   shell \n\n# WSLx $ cd ~/nabinno.github.io $ \\time -f %e git status -sb # Win32/WSLx $ cd ~/nabinno.github.io $ \\time -f %e powershell.exe -Command 'git status -sb' # Win32 PS> cd ~/nabinno.github.io PS> (Measure-Command { git status -sb }).TotalMilliseconds / 1000 | %{ [math]::Round($_, 2) }      Subject WSL Win32     WSL1 0.47 0.09   WSL2 0.00 0.61   Win32/WSL1 2.66 1.91   Win32/WSL2 2.81 1.79   Win32 0.51 0.12      > Docker以外でWSLの課題はないのかDocker以外でWSLの課題はないのか   > デバイスへのアクセスデバイスへのアクセス \n\n以前から要望があったものだと「デバイスアクセスができない」件があります。 \n\n9P導入前だとこれはElixirのIoTフレームワークNervesのように、WSL UtilitiesでWSLパスをWin32パスに変換してからWin32にあるデバイス関連ツールをつかうのが簡単な解決策でした。   sh \n\n$ fwup.exe -a -i $(wslpath -w -a _build/rpi0_dev/nerves/images/hello_nerves.fw) -t complete -d $(fwup.exe -D | sed 's/,.*//')   \n\nただし9Pを導入したWindows 10 Version 1903以降は、WSL1もWSL2もともにWSLパスを変換せずにWin32にあるデバイス関連ツールをつかうことができます。   sh \n\n$ fwup.exe -a -i _build/rpi0_dev/nerves/images/hello_nerves.fw -t complete -d $(fwup.exe -D | sed 's/,.*//')     > WRAPUPWRAPUP \n\nわたしの観測範囲では課題はほぼ問題ない状態になっていました。 \n\nおすすめ開発環境は下記のとおり    item content     IDE WSLx上のエディタ   Webフロントエンド開発 WSL1   Docker関連開発 WSL2   dotfiles WSLx、Win32を共有管理    \n\nWin32側のIDEをつかっているユーザーはパフォーマンス上の不満がまだあるかもしれませんが、WSLでDockerをつかったWebアプリケーション開発は十分できる、と言えそうです。つまり、Linux・macOS・WindowsによるWebアプリケーション開発は十分共有できる、と。 \n\nいい時代になりました。"},"name":"[2019-07-06]WSL2時代のDocker開発スタイル","tags":["wsl","wsl2","ubuntu"],"childPublishedDate":{"published_on":"2019-07-06T00:00:00.000Z","published_on_unix":1562371200}}},{"node":{"number":58,"relative_category":"blog/backend","fields":{"title":"WSL（Windows Subsystem for Linux）でDockerをつかったWebアプリケーション開発をおこなう際の注意点","excerpt":"これは無宗教ななびの  が書くDocker Advent Calendar 2017用記事です。前日はinductorさんの「Docker Meetupの中身まとめ」でした  （写真はクリスマスを日本にひろめた明治屋 ）   > PROBLEMPROBLEM \n\n- macOSとWindowsでWebアプリケーション開発をする際に 環境が異なって管理しづらい それならDockerで と思ったが、macOSはBashでWindowsはPowerShellなのか せめてPowerShellではなくBash... となると、いまWindowsでLinux環境をつかうならWSLか ただ、実際どこまで開発ができるかわからんしなあ \n- 環境が異なって管理しづらい それならDockerで と思ったが、macOSはBashでWindowsはPowerShellなのか せめてPowerShellではなくBash... となると、いまWindowsでLinux環境をつかうならWSLか ただ、実際どこまで開発ができるかわからんしなあ \n- それならDockerで と思ったが、macOSはBashでWindowsはPowerShellなのか せめてPowerShellではなくBash... となると、いまWindowsでLinux環境をつかうならWSLか ただ、実際どこまで開発ができるかわからんしなあ \n- と思ったが、macOSはBashでWindowsはPowerShellなのか せめてPowerShellではなくBash... となると、いまWindowsでLinux環境をつかうならWSLか ただ、実際どこまで開発ができるかわからんしなあ \n- せめてPowerShellではなくBash... となると、いまWindowsでLinux環境をつかうならWSLか ただ、実際どこまで開発ができるかわからんしなあ \n- となると、いまWindowsでLinux環境をつかうならWSLか ただ、実際どこまで開発ができるかわからんしなあ \n- ただ、実際どこまで開発ができるかわからんしなあ   > SOLUTIONSOLUTION \n\nというわけで、この記事ではmacOSとWindowsによるWebアプリケーション開発について、どこまで共有できるか書いていきます。 \n\n前提条件として、当該WebアプリケーションはmacOSというより、Bash/Ubuntu14.04~のLinux環境で動くことを想定しています。macOSはHFS+やAPFSのUnicode正規化以外はおおよそLinux環境に適応できているという判断によります。 \n\n要は、WSLでDockerをつかったWebアプリケーション開発ができるかどうかという点に焦点をしぼります。   > 対象環境対象環境 \n\n- Windows 10 Pro 1709 16299.64 Hyper-V 10.0.16299.15 Docker for Windows 17.09.0-ce-win33 Ubuntu 16.04 (Linux 4.4.0-43-Microsoft) Docker Client 1.12.6 \n- Hyper-V 10.0.16299.15\n- Docker for Windows 17.09.0-ce-win33\n- Ubuntu 16.04 (Linux 4.4.0-43-Microsoft) Docker Client 1.12.6 \n- Docker Client 1.12.6   > Windowsの開発環境を構築するWindowsの開発環境を構築する \n\nまず、Windowsの開発環境の構築ですが、既知の情報をふまえつつTIPSを順次紹介します。   > WSLのインストールWSLのインストール \n\n- Windows Subsystem for Linuxをインストールしてみよう！ \n\nWSLのパッケージ管理は下記3つを押さえておけば問題ないでしょう。 \n\n1. apt WSLではデーモンがつかえないのでDockerクライアントを入れましょう、Dockerデーモンの詳細は後ほど言及します \n2. WSLではデーモンがつかえないのでDockerクライアントを入れましょう、Dockerデーモンの詳細は後ほど言及します\n3. anyenv プログラミング言語をバージョンごとにわけて使いたい場合はこちらをつかいましょう exenvがビルドで失敗するためElixirインストールできないほかは、各言語問題なくビルドできます \n4. プログラミング言語をバージョンごとにわけて使いたい場合はこちらをつかいましょう\n5. exenvがビルドで失敗するためElixirインストールできないほかは、各言語問題なくビルドできます\n6. nix ElixirやHaskellのようにanyenvでインストールできない、あるいは、扱われいないパッケージはnixをつかいましょう また、aptのバージョンが古すぎるパッケージもnixが最適です \n7. ElixirやHaskellのようにanyenvでインストールできない、あるいは、扱われいないパッケージはnixをつかいましょう\n8. また、aptのバージョンが古すぎるパッケージもnixが最適です   > ターミナルのインストールターミナルのインストール \n\nWSLttyかConEmuをおすすめします。各々の特徴は下記のとおりですが、通常のWebアプリケーション開発であればWSLttyがいいでしょう。 \n\n- WSLtty Pros ConEmuとくらべてファイルの読込速度が速い (VMよりは遅い) EmacsでCtrl-SPC set-mark が機能する 画面サイズの変更が柔軟 Cons PowerShellなどほかのコンソールの呼び出しが面倒 \n- Pros ConEmuとくらべてファイルの読込速度が速い (VMよりは遅い) EmacsでCtrl-SPC set-mark が機能する 画面サイズの変更が柔軟 \n- ConEmuとくらべてファイルの読込速度が速い (VMよりは遅い)\n- EmacsでCtrl-SPC set-mark が機能する\n- 画面サイズの変更が柔軟\n- Cons PowerShellなどほかのコンソールの呼び出しが面倒 \n- PowerShellなどほかのコンソールの呼び出しが面倒\n- ConEmu Pros PowerShellなどほかのコンソールの呼び出しが楽 Cons ファイルの読込速度がおそい EmacsでCtrl-SPC set-mark が機能しない 画面サイズの変更に制限がある \n- Pros PowerShellなどほかのコンソールの呼び出しが楽 \n- PowerShellなどほかのコンソールの呼び出しが楽\n- Cons ファイルの読込速度がおそい EmacsでCtrl-SPC set-mark が機能しない 画面サイズの変更に制限がある \n- ファイルの読込速度がおそい\n- EmacsでCtrl-SPC set-mark が機能しない\n- 画面サイズの変更に制限がある   > WSLttyWSLtty \n\n- mintty/wsltty \n\nWSL用ターミナルとしてのMinttyです。操作はMinttyとかわらず、元Cygwinづかいにはうれしい操作感です。というわけで、いつものごとく起動用ショートカットのターゲットを準備します。WSLは chsh がつかえないのでログイン時につかいたいシェルを指定します。もし、 screen をつかいたい場合は /run/screen ディレクトリを作成してからコマンド指定します。   bat \n\n%LOCALAPPDATA%\\wsltty\\bin\\mintty.exe --wsl -o Locale=C -o Charset=UTF-8 /bin/wslbridge -t /bin/bash -c 'sudo mkdir /run/screen && sudo chmod 775 $_ && sudo chown root:utmp $_ && SHELL=/usr/bin/zsh screen'   ConEmu \n\n- ConEmu - Handy Windows Terminal \n\nWSL上で日本語を表示するため、また、WSLのLinux環境とWindows環境でターミナルをわけるため、ConEmuをつかいましょう。ConEmuをスマートにしたCmderはWSLとの相性がわるい1のでおすすめしません。 \n\nConEmuの設定「Startup-Tasks」では、WSL用にパラメータ、コマンドを下記のように指定しています。   bash \n\n# task parameters /icon \"C:\\Program Files\\WindowsApps\\CanonicalGroupLimited.UbuntuonWindows_1604.2017.922.0_x64__79rhkp1fndgsc\\images\\icon.ico\" # task command bash -c 'sudo mkdir /run/screen && sudo chmod 775 $_ && sudo chown root:utmp $_ && SHELL=/usr/bin/zsh screen' -new_console:d:%USERPROFILE%     > Docker for WindowsのインストールDocker for Windowsのインストール \n\n- Docker For Windows \n\nWSLではDockerデーモンがつかえないのでNTFS (WSLからみるとdrvfs) 側で用意します。インストールはDockerのダウンロードページから手順通りおこないます。 \n\n構成は下記のようになります。  \n\nDockerクライアントからDockerデーモンにつなぐには、セキュリティリスクはありますが、 DOCKER_HOST をつかうのが簡易的です。Docker for WindowsとDockerクライアント、各々設定します。 \n\n1. Docker for WindowsよりDockerデーモンを「Expose daemon on tcp://localhost:2375 without TLS」として設定\n2. WSL上のDockerクライアントに DOCKER_HOST=tcp://0.0.0.0:2375 を設定 \n\nWSLには下記のようなaliasを用意しておくといいでしょう。   bash \n\nexport DOCKER_HOST=tcp://0.0.0.0:2375 alias docker=\"DOCKER_HOST=${DOCKER_HOST} docker\" alias docker-compose=\"docker-compose -H ${DOCKER_HOST}\"     > さて、WSLからDocker for Windowsはどの程度つかえるのかさて、WSLからDocker for Windowsはどの程度つかえるのか \n\nWSLがlxfs、Docker for WindowsがNTFS (drvfs) 上で動いていることからわかるように、ファイルシステム上の制約があります。具体的には下記4点です。 \n\n1. Docker for WindowsはNTFS (WSLからみるとdrvfs /mnt/) 上のファイルしかVolumeマウントできません\n2. WSLはLinux形式のパスしか扱えません、C:\\Dev のようなドライブ名にコロンをつけたURIスキーマは扱えません\n3. WSL上のdocker-composeはパスを絶対参照しかできません、相対参照できません2 \n4. WSL上のnpm/yarnによるJSビルドをNTFS (drvfs)上でおこなうとエラーになります3  \n\nひとつずつ解決方法を見ていきましょう。   > 1. Docker for WindowsはNTFS (WSLからみるとdrvfs /mnt/) 上のファイルしかVolumeマウントできません1. Docker for WindowsはNTFS (WSLからみるとdrvfs /mnt/) 上のファイルしかVolumeマウントできません \n\n開発用ディレクトリをNTFS上につくりましょう。普段からWindowsで開発されている方はCドライブ直下につくっているとおもいます。   > 2. WSLはLinux形式のパスしか扱えません、ドライブ名にコロンをつけたURIスキーマは扱えません2. WSLはLinux形式のパスしか扱えません、ドライブ名にコロンをつけたURIスキーマは扱えません \n\nNTFSからのパス参照とWSLからのパス参照を共通化するために、WSLに各ドライブのシンボリックリンクをはりましょう。   bash \n\n$ ln -s /mnt/c /C # 開発ディレクトリはこんな感じで参照できます $ ls -al /C/Dev total 0 drwxrwxrwx 0 root root 512 Oct 27 00:54 . drwxrwxrwx 0 root root 512 Dec 8 07:49 .. drwxrwxrwx 0 root root 512 Jul 14 03:06 app-test-1 drwxrwxrwx 0 root root 512 Oct 25 00:38 app-test-2     > 3. WSL上のdocker-composeはパスを絶対参照しかできません、相対参照できません3. WSL上のdocker-composeはパスを絶対参照しかできません、相対参照できません \n\n各OS間での違いを吸収するため、プロジェクトに PRJ_ROOT のような環境変数を用意しましょう。   yaml \n\nservices: app-front: image: 561534604247952616898.dkr.ecr.amazonaws.com/test/front volumes: - ${PRJ_ROOT}/front:/var/www/front     > 4. WSL上のnpm/yarnによるJSビルドをNTFS (drvfs)上でおこなうとエラーになります4. WSL上のnpm/yarnによるJSビルドをNTFS (drvfs)上でおこなうとエラーになります \n\nこちらはFall Creators Updateのデグレですが、更新プログラム (KB4051963) でこの問題が修正されました  \n\nもし更新プログラムが適用できない場合は、シンボリックリンクでNTFS上のnode_modulesディレクトリをWSLに移しましょう。   bash \n\n$ mkdir /home/foo/tmp/app-test-1/front/node_modules $ ln -s /home/foo/tmp/app-test-1/front/node_modules /C/Dev/app-test-1/front/node_modules     > WRAPUPWRAPUP \n\nまだ未検証な部分はのこっていますが、ひととおりmacOSとWindowsによるWebアプリケーション開発は共有できるところまできている、と言えそうです。 \n\n随時、気になる課題が出てきたら追記します。  \n\n1. https://github.com/cmderdev/cmder/issues/901 ↩ \n2. https://github.com/docker/compose/issues/4039#issuecomment-269558432 ↩ \n3. https://github.com/Microsoft/WSL/issues/2448 ↩"},"name":"[2017-12-10]WSL（Windows Subsystem for Linux）でDockerをつかったWebアプリケーション開発をおこなう際の注意点","tags":["wsl","docker","ubuntu"],"childPublishedDate":{"published_on":"2017-12-10T00:00:00.000Z","published_on_unix":1512864000}}}],"pathPrefix":"categories/blog/backend","first":true,"last":true,"index":1,"pageCount":1,"additionalContext":{"category":"blog/backend"}}},"staticQueryHashes":[]}