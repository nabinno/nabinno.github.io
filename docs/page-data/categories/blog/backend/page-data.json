{"componentChunkName":"component---src-templates-posts-tsx","path":"/categories/blog/backend","result":{"pageContext":{"category":"blog/backend","group":[{"node":{"number":55,"relative_category":"blog/backend","fields":{"title":"PositiveSSLをHerokuに適用する","excerpt":"年に1回のSSL更新のイベントです。毎年同じことをすれば良いかというとそうでもなく、販社と卸の都合でSSLの購入方法が微妙に変わります。とは言え、毎年一から調べ直すのも手間なので備忘として記しておきます。  > PROBLEMPROBLEM \n\n- HerokuのSSLの期限がきた  > SOLUTIONSOLUTION \n\n- というわけで、いつも使っているSSL販売代理店SSLs.com（NameCheap社）でPositiveSSL（運用Comodo社）を購入しHerokuに適用します。  > HOWTOHOWTO \n\n1. 証明書を購入する SSL販売代理店であればどこでもいいのですが、昔から使っているので \n2. SSL販売代理店であればどこでもいいのですが、昔から使っているので\n3. 秘密鍵と署名リクエストをつくる 秘密鍵 openssl genrsa -des3 -out server.orig.key 2048 秘密鍵パスワードなしopenssl rsa -in server.orig.key -out server.key 署名リクエスト openssl req -new -key server.key -out server.csr ※ 最近このあたりの署名情報は、SSL販売代理店側で生成しているケースが増えてきました \n4. 秘密鍵 openssl genrsa -des3 -out server.orig.key 2048\n5. 秘密鍵パスワードなしopenssl rsa -in server.orig.key -out server.key\n6. 署名リクエスト openssl req -new -key server.key -out server.csr\n7. ※ 最近このあたりの署名情報は、SSL販売代理店側で生成しているケースが増えてきました\n8. 証明書発行を申請する SSL販売代理店より署名リクエストserver.csrと関連情報を送信します \n9. SSL販売代理店より署名リクエストserver.csrと関連情報を送信します\n10. ドメイン保持の証明をする PositiveSSLの運用会社Comodoに対しドメイン保持の証明します 証明方法はメールを受信する、あるいは、Webサイトにプレーンテキストを設置するかの2択になります \n11. PositiveSSLの運用会社Comodoに対しドメイン保持の証明します\n12. 証明方法はメールを受信する、あるいは、Webサイトにプレーンテキストを設置するかの2択になります\n13. Heroku用の証明書をつくる 証明タスクをこなししばらくすると、Comodo社より複数の証明書が送られてきます Heroku用に証明書をつくる cat www_example_com.crt COMODORSADomainValidationSecureServerCA.crt COMODORSAAddTrustCA.crt AddTrustExternalCARoot.crt > server.crt \n14. 証明タスクをこなししばらくすると、Comodo社より複数の証明書が送られてきます\n15. Heroku用に証明書をつくる cat www_example_com.crt COMODORSADomainValidationSecureServerCA.crt COMODORSAAddTrustCA.crt AddTrustExternalCARoot.crt > server.crt\n16. Herokuに証明書を適用する 新規で適用する場合は次のコマンドを実行します heroku addons:add ssl:endpoint heroku certs:add server.crt server.key 更新する場合は次のコマンドを実行します heroku certs:update server.crt server.key \n17. 新規で適用する場合は次のコマンドを実行します heroku addons:add ssl:endpoint heroku certs:add server.crt server.key \n18. heroku addons:add ssl:endpoint\n19. heroku certs:add server.crt server.key\n20. 更新する場合は次のコマンドを実行します heroku certs:update server.crt server.key \n21. heroku certs:update server.crt server.key  > WRAPUPWRAPUP \n\nこのあたりが自動化されれば良いと思いつつ、自動化されたらこのあたりを調べるモチベーションがなくなるので年に一回のリハビリイベントとして位置づけておきます、はい。  > 後日談後日談 \n\n現在はAutomated Certificate Management (ACM) 機能が用意されています。そちらを使う方が手間・実費ともにリーズナブルで、リハビリさえもいらなくなりました。以下適用方法。 \n\n1. ACMを有効化します。有効化するまでしばし時間がかかるので watch コマンドをつけて様子見します watch heroku certs:auto:enable \n2. watch heroku certs:auto:enable\n3. 手動で追加した証明書があるか確認します heroku certs \n4. heroku certs\n5. もし手動で追加した証明書がある場合は当該証明書を削除します heroku certs:remove --name foo-bar \n6. heroku certs:remove --name foo-bar"},"name":"[2017-04-23]PositiveSSLをHerokuに適用する","tags":[],"childPublishedDate":{"published_on":"2017-04-23T00:00:00.000Z","published_on_unix":1492905600}}},{"node":{"number":140,"relative_category":"blog/backend","fields":{"title":"提供していない決済方法を業務で取り扱う際に気をつけること","excerpt":"ECプロダクトを扱っている際にどうしても出てくる銀行振込。プロダクト立ち上げ時は、銀行振込が第一にあるターゲット層を除いて、コストの高い銀行振込は実装せずに裏メニューとして扱うのが通例だと思います。今回は、当該ケースの課題を取り上げて、その解決策を示します。単純な話なのですが、時間が経つにつれて業務が硬直化してスケーリングに影響してくるので事前に手を打っておくと良いと思います。   > PROBLEMPROBLEM \n\n- 銀行振込を通常決済方法でしか提供していないケースの場合 人力でトランザクションをはる必要があり、その処理の隙間で想定外の支払い、あるいは、二重決済が行われる可能性がある また、不整合処理を実施するCSあるいはそれに付随する担当に権限が集中しすぎ、統制上難しい運用になる \n- 人力でトランザクションをはる必要があり、その処理の隙間で想定外の支払い、あるいは、二重決済が行われる可能性がある\n- また、不整合処理を実施するCSあるいはそれに付随する担当に権限が集中しすぎ、統制上難しい運用になる  > 通常のケース通常のケース \n\n  > 不整合が起きるケース「銀行振込と通常決済が同時に実行」不整合が起きるケース「銀行振込と通常決済が同時に実行」 \n\n  > SOLUTIONSOLUTION \n\nと言うわけで、解決方法を整理してみました。答えは単純で銀行振込の決済ロックをシステム側に実装するというだけの話です。ただ、振込確認を人力で行っている場合は、銀行振込を決済方法として表側に出すのは難しいので問い合わせタイミングでロックできるよう問い合わせ窓口を工夫する必要があります。プロダクトのUXに関わってくる話なので簡単に実装するだけで済まないのが悩ましいところですが、粘り強く進めるしかないです。 \n\n  > WRAPUPWRAPUP \n\nECプロダクトがスケールしてくると決済方法が増え、業務処理が複雑になってきます。決済の適正性は統制上重要になってくるので決済の処理量に応じて、リスクアセスメントで拾い上げ適切な実装にしていきたいものですね。"},"name":"[2022-05-02]提供していない決済方法を業務で取り扱う際に気をつけること","tags":["payment-service"],"childPublishedDate":{"published_on":"2022-05-02T00:00:00.000Z","published_on_unix":1651449600}}},{"node":{"number":139,"relative_category":"blog/backend","fields":{"title":"ヘルステック界隈のエンジニアが気をつけるべき個人情報の扱い","excerpt":"ヘルステックでエンジニアをしている方であればデータの扱いには苦労していることと思います。CISOがつくったデータセグメンテーションがどういう意図で成り立っているのか、整理されていない現場だと読み解きに時間がかかります。現場に入って早々 何も知らないエンジニアとしては、緩めな方針よりは保守的に設計していく方が後々のトラブルが少なく安全です。   > PROBLEMPROBLEM \n\n- 要配慮個人情報について、厚労省医政局発「医療情報システムの安全管理に関するガイドライン」1を見ると「 医療・健康情報を[..]医師等以外の者が分析等を実施することは許されるものではない 」と書かれている ここでいう「 医療・健康情報 」は要配慮個人情報の中の具体的に何を指しているのか分かりづらい 「 医師等 」の「 等 」が何を指すのか分かりづらい 厚労省医政局の発令0912001号「診療情報の提供等に関する指針」2から推察するに、「 医療・健康情報 」は診療録、「 医師等 」は医療系有資格者を指している 医療系有資格者については、個人情報保護法の関連で出された医療・介護分野用「医療・介護関係事業者における個人情報の適切な取扱いのためのガイダンス」に掲載されている守秘義務対象 \n- ここでいう「 医療・健康情報 」は要配慮個人情報の中の具体的に何を指しているのか分かりづらい\n- 「 医師等 」の「 等 」が何を指すのか分かりづらい\n- 厚労省医政局の発令0912001号「診療情報の提供等に関する指針」2から推察するに、「 医療・健康情報 」は診療録、「 医師等 」は医療系有資格者を指している 医療系有資格者については、個人情報保護法の関連で出された医療・介護分野用「医療・介護関係事業者における個人情報の適切な取扱いのためのガイダンス」に掲載されている守秘義務対象 \n- 医療系有資格者については、個人情報保護法の関連で出された医療・介護分野用「医療・介護関係事業者における個人情報の適切な取扱いのためのガイダンス」に掲載されている守秘義務対象\n- また、データアクセス対象を緩めると、教育が不十分な人が故意に流出させ刑法上の秘密漏示罪3に問われる可能性がある 秘密漏示罪は身分犯ではあるが歯科医師のように解釈の余地もあり範囲が不透明 \n- 秘密漏示罪は身分犯ではあるが歯科医師のように解釈の余地もあり範囲が不透明  > SOLUTIONSOLUTION \n\nというわけで、ヘルステックに関わる個人情報の扱いを整理してみました。 \n\n課題は上記の通りで、時代の流れとともに医療情報の整備が進んでいる状況です。善管注意の責務を負ったエンジニアとしては医療系有資格者以外への診療録の情報提供は、例え、同僚であっても連結可能匿名（仮名加工）ではなく匿名加工で対応すべきでしょう。ゆくゆくは会社として次世代医療基盤法4を適用し、医療分野の研究開発に資するよう体制を構築することが望ましいと考えています。  > 加工なし加工なし \n\n学術研究等をのぞき第三者提供は本人同意が必要となるため、ユースケースは限定されます。各々の個人情報の種類によりアクセス出来る人が変わってきます。また、守秘義務が課せられる範囲が広く、行為によっては秘密漏示罪や不正アクセス禁止法5の罰則の対象になります。     診療録 診療録を除いた要配慮個人情報 要配慮個人情報を除いた個人情報     使用場所 社内 (医療関連有資格者) 社内 社内, 社外   利用目的の必要性 (公表有無) 必要 必要 必要   利用目的の必要性 (変更可否) 関連性を有する合理的な範囲 関連性を有する合理的な範囲 関連性を有する合理的な範囲   目的外利用 不可 不可 不可   第三者提供 (可否) 可 可 可   第三者提供 (本人同意) 必要 (オプトインのみ) 必要 (オプトインのみ) 必要 (オプトアウト)   個人の開示請求 応じる 応じる 応じる   漏洩時の報告 必須 必須 必須     > 仮名加工仮名加工 \n\n診療録に関する規定は次世代医療基盤法でまとめられているので、あえて規定が曖昧な仮名加工（連結可能匿名）をつかうのは望ましくありません。ユースケースとして要配慮個人情報を除いた個人情報の統計分析に限られるでしょう。     診療録を除いた要配慮個人情報 要配慮個人情報を除いた個人情報     使用場所 社内 社内   利用目的の必要性 (公表有無) 必要 必要   利用目的の必要性 (変更可否) 際限なく変更可能 際限なく変更可能   目的外利用 不可 不可   第三者提供 (可否) 不可 不可   個人の開示請求 応じない 応じない   漏洩時の報告 なし なし     > 匿名加工匿名加工 \n\n診療録は本人のオプトアウトありですが、基本本人同意なしで利用可能です。ただ、診療録は可変長文字列の上、特異な記述として最も気をつける対象になります。データマスキングの実装は手厚く行っていく必要があります。     診療録を含んだ要配慮個人情報 要配慮個人情報を除いた個人情報     使用場所 社内, 社外 社内, 社外   利用目的の必要性 (公表有無) 不要 不要   第三者提供 (可否) 可 可   第三者提供 (本人同意) 不要 (オプトアウトあり) 不要   個人の開示請求 応じない 応じない   漏洩時の報告 なし なし     > WRAPUPWRAPUP \n\nポイントをかいつまんでまとめてみました。エンジニア視点のため、考慮漏れの箇所があるかも知れませんが、フィードバックや各種レギュレーションの経過を元に更新していければと思います。  \n\n1. https://www.mhlw.go.jp/stf/shingi/0000516275.html ↩ \n2. https://www.mhlw.go.jp/web/t_doc?dataId=00tb3403&dataType=1&page%20No=1 ↩ \n3. https://elaws.e-gov.go.jp/document?lawid=140AC0000000045 ↩ \n4. https://elaws.e-gov.go.jp/document?lawid=429AC0000000028 ↩ \n5. https://elaws.e-gov.go.jp/document?lawid=411AC0000000128 ↩"},"name":"[2022-04-24]ヘルステック界隈のエンジニアが気をつけるべき個人情報の扱い","tags":["privacy","data-masking","data-engineering","health-informatics"],"childPublishedDate":{"published_on":"2022-04-24T00:00:00.000Z","published_on_unix":1650758400}}},{"node":{"number":137,"relative_category":"blog/backend","fields":{"title":"G Suite無償版停止に伴い、MXレコード等のドメイン管理を整理した","excerpt":"今回は10年以上利用していたG Suite無償版が2022年8月に停止されるとのことで、メールアドレスの管理をどうするか検討しました。メール管理は別のGMailアカウントを使っていたので、転送できれば良いのですが、これを機にドメイン管理をAWSにまとめていくことを思いつきました。   > PROBLEMPROBLEM \n\n- 10年以上利用していたG Suite無償版が2022年8月に停止され、メールアドレスの管理をどうしようか Google Workspaceにアップグレードしても良いけどBusiness Starterプランにしても面白みがないので別の方法を探したい G Suiteはメールしか利用しておらず、メール管理は別のGMailアカウントを使っていたのでメール転送機能で代替できそう \n- Google Workspaceにアップグレードしても良いけどBusiness Starterプランにしても面白みがないので別の方法を探したい G Suiteはメールしか利用しておらず、メール管理は別のGMailアカウントを使っていたのでメール転送機能で代替できそう \n- G Suiteはメールしか利用しておらず、メール管理は別のGMailアカウントを使っていたのでメール転送機能で代替できそう  > SOLUTIONSOLUTION \n\nと言うわけで、今回はG Suiteアカウントの利用を止めて、MXレコード周りを整理することにしました。個人利用なのでドメイン管理は既存のままで良かったのですが、証跡管理のない状況に耐えられずAWSに移管。メール転送機能はPOBOX以外はサブアドレス対応していなかったのですが、キャッチオール対応できるのでまずは良しとしています。現時点での構成は下記の通り。 \n\nなお、複数人数で必要になった場合は、サブアドレスとグループアドレスが対応可能なAmazon Workmailに移管する予定ですが、これでもGoogle Workspaceを利用するよりコストは半分程で済みます。  > 構成構成  > beforebefore \n\n- ドメイン管理 バリュードメイン\n- NSレコード Cloudflare DNS\n- MXレコード G Suite\n- SMTP G Suite  > afterafter \n\n- ドメイン管理 Amazon Route 53\n- NSレコード Amazon Route 53\n- MXレコード Cloudflare Email Routing\n- SMTP Amazon SES  > 手順手順 \n\n方針が決まるまでいくつかメールサービスを検討したのですが、決まってしまえばやることは単純です。  > 1. ドメイン管理を整理する1. ドメイン管理を整理する \n\n基本はドメイン移管申請ですが、G Suiteを後ほど削除することを考慮してMXレコードをCloudflare Email Routingに変更。本来はこの処理の前にG Suiteに紐付いている各サービスの設定変更が必要になります。 \n\n1. 移管元にてWHOIS情報公開代行の解除\n2. 移管元にてドメインロックの解除\n3. 移管元にて認証鍵 (Auth-Code) を確認\n4. 移管先にてホストゾーンの作成、各レコードの内容を移管元に合わせる\n5. Cloudflare Email Routingにて転送先メールアドレスを検証する\n6. 移管先にてMXレコードをCloudflare Email Routingのものを設定する\n7. 移管元のNSレコードを移管先に変更\n8. 移管先にて認証鍵をつかい移管申請を行う\n9. 移管元に対して移管申請を行った旨をメールにて連携する \n\nCf. \n\n- ドメインの他社への移管 | バリュードメイン ユーザーガイド\n- ドメイン登録の Amazon Route 53 への移管 - Amazon Route 53\n- Easily creating and routing email addresses with Cloudflare Email Routing  > 2. SMTPを設定する2. SMTPを設定する \n\n最近はセキュリティ対策のためGMailのSMTPが使いづらくなっているので、今回はAmazon SESを利用しました。サンドボックス解除のため下記の通りサポートに依頼しました。 txt\n\n# メールタイプ 通例の取引がメインとなる予定です # ユースケース ## メールを送信する頻度 週に1-2回 ## 受信者リストのメンテナンス方法 四半期に一度の棚卸し ## バウンス対応 当該メールアドレスの削除 ## 申し立て対応 当該メールアドレスへのフラグ管理 ## 解除申請の管理方法 メールでの受付 ## 送信予定のメールサンプル {{宛先名}}様 お世話になっております。 表題の件につきまして1点問い合わせします。 {{問い合わせ内容}} ご不明な点等ございましたらお気軽にお問い合わせ下さい。 どうぞ、よろしくお願い致します。   > 3. G Suiteを退会する3. G Suiteを退会する \n\nG Suiteに依存しているサービスがないか確認し、退会します。  > WRAPUPWRAPUP \n\n以前からドメイン管理をAWSに移管したかったのですが、積極的な理由がないためなおざりになっていました。今回のG Suite無償版の期限切れに伴い整理できすっきりしたので、これを機にいろいろ整理していきたいですね。  > 後日談後日談 \n\nCloudflare DNSからAmazon Route 53に設定を変更した数日後、Cloudflare Email Routingが使用できなくなりました。転送機能としてドメイン管理から切り離されていると思ったのですがそうではなかったようです。ドメイン管理は厳しめに証跡を取っていきたいところなので、Amazon Route 53による管理は譲れません。 \n\nまた、Amazon SESによる転送機能も検討したのですが、送信元すべてに対してドメイン検証が必要なため現実的ではありませんでした。AWSにはメール転送の種類が2つあって、送信元を転送者に置き換える「転送」と送信元をそのまま利用する「リダイレクト」があります。「転送」だと元の送信元とコミュニケーションが取りづらくなる一方、「リダイレクト」だとすべての送信元のドメイン検証が必要となります。ここでは融通が利かないと判断するのではなく、セキュリティを考慮された実装と捉え、AWSが提供しているWorkMailを素直に使うことにしました。慣れればたいしたことはありません。下記が結果になります。  > beforebefore \n\n- ドメイン管理 Amazon Route 53\n- NSレコード Amazon Route 53\n- MXレコード Cloudflare Email Routing\n- SMTP Amazon SES  > afterafter \n\n- ドメイン管理 Amazon Route 53\n- NSレコード Amazon Route 53\n- MXレコード Amazon WorkMail\n- SMTP Amazon WorkMail"},"name":"[2022-04-12]G Suite無償版停止に伴い、MXレコード等のドメイン管理を整理した","tags":["gsuite","google-workspace","cloudflare","amazon-ses","amazon-workmail"],"childPublishedDate":{"published_on":"2022-04-12T00:00:00.000Z","published_on_unix":1649721600}}},{"node":{"number":119,"relative_category":"blog/backend","fields":{"title":"踏み台をSSM Session ManagerとAWS SSOで実現する","excerpt":"踏み台のユーザーが増えてきたため公開鍵管理や監視と運用負荷が上がってきました。オペミスが発生しやすい上 監査的な意味で無視できない状況になってきたので重い腰を上げることにしました。   > PROBLEMPROBLEM \n\n- EC2インスタンスの踏み台運用がつらい 公開鍵管理がつらい 提出・設定・確認ともに運用コストがかかる AWSアカウント数 x ユーザー数で指数関数的に運用コストが増していくことが想定される インフラ管理が分散していると、提出側・設定側ともに重複コストが発生する 監視運用がつらい 定期的に踏み台がブルートフォース攻撃を受けており、脅威が低いとは言えストレスがかかる 踏み台アクセスへの監査ログが不十分 \n- 公開鍵管理がつらい 提出・設定・確認ともに運用コストがかかる AWSアカウント数 x ユーザー数で指数関数的に運用コストが増していくことが想定される インフラ管理が分散していると、提出側・設定側ともに重複コストが発生する \n- 提出・設定・確認ともに運用コストがかかる\n- AWSアカウント数 x ユーザー数で指数関数的に運用コストが増していくことが想定される\n- インフラ管理が分散していると、提出側・設定側ともに重複コストが発生する\n- 監視運用がつらい 定期的に踏み台がブルートフォース攻撃を受けており、脅威が低いとは言えストレスがかかる 踏み台アクセスへの監査ログが不十分 \n- 定期的に踏み台がブルートフォース攻撃を受けており、脅威が低いとは言えストレスがかかる\n- 踏み台アクセスへの監査ログが不十分  > SOLUTIONSOLUTION \n\nというわけで、Session ManagerとSSOでアクセス管理の効率化を狙います。  > 踏み台サーバーの設定踏み台サーバーの設定 \n\nまず、データフローとしては下記の図の通りで、今回はプライベートサブネット上にEC2を置いて素のSession ManagerでDBへの接続することにします。当該インスタンスは AmazonSSMManagedInstanceCore ポリシー1を含んだロールを適用。なお、ECS ExecではSession Managerでポートフォワーディングを実現でき無かったことに加え、既存の踏み台資産を流用するため今回の実装対象から外しました。 \n\n  > SSOの設定SSOの設定 \n\n踏み台サーバーの設定が終わったら、次に当該インスタンスへ接続するためにSSOで渡すロールをアクセス権限セットに設定します。下記カスタムポリシーはEC2インスタンスにアクセスするための必要最低限のものになります。 カスタムポリシー json\n\n{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"cloudwatch:PutMetricData\", \"ds:CreateComputer\", \"ds:DescribeDirectories\", \"ec2:DescribeInstanceStatus\", \"logs:*\", \"ssm:*\", \"ec2messages:*\" ], \"Resource\": \"*\" }, { \"Effect\": \"Allow\", \"Action\": [ \"ssm:StartSession\" ], \"Resource\": [ \"arn:aws:ssm:*:*:session/<EC2インスタンスID>\", \"arn:aws:ec2:*:*:instance/<EC2インスタンスID>\" ] }, { \"Effect\": \"Deny\", \"Action\": [ \"ssm:Describe*\", \"ssm:Get*\", \"ssm:List*\", \"logs:Describe*\", \"logs:Get*\", \"logs:List*\" ], \"Resource\": \"*\" }, { \"Effect\": \"Allow\", \"Action\": \"iam:CreateServiceLinkedRole\", \"Resource\": \"arn:aws:iam::*:role/aws-service-role/ssm.amazonaws.com/AWSServiceRoleForAmazonSSM*\", \"Condition\": { \"StringLike\": { \"iam:AWSServiceName\": \"ssm.amazonaws.com\" } } }, { \"Effect\": \"Allow\", \"Action\": \"iam:CreateServiceLinkedRole\", \"Resource\": \"arn:aws:iam::*:role/aws-service-role/ssm.amazonaws.com/AWSServiceRoleForAmazonSSM*\", \"Condition\": { \"StringLike\": { \"iam:AWSServiceName\": \"ssm.amazonaws.com\" } } }, { \"Effect\": \"Allow\", \"Action\": [ \"iam:DeleteServiceLinkedRole\", \"iam:GetServiceLinkedRoleDeletionStatus\" ], \"Resource\": \"arn:aws:iam::*:role/aws-service-role/ssm.amazonaws.com/AWSServiceRoleForAmazonSSM*\" }, { \"Effect\": \"Allow\", \"Action\": [ \"ssmmessages:CreateControlChannel\", \"ssmmessages:CreateDataChannel\", \"ssmmessages:OpenControlChannel\", \"ssmmessages:OpenDataChannel\" ], \"Resource\": \"*\" } ] }    > セッションを張るための事前準備セッションを張るための事前準備 \n\nセッションを張るためには下記3つの手順が必要になります。SSO経由のセッション設定が2通りありますが、クレデンシャル方式はセッションが切れる毎に変更する手間があるため、CLI方式をお薦めします。 \n\n1. AWS CLI v2をインストール\n2. 下記いずれかの方式でSSO経由のセッション設定を行う クレデンシャル方式 CLI（ aws sso login ）方式 \n3. クレデンシャル方式\n4. CLI（ aws sso login ）方式\n5. Session Manager プラグインをインストール  > DBクライアントの設定DBクライアントの設定 \n\n最後に、DBクライアントについて3つの手順を踏んで接続を試みます2。なお、ローカル環境でポートフォワーディングを都度行うのを省略したい方は、DataGripを利用すると良いでしょう。 \n\n1. ローカル環境にて ~/.ssh/config ファイルを編集 Session Managerにproxyと対象RDSのエンドポイントを記載 configHost <任意のhost名> HostName <※ 指定しなければlocalhostになる> User ec2-user ProxyCommand sh -c \"aws ssm start-session --target <接続する踏み台のインスタンスID> --document-name AWS-StartSSHSession --parameters 'portNumber=%p' --region ap-northeast-1 --profile <プロフィール>\" LocalForward <任意のポート> <RDSエンドポイント>:<RDSポート> IdentityFile ~/.ssh/<EC2に接続する秘密鍵> 設定したhost名でセッションマネージャー越しにssh接続できるかを確認 sh$ ssh <設定したhost名> \n2. Session Managerにproxyと対象RDSのエンドポイントを記載 configHost <任意のhost名> HostName <※ 指定しなければlocalhostになる> User ec2-user ProxyCommand sh -c \"aws ssm start-session --target <接続する踏み台のインスタンスID> --document-name AWS-StartSSHSession --parameters 'portNumber=%p' --region ap-northeast-1 --profile <プロフィール>\" LocalForward <任意のポート> <RDSエンドポイント>:<RDSポート> IdentityFile ~/.ssh/<EC2に接続する秘密鍵> \n3. 設定したhost名でセッションマネージャー越しにssh接続できるかを確認 sh$ ssh <設定したhost名> \n4. 手順1で設定したsshで接続することでポートフォワーディング\n5. DBクライアントで下記のように接続情報を設定し接続する Host: <手順1のconfigファイルにて任意指定したホスト名> Port: <手順4のconfigファイルにて任意指定したポート> 他項目: DB接続情報 \n6. Host: <手順1のconfigファイルにて任意指定したホスト名>\n7. Port: <手順4のconfigファイルにて任意指定したポート>\n8. 他項目: DB接続情報  > WRAPUPWRAPUP \n\nパブリックサブネット上の踏み台に慣れている方は馴染みのない方法に戸惑うかも知れませんが、踏み台資産を流用できるという意味で導入のコストもそれほどかかりませんし、ユーザーとしても利用の敷居は高くありませんでした。後々の管理コストを心配している方は一度検討してみてはいかがでしょうか。  \n\n1. AmazonEC2RoleforSSM は非推奨のため適用しないように注意します。 ↩ \n2. 今回はメンテナンスコストを避けるためSSH over SSMの関連ツール ssh-ssm.sh ssm-tool は使わない方針でいます。 ↩"},"name":"[2021-11-21]踏み台をSSM Session ManagerとAWS SSOで実現する","tags":["session-manager","aws-sso"],"childPublishedDate":{"published_on":"2021-11-21T00:00:00.000Z","published_on_unix":1637452800}}},{"node":{"number":124,"relative_category":"blog/backend","fields":{"title":"Increment Pは住所のバリデーションチェックでどの程度使えるか","excerpt":"7月に調査した「imi-enrichment-addressは住所のバリデーションチェックでどの程度使えるか」の続きになります。コロナ禍であらゆる流通がオンラインに移行する中、正しい住所を使うことはいっそう求められています。ユーザーが配送用に住所を入力する時そのデータが正しいとどうやって判定するのでしょうか。今回は商用サービスIncrement Pが住所のバリデーションチェックでどの程度使えるか検証してみました。   > PROBLEMPROBLEM \n\n- 住所の不備が至るところで起きている 特に町名番地の抜けもれや不備が多くこの点をどうにか拾いたい 可能ならユーザーの入力時点でFEあるいはBE側でバリデーションチェックしたい imi-enrichment-addressで精度が思わしくなかったので今回は商用サービスで検証したい \n- 特に町名番地の抜けもれや不備が多くこの点をどうにか拾いたい\n- 可能ならユーザーの入力時点でFEあるいはBE側でバリデーションチェックしたい imi-enrichment-addressで精度が思わしくなかったので今回は商用サービスで検証したい \n- imi-enrichment-addressで精度が思わしくなかったので今回は商用サービスで検証したい  > SOLUTIONSOLUTION \n\nというわけで、住所のバリデーションチェックで商用版「Increment P」がどの程度使えるか検証します。  > Increment PとはIncrement Pとは \n\n住所をAPIを介すことで正規化することができます。APIの返値に解析レベル・解析ログを加えることでより柔軟な検証をおこなうことができるようになっています。 \n\n解析レベルとは、対象住所のマッチ度合いを都道府県・市区町村・町域・丁目・番地・号というレベルで分けたものです。APIの結果が解析レベル5「番地・番」以上になっていれば配送が確実に為されると言うように、配送の確実性を前提にして住所の入力者とやりとりを実現します。また、解析ログメッセージとは、住所の正規化を試みた際のログであり、バリデーションを調整する際に頻繁に確認するものです。詳細は「ドキュメント」をご覧下さい。    解析レベル レベルの数字 説明     都道府県 1 県レベルでマッチしました   市区町村 2 市区町村レベルでマッチしました   町域 (大字) 3 町域レベルでマッチしました   丁目 / 小字 4 丁目または小字レベルでマッチしました   番地（番） 5 番地（番）レベルでマッチしました   号情報が存在しない番地 7 番地（番）レベルでマッチしました（号情報が存在しない地域）   号 8 号レベルでマッチしました   不明 -1 不明    \n\n試しにIncrement Pを実行してみましょう。正確な住所を渡したときと不正確な住所を渡したときで解析レベルが5と3と異なった結果を返すことが見て取れます。 sh\n\n$ curl \"https://api-anorm.mapfan.com/v1/$(echo -n 長野県長野市大字長野旭町1108 | jq -sRr @uri).json\" \\ -H 'x-api-key: <api-key>' \\ -H 'Content-Type: application/json' | jq -r { \"type\": \"FeatureCollection\", \"query\": [ \"長野県長野市大字長野旭町1108\" ], \"features\": [ { \"type\": \"Feature\", \"geometry\": null, \"properties\": { \"query\": \"長野県長野市大字長野旭町1108\", \"place_name\": \"長野県長野市長野旭町 1108\", \"pref\": \"長野県\", \"pref_kana\": \"ナガノケン\", \"city\": \"長野市\", \"city_kana\": \"ナガノシ\", \"area\": \"長野\", \"area_kana\": \"ナガノ\", \"koaza_chome\": \"旭町\", \"koaza_chome_kana\": \"アサヒマチ\", \"banchi_go\": \"1108\", \"building\": \"\", \"building_number\": \"\", \"zipcode\": \"3800846\", \"geocoding_level\": 5, \"geocoding_level_desc\": \"番地（番）レベルでマッチしました(5)\", \"log\": \"RM002:[大字(字)]の文字を除去しました\", \"not_normalized\": \"\" } } ], \"attribution\": \"(c) INCREMENT P CORPORATION\" } $ curl \"https://api-anorm.mapfan.com/v1/$(echo -n 長野県長野市旭町1108 | jq -sRr @uri).json\" \\ -H 'x-api-key: <api-key>' \\ -H 'Content-Type: application/json' | jq -r { \"type\": \"FeatureCollection\", \"query\": [ \"長野県長野市旭町1108\" ], \"features\": [ { \"type\": \"Feature\", \"geometry\": null, \"properties\": { \"query\": \"長野県長野市旭町1108\", \"place_name\": \"長野県長野市旭町\", \"pref\": \"長野県\", \"pref_kana\": \"ナガノケン\", \"city\": \"長野市\", \"city_kana\": \"ナガノシ\", \"area\": \"旭町\", \"area_kana\": \"アサヒマチ\", \"koaza_chome\": \"\", \"koaza_chome_kana\": \"\", \"banchi_go\": \"\", \"building\": \"\", \"building_number\": \"\", \"zipcode\": \"3800846\", \"geocoding_level\": 3, \"geocoding_level_desc\": \"町域レベルでマッチしました(3)\", \"log\": \"NT001:正規化処理状況が建物名正規化処理の必要条件を満たさないので建物名正規化は行われません\", \"not_normalized\": \"1108\" } } ], \"attribution\": \"(c) INCREMENT P CORPORATION\" }  \n\nなお、上記結果を見て分かるとおり、Increment Pは大字省略には強そうですが町域自体の省略は苦手なようです。imi-enrichment-addressより柔軟ですが、基本は街区レベル位置参照情報を利用しているように推察されます。  > 検証用データ検証用データ \n\nさて、検証用データですが、imi-enrichment-addressの検証データと合わせて住所.jpを使います。今回はトライアルが1000件と制限があるので、imi-enrichment-addressで無効割合が54.42%と一番多かった青森県と住所の登録数が多い東京・愛知・北海道・大阪・福岡・神奈川、さらに通りが独特な京都、町字の組み合わせで住所が2つ以上存在する長野に対象を絞ります。各々100件ずつの検証になります。 sh\n\n$ { curl -sSL http://jusyo.jp/downloads/new/csv/csv_zenkoku.zip -o csv_zenkoku.zip; unzip -p csv_zenkoku.zip | nkf -w; rm csv_zenkoku.zip } >zenkoku.csv $ brew install noborus/tap/trdsql $ trdsql \" SELECT COUNT(*) FROM zenkoku.csv WHERE c21 <> '' \" 22431 $ trdsql -otbln \" SELECT c8, count(*) cn FROM zenkoku.csv WHERE c21 != '' GROUP BY c8 ORDER BY cn DESC\" | 都道府県 | count(*) | | --- | --- | | 東京都 | 4734 | | 愛知県 | 1541 | | 北海道 | 1251 | | 大阪府 | 884 | | 福岡県 | 845 | | 神奈川県 | 820 | [..] | 長野県 | 594 | [..] | 京都府 | 255 | [..] | 青森県 | 216 |   > Increment Pで検証用データを確認するIncrement Pで検証用データを確認する sh\n\n$ for p in 東京都 愛知県 北海道 大阪府 福岡県 神奈川県 青森県 京都府 長野県; do for a in $(trdsql \" SELECT c8||c10||c21 FROM zenkoku.csv WHERE c21 != '' AND c8 = '$p' ORDER BY RANDOM() LIMIT 100 \"); do curl -w'\\n' \"https://api-anorm.mapfan.com/v1/$(echo -n $a | jq -sRr @uri).json\" \\ -H 'x-api-key: <api-key>' \\ -H 'Content-Type: application/json' >>output.jsonl; done & done &   > 解析結果を確認する解析結果を確認する \n\nIncrement Pの解析結果を確認したところ、imi-enrichment-addressと比べると大方改善しました。特に青森県、北海道の改善率は高く字・条・線に対して有効に機能していることが伺えます。一方、京都や長野のように特殊な住所がある府県については改善が思うように行かないケースもあるようです。 sh\n\n$ cat output.jsonl \\ | jq -r '[ .features[].properties.pref, .features[].properties.query, .features[].properties.geocoding_level, .features[].properties.log ] | @csv' \\ | trdsql -otbln \" SELECT c1, COUNT(*) cn FROM - WHERE c3 >= 5 GROUP BY c1 ORDER BY cn DESC \"  \n\n解析レベル5「番地・番」以上の場合（※ 参考値はimi-enrichment-addressの有効割合）    都道府県 有効割合 参考値     東京都 100 99.11   大阪府 100 96.72   福岡県 95 91   神奈川県 95 98.28   愛知県 92 92.6   青森県 90 45.58   長野県 84 55.72   北海道 80 86.24   京都府 79 63.14    \n\n解析レベル4「丁目/小字」以上の場合（※ 参考値はimi-enrichment-addressの有効割合）    都道府県 有効割合 参考値     東京都 100 99.11   大阪府 100 96.72   北海道 98 86.24   愛知県 97 92.6   福岡県 96 91   神奈川県 95 98.28   青森県 93 45.58   長野県 84 55.72   京都府 79 63.14     > WRAPUPWRAPUP \n\n青森県の有効率が45.58%だったimi-enrichment-addressと比べると、Increment Pは調査した大凡の都道府県で改善し70%以上の有効割合を出していました。バリデーションチェックで使えるのかというと全ての都道府県で100%になっていないため心許ない状況ではあるものの、解析レベル4「丁目/小字」以下の住所については最終確認を促すフローを入れる等ひと手間加えれば実用に耐えうると考えます。"},"name":"[2021-11-23]Increment Pは住所のバリデーションチェックでどの程度使えるか","tags":["incrementp"],"childPublishedDate":{"published_on":"2021-11-23T00:00:00.000Z","published_on_unix":1637625600}}},{"node":{"number":93,"relative_category":"blog/backend","fields":{"title":"AWS CloudTrail用のコスパの良いSIEMを探す","excerpt":"IT統制において証跡管理の充実という観点から、また、ゼロトラストの強化という観点からSIEMの導入が必要になってきました。今回はAWS CloudTrail用のSIEMについてざっと調べました。   > PROBLEMPROBLEM \n\n- AWS CloudTrailのログをセキュリティアカウントに集約しているが、深く監視しきれていない 可能ならアカウントが不審な操作をした場合にアラートを飛ばしたい 可能ならCloudTrail以外のIaaSリソースを監視対象にしたい NewRelicのように人のコストをかけずに管理したい \n- 可能ならアカウントが不審な操作をした場合にアラートを飛ばしたい\n- 可能ならCloudTrail以外のIaaSリソースを監視対象にしたい NewRelicのように人のコストをかけずに管理したい \n- NewRelicのように人のコストをかけずに管理したい  > SOLUTIONSOLUTION \n\nと言うわけで、コスパが良いと噂のSumo LogicとAzure Sentinelを比較評価します。  > Azure SentinelAzure Sentinel  > 料金料金 \n\n- Azure Sentinel の価格 | Microsoft Azure\n- 価格 - Azure Monitor | Microsoft Azure  > SIEMからCloudTrailへの接続方法SIEMからCloudTrailへの接続方法 \n\n1. 下記設定でLog Analyticsワークスペースを作成 サブスクリプション 無料試用版 リソース グループ production 名前 prod-sentinel 地域 東日本 \n2. サブスクリプション 無料試用版\n3. リソース グループ production\n4. 名前 prod-sentinel\n5. 地域 東日本\n6. [ワークスペースprod-sentinel - データコネクタ] にて [アマゾンウェブサービス] コネクタページを開く\n7. [AWSアカウント - IAM - ロール] にて下記設定で [別のAWSアカウント] を作成 アカウントID {Microsoft account ID} オプション 外部IDが必要 をチェック 外部ID {外部ID (ワークスペースID)} パーミッションポリシーを適用 AWSCloudTrailReadOnlyAccess ロール名 AzureSentinel ※ Cf. AWS CloudTrail を Azure Sentinel に接続する | Microsoft Docs アマゾン ウェブ サービス (AWS) のための MCAS と Azure Sentinel - Azure Solution Ideas | Microsoft Docs Security-JAWS 第21回レポート #secjaws #secjaws21 #jawsug | DevelopersIO \n8. アカウントID {Microsoft account ID}\n9. オプション 外部IDが必要 をチェック 外部ID {外部ID (ワークスペースID)} \n10. 外部IDが必要 をチェック\n11. 外部ID {外部ID (ワークスペースID)}\n12. パーミッションポリシーを適用 AWSCloudTrailReadOnlyAccess\n13. ロール名 AzureSentinel\n14. ※ Cf. AWS CloudTrail を Azure Sentinel に接続する | Microsoft Docs アマゾン ウェブ サービス (AWS) のための MCAS と Azure Sentinel - Azure Solution Ideas | Microsoft Docs Security-JAWS 第21回レポート #secjaws #secjaws21 #jawsug | DevelopersIO \n15. AWS CloudTrail を Azure Sentinel に接続する | Microsoft Docs\n16. アマゾン ウェブ サービス (AWS) のための MCAS と Azure Sentinel - Azure Solution Ideas | Microsoft Docs\n17. Security-JAWS 第21回レポート #secjaws #secjaws21 #jawsug | DevelopersIO  > SIEM機能 (AWS CloudTrail)SIEM機能 (AWS CloudTrail) \n\n- デフォルト監視対象 時間経過に伴うイベントアラート 悪意ある可能性があるイベント 最近のインシデント データソースの異常 \n- 時間経過に伴うイベントアラート\n- 悪意ある可能性があるイベント\n- 最近のインシデント\n- データソースの異常\n- ログクエリ Audit Network Security \n- Audit\n- Network\n- Security\n- 脅威管理 インシデント ブック ... 簡易な分析情報を提供 AWSネットワークアクティビティ ... SG、ネットワークACL、IGW、ELB、VPC、サブネット、NIの作成・更新・削除など、AWS ネットワーク関連のリソースアクティビティに関する分析情報を得ます。 AWSユーザーアクティビティ ... 失敗したサインイン試行、IP アドレス、リージョン、ユーザー エージェント、ID の種類、また想定されたロールを持つ悪意のある可能性があるユーザー アクティビティなど、AWS ユーザー アクティビティに関する分析情報を得ます。 ハンティング ... 脅威判定となるログクエリを提供 Changes made to AWS IAM policy Tracking Privileged Account Rare Activity Exploit and Pentest Framework User Agent IAM Privilege Escalation by Instance Profile attachment Privileged role attached to Instance Suspicious credential token access of valid IAM Roles Unused or Unsupported Cloud Regions ノートブック ... Jupyter Notebookによる分析を提供 \n- インシデント\n- ブック ... 簡易な分析情報を提供 AWSネットワークアクティビティ ... SG、ネットワークACL、IGW、ELB、VPC、サブネット、NIの作成・更新・削除など、AWS ネットワーク関連のリソースアクティビティに関する分析情報を得ます。 AWSユーザーアクティビティ ... 失敗したサインイン試行、IP アドレス、リージョン、ユーザー エージェント、ID の種類、また想定されたロールを持つ悪意のある可能性があるユーザー アクティビティなど、AWS ユーザー アクティビティに関する分析情報を得ます。 \n- AWSネットワークアクティビティ ... SG、ネットワークACL、IGW、ELB、VPC、サブネット、NIの作成・更新・削除など、AWS ネットワーク関連のリソースアクティビティに関する分析情報を得ます。\n- AWSユーザーアクティビティ ... 失敗したサインイン試行、IP アドレス、リージョン、ユーザー エージェント、ID の種類、また想定されたロールを持つ悪意のある可能性があるユーザー アクティビティなど、AWS ユーザー アクティビティに関する分析情報を得ます。\n- ハンティング ... 脅威判定となるログクエリを提供 Changes made to AWS IAM policy Tracking Privileged Account Rare Activity Exploit and Pentest Framework User Agent IAM Privilege Escalation by Instance Profile attachment Privileged role attached to Instance Suspicious credential token access of valid IAM Roles Unused or Unsupported Cloud Regions \n- Changes made to AWS IAM policy\n- Tracking Privileged Account Rare Activity\n- Exploit and Pentest Framework User Agent\n- IAM Privilege Escalation by Instance Profile attachment\n- Privileged role attached to Instance\n- Suspicious credential token access of valid IAM Roles\n- Unused or Unsupported Cloud Regions\n- ノートブック ... Jupyter Notebookによる分析を提供\n- ソリューション ... 外部のエンドポイントセキュリティツールと連携することが可能 Trend Micro Apex One McAfee Network Security Platform \n- Trend Micro Apex One\n- McAfee Network Security Platform  > Sumo LogicSumo Logic  > 料金料金 \n\n- Sumo Logic 料金表  > SIEMからCloudTrailへの接続方法SIEMからCloudTrailへの接続方法 \n\n1. [AWSアカウントSecurity - S3] にてバケット cloudtrail-accumulativelogs-{account-id} を下記設定にて作成 パブリックアクセスをすべてブロック オフ バケットポリシー json{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"AWSCloudTrailAclCheck20150319\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"s3:GetBucketAcl\", \"Resource\": \"arn:aws:s3:::cloudtrail-accumulativelogs-{account-id}\" }, { \"Sid\": \"AWSCloudTrailWrite20150319\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"s3:PutObject\", \"Resource\": \"arn:aws:s3:::cloudtrail-accumulativelogs-{account-id}/AWSLogs/{organization-id}/*\", \"Condition\": { \"StringEquals\": { \"s3:x-amz-acl\": \"bucket-owner-full-control\" } } } ] } \n2. パブリックアクセスをすべてブロック オフ\n3. バケットポリシー json{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"AWSCloudTrailAclCheck20150319\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"s3:GetBucketAcl\", \"Resource\": \"arn:aws:s3:::cloudtrail-accumulativelogs-{account-id}\" }, { \"Sid\": \"AWSCloudTrailWrite20150319\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"s3:PutObject\", \"Resource\": \"arn:aws:s3:::cloudtrail-accumulativelogs-{account-id}/AWSLogs/{organization-id}/*\", \"Condition\": { \"StringEquals\": { \"s3:x-amz-acl\": \"bucket-owner-full-control\" } } } ] } \n4. [親AWSアカウント - KMS] にて下記設定でKSMを作成 キーのタイプ 対称 キーマテリアルオリジン KMS リージョンごと 単一リージョン エイリアス名 cloudtrail-kms キーポリシー json{ \"Version\": \"2012-10-17\", \"Id\": \"Key policy created by CloudTrail\", \"Statement\": [ { \"Sid\": \"Enable IAM User Permissions\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": \"kms:*\", \"Resource\": \"*\" }, { \"Sid\": \"Allow CloudTrail to encrypt logs\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"kms:GenerateDataKey*\", \"Resource\": \"*\", \"Condition\": { \"StringLike\": { \"kms:EncryptionContext:aws:cloudtrail:arn\": \"arn:aws:cloudtrail:*:{account-id}:trail/*\" } } }, { \"Sid\": \"Allow CloudTrail to describe key\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"kms:DescribeKey\", \"Resource\": \"*\" }, { \"Sid\": \"Allow principals in the account to decrypt log files\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": [ \"kms:Decrypt\", \"kms:ReEncryptFrom\" ], \"Resource\": \"*\", \"Condition\": { \"StringEquals\": { \"kms:CallerAccount\": \"{account-id}\" }, \"StringLike\": { \"kms:EncryptionContext:aws:cloudtrail:arn\": \"arn:aws:cloudtrail:*:{account-id}:trail/*\" } } }, { \"Sid\": \"Allow alias creation during setup\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": \"kms:CreateAlias\", \"Resource\": \"*\", \"Condition\": { \"StringEquals\": { \"kms:CallerAccount\": \"{account-id}\", \"kms:ViaService\": \"ec2.ap-northeast-1.amazonaws.com\" } } }, { \"Sid\": \"Enable cross account log decryption\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": [ \"kms:Decrypt\", \"kms:ReEncryptFrom\" ], \"Resource\": \"*\", \"Condition\": { \"StringEquals\": { \"kms:CallerAccount\": \"{account-id}\" }, \"StringLike\": { \"kms:EncryptionContext:aws:cloudtrail:arn\": \"arn:aws:cloudtrail:*:{account-id}:trail/*\" } } } ] } \n5. キーのタイプ 対称\n6. キーマテリアルオリジン KMS\n7. リージョンごと 単一リージョン\n8. エイリアス名 cloudtrail-kms\n9. キーポリシー json{ \"Version\": \"2012-10-17\", \"Id\": \"Key policy created by CloudTrail\", \"Statement\": [ { \"Sid\": \"Enable IAM User Permissions\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": \"kms:*\", \"Resource\": \"*\" }, { \"Sid\": \"Allow CloudTrail to encrypt logs\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"kms:GenerateDataKey*\", \"Resource\": \"*\", \"Condition\": { \"StringLike\": { \"kms:EncryptionContext:aws:cloudtrail:arn\": \"arn:aws:cloudtrail:*:{account-id}:trail/*\" } } }, { \"Sid\": \"Allow CloudTrail to describe key\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"kms:DescribeKey\", \"Resource\": \"*\" }, { \"Sid\": \"Allow principals in the account to decrypt log files\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": [ \"kms:Decrypt\", \"kms:ReEncryptFrom\" ], \"Resource\": \"*\", \"Condition\": { \"StringEquals\": { \"kms:CallerAccount\": \"{account-id}\" }, \"StringLike\": { \"kms:EncryptionContext:aws:cloudtrail:arn\": \"arn:aws:cloudtrail:*:{account-id}:trail/*\" } } }, { \"Sid\": \"Allow alias creation during setup\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": \"kms:CreateAlias\", \"Resource\": \"*\", \"Condition\": { \"StringEquals\": { \"kms:CallerAccount\": \"{account-id}\", \"kms:ViaService\": \"ec2.ap-northeast-1.amazonaws.com\" } } }, { \"Sid\": \"Enable cross account log decryption\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": [ \"kms:Decrypt\", \"kms:ReEncryptFrom\" ], \"Resource\": \"*\", \"Condition\": { \"StringEquals\": { \"kms:CallerAccount\": \"{account-id}\" }, \"StringLike\": { \"kms:EncryptionContext:aws:cloudtrail:arn\": \"arn:aws:cloudtrail:*:{account-id}:trail/*\" } } } ] } \n10. [親AWSアカウント - CloudTrail] にて下記設定で証跡を作成 全般的な詳細 証跡名 cloudtrail-logs 組織に証跡を適用 はい ストレージの場所 既存のS3バケットを使用する 証跡ログバケット名 cloudtrail-accumulativelogs-{account-id} ログファイルのSSE-KMS暗号化 有効 カスタマー管理のAWS KMSキー 新規 AWS KMSエイリアス arn:aws:kms:{region}:{account-id}:key/{kms-id} ログファイルの検証 有効 管理イベント APIアクティビティ すべて \n11. 全般的な詳細 証跡名 cloudtrail-logs 組織に証跡を適用 はい ストレージの場所 既存のS3バケットを使用する 証跡ログバケット名 cloudtrail-accumulativelogs-{account-id} ログファイルのSSE-KMS暗号化 有効 カスタマー管理のAWS KMSキー 新規 AWS KMSエイリアス arn:aws:kms:{region}:{account-id}:key/{kms-id} ログファイルの検証 有効 \n12. 証跡名 cloudtrail-logs\n13. 組織に証跡を適用 はい\n14. ストレージの場所 既存のS3バケットを使用する\n15. 証跡ログバケット名 cloudtrail-accumulativelogs-{account-id}\n16. ログファイルのSSE-KMS暗号化 有効\n17. カスタマー管理のAWS KMSキー 新規\n18. AWS KMSエイリアス arn:aws:kms:{region}:{account-id}:key/{kms-id}\n19. ログファイルの検証 有効\n20. 管理イベント APIアクティビティ すべて \n21. APIアクティビティ すべて\n22. [Sumo Logic - Setup Wizard - Start streaming data to Sumo Logic - CloudTrail] にて下記設定でCloudTrailデータタイプを作成 Source Category aws/cloudtrail S3 Bucket S3 Bucket Name cloudtrail-accumulativelogs-{account-id} Path Expression AWSLogs/{organization-id}/* S3 Region Asia Pacific (Tokyo) How do you want the user to access the S3 Bucket? Role-based access 指定されたCFnテンプレートでIAMロールを作成 \n23. Source Category aws/cloudtrail\n24. S3 Bucket S3 Bucket Name cloudtrail-accumulativelogs-{account-id} Path Expression AWSLogs/{organization-id}/* S3 Region Asia Pacific (Tokyo) How do you want the user to access the S3 Bucket? Role-based access 指定されたCFnテンプレートでIAMロールを作成 \n25. S3 Bucket Name cloudtrail-accumulativelogs-{account-id}\n26. Path Expression AWSLogs/{organization-id}/*\n27. S3 Region Asia Pacific (Tokyo)\n28. How do you want the user to access the S3 Bucket? Role-based access 指定されたCFnテンプレートでIAMロールを作成 \n29. 指定されたCFnテンプレートでIAMロールを作成  > SIEM機能 (AWS CloudTrail)SIEM機能 (AWS CloudTrail) \n\nデフォルト監視対象 \n\n- Console Logins Geo Location of All Users Login Events By User Logins Over Time Logins from Multiple IP Logins from Outside the USA Outlier - Success Login Outlier - Failed Login Login Results - One Day Time Comparison Logins without MFA \n- Geo Location of All Users\n- Login Events By User\n- Logins Over Time\n- Logins from Multiple IP\n- Logins from Outside the USA\n- Outlier - Success Login\n- Outlier - Failed Login\n- Login Results - One Day Time Comparison\n- Logins without MFA\n- Network and Security Authorization Failures from All Countries Network and Security Events Over Time Authorization Failures Over Time Network ACL with All Allowed Ingress/Egress Recent Authorization Failures Recent Security Group and Network ACL Changes Created and Deleted Network and Security Events Short Lived Critical Operations \n- Authorization Failures from All Countries\n- Network and Security Events Over Time\n- Authorization Failures Over Time\n- Network ACL with All Allowed Ingress/Egress\n- Recent Authorization Failures\n- Recent Security Group and Network ACL Changes\n- Created and Deleted Network and Security Events\n- Short Lived Critical Operations\n- Operations Action Events Requested AWS Services Over Time Events by AWS Region Recent Elastic IP Address Operations Created Resources Over Time Deleted Resources Over Time \n- Action Events\n- Requested AWS Services Over Time\n- Events by AWS Region\n- Recent Elastic IP Address Operations\n- Created Resources Over Time\n- Deleted Resources Over Time\n- Overview Geo Location of All Users Created Resources Deleted Resources Over Time Top 10 Users Failed Logins Created and Deleted Network and Security Events \n- Geo Location of All Users\n- Created Resources\n- Deleted Resources Over Time\n- Top 10 Users\n- Failed Logins\n- Created and Deleted Network and Security Events\n- S3 Public Objects and Buckets New Public Objects New Public Object by Object-Bucket New Public Objects Table Public Buckets Public Buckets Table Modified Public Objects Modified Public Objects by Object-Buket Modified Public Objects Table \n- New Public Objects\n- New Public Object by Object-Bucket\n- New Public Objects Table\n- Public Buckets\n- Public Buckets Table\n- Modified Public Objects\n- Modified Public Objects by Object-Buket\n- Modified Public Objects Table\n- User Monitoring Geo Location of All Users Top 10 Users Launched and Terminated Instances by User Administrative Activities Over Time Top 10 Activities by Administrative User Recent Activity by Administrative Users \n- Geo Location of All Users\n- Top 10 Users\n- Launched and Terminated Instances by User\n- Administrative Activities Over Time\n- Top 10 Activities by Administrative User\n- Recent Activity by Administrative Users  > 総評総評  > 使用コスト使用コスト \n\n初期導入の段階ではSumo LogicよりAzure Sentinelの方が倍のコストがかかります。    ログ取込量/日 Azure Sentinel月額 Sumo Logic月額     100MB 2,396 JPY 0 USD   500MB 11,978 JPY 0 USD   3GB 71,870 JPY 332 USD    \n\n※ Azure Sentinelの内訳は「 ((GB当たりのAzure Sentinel取込量347.20円) + (GB当たりのLog Analytics取込量451.36円) * 取込量GB 」  > 導入コスト導入コスト \n\n一度の設定で完了するSumo Logicの方が導入コストが低いです。Azure SentinelはIAMロールのみで済むという点で導入は楽ですがAWSアカウントごとに設定する必要があるので手離れが悪いです。  > SIEM機能SIEM機能 \n\nAzure Sentinelの方が分析機能が充実しています。Sumo Logicが大まかな脅威をログクエリからしか拾えないのに対し、Azure Sentinelは細かな脅威判定をログクエリで提供しているのに加え、Jupyter Notebookや外部のエンドポイントセキュリティツールを提供しています。また、デフォルトの監視対象も時間経過に伴うイベントアラート、悪意ある可能性があるイベント、最近のインシデント等必要十分な情報を提供しています。 \n\nまた、対象のデータソースはAzure SentinelがAWS CloudTrail、Google Workspace、Office 365、Azure AD等と幅広く用意しているのに対し、Sumo LogicはSIEMという観点では実質AWS CloudTrail専用のツールに落ち着いています。  > WRAPUPWRAPUP \n\nメインプロダクトがまだ2-3しかない状況でSIEMをAWSだけに限定する場合はSumo Logicで十分でしょう。使用コスト、導入コストともに低く抑えることができるので、しばらくはSumo Logicで運用し、プロダクトがスケールする段階でAzure Sentinelを移行するのが現実的だと思いました。"},"name":"[2021-08-15]AWS CloudTrail用のコスパの良いSIEMを探す","tags":["siem","aws-cloudtrail","azure-sentinel","sumo-logic"],"childPublishedDate":{"published_on":"2021-08-15T00:00:00.000Z","published_on_unix":1628985600}}},{"node":{"number":91,"relative_category":"blog/backend","fields":{"title":"Hardware-Accelerated GPU Scheduling機能を使ったWSL2はどのくらいパフォーマンスが向上するか","excerpt":"新しいPC端末を購入したところ「Hardware-Accerlarated GPU Scheduling」機能があることに気づきました。使用したところ気持ち速くなったように感じたのでどのくらいパフォーマンスが向上したか調べてみました。   > PROBLEMPROBLEM \n\n- システム設定で「Hardware-Accerlarated GPU Scheduling（HAGS）」機能を使ったところWSL2のパフォーマンスが体感的に速くなったように感じた 他の端末にもHAGSを展開していきたいので実際にどのらくらいパフォーマンスが向上するか検証したい \n- 他の端末にもHAGSを展開していきたいので実際にどのらくらいパフォーマンスが向上するか検証したい  > SOLUTIONSOLUTION \n\nと言うわけで、以前Phoronixによって書かれた「WSLとWSL2とのベンチマーク比較の記事」を参考にPhoronix Test SuiteでHAGSのオン・オフのベンチマーク比較を行います。  > 検証端末の環境検証端末の環境    Item Content     Processor AMD Ryzen 9 5900X 12-Core (12 Cores / 24 Threads)   Memory 52 GB   Disk 2 x 275GB Virtual Disk   OS Ubuntu 20.04   Kernel 5.4.72-microsoft-standard-WSL2 (x86_64)   Display Server X Server   Compiler GCC 9.3.0   File System ext4   System Layer wsl     > Phoronix Test SuiteをインストールするPhoronix Test Suiteをインストールする sh\n\nbrew install phoronix-test-suite sudo apt install php php-gd php-xml php-curl   > 実行するベンチマークテストを選定する実行するベンチマークテストを選定する \n\nまず実行可能なテストとテストスーツを確認します、テストスーツは関連テストのグループになります。 sh\n\nphoronix-test-suite list-available-tests phoronix-test-suite list-available-suite  \n\n今回は開発する際に関係がある下記のテストを選定しました。テストスーツは数時間では完了しないケースがあったので今回の対象から外しています。 \n\n- pts/build-gcc\n- pts/compress-gzip\n- pts/system-decompress-gzip\n- pts/gnupg\n- pts/mutex\n- pts/openssl\n- pts/git\n- pts/pybench\n- pts/nginx\n- pts/node-web-tooling  > ベンチマーク結果ベンチマーク結果    Item HAGSオン HAGSオフ     pts/build-gcc 717.39 sec 715.56 sec   pts/compress-gzip 29.10 sec 29.36 sec   pts/system-decompress-gzip 2.397 sec 2.427 sec   pts/mutex Lock Shared 15.2 sec 15.2 sec   pts/mutex Unlock spinlock 33.1 sec 33.4 sec   pts/mutex Unlock std::mutex 14.8 sec 14.7 sec   pts/mutex Semaphore Release And Acquire 8.44 sec 8.36 sec   pts/mutex Unlock pthread_mutex 8.45 sec 8.34 sec   pts/openssl 3704.3 sign/sec 3694 sign/sec   pts/git 39.01 sec 38.85 sec   pts/pybench 869 msec 877 msec   pts/nginx 70124.29 req/sec 71919.70 req/sec   pts/node-web-tooling 16.71 sec 17.01 sec     > WRAPUPWRAPUP \n\n残念ながらベンチマーク結果からHAGSのオンとオフの間に大きなパフォーマンスの変化は見られませんでした。通常の開発の場合はほぼ恩恵を受けられないと言って問題ないでしょう。 \n\n結論として、他の端末へのHAGSの展開はお薦めしません。不具合等の口コミも散見されるので使用端末との相性を見ながら導入するのが良さそうです。個人的にはChromeのハードウェアアクセラレーション機能との相性を見つつしばらく運用しようと思います。"},"name":"[2021-08-01]Hardware-Accelerated GPU Scheduling機能を使ったWSL2はどのくらいパフォーマンスが向上するか","tags":["wsl2","hags","windows-10"],"childPublishedDate":{"published_on":"2021-08-01T00:00:00.000Z","published_on_unix":1627776000}}},{"node":{"number":89,"relative_category":"blog/backend","fields":{"title":"imi-enrichment-addressは住所のバリデーションチェックでどの程度使えるか","excerpt":"コロナ禍であらゆる流通がオンラインに移行する中、正しい住所を使うことはいっそう求められています。ユーザーが配送用に住所を入力する時そのデータが正しいとどうやって判定するのでしょうか。今回はOSSライブラリimi-enrichment-addressが住所のバリデーションチェックでどの程度使えるか検証してみました。   > PROBLEMPROBLEM \n\n- 住所の不備が至るところで起きている 特に町名番地の抜けもれや不備が多くこの点をどうにか拾いたい 可能ならユーザーの入力時点でFEあるいはBE側でバリデーションチェックしたい まずはOSSのライブラリで検証したい \n- 特に町名番地の抜けもれや不備が多くこの点をどうにか拾いたい\n- 可能ならユーザーの入力時点でFEあるいはBE側でバリデーションチェックしたい まずはOSSのライブラリで検証したい \n- まずはOSSのライブラリで検証したい  > SOLUTIONSOLUTION \n\nというわけで、昨年（2020年）経産省IMI（情報共有基盤）から公開された住所変換コンポーネント「IMI-Tool-Project/imi-enrichment-address」がバリデーションチェックでどの程度使えるか検証します。  > imi-enrichment-addressとはimi-enrichment-addressとは \n\n経産省IMIツールプロジェクトで公開された住所変換コンポーネントです。CLIとサーバーが用意されていますが、今回はCLIを見ていきます。 \n\nヘルプを見ると住所を引数として渡すことで処理されることが分かります。 sh\n\n$ npm install -g https://info.gbiz.go.jp/tools/imi_tools/resource/imi-enrichment-address/imi-enrichment-address-2.0.0.tgz $ imi-enrichment-address --help imi-enrichment-address 住所文字列をもとに住所型・場所型の情報を補完します オプション -h, --help このヘルプを表示します -f, --file file 変換対象とする JSON ファイル -s, --string string 変換対象とする住所文字列 -i, --indent number 出力する JSON のインデント (default 2) 実行例 ヘルプの表示 $ imi-enrichment-address -h 文字列の処理 $ imi-enrichment-address -s 霞が関2 ファイルの処理 $ imi-enrichment-address input.json 標準入力の処理 $ cat input.json | imi-enrichment-address  \n\n実行すると正確な住所を渡したときと不正確な住所を渡したときで異なった結果を返すことが分かります。今回はこの正確・不正確の異なった結果を利用して検証していこうと思います。 sh\n\n$ imi-enrichment-address -s 長野県長野市大字長野旭町1108 { \"@context\": \"https://imi.go.jp/ns/core/context.jsonld\", \"@type\": \"場所型\", \"住所\": { \"@type\": \"住所型\", \"表記\": \"長野県長野市大字長野旭町1108\", \"都道府県\": \"長野県\", \"都道府県コード\": \"http://data.e-stat.go.jp/lod/sac/C20000\", \"市区町村\": \"長野市\", \"市区町村コード\": \"http://data.e-stat.go.jp/lod/sac/C20201\", \"町名\": \"大字長野\" }, \"地理座標\": { \"@type\": \"座標型\", \"緯度\": \"36.674892\", \"経度\": \"138.178449\" } } $ imi-enrichment-address -s 長野県長野市旭町1108 { \"@context\": \"https://imi.go.jp/ns/core/context.jsonld\", \"@type\": \"場所型\", \"住所\": { \"@type\": \"住所型\", \"表記\": \"長野県長野市旭町1108\", \"都道府県\": \"長野県\", \"都道府県コード\": \"http://data.e-stat.go.jp/lod/sac/C20000\", \"市区町村\": \"長野市\", \"市区町村コード\": \"http://data.e-stat.go.jp/lod/sac/C20201\" }, \"メタデータ\": { \"@type\": \"文書型\", \"説明\": \"該当する町名が見つかりません\" } }  \n\nなお、GitHubコードを見るとimi-enrichment-addressは街区レベル位置参照情報を利用して実装しています。このことを考えるとバリデーションチェックで積極的につかうのは難しく、ユースケースとしては下記2点に落ち着くと考えます。 \n\n- ユーザーに住所の再確認を促す\n- 入力後の住所不備について人が目検で確認する前段階で利用  > 検証用データ検証用データ \n\nさて、検証に進みましょう。imi-enrichment-addressで検証するデータは簡易に使える住所.jp、その中の事業所住所22402件を使います。他にも検証データはありますが、コストもそれほどかけられないのでコマンドだけで完結するものを選んでいます。 sh\n\n$ curl -sSL http://jusyo.jp/downloads/new/csv/csv_zenkoku.zip -o csv_zenkoku.zip $ unzip csv_zenkoku.zip $ go get github.com/mithrandie/csvq $ csvq -f CSV \"SELECT COUNT(*) FROM zenkoku WHERE 事業所住所 IS NOT NULL\" COUNT(*) 22402   > imi-enrichment-addressで検証用データを確認するimi-enrichment-addressで検証用データを確認する \n\n今回実行したCLIはNodeJSであることと数時間で処理できるという点で逐次で済ませました。 sh\n\n$ for i in $( csvq -f CSV \"SELECT 都道府県,市区町村,事業所住所 FROM zenkoku WHERE 事業所住所 IS NOT NULL\" \\ | sed 's/,//g' \\ | tail +2 \\ ); do imi-enrichment-address -s $i \\ | jq -r ' [ .[\"住所\"][\"表記\"], ( if .[\"地理座標\"] != null then true else false end ), .[\"メタデータ\"][\"説明\"] ] | @csv ' >>output.csv; done &   > バリデーションチェックの結果を確認するバリデーションチェックの結果を確認する \n\nimi-enrichment-addressの出力結果を確認したところ全国で9.25%が無効、下記の通り町名番地の表記揺れに弱いことが分かりました。特に町字（まちあざ）省略によるバリデーションエラーの比率が高く、青森、長野、沖縄等複数の県の住所が実用に耐えない結果となりました。 \n\nバリデーションエラーになった原因 \n\n- 各地方の字・大字の省略\n- 京都の通り上る・下るの表記\n- 北海道の条、線の表記揺れ\n- 茨城、岐阜等の町名省略\n- 茨城、神奈川、岐阜、石川等の区画整理地    都道府県 無効割合（%） 備考     青森県 54.42 字省略により無効   長野県 44.28 字省略により無効   沖縄県 43.55 字省略により無効   大分県 38.96 字省略により無効   京都府 36.86 字省略、通りにより無効   佐賀県 33.33 字省略により無効   奈良県 29.94 字省略により無効   福島県 29.18 字省略により無効   宮崎県 27.71 字省略により無効   埼玉県 23.08 字省略により無効   山口県 22.65 字省略により無効   和歌山県 17.78 字省略により無効   群馬県 17.08 字省略、ノ町により無効   茨城県 15.51 字省略、町名省略、区画整理により無効   熊本県 14.89 字省略により無効   山形県 14.38 字省略により無効   北海道 13.76 字省略、条、線により無効   栃木県 13.6 字省略により無効   新潟県 13.19 字省略により無効   鳥取県 9.57 字省略により無効   全国 9.25    福岡県 9 字省略により無効   三重県 7.74 字省略により無効   愛知県 7.4 字省略により無効   鹿児島県 7.09 字省略により無効   山梨県 6.8 字省略により無効   宮城県 6.37 字省略により無効   岩手県 6.28 字省略により無効   岐阜県 5.67 字省略、町名省略、区画整理により無効   香川県 4.71 字省略により無効   石川県 4.7 字省略、区画整理により無効   愛媛県 4.39 字省略により無効   秋田県 4.17 字省略により無効   滋賀県 3.76 字省略により無効   広島県 3.74 字省略により無効   高知県 3.38 字省略により無効   大阪府 3.28 字省略により無効   兵庫県 2.71 字省略により無効   島根県 2.04 字省略により無効   岡山県 1.81 字省略により無効   神奈川県 1.72 字省略、区画整理により無効   徳島県 1.64 字省略により無効   富山県 1.14 字省略により無効   静岡県 1.06 字省略、町名省略、区画整理により無効   東京都 0.89 字省略により無効   福井県 0.71 字省略により無効   千葉県 0.64 字省略により無効   長崎県 0      > WRAPUPWRAPUP \n\nimi-enrichment-addressは町名番地の判定に素の街区レベル位置参照情報を使用しているため、町字（まちあざ）の省略に弱いことが分かりました。 \n\n- ユーザーに住所の再確認を促す\n- 入力後の住所不備について人が目検で確認する前段階で利用 \n\nまず、想定したユースケースの内1つ「ユーザーに住所の再確認を促す」については、配送で使う住所の場合「町字の省略は影響ない」ので機能として適切ではありません。ユーザーが東京に集中している場合は関係ないですが、「町字が存在するさいたま市、川崎市、名古屋市、広島市、北九州市、福岡市、熊本市等の政令指定都市」や長野市のように住所が町字の組み合わせで2つ以上存在する都市の場合、使い勝手の悪い機能となります。 \n\n次に「入力後の住所不備について人が目検で確認する前段階で利用」については多少は有効に機能するでしょう。ただし、町字が多い地域では上記同様に使い勝手が悪くなります。 \n\n今回の検証の結果、現状の仕様ではimi-enrichment-addressを使うケースは限定せざるを得ず、一旦使用を見送りとします。とは言え、街区レベル位置参照情報にある町名番地から町字を除けば活用範囲が広がる可能性も確認できました。幸いなことにライブラリはMITライセンスで公開されています。"},"name":"[2021-07-24]imi-enrichment-addressは住所のバリデーションチェックでどの程度使えるか","tags":["imi-enrichment-address","mlit-isj"],"childPublishedDate":{"published_on":"2021-07-24T00:00:00.000Z","published_on_unix":1627084800}}},{"node":{"number":75,"relative_category":"blog/backend","fields":{"title":"CDKで管理する今どきのJenkins","excerpt":"先日のAWS障害で管理していたECSに多少の影響が出たので、そのタイミングで敷設していたJenkinsの構成を改めて整理しました。今回は課題解決というより、既に稼働していたシステム構成の振り返りを行いました。  > PROBLEMPROBLEM \n\n- インフラ系タスクがコード管理されていないので属人化しやすい 可能なら当該タスクはインフラ担当から手離れして欲しい 当該タスクは通常のCIワークフローとは異なるので管理する場所がない そういう意味でJenkinsの出番だけどこれはこれで管理が手間 ヘルスチェックエラーにひっかかったら自動で再起動してほしい \n- 可能なら当該タスクはインフラ担当から手離れして欲しい\n- 当該タスクは通常のCIワークフローとは異なるので管理する場所がない そういう意味でJenkinsの出番だけどこれはこれで管理が手間 ヘルスチェックエラーにひっかかったら自動で再起動してほしい \n- そういう意味でJenkinsの出番だけどこれはこれで管理が手間 ヘルスチェックエラーにひっかかったら自動で再起動してほしい \n- ヘルスチェックエラーにひっかかったら自動で再起動してほしい  > SOLUTIONSOLUTION \n\nというわけで、モダンなJenkins2系をAWS CDKで敷設してみました。  > 1. 構成1. 構成 \n\n大方の構成は「nabinno/jenkins-cdk-on-ec2」のシステム構成図をご覧下さい。元ネタはaws-sampleになりますが、今回はAWS FargateではなくAmazon ECSを採用し、CDKはTypeScriptで実装しています。 \n\n使用技術スタック \n\n- Jenkins\n- Amazon ECS（Amazon EC2）\n- Application Load Balancer\n- Amazon EFS   > 2. CDKによるJenkinsの敷設2. CDKによるJenkinsの敷設 \n\nCDKによるJenkinsの敷設はGitHubレポジトリーを見ていただくとして、ここではCDKのコード上の注意点を2点ほど共有しておきます。  > 2-a. CDKの注意点：リソース名を明示する2-a. CDKの注意点：リソース名を明示する \n\nCDKで各リソース名を明示しないとCloudFormation（CFn）独特の命名規則でリソースが敷設されます。インフラ担当が自分一人の場合は良いですが、インフラ担当を増員する際は、他のIaCツールの運用方針とバッティングする等、後で足かせになるので命名規則にのっとりリソース名を付けていくようにしましょう。 \n\n命名規則は「クラスメソッドさんの記事」を参考に決めるのが定番のようです。下記例になります。    AWSリソース 命名規則     ELB {sysname}-{env}-alb/clb   TargetGroup {sysname}-{env}-tg   EC2 {sysname}-{env}-{type}   SecurityGroup {sysname}-{env}-{type}-sg    \n\nCDKでリソース名を明示するには次のいずれかの方法で対応します。 \n\n- 各クラスのコンストラクトプロパティにある名前を記述する\n- 暗黙的生成されるリソースを明示的に作成する \n\n下記コードでは暗黙的に生成されていたSecurity Groupを明示的に作成している様子等が見て取れます。 ts\n\n// ECS: Service const serviceSecGrp = new ec2.SecurityGroup(this, \"JenkinsMasterServiceSecGrp\", { securityGroupName: \"jenkins-production-master-sg\", vpc: network.vpc, allowAllOutbound: true, }); serviceSecGrp.addIngressRule(worker.workerSecurityGroup, ec2.Port.tcp(50000), \"from JenkinsWorkerSecurityGroup 50000\"); serviceSecGrp.addIngressRule(worker.workerSecurityGroup, ec2.Port.tcp(8080), \"from JenkinsWorkerSecurityGroup 8080\"); const jenkinsMasterService = new ecs.Ec2Service(this, \"EC2MasterService\", { serviceName: 'jenkins-production-master-svc', taskDefinition: jenkinsMasterTask, cloudMapOptions: { name: \"master\", dnsRecordType: sd.DnsRecordType.A }, desiredCount: 1, minHealthyPercent: 0, maxHealthyPercent: 100, enableECSManagedTags: true, cluster: ecsCluster.cluster, securityGroups: [serviceSecGrp] });  \n\nなお、リソース名の明示化について、もちろんCDKのクラスによっては暗黙的なリソースを含んでおり当該リソースに名前を付けることが出来ないケースはあります。今回のケースで言うと、例えば、ECSクラスター（EC2）のIAM RoleやSecurity Group。その場合は、インフラのCDK運用方針としてドキュメントに残しておく等しておくと良いでしょう。  > 2-b. CDKの注意点：cdk.RemovablePolicy.RETAINをつける2-b. CDKの注意点：cdk.RemovablePolicy.RETAINをつける \n\nネットワーク、ストレージ関連のリソースを扱う場合、削除されるとリソース構成が破綻する可能性があるのでcdk.RemovablePolicy.RETAIN、CFnの言うところの \"DeletionPolicy\": \"Retain\" をつけましょう。今回はEFSがその対象になります。 ts\n\nconst efsFilesystem = new efs.CfnFileSystem(this, \"EFSBackend\"); efsFilesystem.applyRemovalPolicy(cdk.RemovalPolicy.RETAIN);  \n\n個人的にはRETAINをつけるとcdk destroy cdk deployを気軽に行えなくなるので、RETAINをつけるならCDK/CFnからはARNで参照する程度に抑えた方が良いと思っています。  > 3. Jenkinsの設定を行う3. Jenkinsの設定を行う \n\nCDKでJenkinsを敷設した終わったらJenkinsの設定を行いましょう。  > 3-a. Jenkinsでつかっているプラグイン3-a. Jenkinsでつかっているプラグイン \n\n昔と違って今のJenkinsは下記プラグインがあれば十分運用できます。 \n\n- github-oauth\n- role-strategy\n- configuration-as-code\n- blueocean \n\nざっと説明するとgithub-oauthでGitHub認証させ、role-strategyでロールごとの権限付与を行い、configuration-as-codeでそれらの管理設定をコード化します。configuration-as-codeは素晴らしく設定情報をコード化することでdockerイメージに当該設定情報を反映させることが出来ます。また、blueoceanはモダンなインターフェイスでジョブ実行します。こちらは次のセクションで詳細を説明します。 \n\nなお、プラグイン管理はIaC化でき下記のようにdockerイメージに反映できます。 sh\n\n$ cat plugins.txt role-strategy:3.1 github-oauth:0.33 thinBackup:1.10 git:4.6.0 authorize-project:1.3.0 configuration-as-code:1.47 blueocean:1.24.4 $ cat Dockerfile [...] COPY plugins.txt /usr/share/jenkins/ref/plugins.txt RUN /usr/local/bin/install-plugins.sh < /usr/share/jenkins/ref/plugins.txt [...]   > 3-b. JenkinsジョブをGitHubで管理する3-b. JenkinsジョブをGitHubで管理する \n\nいよいよJenkinsでジョブの管理設定を行います。具体的には下記手順で実施します。手順が完了すると作ったブランチ分だけJenkinsにジョブが追加されます、とても簡単です。 \n\n1. ジョブを管理させたいGitHubレポジトリでジョブ管理用のブランチを作成し、Jenkinsfile を配置\n2. 「Jenkins - Blue Ocean - New Pipeline」にて下記設定をおこなう Where do you store your code? - GitHub Which organization does the repository belong to? - 任意のuserあるいはorganization Choose a repository - 任意のレポジトリ（1で作成したレポジトリ） \n3. Where do you store your code? - GitHub\n4. Which organization does the repository belong to? - 任意のuserあるいはorganization\n5. Choose a repository - 任意のレポジトリ（1で作成したレポジトリ） \n\nJenkinsfile の作成方法は「ユーザーハンドブック」にありますが、下記例のように直感的に記述することが出来ます。環境変数は「Jenkins - {{レポジトリ}} - 認証情報 - Stores scoped to {{レポジトリ}} - global - Add credential」から追加します。 Jenkinsfile\n\n pipeline { agent any stages { stage('Show env') { steps { sh '''mysql --version ls -al bin env | sort''' } } stage('Run script') { steps { git(url: 'https://github.com/nabinno/jenkins-jobs', branch: 'master', credentialsId: 'github') sh '''git diff sync-db-from-staging-to-integration | patch -p1 -R -f bin/sync_db_from_staging_to_integration''' } } } environment { STAG_DB_DATABASE = credentials('STAG_DB_DATABASE') STAG_DB_HOSTNAME = credentials('STAG_DB_HOSTNAME') STAG_DB_PASSWORD = credentials('STAG_DB_PASSWORD') STAG_DB_USERNAME = credentials('STAG_DB_USERNAME') INTEG_DB_HOSTNAME = credentials('INTEG_DB_HOSTNAME') INTEG_DB_PASSWORD = credentials('INTEG_DB_PASSWORD') INTEG_DB_USERNAME = credentials('INTEG_DB_USERNAME') INTEG_DB_DATABASE = credentials('INTEG_DB_USERNAME') } }   > WRAPUPWRAPUP \n\n今回の振り返りで、2点気づきを得られました。CDKのリソース名の扱いに困っていたのですが、どうにか制御できそうなのでまたしばらくは付き合っていくことになりそうです。 \n\n1. CDKは意外とかゆいところに手が届く。ただ、暗黙的に生成され、CDK側で制御できないリソース名があるので、そういう前提で運用ポリシーを作ると各IaC使いの平穏に繋がる。\n2. Jenkins2は思った以上に手離れが良い。CDK、ECS、EFS、configuration-as-code、Jenkinsfileの組み合わせは保守性、可用性に大きな貢献をしている。"},"name":"[2021-02-24]CDKで管理する今どきのJenkins","tags":["aws-cdk","jenkins","amazon-ecs"],"childPublishedDate":{"published_on":"2021-02-24T00:00:00.000Z","published_on_unix":1614124800}}},{"node":{"number":80,"relative_category":"blog/backend","fields":{"title":"AWS Organizationsを別のAWSアカウントに移行する","excerpt":"最近のAWSはCDKの発表に代表されるようにインフラ以外の開発者が触りやすい環境が整ってきています。ただ、こうした機能やリソースを存分に享受するにはIAM管理だけでは不足しており、AWSアカウントの管理方針を大枠で整理する必要が出てきました。今回は深く考えずに使っていたOrganizationsを整理する際にはまったポイントを記していきます。   > PROBLEMPROBLEM \n\n- 初期の頃につくったAWSアカウントにコンソリ請求の便利さからとりあえずOrganizations機能をつけてみた その後、当該アカウントに異なるワークロードのリソースを加えすぎてスケールしづらい構成になってきた 例えば 開発環境をAWSアカウント単位で分けられないためIAMや開発サイクルが複雑になり開発スピードに支障が出てきた セキュリティ上望ましくないシステム構成について改修のハードルが上がってきた \n- その後、当該アカウントに異なるワークロードのリソースを加えすぎてスケールしづらい構成になってきた 例えば 開発環境をAWSアカウント単位で分けられないためIAMや開発サイクルが複雑になり開発スピードに支障が出てきた セキュリティ上望ましくないシステム構成について改修のハードルが上がってきた \n- 例えば 開発環境をAWSアカウント単位で分けられないためIAMや開発サイクルが複雑になり開発スピードに支障が出てきた セキュリティ上望ましくないシステム構成について改修のハードルが上がってきた \n- 開発環境をAWSアカウント単位で分けられないためIAMや開発サイクルが複雑になり開発スピードに支障が出てきた\n- セキュリティ上望ましくないシステム構成について改修のハードルが上がってきた  > SOLUTIONSOLUTION \n\nというわけで、一旦Organizations機能を解除して新しく作成したAWS管理アカウントに移行していくことにしました。一つ一つの作業は単純なのですが意外と時間がかかることが分かったので備忘として残しておきます。 \n\nOrganizationsのOU構成はサムネイル画像のBEFORE/AFTERの通りです。 \n\nBEFORE：Organization Unitの構成は全然考えずとりあえず追加していました。 \n\n- Foo - AWS Organizationsのオーナーアカウントであり、異なるワークロードや環境が混在しているアカウント\n- Bar - お試し用アカウント1\n- Buzz - お試し用アカウント2 \n\nAFTER：こちらの記事「Best Practices for Organizational Units with AWS Organizations | AWS Management & Governance Blog」を参考に構成しました。 \n\n- Foundation Management - AWS Organizationsのオーナーアカウント Security Infrastructure \n- Management - AWS Organizationsのオーナーアカウント\n- Security\n- Infrastructure\n- Workload Prod Foo Stg FooStg Integ FooInteg \n- Prod Foo \n- Foo\n- Stg FooStg \n- FooStg\n- Integ FooInteg \n- FooInteg\n- Sandbox BarSandbox BuzzSandbox \n- BarSandbox\n- BuzzSandbox  > Organizationsを別アカウントに移行する方法Organizationsを別アカウントに移行する方法 \n\nやったことはこちらの記事「2 つの AWS Organizations 間でアカウントを移動する」の通りですが、いくつかはまるポイントが書かれていないのでそちらも合わせて記します。まず注意点として3つあります。 \n\n一つ目は、Organizationsの移行期間中は請求の種類が3種類になる可能性があります。具体的には「古いOrganizationsによるコンソリ請求」「スタンドアロンのAWSアカウントによる請求」「新しいOrganizationsによるコンソリ請求」です。会社組織としてAWSを利用している場合は経理側との連携が必要になってくるでしょう。 \n\n二つ目は、古いOrganizationsから追加作成されたメンバーアカウントには請求情報の追加と電話番号の認証を行う必要があります。前者の請求情報の追加はそれほど手間ではないのですが、後者の電話番号の認証はAWSサポートを介すため1アカウントごとに3日から1週間ほど時間がかかります。詳細の対応方法はこちらの記事「組織からのメンバーアカウントのリンク解除のエラーを解決する」を参照下さい。 \n\n三つ目は、新しいOrganizationsでは先に制限緩和を行っておきましょう。新しいOrganizationsを作成する際はおそらく古いOrganizationsの時よりもにメンバーアカウントが増えることと思います。特にベストプラクティスのOrganization Unitでアカウントを分けていくとあっという間にデフォルト制限の10を超える可能性が高いです。 \n\n次に移行手順ですが、上記の注意点をクリアしたらほぼ単純作業になります。 \n\n1. 古いOrganizationからメンバーアカウントを削除\n2. 新しいOrganizationからメンバーアカウントに招待を送信\n3. メンバーアカウントで新しいOrganizationへの招待を受け入れる\n4. （全てのメンバーアカウントを削除し終わった後に）古いOrganizationsを削除\n5. 古いOrganizationsの管理アカウントをメンバーアカウントとして新しい Organization に招待  > WRAPUPWRAPUP \n\n昨今のAWSの動きを見ると、インフラ以外の開発者にもAWSを気軽に使えるようになってきており、Organizations機能を使うこと前提にサービスが展開されているようです。なのでこうした恩恵をうけるためにもOrganizationsのベストプラクティスに則ったアカウント構成にする必要があります。 \n\n一応の注意点としては、Organizationsが便利だからといってOrganizationsからメンバーアカウントを追加することは止めた方がいいです。Organizations移行の注意点から分かる通り、Organizationsから追加されたメンバーアカウントには請求情報追加も電話番号認証も行われません。いざ別のOrganizationsに移行する際に想定外の手間と時間をかけないよう、常にスタンドアロンでAWSアカウントを作成するようにしましょう。 \n\nさて、Organizationsの勘所が見えてきたら次はAWS SSOという便利な機能が待っています。AWSを楽しみましょう。"},"name":"[2021-05-09]AWS Organizationsを別のAWSアカウントに移行する","tags":["aws-organizations"],"childPublishedDate":{"published_on":"2021-05-09T00:00:00.000Z","published_on_unix":1620518400}}},{"node":{"number":90,"relative_category":"blog/backend","fields":{"title":"yubinbango-dataをどうやって生成するか","excerpt":"郵便番号から住所を補完するライブラリ「yubinbango」を継続的に利用するにあたり、当該ライブラリが参照している郵便データ「yubinbango-data」を自前でメンテナンスできるか確認します。   > PROBLEMPROBLEM \n\n- 「yubinbango/yubinbango」を利用するにあたり「yubinbango/yubinbango-data」の更新が継続的に行われるかサービス継続性の懸念がある そこで自前でメンテナンスをする場合の対処方法を事前に知っておきたい \n- そこで自前でメンテナンスをする場合の対処方法を事前に知っておきたい  > SOLUTIONSOLUTION \n\nというわけで、yubinbango-dataの中身であるken_all.csvとjigyosyo.csvを安定して変換する方法を確認します。  > ken_all.csvを正規化するken_all.csvを正規化する \n\nyubinbango-dataのken_all.csvの部分はアイビスが提供しているzipcloudを参照しているようなので、そちらに合わせて利用します。 sh\n\nsudo apt install nkf { curl -sSL \"http://zipcloud.ibsnet.co.jp/zipcodedata/download?di=1625040649647\" -o ./x_ken_all.zip; unzip -p x_ken_all.zip | nkf -w; rm x_ken_all.zip } >ken_all.csv  \n\nzipcloudを使うことに抵抗がある場合はgokenallもありますが、正規化によって一つの郵便番号に複数の町名番地が存在するため郵便番号をキーとするyubinbango-dataに変換する際には工夫が必要です。 sh\n\ngo get github.com/oirik/gokenall/cmd/kenall { kenall download -x | kenall normalize } >ken_all.csv   > jigyosyo.csvを取得するjigyosyo.csvを取得する \n\njigyosyo.csvは特に正規化は必要ないです。 sh\n\n{ curl -sSL https://www.post.japanpost.jp/zipcode/dl/jigyosyo/zip/jigyosyo.zip -o ./jigyosyo.zip; unzip -p jigyosyo.zip | nkf -w; rm jigyosyo.zip } >jigyosyo.csv   > yubinbango-dataを生成するyubinbango-dataを生成する \n\nken_all.csvとjigyosyo.csvをUNIONしてjqで郵便番号をキーとしたオブジェクトに変換します。一部buildingカラムがnullを持っておりyubinbango-dataと異なる部分はありますが、大凡同等の状態にまで持っていくことが出来ました。 sh\n\nbrew install noborus/tap/trdsql for i in {001..999}; do trdsql -ojson \" SELECT * FROM ( SELECT c3 zip, c8 city, c9 town, NULL building FROM ken_all.csv UNION SELECT c8 zip, c5 city, c6 town, c7 building FROM jigyosyo.csv ) WHERE SUBSTRING(zip,0,4) = '$i' ORDER BY zip ASC \" \\ | jq --compact-output ' . | to_entries | map({ (.value.zip): [1, .value.city, .value.town, .value.building] }) | add ' \\ | sed -E 's/(.+?)/$yubin(\\1);/g' \\ >$i.js; done   > WRAPUPWRAPUP \n\n昔から何かと話題に上がるken_all.csvですが、正規化のサービスに加えCSV用SQLクライアントとjqの登場により思った以上に簡単に変換することができました。"},"name":"[2021-07-25]yubinbango-dataをどうやって生成するか","tags":["yubinbango","ken_all.csv","jq","trdsql"],"childPublishedDate":{"published_on":"2021-07-25T00:00:00.000Z","published_on_unix":1627171200}}}],"pathPrefix":"categories/blog/backend","first":true,"last":false,"index":1,"pageCount":2,"additionalContext":{"category":"blog/backend"}}},"staticQueryHashes":[]}