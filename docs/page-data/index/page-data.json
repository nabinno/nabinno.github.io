{"componentChunkName":"component---src-templates-posts-tsx","path":"/","result":{"pageContext":{"group":[{"node":{"number":90,"relative_category":"blog/backend","fields":{"title":"yubinbango-dataをどうやって生成するか","excerpt":"郵便番号から住所を補完するライブラリ「yubinbango」を継続的に利用するにあたり、当該ライブラリが参照している郵便データ「yubinbango-data」を自前でメンテナンスできるか確認します。   > PROBLEMPROBLEM \n\n- 「yubinbango/yubinbango」を利用するにあたり「yubinbango/yubinbango-data」の更新が継続的に行われるかサービス継続性の懸念がある そこで自前でメンテナンスをする場合の対処方法を事前に知っておきたい \n- そこで自前でメンテナンスをする場合の対処方法を事前に知っておきたい  > SOLUTIONSOLUTION \n\nというわけで、yubinbango-dataの中身であるken_all.csvとjigyosyo.csvを安定して変換する方法を確認します。  > ken_all.csvを正規化するken_all.csvを正規化する \n\nyubinbango-dataのken_all.csvの部分はアイビスが提供しているzipcloudを参照しているようなので、そちらに合わせて利用します。 sh\n\nsudo apt install nkf { curl -sSL \"http://zipcloud.ibsnet.co.jp/zipcodedata/download?di=1625040649647\" -o ./x_ken_all.zip; unzip -p x_ken_all.zip | nkf -w; rm x_ken_all.zip } >ken_all.csv  \n\nzipcloudを使うことに抵抗がある場合はgokenallもありますが、正規化によって一つの郵便番号に複数の町名番地が存在するため郵便番号をキーとするyubinbango-dataに変換する際には工夫が必要です。 sh\n\ngo get github.com/oirik/gokenall/cmd/kenall { kenall download -x | kenall normalize } >ken_all.csv   > jigyosyo.csvを取得するjigyosyo.csvを取得する \n\njigyosyo.csvは特に正規化は必要ないです。 sh\n\n{ curl -sSL https://www.post.japanpost.jp/zipcode/dl/jigyosyo/zip/jigyosyo.zip -o ./jigyosyo.zip; unzip -p jigyosyo.zip | nkf -w; rm jigyosyo.zip } >jigyosyo.csv   > yubinbango-dataを生成するyubinbango-dataを生成する \n\nken_all.csvとjigyosyo.csvをUNIONしてjqで郵便番号をキーとしたオブジェクトに変換します。一部buildingカラムがnullを持っておりyubinbango-dataと異なる部分はありますが、大凡同等の状態にまで持っていくことが出来ました。 sh\n\nbrew install noborus/tap/trdsql for i in {001..999}; do trdsql -ojson \" SELECT * FROM ( SELECT c3 zip, c8 city, c9 town, NULL building FROM ken_all.csv UNION SELECT c8 zip, c5 city, c6 town, c7 building FROM jigyosyo.csv ) WHERE SUBSTRING(zip,0,4) = '$i' ORDER BY zip ASC \" \\ | jq --compact-output ' . | to_entries | map({ (.value.zip): [1, .value.city, .value.town, .value.building] }) | add ' \\ | sed -E 's/(.+?)/$yubin(\\1);/g' \\ >$i.js; done   > WRAPUPWRAPUP \n\n昔から何かと話題に上がるken_all.csvですが、正規化のサービスに加えCSV用SQLクライアントとjqの登場により思った以上に簡単に変換することができました。"},"name":"yubinbango-dataをどうやって生成するか","tags":["yubinbango","ken_all.csv","jq","trdsql"],"childPublishedDate":{"published_on":"2021-07-24T17:53:57.000Z","published_on_unix":1627149237}}},{"node":{"number":89,"relative_category":"blog/backend","fields":{"title":"imi-enrichment-addressは住所のバリデーションチェックでどの程度使えるか","excerpt":"コロナ禍であらゆる流通がオンラインに移行する中、正しい住所を使うことはいっそう求められています。ユーザーが配送用に住所を入力する時そのデータが正しいとどうやって判定するのでしょうか。今回はOSSライブラリimi-enrichment-addressが住所のバリデーションチェックでどの程度使えるか検証してみました。   > PROBLEMPROBLEM \n\n- 住所の不備が至るところで起きている 特に町名番地の抜けもれや不備が多くこの点をどうにか拾いたい 可能ならユーザーの入力時点でFEあるいはBE側でバリデーションチェックしたい まずはOSSのライブラリで検証したい \n- 特に町名番地の抜けもれや不備が多くこの点をどうにか拾いたい\n- 可能ならユーザーの入力時点でFEあるいはBE側でバリデーションチェックしたい まずはOSSのライブラリで検証したい \n- まずはOSSのライブラリで検証したい  > SOLUTIONSOLUTION \n\nというわけで、昨年（2020年）経産省IMI（情報共有基盤）から公開された住所変換コンポーネント「IMI-Tool-Project/imi-enrichment-address」がバリデーションチェックでどの程度使えるか検証します。  > imi-enrichment-addressとはimi-enrichment-addressとは \n\n経産省IMIツールプロジェクトで公開された住所変換コンポーネントです。CLIとサーバーが用意されていますが、今回はCLIを見ていきます。 \n\nヘルプを見ると住所を引数として渡すことで処理されることが分かります。 sh\n\n$ npm install -g https://info.gbiz.go.jp/tools/imi_tools/resource/imi-enrichment-address/imi-enrichment-address-2.0.0.tgz $ imi-enrichment-address --help imi-enrichment-address 住所文字列をもとに住所型・場所型の情報を補完します オプション -h, --help このヘルプを表示します -f, --file file 変換対象とする JSON ファイル -s, --string string 変換対象とする住所文字列 -i, --indent number 出力する JSON のインデント (default 2) 実行例 ヘルプの表示 $ imi-enrichment-address -h 文字列の処理 $ imi-enrichment-address -s 霞が関2 ファイルの処理 $ imi-enrichment-address input.json 標準入力の処理 $ cat input.json | imi-enrichment-address  \n\n実行すると正確な住所を渡したときと不正確な住所を渡したときで異なった結果を返すことが分かります。今回はこの正確・不正確の異なった結果を利用して検証していこうと思います。 sh\n\n$ imi-enrichment-address -s 長野県長野市大字長野旭町1108 { \"@context\": \"https://imi.go.jp/ns/core/context.jsonld\", \"@type\": \"場所型\", \"住所\": { \"@type\": \"住所型\", \"表記\": \"長野県長野市大字長野旭町1108\", \"都道府県\": \"長野県\", \"都道府県コード\": \"http://data.e-stat.go.jp/lod/sac/C20000\", \"市区町村\": \"長野市\", \"市区町村コード\": \"http://data.e-stat.go.jp/lod/sac/C20201\", \"町名\": \"大字長野\" }, \"地理座標\": { \"@type\": \"座標型\", \"緯度\": \"36.674892\", \"経度\": \"138.178449\" } } $ imi-enrichment-address -s 長野県長野市旭町1108 { \"@context\": \"https://imi.go.jp/ns/core/context.jsonld\", \"@type\": \"場所型\", \"住所\": { \"@type\": \"住所型\", \"表記\": \"長野県長野市旭町1108\", \"都道府県\": \"長野県\", \"都道府県コード\": \"http://data.e-stat.go.jp/lod/sac/C20000\", \"市区町村\": \"長野市\", \"市区町村コード\": \"http://data.e-stat.go.jp/lod/sac/C20201\" }, \"メタデータ\": { \"@type\": \"文書型\", \"説明\": \"該当する町名が見つかりません\" } }  \n\nなお、GitHubコードを見るとimi-enrichment-addressは街区レベル位置参照情報を利用して実装しています。このことを考えるとバリデーションチェックで積極的につかうのは難しく、ユースケースとしては下記2点に落ち着くと考えます。 \n\n- ユーザーに住所の再確認を促す\n- 入力後の住所不備について人が目検で確認する前段階で利用  > 検証用データ検証用データ \n\nさて、検証に進みましょう。imi-enrichment-addressで検証するデータは簡易に使える住所.jp、その中の事業所住所22402件を使います。他にも検証データはありますが、コストもそれほどかけられないのでコマンドだけで完結するものを選んでいます。 sh\n\n$ curl -sSL http://jusyo.jp/downloads/new/csv/csv_zenkoku.zip -o csv_zenkoku.zip $ unzip csv_zenkoku.zip $ go get github.com/mithrandie/csvq $ csvq -f CSV \"SELECT COUNT(*) FROM zenkoku WHERE 事業所住所 IS NOT NULL\" COUNT(*) 22402   > imi-enrichment-addressで検証用データを確認するimi-enrichment-addressで検証用データを確認する \n\n今回実行したCLIはNodeJSであることと数時間で処理できるという点で逐次で済ませました。 sh\n\n$ for i in $( csvq -f CSV \"SELECT 都道府県,市区町村,事業所住所 FROM zenkoku WHERE 事業所住所 IS NOT NULL\" \\ | sed 's/,//g' \\ | tail +2 \\ ); do imi-enrichment-address -s $i \\ | jq -r ' [ .[\"住所\"][\"表記\"], ( if .[\"地理座標\"] != null then true else false end ), .[\"メタデータ\"][\"説明\"] ] | @csv ' >>output.csv; done &   > バリデーションチェックの結果を確認するバリデーションチェックの結果を確認する \n\nimi-enrichment-addressの出力結果を確認したところ全国で9.25%が無効、下記の通り町名番地の表記揺れに弱いことが分かりました。特に町字（まちあざ）省略によるバリデーションエラーの比率が高く、青森、長野、沖縄等複数の県の住所が実用に耐えない結果となりました。 \n\nバリデーションエラーになった原因 \n\n- 各地方の字・大字の省略\n- 京都の通り上る・下るの表記\n- 北海道の条、線の表記揺れ\n- 茨城、岐阜等の町名省略\n- 茨城、神奈川、岐阜、石川等の区画整理地    都道府県 無効割合（%） 備考     青森県 54.42 字省略により無効   長野県 44.28 字省略により無効   沖縄県 43.55 字省略により無効   大分県 38.96 字省略により無効   京都府 36.86 字省略、通りにより無効   佐賀県 33.33 字省略により無効   奈良県 29.94 字省略により無効   福島県 29.18 字省略により無効   宮崎県 27.71 字省略により無効   埼玉県 23.08 字省略により無効   山口県 22.65 字省略により無効   和歌山県 17.78 字省略により無効   群馬県 17.08 字省略、ノ町により無効   茨城県 15.51 字省略、町名省略、区画整理により無効   熊本県 14.89 字省略により無効   山形県 14.38 字省略により無効   北海道 13.76 字省略、条、線により無効   栃木県 13.6 字省略により無効   新潟県 13.19 字省略により無効   鳥取県 9.57 字省略により無効   全国 9.25    福岡県 9 字省略により無効   三重県 7.74 字省略により無効   愛知県 7.4 字省略により無効   鹿児島県 7.09 字省略により無効   山梨県 6.8 字省略により無効   宮城県 6.37 字省略により無効   岩手県 6.28 字省略により無効   岐阜県 5.67 字省略、町名省略、区画整理により無効   香川県 4.71 字省略により無効   石川県 4.7 字省略、区画整理により無効   愛媛県 4.39 字省略により無効   秋田県 4.17 字省略により無効   滋賀県 3.76 字省略により無効   広島県 3.74 字省略により無効   高知県 3.38 字省略により無効   大阪府 3.28 字省略により無効   兵庫県 2.71 字省略により無効   島根県 2.04 字省略により無効   岡山県 1.81 字省略により無効   神奈川県 1.72 字省略、区画整理により無効   徳島県 1.64 字省略により無効   富山県 1.14 字省略により無効   静岡県 1.06 字省略、町名省略、区画整理により無効   東京都 0.89 字省略により無効   福井県 0.71 字省略により無効   千葉県 0.64 字省略により無効   長崎県 0      > WRAPUPWRAPUP \n\nimi-enrichment-addressは町名番地の判定に素の街区レベル位置参照情報を使用しているため、町字（まちあざ）の省略に弱いことが分かりました。 \n\n- ユーザーに住所の再確認を促す\n- 入力後の住所不備について人が目検で確認する前段階で利用 \n\nまず、想定したユースケースの内1つ「ユーザーに住所の再確認を促す」については、配送で使う住所の場合「町字の省略は影響ない」ので機能として適切ではありません。ユーザーが東京に集中している場合は関係ないですが、「町字が存在するさいたま市、川崎市、名古屋市、広島市、北九州市、福岡市、熊本市等の政令指定都市」や長野市のように住所が町字の組み合わせで2つ以上存在する都市の場合、使い勝手の悪い機能となります。 \n\n次に「入力後の住所不備について人が目検で確認する前段階で利用」については多少は有効に機能するでしょう。ただし、町字が多い地域では上記同様に使い勝手が悪くなります。 \n\n今回の検証の結果、現状の仕様ではimi-enrichment-addressを使うケースは限定せざるを得ず、一旦使用を見送りとします。とは言え、街区レベル位置参照情報にある町名番地から町字を除けば活用範囲が広がる可能性も確認できました。幸いなことにライブラリはMITライセンスで公開されています。"},"name":"imi-enrichment-addressは住所のバリデーションチェックでどの程度使えるか","tags":["imi-enrichment-address","mlit-isj"],"childPublishedDate":{"published_on":"2021-07-24T17:51:16.000Z","published_on_unix":1627149076}}},{"node":{"number":80,"relative_category":"blog/backend","fields":{"title":"AWS Organizationsを別のAWSアカウントに移行する","excerpt":"最近のAWSはCDKの発表に代表されるようにインフラ以外の開発者が触りやすい環境が整ってきています。ただ、こうした機能やリソースを存分に享受するにはIAM管理だけでは不足しており、AWSアカウントの管理方針を大枠で整理する必要が出てきました。今回は深く考えずに使っていたOrganizationsを整理する際にはまったポイントを記していきます。    > PROBLEMPROBLEM \n\n- 初期の頃につくったAWSアカウントにコンソリ請求の便利さからとりあえずOrganizations機能をつけてみた その後、当該アカウントに異なるワークロードのリソースを加えすぎてスケールしづらい構成になってきた 例えば 開発環境をAWSアカウント単位で分けられないためIAMや開発サイクルが複雑になり開発スピードに支障が出てきた セキュリティ上望ましくないシステム構成について改修のハードルが上がってきた \n- その後、当該アカウントに異なるワークロードのリソースを加えすぎてスケールしづらい構成になってきた 例えば 開発環境をAWSアカウント単位で分けられないためIAMや開発サイクルが複雑になり開発スピードに支障が出てきた セキュリティ上望ましくないシステム構成について改修のハードルが上がってきた \n- 例えば 開発環境をAWSアカウント単位で分けられないためIAMや開発サイクルが複雑になり開発スピードに支障が出てきた セキュリティ上望ましくないシステム構成について改修のハードルが上がってきた \n- 開発環境をAWSアカウント単位で分けられないためIAMや開発サイクルが複雑になり開発スピードに支障が出てきた\n- セキュリティ上望ましくないシステム構成について改修のハードルが上がってきた   > SOLUTIONSOLUTION \n\nというわけで、一旦Organizations機能を解除して新しく作成したAWS管理アカウントに移行していくことにしました。一つ一つの作業は単純なのですが意外と時間がかかることが分かったので備忘として残しておきます。 \n\nOrganizationsのOU構成はサムネイル画像のBEFORE/AFTERの通りです。 \n\nBEFORE：Organization Unitの構成は全然考えずとりあえず追加していました。 \n\n- Foo - AWS Organizationsのオーナーアカウントであり、異なるワークロードや環境が混在しているアカウント\n- Bar - お試し用アカウント1\n- Buzz - お試し用アカウント2 \n\nAFTER：こちらの記事「Best Practices for Organizational Units with AWS Organizations | AWS Management & Governance Blog」を参考に構成しました。 \n\n- Foundation Management - AWS Organizationsのオーナーアカウント Security Infrastructure \n- Management - AWS Organizationsのオーナーアカウント\n- Security\n- Infrastructure\n- Workload Prod Foo Stg FooStg Integ FooInteg \n- Prod Foo \n- Foo\n- Stg FooStg \n- FooStg\n- Integ FooInteg \n- FooInteg\n- Sandbox BarSandbox BuzzSandbox \n- BarSandbox\n- BuzzSandbox   > Organizationsを別アカウントに移行する方法Organizationsを別アカウントに移行する方法 \n\nやったことはこちらの記事「2 つの AWS Organizations 間でアカウントを移動する」の通りですが、いくつかはまるポイントが書かれていないのでそちらも合わせて記します。まず注意点として3つあります。 \n\n一つ目は、Organizationsの移行期間中は請求の種類が3種類になる可能性があります。具体的には「古いOrganizationsによるコンソリ請求」「スタンドアロンのAWSアカウントによる請求」「新しいOrganizationsによるコンソリ請求」です。会社組織としてAWSを利用している場合は経理側との連携が必要になってくるでしょう。 \n\n二つ目は、古いOrganizationsから追加作成されたメンバーアカウントには請求情報の追加と電話番号の認証を行う必要があります。前者の請求情報の追加はそれほど手間ではないのですが、後者の電話番号の認証はAWSサポートを介すため1アカウントごとに3日から1週間ほど時間がかかります。詳細の対応方法はこちらの記事「組織からのメンバーアカウントのリンク解除のエラーを解決する」を参照下さい。 \n\n三つ目は、新しいOrganizationsでは先に制限緩和を行っておきましょう。新しいOrganizationsを作成する際はおそらく古いOrganizationsの時よりもにメンバーアカウントが増えることと思います。特にベストプラクティスのOrganization Unitでアカウントを分けていくとあっという間にデフォルト制限の10を超える可能性が高いです。 \n\n次に移行手順ですが、上記の注意点をクリアしたらほぼ単純作業になります。 \n\n1. 古いOrganizationからメンバーアカウントを削除\n2. 新しいOrganizationからメンバーアカウントに招待を送信\n3. メンバーアカウントで新しいOrganizationへの招待を受け入れる\n4. （全てのメンバーアカウントを削除し終わった後に）古いOrganizationsを削除\n5. 古いOrganizationsの管理アカウントをメンバーアカウントとして新しい Organization に招待   > WRAPUPWRAPUP \n\n昨今のAWSの動きを見ると、インフラ以外の開発者にもAWSを気軽に使えるようになってきており、Organizations機能を使うこと前提にサービスが展開されているようです。なのでこうした恩恵をうけるためにもOrganizationsのベストプラクティスに則ったアカウント構成にする必要があります。 \n\n一応の注意点としては、Organizationsが便利だからといってOrganizationsからメンバーアカウントを追加することは止めた方がいいです。Organizations移行の注意点から分かる通り、Organizationsから追加されたメンバーアカウントには請求情報追加も電話番号認証も行われません。いざ別のOrganizationsに移行する際に想定外の手間と時間をかけないよう、常にスタンドアロンでAWSアカウントを作成するようにしましょう。 \n\nさて、Organizationsの勘所が見えてきたら次はAWS SSOという便利な機能が待っています。AWSを楽しみましょう。"},"name":"AWS Organizationsを別のAWSアカウントに移行する","tags":["aws-organizations"],"childPublishedDate":{"published_on":"2021-05-13T11:39:28.000Z","published_on_unix":1620905968}}},{"node":{"number":47,"relative_category":"blog/organization","fields":{"title":"マネジメントとは何か","excerpt":"組織が大きくなってくると自然と自らの手ではどうしようもできなくなり、マネジメント業務を各メンバーに委譲する必要が出てきます。そうは言っても個別のタスク指示はすんなり出来ても、「よしなにやって」つまり「周辺の整理（マネジメント）も含めて上手くタスクを回せるように調整して」と言う指示は一言では伝えきれません。マネジメント職同士のやりとりなら問題ないのですが、これからマネジメント領域に入っていって欲しいメンバーの場合はどう連携すれば良いのでしょうか。未完ではありますが、今回はマネジメントそのものについて整理しました。   > PROBLEMPROBLEM \n\n- チームメンバーにマネジメントを理解して欲しい けれど、マネジメントに関する書籍が多く、一言でこれを読めと伝えるのが難しい 一方、一言では言い表せないが、一目でなら表せるものが自分の中に出来上がっている 昔手にした書籍をヒントにマネジメントの枠組みというのを自分の頭に構築していた ただ、そのことについて書かれた書籍を見たことがない \n- けれど、マネジメントに関する書籍が多く、一言でこれを読めと伝えるのが難しい\n- 一方、一言では言い表せないが、一目でなら表せるものが自分の中に出来上がっている 昔手にした書籍をヒントにマネジメントの枠組みというのを自分の頭に構築していた ただ、そのことについて書かれた書籍を見たことがない \n- 昔手にした書籍をヒントにマネジメントの枠組みというのを自分の頭に構築していた ただ、そのことについて書かれた書籍を見たことがない \n- ただ、そのことについて書かれた書籍を見たことがない   > SOLUTIONSOLUTION \n\nというわけで、自分の頭の中に出来上がったマネジメントのフレームワークについて改めて整理することにしました。 \n\n私はそのフレームワークを「GRPR（グルーパー）マネジメントサイクル」と呼んでいます。GRPRはゴール（G）、リソース（R）、プロセス（P）、ルール（R）の頭文字の組み合わせです。私はこのGRPRを grouper（熱帯や温帯の海域に分布する魚のハタの意）の略字に見立てることで、マネジメントサイクルをハタの形に重ねて覚えています。下記がそのサイクルです。どうです、ハタに見えませんか? \n\n \n\nこのフレームワークはどの職種にも応用ができ、今までいくつかの職種の中でマネジメントを行ってきましたが、どれも無理なく実施できました。そして、これは各種マネジメント関連の書籍を整理する際の枠組みとしても使えます。この当たりを冗長に書こうとすると切りがないのでここでは完結に記す予定です。 \n\nでは、具体的に各要素を見ていきましょう。   > ゴールゴール \n\n計画と意思決定を行います。これはSMARTに則り戦略的かつ具体的に測定可能で達成可能、関連性のある期限あるものが良いです。下記のようなMBOで設定する目標が分かりやすい例です。 \n\n目標例 \n\n- デザインコーディネーション 組織パターン \n- 組織パターン\n- サービスカタログ   > 変化前のリソースとプロセス変化前のリソースとプロセス \n\nゴールを決めた後にその方向に動き出すための現状把握を行います。対象にはリソースとプロセスがありますが、それらは人も含みます。まずリソースについて、人の場合は意志の状態と価値観の確認を行い、人以外の場合は当該リソースのステータスを確認します。 \n\n- マインドフルネス、アンガーマネジメント、心理的安全性\n- キャリアアンカー \n\nプロセスについては各業務フロー、システムフローを確認します。 \n\n- CMMI   > 変化後のリソースとプロセス変化後のリソースとプロセス \n\n現状を把握した後に目指すべきリソースとプロセスが決まったらそちらに変更を促します。所謂 指示と動機付けを元にした「変更管理」を行います。これはリーダーシップという切り口で語られることが多いマネジメント領域です。   > ルールルール \n\n最後にリソースやプロセスの現状や変化を観察し評価します。この評価によってルールを定め、次のゴールへと段階を上げていきます。なお、ルールはリソースやプロセスに制限をかけるものではありますが、長期的に見た際に安全に業務を回すためのガードレールの役割を果たします。 \n\n例えば、ルールには下記のようなものがあります。 \n\n- 業務運用方針\n- 各パブリッククラウドのIAM設定・運用の方針\n- AWS Control Tower   > WRAPUPWRAPUP \n\n最低限の部分をまとめてみました。まずはメンバーからのフィードバックをもらいつつ今後も気になるところを追加していく予定です。"},"name":"マネジメントとは何か","tags":["team-building"],"childPublishedDate":{"published_on":"2021-03-31T22:39:35.000Z","published_on_unix":1617230375}}},{"node":{"number":75,"relative_category":"blog/backend","fields":{"title":"CDKで管理する今どきのJenkins","excerpt":"先日のAWS障害で管理していたECSに多少の影響が出たので、そのタイミングで敷設していたJenkinsの構成を改めて整理しました。今回は課題解決というより、既に稼働していたシステム構成の振り返りを行いました。   > PROBLEMPROBLEM \n\n- インフラ系タスクがコード管理されていないので属人化しやすい 可能なら当該タスクはインフラ担当から手離れして欲しい 当該タスクは通常のCIワークフローとは異なるので管理する場所がない そういう意味でJenkinsの出番だけどこれはこれで管理が手間 ヘルスチェックエラーにひっかかったら自動で再起動してほしい \n- 可能なら当該タスクはインフラ担当から手離れして欲しい\n- 当該タスクは通常のCIワークフローとは異なるので管理する場所がない そういう意味でJenkinsの出番だけどこれはこれで管理が手間 ヘルスチェックエラーにひっかかったら自動で再起動してほしい \n- そういう意味でJenkinsの出番だけどこれはこれで管理が手間 ヘルスチェックエラーにひっかかったら自動で再起動してほしい \n- ヘルスチェックエラーにひっかかったら自動で再起動してほしい   > SOLUTIONSOLUTION \n\nというわけで、モダンなJenkins2系をAWS CDKで敷設してみました。   > 1. 構成1. 構成 \n\n大方の構成は「nabinno/jenkins-cdk-on-ec2」のシステム構成図をご覧下さい。元ネタはaws-sampleになりますが、今回はAWS FargateではなくAmazon ECSを採用し、CDKはTypeScriptで実装しています。 \n\n使用技術スタック \n\n- Jenkins\n- Amazon ECS（Amazon EC2）\n- Application Load Balancer\n- Amazon EFS    > 2. CDKによるJenkinsの敷設2. CDKによるJenkinsの敷設 \n\nCDKによるJenkinsの敷設はGitHubレポジトリーを見ていただくとして、ここではCDKのコード上の注意点を2点ほど共有しておきます。   > 2-a. CDKの注意点：リソース名を明示する2-a. CDKの注意点：リソース名を明示する \n\nCDKで各リソース名を明示しないとCloudFormation（CFn）独特の命名規則でリソースが敷設されます。インフラ担当が自分一人の場合は良いですが、インフラ担当を増員する際は、他のIaCツールの運用方針とバッティングする等、後で足かせになるので命名規則にのっとりリソース名を付けていくようにしましょう。 \n\n命名規則は「クラスメソッドさんの記事」を参考に決めるのが定番のようです。下記例になります。    AWSリソース 命名規則     ELB {sysname}-{env}-alb/clb   TargetGroup {sysname}-{env}-tg   EC2 {sysname}-{env}-{type}   SecurityGroup {sysname}-{env}-{type}-sg    \n\nCDKでリソース名を明示するには次のいずれかの方法で対応します。 \n\n- 各クラスのコンストラクトプロパティにある名前を記述する\n- 暗黙的生成されるリソースを明示的に作成する \n\n下記コードでは暗黙的に生成されていたSecurity Groupを明示的に作成している様子等が見て取れます。   ts \n\n// ECS: Service const serviceSecGrp = new ec2.SecurityGroup(this, \"JenkinsMasterServiceSecGrp\", { securityGroupName: \"jenkins-production-master-sg\", vpc: network.vpc, allowAllOutbound: true, }); serviceSecGrp.addIngressRule(worker.workerSecurityGroup, ec2.Port.tcp(50000), \"from JenkinsWorkerSecurityGroup 50000\"); serviceSecGrp.addIngressRule(worker.workerSecurityGroup, ec2.Port.tcp(8080), \"from JenkinsWorkerSecurityGroup 8080\"); const jenkinsMasterService = new ecs.Ec2Service(this, \"EC2MasterService\", { serviceName: 'jenkins-production-master-svc', taskDefinition: jenkinsMasterTask, cloudMapOptions: { name: \"master\", dnsRecordType: sd.DnsRecordType.A }, desiredCount: 1, minHealthyPercent: 0, maxHealthyPercent: 100, enableECSManagedTags: true, cluster: ecsCluster.cluster, securityGroups: [serviceSecGrp] });   \n\nなお、リソース名の明示化について、もちろんCDKのクラスによっては暗黙的なリソースを含んでおり当該リソースに名前を付けることが出来ないケースはあります。今回のケースで言うと、例えば、ECSクラスター（EC2）のIAM RoleやSecurity Group。その場合は、インフラのCDK運用方針としてドキュメントに残しておく等しておくと良いでしょう。   > 2-b. CDKの注意点：cdk.RemovablePolicy.RETAINをつける2-b. CDKの注意点：cdk.RemovablePolicy.RETAINをつける \n\nネットワーク、ストレージ関連のリソースを扱う場合、削除されるとリソース構成が破綻する可能性があるのでcdk.RemovablePolicy.RETAIN、CFnの言うところの \"DeletionPolicy\": \"Retain\" をつけましょう。今回はEFSがその対象になります。   ts \n\nconst efsFilesystem = new efs.CfnFileSystem(this, \"EFSBackend\"); efsFilesystem.applyRemovalPolicy(cdk.RemovalPolicy.RETAIN);   \n\n個人的にはRETAINをつけるとcdk destroy cdk deployを気軽に行えなくなるので、RETAINをつけるならCDK/CFnからはARNで参照する程度に抑えた方が良いと思っています。   > 3. Jenkinsの設定を行う3. Jenkinsの設定を行う \n\nCDKでJenkinsを敷設した終わったらJenkinsの設定を行いましょう。   > 3-a. Jenkinsでつかっているプラグイン3-a. Jenkinsでつかっているプラグイン \n\n昔と違って今のJenkinsは下記プラグインがあれば十分運用できます。 \n\n- github-oauth\n- role-strategy\n- configuration-as-code\n- blueocean \n\nざっと説明するとgithub-oauthでGitHub認証させ、role-strategyでロールごとの権限付与を行い、configuration-as-codeでそれらの管理設定をコード化します。configuration-as-codeは素晴らしく設定情報をコード化することでdockerイメージに当該設定情報を反映させることが出来ます。また、blueoceanはモダンなインターフェイスでジョブ実行します。こちらは次のセクションで詳細を説明します。 \n\nなお、プラグイン管理はIaC化でき下記のようにdockerイメージに反映できます。   sh \n\n$ cat plugins.txt role-strategy:3.1 github-oauth:0.33 thinBackup:1.10 git:4.6.0 authorize-project:1.3.0 configuration-as-code:1.47 blueocean:1.24.4 $ cat Dockerfile [...] COPY plugins.txt /usr/share/jenkins/ref/plugins.txt RUN /usr/local/bin/install-plugins.sh < /usr/share/jenkins/ref/plugins.txt [...]     > 3-b. JenkinsジョブをGitHubで管理する3-b. JenkinsジョブをGitHubで管理する \n\nいよいよJenkinsでジョブの管理設定を行います。具体的には下記手順で実施します。手順が完了すると作ったブランチ分だけJenkinsにジョブが追加されます、とても簡単です。 \n\n1. ジョブを管理させたいGitHubレポジトリでジョブ管理用のブランチを作成し、Jenkinsfile を配置\n2. 「Jenkins - Blue Ocean - New Pipeline」にて下記設定をおこなう Where do you store your code? - GitHub Which organization does the repository belong to? - 任意のuserあるいはorganization Choose a repository - 任意のレポジトリ（1で作成したレポジトリ） \n3. Where do you store your code? - GitHub\n4. Which organization does the repository belong to? - 任意のuserあるいはorganization\n5. Choose a repository - 任意のレポジトリ（1で作成したレポジトリ） \n\nJenkinsfile の作成方法は「ユーザーハンドブック」にありますが、下記例のように直感的に記述することが出来ます。環境変数は「Jenkins - {{レポジトリ}} - 認証情報 - Stores scoped to {{レポジトリ}} - global - Add credential」から追加します。   Jenkinsfile \n\n pipeline { agent any stages { stage('Show env') { steps { sh '''mysql --version ls -al bin env | sort''' } } stage('Run script') { steps { git(url: 'https://github.com/nabinno/jenkins-jobs', branch: 'master', credentialsId: 'github') sh '''git diff sync-db-from-staging-to-integration | patch -p1 -R -f bin/sync_db_from_staging_to_integration''' } } } environment { STAG_DB_DATABASE = credentials('STAG_DB_DATABASE') STAG_DB_HOSTNAME = credentials('STAG_DB_HOSTNAME') STAG_DB_PASSWORD = credentials('STAG_DB_PASSWORD') STAG_DB_USERNAME = credentials('STAG_DB_USERNAME') INTEG_DB_HOSTNAME = credentials('INTEG_DB_HOSTNAME') INTEG_DB_PASSWORD = credentials('INTEG_DB_PASSWORD') INTEG_DB_USERNAME = credentials('INTEG_DB_USERNAME') INTEG_DB_DATABASE = credentials('INTEG_DB_USERNAME') } }     > WRAPUPWRAPUP \n\n今回の振り返りで、2点気づきを得られました。CDKのリソース名の扱いに困っていたのですが、どうにか制御できそうなのでまたしばらくは付き合っていくことになりそうです。 \n\n1. CDKは意外とかゆいところに手が届く。ただ、暗黙的に生成され、CDK側で制御できないリソース名があるので、そういう前提で運用ポリシーを作ると各IaC使いの平穏に繋がる。\n2. Jenkins2は思った以上に手離れが良い。CDK、ECS、EFS、configuration-as-code、Jenkinsfileの組み合わせは保守性、可用性に大きな貢献をしている。"},"name":"CDKで管理する今どきのJenkins","tags":["aws-cdk","jenkins","amazon-ecs"],"childPublishedDate":{"published_on":"2021-02-24T02:04:50.000Z","published_on_unix":1614132290}}},{"node":{"number":68,"relative_category":"blog/organization","fields":{"title":"飲み会に参加するための機材","excerpt":"以前チーム内でリモート懇親会を画策したのですが、食材の調達や経費精算など手間が多すぎて断念しました。ただ、その言い訳は実は本質的ではなく、実際に後ろ向きにさせていたのは「しゃべりながら食べるのがつらい」ということにありました。今回はそれを解決した機材を紹介します。   > PROBLEMPROBLEM \n\n- リモート飲みがつらい 何がつらいって、ヘッドホンをしながら飯を食べるのがつらい 有線ヘッドホンだとPCの前に張り付きになりつらい 無線ヘッドホンだと音声が悪すぎて相手のメッセージが聞き取りづらい というか、有線だろうが無線だろうが直接PCにつなげると少量のノイズが乗る場合がありつらい 音声が悪すぎて相手にメッセージが伝わらない 「えっ、今なんて言ったの?」という会話を何度も繰り返す様がいたたまれない 自分の顔を相手に見せつけるのが気持ち的にいたたまれない アバターはPCリソースを消費する上、アバターに気を使うのは飲み会の意義から少しずれている 最初は楽しいがすぐ飽きる \n- 何がつらいって、ヘッドホンをしながら飯を食べるのがつらい 有線ヘッドホンだとPCの前に張り付きになりつらい 無線ヘッドホンだと音声が悪すぎて相手のメッセージが聞き取りづらい というか、有線だろうが無線だろうが直接PCにつなげると少量のノイズが乗る場合がありつらい \n- 有線ヘッドホンだとPCの前に張り付きになりつらい\n- 無線ヘッドホンだと音声が悪すぎて相手のメッセージが聞き取りづらい\n- というか、有線だろうが無線だろうが直接PCにつなげると少量のノイズが乗る場合がありつらい\n- 音声が悪すぎて相手にメッセージが伝わらない\n- 「えっ、今なんて言ったの?」という会話を何度も繰り返す様がいたたまれない\n- 自分の顔を相手に見せつけるのが気持ち的にいたたまれない アバターはPCリソースを消費する上、アバターに気を使うのは飲み会の意義から少しずれている 最初は楽しいがすぐ飽きる \n- アバターはPCリソースを消費する上、アバターに気を使うのは飲み会の意義から少しずれている 最初は楽しいがすぐ飽きる \n- 最初は楽しいがすぐ飽きる   > SOLUTIONSOLUTION \n\nというわけで、自分がこの1年試行錯誤した末に辿り着いた飲み会参加の機材スタックを共有します。   > オーディオインターフェイスオーディオインターフェイス \n\nオーディオインターフェイスはマイクやギターの音をパソコンに取り込むアナログ・デジタル変換と、取り込んだ音を再生するデジタル・アナログ変換の機能を提供します。 \n\nボイスメモ程度なら必要ないですが、フルリモートで頻繁に会議をしている機会が多いと音質とレイテンシーに多分な影響を与えます。オーディオインターフェイスがない場合、入力時にノイズが乗ったり、出力時に音質が劣化します。また、レイテンシーがひどくなったり音がゆがんだり、下手をするとPCに負荷がかかりフリーズします... \n\n会議を頻繁にする人はとりあえず手に入れたい機材。Steinberg UR22Cが人気です。 \n\n- Steinberg UR22C   > マイクマイク \n\n演説やスピーチ用にダイナミックマイクが使われていますが、オンラインミーティングで使う場合は聞き取りづらいので、何はともあれコンデンサーマイクを使うべきです。 \n\nコンデンサーマイクと言っても、いろいろあります。特にマイクの振動板（ダイアフラム）が大型か小型かで音質の印象が変わるので注意が必要です。私は下記の表のように利用シーンごとに使い分けています。    - 説明 利用シーン     スモールダイアフラム 現実主義。色のない、ニュートラルな音色を提供 ファシリテート   ラージダイアフラム 浪漫主義。音源をより大きく、愛らしいものに変換 発表、音楽活動    \n\nなお、HHKB等の打鍵音が大きいキーボードを利用している方や仕事スペースと家庭スペースとの距離が近い方は、いずれにしてもスモールダイアフラムがお薦めです。スモールダイアフラムはマイクから口元を少しでもずらすと音が入力されずらくなくなるため、期待した音質を提供することが出来ます。 \n\n製品としてはShure Beta87Aが人気です。また、購入する際はマイクスタンドとマイクスポンジもセットで検討すると良いです。マイクの位置を固定し風よけを設置した方が安定した音質に繋がります。 \n\n- Shure Beta87A   > ヘッドホンヘッドホン \n\n食事を取りながら相手の話を聞くには通常のヘッドホンだと食べ物を咀嚼するのに苦労します。口を開けたり閉めたりする際、顎とともにヘッドホンが上下に動くため相手の声が聞き取りづらくなります。 \n\n耳の穴に接しない骨伝導ヘッドホンは、食べ物を咀嚼する際の顎の動きに左右されることがないです。テレワークのヘッドホン多用が外耳炎を引き起こしているという話もあるので、そういう意味で骨伝導ヘッドホンは健康を保つ上でも重要な機材となります。 \n\nまた、使用していて分かったのですが、普段の食事の中でも使うことが出来るので、隙間時間に気軽にメディアに接しやすくなります。例えば、家族と一緒の部屋にいる中、食事を取りながらAWSのWebinarを聞くことができます。 \n\n製品としては業界を牽引しているAfterShokzのAeropexが人気です。今回はオーディオインターフェイスを利用しているので、音質をさらに高めるためにトランスリミッターと組み合わせましょう。 \n\n- AfterShokz Aeropex\n- トランスリミッター TaoTronics aptX-LL   > ビデオビデオ \n\nソーシャルメディアでよく登場するビデオ画像は、表情アップの図（ず）が前面に押し出された絵が一般的ですが、地（じ）の表現が薄く解釈余地がないものが多いです。表情が豊かな方は良いのですが、全員がそういうわけではないので地（じ）の生活の部分に焦点を当てた方が実態に合っています。 \n\n例えば、対面での会話の中では身につけている服装や持ち物等のアトリビュートに焦点が当たりますよね。「その身につけているアクセサリーは何?」「机の上に置いてあるその本、面白そうだね」という会話を思い出してください。 \n\nそういう意味で広角レンズを搭載したアクションカムは望ましい選択です。今時のアクションカムは高解像で鮮やかに表現してくれますし、外にいなくても部屋の中で十分面白い絵になります。 \n\nアクションカムは何でも良いのですが、私は普段「撮れラン」で使っているSony HDR-AS3000をミーティングの際に使っています。 \n\n- Sony HDR-AS3000   > WRAPUPWRAPUP \n\n今回紹介した機材に出会うまで紆余曲折ありましたが、揃えてみて満足しています。 \n\n飲み会でなくても良いですが、機材を揃えた方でいろいろ試してみたい方は一緒に雑談してみませんか。30分雑談会というのを開催しているので、いつでもお気軽にお声がけください。"},"name":"飲み会に参加するための機材","tags":["drinkup","team-building"],"childPublishedDate":{"published_on":"2021-01-30T03:02:00.000Z","published_on_unix":1611975720}}},{"node":{"number":67,"relative_category":"blog/frontend","fields":{"title":"esaをHeadless CMSとして使う","excerpt":"最近仕事の同僚からHeadless CMS という言葉を聞いていて「自分には関係ないな」と距離を取っていたのですが、なぜか回り回って自分からHeadless CMSを作ることになりました。世の中何が起きるか分からないですね。   > PROBLEMPROBLEM \n\n- ブログを普段書かない人なのだが、よそ向けに情報発信する必要が出てきた とは言っても、今までMarkdownをJekyllで管理していたので画像を貼り付けるのが手間でモチベーションが大きく下がっていた さらにPlantUMLを出力するのも手間、試行錯誤した末にいずれも付け焼き刃で、esaの操作感に勝てるものはなかった \n- とは言っても、今までMarkdownをJekyllで管理していたので画像を貼り付けるのが手間でモチベーションが大きく下がっていた さらにPlantUMLを出力するのも手間、試行錯誤した末にいずれも付け焼き刃で、esaの操作感に勝てるものはなかった \n- さらにPlantUMLを出力するのも手間、試行錯誤した末にいずれも付け焼き刃で、esaの操作感に勝てるものはなかった   > SOLUTIONSOLUTION \n\nというわけで、esaをHeadless CMSとして使うことにしました。 \n\nやってることは昔のMovableTypeそのもので懐かしかったです。コンテンツを別システムで管理しビルドサーバーに当該コンテンツを流し込みリビルド、最後にホストサーバーにアップロードというワークフロー。今はJAMStackの文脈で語られているようです。 \n\nこのHeadless CMSが昔と違うのはコンテンツ作成に集中できること。CI周りが発達したので一度ワークフローを組み立てれば後は自動でコンテンツを生成できます。   > やり方やり方 \n\n- esa.io でゆるふわ情報共有 - Middleman Blog への Export サンプル付き #esa_io - Qiita\n- 技術ブログを支える技術（Gatsby + esaio） - mottox2 blog\n- Next.jsとesaを使った個人サイト構築 | corocn.dev \n\nそれほど時間をかけられなかったので、上記3記事の中で手軽さを考慮しmottox2さんのソースコードを拝借しました。ありがとうございます。 \n\n- 作ったレポジトリ：nabinno/nabinno.github.io: On Blahfe - Nab's Github Pages    > シークエンス図シークエンス図 \n\n私が手を入れたのはコンポーネントを削りGatsby Blog Starterに寄せたのと、デプロイ方法を使い慣れたCircleCIに変えたくらいです。 \n\nGitHub PagesにはVercelのような便利なWebhookがないので、esaで実装されたGitHub Webhook連携を使いそれをトリガーにCircleCIジョブを走らせています。 \n\n   > CircleCIジョブCircleCIジョブ \n\nまた、CircleCIジョブは何の変哲もないもので、NodeJSを叩いてGitプッシュしているくらいです。先ほどのGitHub Webhookと似た感じの泥臭いワークフローは [skip ci] コメントの追加があります。当該コメントを入れないとジョブが再帰的に走り続けるので出口で明示してあります。   yml \n\nversion: 2.1 jobs: build_deploy: docker: - image: circleci/node:12.4 steps: - checkout - run: name: Install NPM command: npm install - run: name: Build command: npm run clean && npm run build - add_ssh_keys: fingerprints: - \"{foo}\" - deploy: name: Deploy command: | git config --global user.email \"nab+circleci@blahfe.com\" git config --global user.name \"nabinno+circleci\" git add . git commit -m \"[skip ci]Run npm run clean && npm run build.\" git push origin master workflows: build_deploy: jobs: - build_deploy: filters: branches: only: master     > WRAPUPWRAPUP \n\nとまあ大した作業内容ではないのですが、久しぶりに昔懐かしのMovableTypeのリビルドを思い出しつつ、副産物として全く縁遠かったNetlifyとVercelの位置づけを薄らと感じ取れました。"},"name":"[2021-01-18]esaをHeadless CMSとして使う","tags":["gatsby","esa","headless-cms","cms"],"childPublishedDate":{"published_on":"2021-01-18T00:00:00.000Z","published_on_unix":1610928000}}},{"node":{"fields":{"title":"ネクイノ開発者ブログ：整理したい私はITILをかぶる、PlantUMLへの愛","excerpt":"入社後8ヶ月、年の瀬ということで振り返り記事を書くことにしました。テーマはPlantUMLです。","category":"blog/organization"},"childPublishedDate":{"published_on":"2020-12-30T11:30:00.000Z","published_on_unix":1609327800},"link":"https://nextinnovation-tec.hatenablog.com/entry/plantuml-to-itil"}},{"node":{"number":64,"relative_category":"blog/backend","fields":{"title":"WSL2時代のDocker開発スタイル","excerpt":"6月13日は狂喜乱舞しました、久しぶりに徹夜するくらい興奮しました。そう、WSL2が出たのですよね。先日やっと私の手元に届いたので早々に検証しました。   > PROBLEMPROBLEM \n\n- あたらしくでたWSL2によって以前書いた記事からだいぶ状況が変わった 主な変更点 WSLのアーキテクチャが2種類になり、WSLはその2つのアーキテクチャを管理する機能に変わった WSL1 Windows Subsystem for Linux上のLinux (LXCore/Lxss) WSL2 軽量Hyper-V上のLinux (Linux Kernel) /procや/sysなどの特殊ファイルもふくめた共有プロトコル「9P」が実装された Win32側の9Pクライアント 9prdr.sys WSL側の9Pクライアント /init \n- 主な変更点 WSLのアーキテクチャが2種類になり、WSLはその2つのアーキテクチャを管理する機能に変わった WSL1 Windows Subsystem for Linux上のLinux (LXCore/Lxss) WSL2 軽量Hyper-V上のLinux (Linux Kernel) /procや/sysなどの特殊ファイルもふくめた共有プロトコル「9P」が実装された Win32側の9Pクライアント 9prdr.sys WSL側の9Pクライアント /init \n- WSLのアーキテクチャが2種類になり、WSLはその2つのアーキテクチャを管理する機能に変わった WSL1 Windows Subsystem for Linux上のLinux (LXCore/Lxss) WSL2 軽量Hyper-V上のLinux (Linux Kernel) \n- WSL1 Windows Subsystem for Linux上のLinux (LXCore/Lxss)\n- WSL2 軽量Hyper-V上のLinux (Linux Kernel)\n- /procや/sysなどの特殊ファイルもふくめた共有プロトコル「9P」が実装された Win32側の9Pクライアント 9prdr.sys WSL側の9Pクライアント /init \n- Win32側の9Pクライアント 9prdr.sys \n- WSL側の9Pクライアント /init    > SOLUTIONSOLUTION \n\nというわけで、前記事で掲げていた目標「WSLでDockerをつかったWebアプリケーション開発ができるかどうか」について再確認します。   > 対象環境対象環境 \n\n- Windows 10 Pro Version 1903 OS Build 18922.1000 Windows Terminal (Preview) Version 0.2.1715.0 WSL2 Ubuntu Version 1804.2019.5210 (Linux 4.19.43-microsoft-standard) Docker version 19.03.0-rc3, build 27fcb77 WSL1 Ubuntu 18.04 LTS Version 1804.2019.522.0 (Linux 4.4.0-18922-Microsoft) \n- Windows Terminal (Preview) Version 0.2.1715.0\n- WSL2 Ubuntu Version 1804.2019.5210 (Linux 4.19.43-microsoft-standard) Docker version 19.03.0-rc3, build 27fcb77 \n- Ubuntu Version 1804.2019.5210 (Linux 4.19.43-microsoft-standard)\n- Docker version 19.03.0-rc3, build 27fcb77\n- WSL1 Ubuntu 18.04 LTS Version 1804.2019.522.0 (Linux 4.4.0-18922-Microsoft) \n- Ubuntu 18.04 LTS Version 1804.2019.522.0 (Linux 4.4.0-18922-Microsoft)   > Windowsの開発環境を構築するWindowsの開発環境を構築する \n\nまず、Windowsの開発環境の構築ですが、既知の情報をふまえつつTIPSを順次紹介します。   > WSLのインストールWSLのインストール \n\n- WSL2を使ってみる (InsiderPreview) \n\nWSLのパッケージ管理は下記2つを押さえておけば問題ないでしょう。 \n\n1. asdf/anyenv プログラミング言語をバージョンごとにわけて使いたい場合はこちらをつかいましょう 関数言語界隈ではasdfが主流になってきてるようです。 \n2. プログラミング言語をバージョンごとにわけて使いたい場合はこちらをつかいましょう\n3. 関数言語界隈ではasdfが主流になってきてるようです。\n4. nix Haskellのようにasdf/anyenvでインストールできない、あるいは、扱われいないパッケージはnixをつかいましょう また、aptのバージョンが古すぎるパッケージもnixが最適です \n5. Haskellのようにasdf/anyenvでインストールできない、あるいは、扱われいないパッケージはnixをつかいましょう\n6. また、aptのバージョンが古すぎるパッケージもnixが最適です   > ターミナルのインストールターミナルのインストール \n\nWSLttyはWSL2に対応しておらずConEmuは描画がくずれやすいため、デフォルトのターミナルかWindows Terminalが選択肢となります。 \n\nWindows TerminalとConEmuとの比較    - Windows Terminal ConEmu     透過対象 backgroundImage ConEmu自体   キーバインド制約 Alt+Shiftが効かない 特になし   WSL2の描画 特になし くずれる   管理者権限で実行 初回のみ タスク実行ごと      > DockerのインストールDockerのインストール \n\nWSL1ではDockerデーモンがつかえないのでWSL2でDockerをつかうようにしましょう。Docker CEをインストールします。 \n\nどうしてもWSL1でということであれば、Win32 (WSL1からみるとdrvfs) 側でDocker For Windowsを用意します。インストールはDockerのダウンロードページから手順通りおこないます。\n 構成等は前回の記事を参照ください。   > さて、WSL2からDockerはどの程度つかえるのかさて、WSL2からDockerはどの程度つかえるのか \n\nWSL2は軽量Hyper-V上にLinuxコンテナを動かしているので、基本Hyper-Vと同様にDockerをつかうことができます。 \n\nただし、WSL1と違いlocalhostにWSL2がバインドできません (2019-07-27追記: Build Version 18945で解決しました )。\n また、WSL1と同様にWin32・WSL間でのファイルの読み書きにパフォーマンスの差が大きく出ています。 \n\nひとつずつ解決方法を見ていきましょう。   > 1. WSL1と違いlocalhostにWSL2がバインドできません1. WSL1と違いlocalhostにWSL2がバインドできません \n\nWSL2がつかっているVirtual Switchはinternal onlyのため、Win32側からlocalhostをつかってWSL2にアクセスすることができません。現在対応中のようです (2019-07-27追記: Build Version 18945で解決しました )。 \n\n対処方法は2つあります。 \n\na. WSL1をつかう \n\nこれが一番楽ですが、WSL1は次項であげるパフォーマンス上の欠点があるので、Web系フロントエンド開発におけるライブリローディング機能をつかうケースに限定するといいでしょう。 \n\nb. Hostsファイルをつかう \n\nWin32のHostsファイルでWSL2のeth0インターフェイスのIPアドレスに適当なホスト名を割り当てます（ポートごとにホストを振り分けたい場合はWSL2側にProxyを用意するといいでしょう）。   shell \n\n# C:\\Windows\\System32\\drivers\\etc\\hosts 172.17.72.217 dashboard.local.me   \n\nWSL2のIPアドレスはコンテナを立ち上げるごとに変わるので、下記のようなコマンドレットをWin32側のPowerShell $PROFILEに用意しておくといいでしょう。WSL2だけで完結したい方はシェル上から powershell.exe -Command 'Sync-HostsToWslIp' と打つだけです。   powershell \n\n# $PROFILE function Sync-HostsToWslIp { $hosts = \"$env:SystemRoot\\System32\\drivers\\etc\\hosts\"; $pattern = \"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\"; $wslip = bash.exe -c \"ifconfig eth0 | grep 'inet '\"; if ($wslip -match $pattern) { $wslip = $matches[0]; } else { echo \"The Script Exited, the ip address of WSL 2 cannot be found\"; exit; } cat $hosts | %{ $_ -match $pattern } $rc = cat $hosts | %{ $_ -replace $matches[0], $wslip } $rc | Out-File $hosts; }     > 2. WSL1と同様にWin32・WSL間でのファイルの読み書きにパフォーマンスの差が大きく出ています2. WSL1と同様にWin32・WSL間でのファイルの読み書きにパフォーマンスの差が大きく出ています \n\nいろんな方がベンチマークを公開してるのでそれを参考にするといいでしょう。 \n\nCf. \n\n- Pythonでファイル操作のベンチマーク\n- dd、git cloneのベンチマーク \n\nわたしは git status -sb をよくつかうので、そのコマンドで簡単なベンチマークとりました。   shell \n\n# WSLx $ cd ~/nabinno.github.io $ \\time -f %e git status -sb # Win32/WSLx $ cd ~/nabinno.github.io $ \\time -f %e powershell.exe -Command 'git status -sb' # Win32 PS> cd ~/nabinno.github.io PS> (Measure-Command { git status -sb }).TotalMilliseconds / 1000 | %{ [math]::Round($_, 2) }      Subject WSL Win32     WSL1 0.47 0.09   WSL2 0.00 0.61   Win32/WSL1 2.66 1.91   Win32/WSL2 2.81 1.79   Win32 0.51 0.12      > Docker以外でWSLの課題はないのかDocker以外でWSLの課題はないのか   > デバイスへのアクセスデバイスへのアクセス \n\n以前から要望があったものだと「デバイスアクセスができない」件があります。 \n\n9P導入前だとこれはElixirのIoTフレームワークNervesのように、WSL UtilitiesでWSLパスをWin32パスに変換してからWin32にあるデバイス関連ツールをつかうのが簡単な解決策でした。   sh \n\n$ fwup.exe -a -i $(wslpath -w -a _build/rpi0_dev/nerves/images/hello_nerves.fw) -t complete -d $(fwup.exe -D | sed 's/,.*//')   \n\nただし9Pを導入したWindows 10 Version 1903以降は、WSL1もWSL2もともにWSLパスを変換せずにWin32にあるデバイス関連ツールをつかうことができます。   sh \n\n$ fwup.exe -a -i _build/rpi0_dev/nerves/images/hello_nerves.fw -t complete -d $(fwup.exe -D | sed 's/,.*//')     > WRAPUPWRAPUP \n\nわたしの観測範囲では課題はほぼ問題ない状態になっていました。 \n\nおすすめ開発環境は下記のとおり    item content     IDE WSLx上のエディタ   Webフロントエンド開発 WSL1   Docker関連開発 WSL2   dotfiles WSLx、Win32を共有管理    \n\nWin32側のIDEをつかっているユーザーはパフォーマンス上の不満がまだあるかもしれませんが、WSLでDockerをつかったWebアプリケーション開発は十分できる、と言えそうです。つまり、Linux・macOS・WindowsによるWebアプリケーション開発は十分共有できる、と。 \n\nいい時代になりました。"},"name":"[2019-07-06]WSL2時代のDocker開発スタイル","tags":["wsl","wsl2","ubuntu"],"childPublishedDate":{"published_on":"2019-07-06T00:00:00.000Z","published_on_unix":1562371200}}},{"node":{"number":63,"relative_category":"blog/frontend","fields":{"title":"イケてるしヤバい言語REBOLの後継Redでクライアントソフトをつくった話","excerpt":"Redという言語はご存じでしょうか。可読性が高いシンタックスを持ち、ワンバイナリーをクロスコンパイルでき、かつ、クライアント用のUIコンポーネントを標準ライブラリに備えたプログラミング言語です。その野心的な挑戦にすぐに虜になりました。新年早々の恋です。   > PROBLEMPROBLEM \n\n- クロスプラットフォーム用のクライアントソフトをつくるにあたり 重たいフレームワークが多い 汎用的な言語をつかってるものが多く、そのためライブラリー等の依存関係が多くなりやすい \n- 重たいフレームワークが多い\n- 汎用的な言語をつかってるものが多く、そのためライブラリー等の依存関係が多くなりやすい   > SOLUTIONSOLUTION \n\nというわけで、年明け見つけたRedがシンプルだったので使ってみました。題材は以前つくったEmacsライブラリ「esa.el」の移植です。 \n\n- 今回作ったコード https://github.com/nabinno/esa.red    > やったことやったこと   > エディターエディター \n\n構文がすなおなので特にエディタは関係なさそうでしたが、慣れ親しんでるEmacsに「Skrylar/red.el」を適用しました。その際、 red-font-lock-keywords と red-indent-line に足りない箇所があったのでオーバーライドしました。   > 糖衣構文の適用糖衣構文の適用 \n\nRedはコマンドラインREPLがつかえるので、 docs.red-lang.org とRed by Exampleをみながらひとつひとつ挙動を確認しました。その中でどうしても慣れない表現が2つあったので糖衣構文を実装しました。 \n\n- 実装した糖衣構文 nabinno/red-elixir  \n\n1. compose \n\nブロック内の変数を評価しブロックとして返す関数 compose は、VIDのフェイス更新によく使われます。HTML/JavaScripでいうところDOM更新にあたるものといえば分かるでしょうか。頻繁に「 compose [foo (bar)] 」のような表現がつづくとほかの変数や関数とまざり可読性がおちるので、Elixirのシジルを参考に compose 関数を省略しました。こんな感じです。 \n\n;-- before compose [foo (bar)] ;-- after ~c[foo (bar)]  \n\n2. 関数の入れ子 \n\n素のRedはイテレーター構文なので、関数の入れ子による可読性低下をおさえるため変数定義をよく使います。個人的には変数は意味のあるものだけ使いたい派なので、パイプを導入しました。といっても、フロントエンドの場合、データ加工はあまりやらないのでつかうケースはほぼありませんでした。あってもこのくらいです。   red \n\n;-- before rejoin collect [ foreach d data [ keep rejoin [d \" \"] ] ] ;-- after data .[ |> Series/map 'd [rejoin [d \" \"]] |> rejoin ]     > タスクランナーの用意タスクランナーの用意 \n\n今回は上で実装したライブラリ「red-elixir」のほかにHTTPリクエスト・JSONパーサーライブラリを使っています。ライブラリパッケージはインストールはgit submodulesで良いですが、呼び出しも考えると実装が冗長的になるのでパッケージ管理とタスクランナーをあわせて用意しました（nabinno/hot、nabinno/mods）。 \n\nタスクランナーインストール後、パッケージのインストールから呼び出しまでの流れ \n\nRedはGoとおなじくワンバイナリーなので、wgetやcurlだけでインストールが完了します。   sh \n\n> mkdir -p ~/.local/bin > wget https://github.com/nabinno/hot/releases/download/0.0.3/hot-linux -O ~/.local/bin/hot > chmod 744 ~/.local/bin/hot   \n\nパッケージ管理はElixirのmixを参考にタスクランナー管理ファイル内に定義します。   sh \n\n> hot cmd/install https://raw.githubusercontent.com/nabinno/mods/master/mods.red > cat hots.red Red [] hots: context [ mods: [ red-elixir #(init: %init.red git: https://github.com/nabinno/red-elixir) json #(init: %json.red git: https://github.com/rebolek/red-tools) http-tools #(init: %http-tools.red git: https://github.com/rebolek/red-tools) ] ] > hot mods/get   \n\nビルド時は #include をつかうのでパッケージ呼び出し機能は使えないですが、コマンドラインREPLで挙動確認している際は do/args %require を使います。   sh \n\n> red >> do/args %require [red-elixir] >> 1 .. 10 .[ |> Series/map 'i [i * 2] |> Series/map 'i [i + 1] ] == [3 5 7 9 11 13 15 17 19 21]     > WRAPUPWRAPUP \n\nクライアントソフトを作る中で感じたことは、この1点です。Redは既存のフレームワークと比べるとまだまだ機能不足感が拭えませんが、それを補えるだけの表現力を持っていました。手触りが本当に良い言語でした。"},"name":"[2019-03-31]イケてるしヤバい言語REBOLの後継Redでクライアントソフトをつくった話","tags":["red","esa"],"childPublishedDate":{"published_on":"2019-03-31T00:00:00.000Z","published_on_unix":1553990400}}},{"node":{"number":62,"relative_category":"blog/backend","fields":{"title":"Elixirではてなブックマーク","excerpt":"紆余曲折合ってはてなブックマークの運用を見直す必要が出てきました。人の興味というのは尽きないもので知りたいことが次々出てきます。にも拘わらず人の時間は有限でそれにあがなうための手段を考えたわけです。   > PROBLEMPROBLEM \n\n- フィードリーダーで記事を読んだ後にはてなブックマーク（ブクマ）するとフィード消化するのに時間がかかる フィードをそのままブクマしていると下記の問題がでてくる あとで確認することができない 読みたくない記事をブクマしてしまう 適切でないURLでブクマしてしまう \n- フィードをそのままブクマしていると下記の問題がでてくる あとで確認することができない 読みたくない記事をブクマしてしまう 適切でないURLでブクマしてしまう \n- あとで確認することができない\n- 読みたくない記事をブクマしてしまう\n- 適切でないURLでブクマしてしまう   > SOLUTIONSOLUTION \n\nというわけで、下記の方針でブクマすることにしました。設置方法の詳細はGitHubレポジトリを参照ください。そして、方針は下記の通りになります。 \n\n方針 \n\n- フィードごとにタグづけする\n- ブクマ対象になる記事をリンクとタイトルで除外判定する\n- ブクマ対象になる記事をリンクから校正すべきものかリダイレクトすべきものか判定する\n- 上記設定はYAMLファイルで簡単に管理できるようにする\n- フィード読込とブクマを非同期処理できるようElixirで実装する   > ブクマの管理方法ブクマの管理方法 \n\nまずブクマの管理ですが、下記5つのYAMLファイルで構成しています、構造はマップとリストのみ。ブクマしたいと思う記事を読みすすめる中で気になるキーワードが出てきたら都度 feed.yaml を更新します。また、記事にノイズが多いようだったら傾向を分析して除外ファイル feed_excluded_link.yaml feed_excluded_title.yaml を更新します。    item description     feed.yaml フィードグループ名に対するリンク、タグのマップ   feed_excluded_link.yaml 除外すべきフィードリンクのリスト   feed_excluded_title.yaml 除外すべきフィードタイトルのリスト   feed_corrected_link.yaml フィードリンクに対するトリミングすべきパラメータのマップ   feed_redirected_link.yaml フィードリンクに対するリダイレクト先リンクのマップ      yaml \n\n# feed.yaml nabinno/sports/feed_group_name: tags: - ski links: - http://rss.example.com/ski_feed.rss - http://rss.example.com/snowboard_feed.rss - http://ski-status.example.com/rss # feed_excluded_link.yaml - anti-ski.example.com - awesome-snowboard.example.com # feed_excluded_title.yaml - queer - two-planker - beaver-tail # feed_corrected_link.yaml amazon.com: - ref - ie # feed_redirected_link.yaml ski-status.example.com: - Floki.find(fst, \".post__body a\")     > Elixirによる非同期処理Elixirによる非同期処理 \n\nElixirで非同期処理を行っているのですが、大きく分けて監視機構のSupervisorと非同期処理のTask.async_streamを使っています。   > 監視機構 Supervisor監視機構 Supervisor \n\nまず、Supervisor。Elixirには監視機構Supervisorがあり、それが各ワーカーを子プロセスとして管理しています。ここではフィード読込とブクマは別々のワーカーで処理しますが、キャッシュが暖気処理を別ワーカーで行っているため再起動戦略は「失敗したイベントの中にあるすべての子プロセスを再起動」（ one_for_all ）にしてあります。再起動戦略の詳細は「OTPスーパバイザ · Elixir School」を参照下さい。 \n\n下記のように Supervisor.start_link を Keshikimi2.Application.start に適用すると、アプリケーション開始（ mix run ）した時点で監視機構が起動されます。   ex \n\nSupervisor.start_link( [ :hackney_pool.child_spec(:hatena_bookmark_pool, timeout: 15_000, max_connections: 100), # @todo 当該ワーカーで暖気処理を行っていないので `one_for_one` にした場合、再起動時にほかに影響する supervisor(Cachex, [:feed, []]), supervisor(Keshikimi2Feed.Registry, [prefix]), # フィード読込処理 (PubSub) supervisor(Keshikimi2Feed.Subscriber, [prefix]), worker(Keshikimi2Feed.Worker, [prefix]), worker(Keshikimi2Feed.Publisher, [[prefix: prefix, poll_interval: 3_000]]), # ブクマ処理 worker(Keshikimi2.HatenaBookmark.AddEntry, [ [prefix: prefix, poll_interval: 3_000] ]) ], strategy: :one_for_all, name: name(prefix) )     > 非同期処理 Task.async_stream非同期処理 Task.async_stream \n\n次に、Task.async_stream。配列を引き回すリクエスト処理は Task.async_stream がうってつけです。下記ではキャッシュからブクマ対象になるフィードリンクを取り出し、除外処理、校正処理を加えて、ブクマのリクエストを出すという流れを組んでいます。Elixirでは、流れをひとまとめにして視覚的にわかりやすく非同期処理してくことができます。   ex \n\nCachex.keys!(:feed) |> Enum.reject(fn key -> key in [ \"excluded_links\", \"excluded_titles\", \"corrected_links\", \"redirected_links\", \"feed_group\", \"archived_links\" ] end) |> Task.async_stream( fn item_link -> with {:ok, [item_title, feed_tags]} <- Cachex.get(:feed, item_link), :ok <- validate_all(item_link, item_title), corrected_link <- correct_all(item_link), {:ok, payload} <- FormData.create( %{ url: corrected_link, comment: feed_tags |> Enum.map_join(fn tag -> \"[#{tag}]\" end), rks: System.get_env(\"HATENA_BOOKMARK_RKS\"), private: 0, keep_original_url: 1, with_status_op: 1, from: \"inplace\", post_twitter: 0, post_evernote: 0 }, :url_encoded, get: false ) do do_add_entries_to_hb(payload) Logger.info(\"add entry: #{item_link}\") end archive_link(item_link) end, timeout: 15_000 ) |> Stream.run()     > WRAPUPWRAPUP \n\nElixirの非同期処理を使うことではてなブックマークの運用がとても快適になりました。はてなブックマークとの今後の付き合い方は下記のように考えています。 \n\n- 手動でブクマ: 気になった記事があるごとに\n- ブクマの確認: 気になるタグごとにまとめて確認 \n\nブクマの確認については、例えば、CIでデプロイしている間に最近のGitHubの動向を確認したい場合は「nabinno/github」をみる、という感じの運用です。 \n\n融通が利かない点で途中運用が難しくなる気もしますが、しばらく回してみます。"},"name":"[2019-01-01]Elixirではてなブックマーク","tags":["elixir","hatena-bookmark"],"childPublishedDate":{"published_on":"2019-01-01T00:00:00.000Z","published_on_unix":1546300800}}},{"node":{"number":61,"relative_category":"blog/health","fields":{"title":"ElixirとRaspberry PiでPM2.5などの環境データを定点観察し、目・喉の痛みに備える","excerpt":"皆さんは体調管理どうされていますか。一度痛い目に遭うと日常の細かい差異が気になってきて、そこをどうにか解決したいというのが人情です。今回は自分の咽頭痛の解消のため一つ実験をしてみました。   > PROBLEMPROBLEM \n\n- 以前からオフィスに行くと目や喉が痛くなることがあったので、自分の体調なのか環境なのか原因を切り分けるために汚染計測器「Dienmern DM106A」を購入 ただ、DM106Aの計測はその時その時のスナップショットなので傾向を読み解きづらい、また、都度実施する手間がかかる \n- ただ、DM106Aの計測はその時その時のスナップショットなので傾向を読み解きづらい、また、都度実施する手間がかかる   > SOLUTIONSOLUTION \n\nというわけで、DM106AのセンサーデータをRaspberry Piで定期取得することにしました。設置方法の詳細はGitHubレポジトリを参照ください。下記、実装概要になります。   > 電子部品の構成電子部品の構成    item description     Raspberry Pi 3 Model B+    Aosong DHT11 気温・湿度センサー、GPIO   Nova SDS021 PM2.5・PM10センサー、UART   ams CCS811 TVOC・CO2eセンサー、I2C    \n\nまず、電子工作は素人ゆえどのセンサーを買えばいいか分からなかったのでDM106Aを分解して各センサーの型番を調べました。DHT011、SDS021はDM106Aとおなじセンサー、HCHOセンサーは信頼性があり手ごろなのがうまく見つけられませんでした。TVOCセンサーはAdafruitが推しているCCS811を採用しました。   > コードの構成コードの構成    item description     AirElixir.Application アプリケーション管理   AirElixir.GoogleSpreadsheets センサーデータ記録   AirElixirSensor.Publisher センサーデータ発行・送信   AirElixirSensor.Subscriber センサーデータ購読・受信    \n\n次に、基本構成はGrovePiを参考にしました。発行処理はElixirでうまくいかないケースがあったのでまずはPython/ErlPortで行いました。後々Elixirに移行できるようにマクロにしました。   > 5日ほど稼働してわかったこと・見立て、今後の課題5日ほど稼働してわかったこと・見立て、今後の課題  \n\n最後に、分かったこと、見立てですが、3点あります。2番目に関しては予想通りだったのですが、1番目、3番目に関しては意外であり、疑り深い私としては特に空気清浄機がきちんと機能していたことに驚きました。 \n\n1. オフィスの空気清浄機「Hitachi EP-LVG110」はPMをきちんとフィルターしていた ただし、空気清浄機はTVOCには効果がなく、これはTroia氏や加藤氏・苅部氏の考察でも言及されている \n2. ただし、空気清浄機はTVOCには効果がなく、これはTroia氏や加藤氏・苅部氏の考察でも言及されている\n3. 人の入りが多い時間帯に空気（TVOCやCO2e）が汚れる 人が「出る」時よりも「入る」際に濃度があがるのは、外のVOCが服などに付着しているためと推察 \n4. 人が「出る」時よりも「入る」際に濃度があがるのは、外のVOCが服などに付着しているためと推察\n5. TVOCやCO2eはPMのうごきに連動している（かも） チャート上はEP-LVG110がPM除去しているためわからないが、日本気象協会のPM2.5分布予測に照らしてみるとPM濃度が高い日にTVOC濃度があがっていた TODO: PMがVOCを運んでいる可能性があるので、IQAirなどのAPIから周辺環境のPMデータも取得したいところ \n6. チャート上はEP-LVG110がPM除去しているためわからないが、日本気象協会のPM2.5分布予測に照らしてみるとPM濃度が高い日にTVOC濃度があがっていた TODO: PMがVOCを運んでいる可能性があるので、IQAirなどのAPIから周辺環境のPMデータも取得したいところ \n7. TODO: PMがVOCを運んでいる可能性があるので、IQAirなどのAPIから周辺環境のPMデータも取得したいところ \n\n課題としてはその性質からして仕方ないのですがTVOCの変動が大きすぎて解読を難しかったです。計測方法等を再度見直す必要がありそうです。 \n\n- TVOCの変動が大きすぎる ポーリング・出力を20分ごとからポーリング3秒ごと・出力20分ごとに変更した、出力データは20分の平均 \n- ポーリング・出力を20分ごとからポーリング3秒ごと・出力20分ごとに変更した、出力データは20分の平均\n- TVOCのスパイクを抑えたい TODO: ファイトレメディエーションによる効果を見ていきたいところ \n- TODO: ファイトレメディエーションによる効果を見ていきたいところ   > WRAPUPWRAPUP \n\n今回の実験はこれが言いたかっただけという指摘をされるとぐうの音も出ませんが、はっきり言わせてください。そう、Elixirは健康管理に向いています。   txt \n\n「なんか体調がすぐれないなあ...」 「Elixirちょうだい!」   \n\nという感じです、はい。"},"name":"[2018-12-22]ElixirとRaspberry PiでPM2.5などの環境データを定点観察し、目・喉の痛みに備える","tags":["elixir","raspberry-pi","particulates","physiology"],"childPublishedDate":{"published_on":"2018-12-22T00:00:00.000Z","published_on_unix":1545436800}}}],"pathPrefix":"","first":true,"last":false,"index":1,"pageCount":3,"additionalContext":{}}},"staticQueryHashes":[]}