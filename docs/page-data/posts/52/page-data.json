{"componentChunkName":"component---src-templates-post-tsx","path":"/posts/52","result":{"data":{"esaPost":{"number":52,"relative_category":"blog/backend","fields":{"title":"HerokuとGAEのCIをDockerとパイプラインから構成されたWerckerで管理する","excerpt":"Continuous Integration (CI) が徐々にDockerに対応し始める機運です。先行してWerckerがDocker対応を始めたので、その流れに乗るべくWerckerをDocker化してみました。   > PROBLEMPROBLEM \n\n- パフォーマンス改善のための開発環境がいけてない\n- 別PaaSへ移行するための開発環境が汎用化できてない、つらい   > SOLUTIONSOLUTION \n\nというわけで、まずはCI上のDockerに載せてから次の手（GAEあたり）を考えることにしました。CIはWerckerを使用。以前から使っていたのですが、今回はボックスがDockerになったのでそちらに対応しました。 \n\nまず、Werckerは「Docker」「環境変数」による環境管理、「パイプライン」によるワークフロー管理を行っています。 \n\n1. Dockerで環境を管理。 今回は対応していないですが、GAEのコンテナ（gcr.io/google_appengine/ruby:xxx）と共通化することもできます。ただし、HerokuのHobby Dynosはプロセス数に制限があるのでコンテナ運用は工夫が必要です。\n2. 異なるサービス間のネットワークをWerckerが生成する環境変数で管理。 Dockerのネットワーク設定の煩雑さを解消します。\n3. タスクをワークフローとしてパイプラインで条件付け管理。 パイプラインごとにコンテナを立ち上げているので、同じDocker環境でもパイプラインごとに環境変数を分けることが可能です。Herokuのパイプラインでもいいですが、今後別PaaSに移行する可能性を考えてCI管理にbetしました。 \n\n次に、Werckerのふるまいを定義するwercker.ymlは、下記シークエンス図のようにパイプラインごとに記述されています。今回は各パイプラインの詳細を見ていくことにします。    > devパイプラインdevパイプライン \n\ndevパイプラインは wercker dev コマンドをローカルでたたく際に使います。下記の例だとRSpec走らせているだけなのでおまけ程度。ただ、ローカル開発でDockerを使うことになったらこういう提案もありだと思います。プロジェクトレポジトリすべてをDockerにしてローカル開発するペイン、所謂git-dockerのバージョン管理問題があるので代替案として。   yaml \n\nbox: ruby:2.3.1 services: - postgres:9.6.1 - redis:3.0.3 dev: steps: - bundle-install - script: name: Install ImageMagick code: | apt-get update apt-get install -y nodejs imagemagick - script: name: Setup database code: | RAILS_ENV=test bundle exec rake db:create db:migrate - internal/watch: name: Run rspec code: | RAILS_ENV=test bundle exec rake spec reload: true     > buildパイプラインbuildパイプライン \n\nbuildパイプラインもdevパイプラインと同じDockerボックスを使っています。やっていることはdevパイプラインと変わらず、すべてのブランチで走ります。   yaml \n\nbuild: steps: - bundle-install - script: name: Install ImageMagick code: | apt-get update apt-get install -y nodejs imagemagick - script: name: Echo Ruby information code: | env echo \"ruby version $(ruby --version) running!\" echo \"from location $(which ruby)\" echo -p \"gem list: $(gem list)\" - script: name: Setup database code: | RAILS_ENV=test bundle exec rake db:create db:migrate - script: name: Run rspec code: | RAILS_ENV=test bundle exec rake spec     > deploy-stageパイプラインdeploy-stageパイプライン \n\ndeploy-stageパイプラインはステージング環境用。現在Herokuを本番環境で利用しているので、デプロイごとにそれをフォークして環境構築しています。また、Railsのアセットプリコンパイルの時間短縮はほかのCIと同様にキャッシュを利用しています。 \n\n他のPaaSに移った場合に現在行っている本番環境のフォークをどうするかが検討課題となります。   yaml \n\ndeploy-stage-heroku: steps: - bundle-install - script: name: Install NodeJS code: | apt-get update apt-get install -y nodejs - nabinno/heroku-install: key: $HEROKU_KEY user: $HEROKU_USER app-name: $HEROKU_APP_NAME - script: name: Fork Application - destroy application code: | heroku apps:destroy --app $HEROKU_APP_NAME --confirm $HEROKU_APP_NAME - script: name: Fork Application - fork code: | heroku fork --from $FROM_HEROKU_APP_NAME --to $HEROKU_APP_NAME - script: name: Fork Application - setup addons of rediscloud code: | heroku addons:create rediscloud:30 --app $HEROKU_APP_NAME - script: name: Fork Application -change dynos code: | heroku ps:scale web=1:Free worker=1:Free --app $HEROKU_APP_NAME - script: name: Fork Application - change environment variables code: | _rediscloud_url=$(heroku run 'env | grep -e REDISCLOUD_.*_URL' --app $HEROKU_APP_NAME | awk -F= '{print $2}') heroku config:set \\ S3_BUCKET=$S3_BUCKET \\ HEROKU_APP=$HEROKU_APP_NAME \\ REDISCLOUD_URL=$_rediscloud_url \\ --app $HEROKU_APP_NAME - script: name: Assets Precompile - restore assets cache code: | [ -e $WERCKER_CACHE_DIR/public/assets ] && cp -fr $WERCKER_CACHE_DIR/public/assets $WERCKER_SOURCE_DIR/public || true mkdir -p $WERCKER_SOURCE_DIR/tmp/cache [ -e $WERCKER_CACHE_DIR/tmp/cache/assets ] && cp -fr $WERCKER_CACHE_DIR/tmp/cache/assets $WERCKER_SOURCE_DIR/tmp/cache || true - script: name: Assets Precompile - main process code: | RAILS_ENV=production bundle exec rake assets:precompile --trace - script: name: Assets Precompile - store assets cache code: | mkdir -p $WERCKER_CACHE_DIR/public/assets cp -fr $WERCKER_SOURCE_DIR/public/assets $WERCKER_CACHE_DIR/public mkdir -p $WERCKER_CACHE_DIR/tmp/cache/assets cp -fr $WERCKER_SOURCE_DIR/tmp/cache/assets $WERCKER_CACHE_DIR/tmp/cache - add-ssh-key: host: github.com keyname: GITHUB - add-to-known_hosts: hostname: github.com fingerprint: 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48 - script: name: Assets Precompile - git commit code: | { git add public/assets/.sprockets-manifest-*.json git commit -m 'Run `rake assets:precompile` on Wercker.' } || { echo 'Skip: keep precompiled assets manifest.' } - heroku-deploy: key: $HEROKU_KEY user: $HEROKU_USER app-name: $HEROKU_APP_NAME - script: name: DB Migrate code: | heroku run 'bundle exec rake db:migrate --trace' --app $HEROKU_APP_NAME after-steps: - wantedly/pretty-slack-notify: webhook_url: ${SLACK_WEBHOOK_URL} channel: general     > deploy-prod-herokuパイプラインdeploy-prod-herokuパイプライン \n\ndeploy-prod-herokuパイプラインは本番環境へのリリース用。環境変数以外はdeploy-stageパイプラインと同じものです。   yaml \n\ndeploy-prod-heroku: steps: - bundle-install - script: name: Install NodeJS code: | apt-get update apt-get install -y nodejs - script: name: Assets Precompile - restore assets cache code: | [ -e $WERCKER_CACHE_DIR/public/assets ] && cp -fr $WERCKER_CACHE_DIR/public/assets $WERCKER_SOURCE_DIR/public || true mkdir -p $WERCKER_SOURCE_DIR/tmp/cache [ -e $WERCKER_CACHE_DIR/tmp/cache/assets ] && cp -fr $WERCKER_CACHE_DIR/tmp/cache/assets $WERCKER_SOURCE_DIR/tmp/cache || true - script: name: Assets Precompile - main process code: | RAILS_ENV=production bundle exec rake assets:precompile --trace - script: name: Assets Precompile - store assets cache code: | mkdir -p $WERCKER_CACHE_DIR/public/assets cp -fr $WERCKER_SOURCE_DIR/public/assets $WERCKER_CACHE_DIR/public mkdir -p $WERCKER_CACHE_DIR/tmp/cache/assets cp -fr $WERCKER_SOURCE_DIR/tmp/cache/assets $WERCKER_CACHE_DIR/tmp/cache - add-ssh-key: host: github.com keyname: GITHUB - add-to-known_hosts: hostname: github.com fingerprint: 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48 - script: name: Assets Precompile - git commit code: | { git add public/assets/.sprockets-manifest-*.json git commit -m 'Run `rake assets:precompile` on Wercker.' } || { echo 'Skip: keep precompiled assets manifest.' } - script: name: Add git-tag code: | _tag=$(date -u -d '9 hours' +%Y-%m-%d-%H-%M-%S) git config --global user.email 'wercker@blahfe.com' git config --global user.name 'Wercker Bot' git tag -a $_tag master -m 'wercker deploy' git push origin $_tag - heroku-deploy: key: $HEROKU_KEY user: $HEROKU_USER app-name: $HEROKU_APP_NAME install-toolbelt: true - script: name: DB Migrate code: | heroku run 'bundle exec rake db:migrate --trace' --app $HEROKU_APP_NAME after-steps: - wantedly/pretty-slack-notify: webhook_url: ${SLACK_WEBHOOK_URL} channel: general     > deploy-prod-gaeパイプラインdeploy-prod-gaeパイプライン \n\ndeploy-prod-gaeパイプラインはdeploy-prod-herokuパイプラインと同じく本番環境へのリリース用。GAEにいつでも移行できるように走らせています。 \n\nGAEのデプロイは癖があって、gcloud app deployコマンドをつかってDockerビルドを走らせますが、その時にDocker内に外部から環境変数を設定することができません。そのため、アセットプリコンパイルのビルドの際、asset_syncを使っていると別サーバーへ同期に失敗します。また、パイプライン上の別ステップに環境変数を当てて行うことはできるが、gcloudのデプロイステップとアセットプリコンパイルが重複して適切なダイジェストを発行できません。従って、GAEをつかう場合は ./public ディレクトリをつかうのが現状の正解です。HerokuのSlugの取り扱い方針と違うので注意が必要です。 \n\nGAEのコンテナの中身は、gcloud beta app gen-config --runtime=ruby --custom で出力されるDockerfileを参照ください。   yaml \n\ndeploy-prod-gae: steps: - bundle-install - script: name: Install ImageMagick code: | apt-get update apt-get install -y nodejs imagemagick - script: name: Echo Ruby information code: | env echo \"ruby version $(ruby --version) running!\" echo \"from location $(which ruby)\" echo -p \"gem list: $(gem list)\" - script: name: DB Migrate code: | RAILS_ENV=production \\ DATABASE_URL=${DATABASE_URL} \\ bundle exec rake db:create db:migrate --trace - script: name: Install gcloud code: | curl https://sdk.cloud.google.com | bash source ~/.bashrc - script: name: Authenticate gcloud code: | gcloud config set project utagaki-v2 openssl aes-256-cbc -k ${DECRYPT_KEY} -d -in ./gcloud.json.encrypted -out ./gcloud.json gcloud auth activate-service-account --key-file ./gcloud.json - script: name: Deploy app to Google App Engine code: | gcloud app deploy ./app.yaml --promote --stop-previous-version after-steps: - wantedly/pretty-slack-notify: webhook_url: ${SLACK_WEBHOOK_URL} channel: general     > post-deployパイプラインpost-deployパイプライン \n\npost-deployパイプラインは本番環境にデプロイした後の後処理用です。参考程度に git tag をつけています。   yaml \n\npost-deploy: steps: - add-ssh-key: host: github.com keyname: GITHUB - add-to-known_hosts: hostname: github.com fingerprint: 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48 - script: name: Add git-tag code: | _tag=$(date -u -d '9 hours' +%Y-%m-%d-%H-%M-%S) git remote add origin git@github.com:nabinno/utagaki.git git config --global user.email 'wercker@blahfe.com' git config --global user.name 'Wercker Bot' git tag -a $_tag master -m 'wercker deploy' git push origin $_tag after-steps: - wantedly/pretty-slack-notify: webhook_url: ${SLACK_WEBHOOK_URL} channel: general     > WRAPUPWRAPUP \n\nこうしてWerckerの設定ファイルを書いてみるに、どのCI、どの仮想環境も同じ書き味ということが分かります。当処懸念していたDocker化することによる嵌まり事はなく、すんなり移行することができました。 \n\n手軽さ、管理のしやすさから、今後はすべてのCIがDockerに移行するでしょう。","thumbnail":"https://img.esa.io/uploads/production/attachments/16651/2021/01/11/97367/7fab9f4f-a709-44e9-91bd-95974de3ade4.png"},"wip":false,"body_md":"Continuous Integration (CI) が徐々にDockerに対応し始める機運です。先行してWerckerがDocker対応を始めたので、その流れに乗るべくWerckerをDocker化してみました。\r\n\r\n# PROBLEM\r\n- パフォーマンス改善のための開発環境がいけてない\r\n- 別PaaSへ移行するための開発環境が汎用化できてない、つらい\r\n\r\n# SOLUTION\r\nというわけで、まずはCI上のDockerに載せてから次の手（GAEあたり）を考えることにしました。CIはWerckerを使用。以前から使っていたのですが、今回はボックスがDockerになったのでそちらに対応しました。\r\n\r\nまず、Werckerは「Docker」「環境変数」による環境管理、「パイプライン」によるワークフロー管理を行っています。\r\n\r\n1. **Dockerで環境を管理。** 今回は対応していないですが、GAEのコンテナ（`gcr.io/google_appengine/ruby:xxx`）と共通化することもできます。ただし、HerokuのHobby Dynosはプロセス数に制限があるのでコンテナ運用は工夫が必要です。\r\n2. **異なるサービス間のネットワークをWerckerが生成する環境変数で管理。** Dockerのネットワーク設定の煩雑さを解消します。\r\n3. **タスクをワークフローとしてパイプラインで条件付け管理。** パイプラインごとにコンテナを立ち上げているので、同じDocker環境でもパイプラインごとに環境変数を分けることが可能です。Herokuのパイプラインでもいいですが、今後別PaaSに移行する可能性を考えてCI管理にbetしました。\r\n\r\n次に、Werckerのふるまいを定義する`wercker.yml`は、下記シークエンス図のようにパイプラインごとに記述されています。今回は各パイプラインの詳細を見ていくことにします。\r\n\r\n<img width=\"757\" alt=\"thumbnail\" src=\"https://img.esa.io/uploads/production/attachments/16651/2021/01/11/97367/7fab9f4f-a709-44e9-91bd-95974de3ade4.png\">\r\n\r\n## devパイプライン\r\ndevパイプラインは `wercker dev` コマンドをローカルでたたく際に使います。下記の例だとRSpec走らせているだけなのでおまけ程度。ただ、ローカル開発でDockerを使うことになったらこういう提案もありだと思います。プロジェクトレポジトリすべてをDockerにしてローカル開発するペイン、所謂git-dockerのバージョン管理問題があるので代替案として。\r\n\r\n``` yaml\r\nbox: ruby:2.3.1\r\nservices:\r\n  - postgres:9.6.1\r\n  - redis:3.0.3\r\n\r\ndev:\r\n  steps:\r\n    - bundle-install\r\n    - script:\r\n        name: Install ImageMagick\r\n        code: |\r\n          apt-get update\r\n          apt-get install -y nodejs imagemagick\r\n    - script:\r\n        name: Setup database\r\n        code: |\r\n          RAILS_ENV=test bundle exec rake db:create db:migrate\r\n    - internal/watch:\r\n        name: Run rspec\r\n        code: |\r\n          RAILS_ENV=test bundle exec rake spec\r\n        reload: true\r\n```\r\n\r\n## buildパイプライン\r\nbuildパイプラインもdevパイプラインと同じDockerボックスを使っています。やっていることはdevパイプラインと変わらず、すべてのブランチで走ります。\r\n\r\n``` yaml\r\nbuild:\r\n  steps:\r\n    - bundle-install\r\n    - script:\r\n        name: Install ImageMagick\r\n        code: |\r\n          apt-get update\r\n          apt-get install -y nodejs imagemagick\r\n    - script:\r\n        name: Echo Ruby information\r\n        code: |\r\n          env\r\n          echo \"ruby version $(ruby --version) running!\"\r\n          echo \"from location $(which ruby)\"\r\n          echo -p \"gem list: $(gem list)\"\r\n    - script:\r\n        name: Setup database\r\n        code: |\r\n          RAILS_ENV=test bundle exec rake db:create db:migrate\r\n    - script:\r\n        name: Run rspec\r\n        code: |\r\n          RAILS_ENV=test bundle exec rake spec\r\n```\r\n\r\n## deploy-stageパイプライン\r\ndeploy-stageパイプラインはステージング環境用。現在Herokuを本番環境で利用しているので、デプロイごとにそれをフォークして環境構築しています。また、Railsのアセットプリコンパイルの時間短縮はほかのCIと同様にキャッシュを利用しています。\r\n\r\n他のPaaSに移った場合に現在行っている本番環境のフォークをどうするかが検討課題となります。\r\n\r\n``` yaml\r\ndeploy-stage-heroku:\r\n  steps:\r\n    - bundle-install\r\n    - script:\r\n        name: Install NodeJS\r\n        code: |\r\n          apt-get update\r\n          apt-get install -y nodejs\r\n    - nabinno/heroku-install:\r\n        key: $HEROKU_KEY\r\n        user: $HEROKU_USER\r\n        app-name: $HEROKU_APP_NAME\r\n    - script:\r\n        name: Fork Application - destroy application\r\n        code: |\r\n          heroku apps:destroy --app $HEROKU_APP_NAME --confirm $HEROKU_APP_NAME\r\n    - script:\r\n        name: Fork Application - fork\r\n        code: |\r\n          heroku fork --from $FROM_HEROKU_APP_NAME --to $HEROKU_APP_NAME\r\n    - script:\r\n        name: Fork Application - setup addons of rediscloud\r\n        code: |\r\n          heroku addons:create rediscloud:30 --app $HEROKU_APP_NAME\r\n    - script:\r\n        name: Fork Application -change dynos\r\n        code: |\r\n          heroku ps:scale web=1:Free worker=1:Free --app $HEROKU_APP_NAME\r\n    - script:\r\n        name: Fork Application - change environment variables\r\n        code: |\r\n          _rediscloud_url=$(heroku run 'env | grep -e REDISCLOUD_.*_URL' --app $HEROKU_APP_NAME | awk -F= '{print $2}')\r\n          heroku config:set \\\r\n            S3_BUCKET=$S3_BUCKET \\\r\n            HEROKU_APP=$HEROKU_APP_NAME \\\r\n            REDISCLOUD_URL=$_rediscloud_url \\\r\n            --app $HEROKU_APP_NAME\r\n    - script:\r\n        name: Assets Precompile - restore assets cache\r\n        code: |\r\n          [ -e $WERCKER_CACHE_DIR/public/assets ] && cp -fr $WERCKER_CACHE_DIR/public/assets $WERCKER_SOURCE_DIR/public || true\r\n          mkdir -p $WERCKER_SOURCE_DIR/tmp/cache\r\n          [ -e $WERCKER_CACHE_DIR/tmp/cache/assets ] && cp -fr $WERCKER_CACHE_DIR/tmp/cache/assets $WERCKER_SOURCE_DIR/tmp/cache || true\r\n    - script:\r\n        name: Assets Precompile - main process\r\n        code: |\r\n          RAILS_ENV=production bundle exec rake assets:precompile --trace\r\n    - script:\r\n        name: Assets Precompile - store assets cache\r\n        code: |\r\n          mkdir -p $WERCKER_CACHE_DIR/public/assets\r\n          cp -fr $WERCKER_SOURCE_DIR/public/assets $WERCKER_CACHE_DIR/public\r\n          mkdir -p $WERCKER_CACHE_DIR/tmp/cache/assets\r\n          cp -fr $WERCKER_SOURCE_DIR/tmp/cache/assets $WERCKER_CACHE_DIR/tmp/cache\r\n    - add-ssh-key:\r\n        host: github.com\r\n        keyname: GITHUB\r\n    - add-to-known_hosts:\r\n        hostname: github.com\r\n        fingerprint: 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48\r\n    - script:\r\n        name: Assets Precompile - git commit\r\n        code: |\r\n          {\r\n            git add public/assets/.sprockets-manifest-*.json\r\n            git commit -m 'Run `rake assets:precompile` on Wercker.'\r\n          } || {\r\n            echo 'Skip: keep precompiled assets manifest.'\r\n          }\r\n    - heroku-deploy:\r\n        key: $HEROKU_KEY\r\n        user: $HEROKU_USER\r\n        app-name: $HEROKU_APP_NAME\r\n    - script:\r\n        name: DB Migrate\r\n        code: |\r\n          heroku run 'bundle exec rake db:migrate --trace' --app $HEROKU_APP_NAME\r\n  after-steps:\r\n    - wantedly/pretty-slack-notify:\r\n        webhook_url: ${SLACK_WEBHOOK_URL}\r\n        channel: general\r\n```\r\n\r\n## deploy-prod-herokuパイプライン\r\ndeploy-prod-herokuパイプラインは本番環境へのリリース用。環境変数以外はdeploy-stageパイプラインと同じものです。\r\n\r\n``` yaml\r\ndeploy-prod-heroku:\r\n  steps:\r\n    - bundle-install\r\n    - script:\r\n        name: Install NodeJS\r\n        code: |\r\n          apt-get update\r\n          apt-get install -y nodejs\r\n    - script:\r\n        name: Assets Precompile - restore assets cache\r\n        code: |\r\n          [ -e $WERCKER_CACHE_DIR/public/assets ] && cp -fr $WERCKER_CACHE_DIR/public/assets $WERCKER_SOURCE_DIR/public || true\r\n          mkdir -p $WERCKER_SOURCE_DIR/tmp/cache\r\n          [ -e $WERCKER_CACHE_DIR/tmp/cache/assets ] && cp -fr $WERCKER_CACHE_DIR/tmp/cache/assets $WERCKER_SOURCE_DIR/tmp/cache || true\r\n    - script:\r\n        name: Assets Precompile - main process\r\n        code: |\r\n          RAILS_ENV=production bundle exec rake assets:precompile --trace\r\n    - script:\r\n        name: Assets Precompile - store assets cache\r\n        code: |\r\n          mkdir -p $WERCKER_CACHE_DIR/public/assets\r\n          cp -fr $WERCKER_SOURCE_DIR/public/assets $WERCKER_CACHE_DIR/public\r\n          mkdir -p $WERCKER_CACHE_DIR/tmp/cache/assets\r\n          cp -fr $WERCKER_SOURCE_DIR/tmp/cache/assets $WERCKER_CACHE_DIR/tmp/cache\r\n    - add-ssh-key:\r\n        host: github.com\r\n        keyname: GITHUB\r\n    - add-to-known_hosts:\r\n        hostname: github.com\r\n        fingerprint: 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48\r\n    - script:\r\n        name: Assets Precompile - git commit\r\n        code: |\r\n          {\r\n            git add public/assets/.sprockets-manifest-*.json\r\n            git commit -m 'Run `rake assets:precompile` on Wercker.'\r\n          } || {\r\n            echo 'Skip: keep precompiled assets manifest.'\r\n          }\r\n    - script:\r\n        name: Add git-tag\r\n        code: |\r\n          _tag=$(date -u -d '9 hours' +%Y-%m-%d-%H-%M-%S)\r\n          git config --global user.email 'wercker@blahfe.com'\r\n          git config --global user.name 'Wercker Bot'\r\n          git tag -a $_tag master -m 'wercker deploy'\r\n          git push origin $_tag\r\n    - heroku-deploy:\r\n        key: $HEROKU_KEY\r\n        user: $HEROKU_USER\r\n        app-name: $HEROKU_APP_NAME\r\n        install-toolbelt: true\r\n    - script:\r\n        name: DB Migrate\r\n        code: |\r\n          heroku run 'bundle exec rake db:migrate --trace' --app $HEROKU_APP_NAME\r\n  after-steps:\r\n    - wantedly/pretty-slack-notify:\r\n        webhook_url: ${SLACK_WEBHOOK_URL}\r\n        channel: general\r\n```\r\n\r\n## deploy-prod-gaeパイプライン\r\ndeploy-prod-gaeパイプラインはdeploy-prod-herokuパイプラインと同じく本番環境へのリリース用。GAEにいつでも移行できるように走らせています。\r\n\r\nGAEのデプロイは癖があって、`gcloud app deploy`コマンドをつかってDockerビルドを走らせますが、その時にDocker内に外部から環境変数を設定することができません。そのため、アセットプリコンパイルのビルドの際、`asset_sync`を使っていると別サーバーへ同期に失敗します。また、パイプライン上の別ステップに環境変数を当てて行うことはできるが、`gcloud`のデプロイステップとアセットプリコンパイルが重複して適切なダイジェストを発行できません。従って、GAEをつかう場合は `./public` ディレクトリをつかうのが現状の正解です。HerokuのSlugの取り扱い方針と違うので注意が必要です。\r\n\r\nGAEのコンテナの中身は、`gcloud beta app gen-config --runtime=ruby --custom` で出力されるDockerfileを参照ください。\r\n\r\n``` yaml\r\ndeploy-prod-gae:\r\n  steps:\r\n    - bundle-install\r\n    - script:\r\n        name: Install ImageMagick\r\n        code: |\r\n          apt-get update\r\n          apt-get install -y nodejs imagemagick\r\n    - script:\r\n        name: Echo Ruby information\r\n        code: |\r\n          env\r\n          echo \"ruby version $(ruby --version) running!\"\r\n          echo \"from location $(which ruby)\"\r\n          echo -p \"gem list: $(gem list)\"\r\n    - script:\r\n        name: DB Migrate\r\n        code: |\r\n          RAILS_ENV=production \\\r\n            DATABASE_URL=${DATABASE_URL} \\\r\n            bundle exec rake db:create db:migrate --trace\r\n    - script:\r\n        name: Install gcloud\r\n        code: |\r\n          curl https://sdk.cloud.google.com | bash\r\n          source ~/.bashrc\r\n    - script:\r\n        name: Authenticate gcloud\r\n        code: |\r\n          gcloud config set project utagaki-v2\r\n          openssl aes-256-cbc -k ${DECRYPT_KEY} -d -in ./gcloud.json.encrypted -out ./gcloud.json\r\n          gcloud auth activate-service-account --key-file ./gcloud.json\r\n    - script:\r\n        name: Deploy app to Google App Engine\r\n        code: |\r\n          gcloud app deploy ./app.yaml --promote --stop-previous-version\r\n  after-steps:\r\n    - wantedly/pretty-slack-notify:\r\n        webhook_url: ${SLACK_WEBHOOK_URL}\r\n        channel: general\r\n```\r\n\r\n## post-deployパイプライン\r\npost-deployパイプラインは本番環境にデプロイした後の後処理用です。参考程度に `git tag` をつけています。\r\n\r\n``` yaml\r\npost-deploy:\r\n  steps:\r\n    - add-ssh-key:\r\n        host: github.com\r\n        keyname: GITHUB\r\n    - add-to-known_hosts:\r\n        hostname: github.com\r\n        fingerprint: 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48\r\n    - script:\r\n        name: Add git-tag\r\n        code: |\r\n          _tag=$(date -u -d '9 hours' +%Y-%m-%d-%H-%M-%S)\r\n          git remote add origin git@github.com:nabinno/utagaki.git\r\n          git config --global user.email 'wercker@blahfe.com'\r\n          git config --global user.name 'Wercker Bot'\r\n          git tag -a $_tag master -m 'wercker deploy'\r\n          git push origin $_tag\r\n  after-steps:\r\n    - wantedly/pretty-slack-notify:\r\n        webhook_url: ${SLACK_WEBHOOK_URL}\r\n        channel: general\r\n```\r\n\r\n# WRAPUP\r\nこうしてWerckerの設定ファイルを書いてみるに、どのCI、どの仮想環境も同じ書き味ということが分かります。当処懸念していたDocker化することによる嵌まり事はなく、すんなり移行することができました。\r\n\r\n手軽さ、管理のしやすさから、今後はすべてのCIがDockerに移行するでしょう。","body_html":"<p data-sourcepos=\"1:1-1:204\">Continuous Integration (CI) が徐々にDockerに対応し始める機運です。先行してWerckerがDocker対応を始めたので、その流れに乗るべくWerckerをDocker化してみました。</p>\n<h1 data-sourcepos=\"3:1-3:9\" id=\"1-0-0\" name=\"1-0-0\">\n<a class=\"anchor\" id=\"PROBLEM\" name=\"PROBLEM\" href=\"#PROBLEM\" data-position=\"1-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"PROBLEM\"> &gt; PROBLEM</span></a>PROBLEM</h1>\n<ul data-sourcepos=\"4:1-6:0\">\n<li data-sourcepos=\"4:1-4:71\">パフォーマンス改善のための開発環境がいけてない</li>\n<li data-sourcepos=\"5:1-6:0\">別PaaSへ移行するための開発環境が汎用化できてない、つらい</li>\n</ul>\n<h1 data-sourcepos=\"7:1-7:10\" id=\"2-0-0\" name=\"2-0-0\">\n<a class=\"anchor\" id=\"SOLUTION\" name=\"SOLUTION\" href=\"#SOLUTION\" data-position=\"2-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"SOLUTION\"> &gt; SOLUTION</span></a>SOLUTION</h1>\n<p data-sourcepos=\"8:1-8:272\">というわけで、まずはCI上のDockerに載せてから次の手（GAEあたり）を考えることにしました。CIはWerckerを使用。以前から使っていたのですが、今回はボックスがDockerになったのでそちらに対応しました。</p>\n<p data-sourcepos=\"10:1-10:154\">まず、Werckerは「Docker」「環境変数」による環境管理、「パイプライン」によるワークフロー管理を行っています。</p>\n<ol data-sourcepos=\"12:1-15:0\">\n<li data-sourcepos=\"12:1-12:296\">\n<strong>Dockerで環境を管理。</strong> 今回は対応していないですが、GAEのコンテナ（<code>gcr.io/google_appengine/ruby:xxx</code>）と共通化することもできます。ただし、HerokuのHobby Dynosはプロセス数に制限があるのでコンテナ運用は工夫が必要です。</li>\n<li data-sourcepos=\"13:1-13:168\">\n<strong>異なるサービス間のネットワークをWerckerが生成する環境変数で管理。</strong> Dockerのネットワーク設定の煩雑さを解消します。</li>\n<li data-sourcepos=\"14:1-15:0\">\n<strong>タスクをワークフローとしてパイプラインで条件付け管理。</strong> パイプラインごとにコンテナを立ち上げているので、同じDocker環境でもパイプラインごとに環境変数を分けることが可能です。Herokuのパイプラインでもいいですが、今後別PaaSに移行する可能性を考えてCI管理にbetしました。</li>\n</ol>\n<p data-sourcepos=\"16:1-16:233\">次に、Werckerのふるまいを定義する<code>wercker.yml</code>は、下記シークエンス図のようにパイプラインごとに記述されています。今回は各パイプラインの詳細を見ていくことにします。</p>\n<a href=\"https://img.esa.io/uploads/production/attachments/16651/2021/01/11/97367/7fab9f4f-a709-44e9-91bd-95974de3ade4.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img width=\"757\" alt=\"thumbnail\" src=\"https://img.esa.io/uploads/production/attachments/16651/2021/01/11/97367/7fab9f4f-a709-44e9-91bd-95974de3ade4.png\"></a>\n<h2 data-sourcepos=\"20:1-20:24\" id=\"2-1-0\" name=\"2-1-0\">\n<a class=\"anchor\" id=\"devパイプライン\" name=\"dev%E3%83%91%E3%82%A4%E3%83%97%E3%83%A9%E3%82%A4%E3%83%B3\" href=\"#dev%E3%83%91%E3%82%A4%E3%83%97%E3%83%A9%E3%82%A4%E3%83%B3\" data-position=\"2-1-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"devパイプライン\"> &gt; devパイプライン</span></a>devパイプライン</h2>\n<p data-sourcepos=\"21:1-21:465\">devパイプラインは <code>wercker dev</code> コマンドをローカルでたたく際に使います。下記の例だとRSpec走らせているだけなのでおまけ程度。ただ、ローカル開発でDockerを使うことになったらこういう提案もありだと思います。プロジェクトレポジトリすべてをDockerにしてローカル開発するペイン、所謂git-dockerのバージョン管理問題があるので代替案として。</p>\n<div class=\"code-block\" data-sourcepos=\"23:1-46:3\">\n<div class=\"code-filename\">\n<i class=\"fa fa-file-code-o\"></i>yaml</div>\n<div class=\"highlight\"><pre class=\"highlight yaml\"><code><span class=\"na\">box</span><span class=\"pi\">:</span> <span class=\"s\">ruby:2.3.1</span>\n<span class=\"na\">services</span><span class=\"pi\">:</span>\n  <span class=\"pi\">-</span> <span class=\"s\">postgres:9.6.1</span>\n  <span class=\"pi\">-</span> <span class=\"s\">redis:3.0.3</span>\n\n<span class=\"na\">dev</span><span class=\"pi\">:</span>\n  <span class=\"na\">steps</span><span class=\"pi\">:</span>\n    <span class=\"pi\">-</span> <span class=\"s\">bundle-install</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Install ImageMagick</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">apt-get update</span>\n          <span class=\"s\">apt-get install -y nodejs imagemagick</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Setup database</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">RAILS_ENV=test bundle exec rake db:create db:migrate</span>\n    <span class=\"pi\">-</span> <span class=\"s\">internal/watch</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Run rspec</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">RAILS_ENV=test bundle exec rake spec</span>\n        <span class=\"na\">reload</span><span class=\"pi\">:</span> <span class=\"no\">true</span>\n</code></pre></div>\n</div>\n<h2 data-sourcepos=\"48:1-48:26\" id=\"2-2-0\" name=\"2-2-0\">\n<a class=\"anchor\" id=\"buildパイプライン\" name=\"build%E3%83%91%E3%82%A4%E3%83%97%E3%83%A9%E3%82%A4%E3%83%B3\" href=\"#build%E3%83%91%E3%82%A4%E3%83%97%E3%83%A9%E3%82%A4%E3%83%B3\" data-position=\"2-2-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"buildパイプライン\"> &gt; buildパイプライン</span></a>buildパイプライン</h2>\n<p data-sourcepos=\"49:1-49:203\">buildパイプラインもdevパイプラインと同じDockerボックスを使っています。やっていることはdevパイプラインと変わらず、すべてのブランチで走ります。</p>\n<div class=\"code-block\" data-sourcepos=\"51:1-75:3\">\n<div class=\"code-filename\">\n<i class=\"fa fa-file-code-o\"></i>yaml</div>\n<div class=\"highlight\"><pre class=\"highlight yaml\"><code><span class=\"na\">build</span><span class=\"pi\">:</span>\n  <span class=\"na\">steps</span><span class=\"pi\">:</span>\n    <span class=\"pi\">-</span> <span class=\"s\">bundle-install</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Install ImageMagick</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">apt-get update</span>\n          <span class=\"s\">apt-get install -y nodejs imagemagick</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Echo Ruby information</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">env</span>\n          <span class=\"s\">echo \"ruby version $(ruby --version) running!\"</span>\n          <span class=\"s\">echo \"from location $(which ruby)\"</span>\n          <span class=\"s\">echo -p \"gem list: $(gem list)\"</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Setup database</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">RAILS_ENV=test bundle exec rake db:create db:migrate</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Run rspec</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">RAILS_ENV=test bundle exec rake spec</span>\n</code></pre></div>\n</div>\n<h2 data-sourcepos=\"77:1-77:33\" id=\"2-3-0\" name=\"2-3-0\">\n<a class=\"anchor\" id=\"deploy-stageパイプライン\" name=\"deploy-stage%E3%83%91%E3%82%A4%E3%83%97%E3%83%A9%E3%82%A4%E3%83%B3\" href=\"#deploy-stage%E3%83%91%E3%82%A4%E3%83%97%E3%83%A9%E3%82%A4%E3%83%B3\" data-position=\"2-3-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"deploy-stageパイプライン\"> &gt; deploy-stageパイプライン</span></a>deploy-stageパイプライン</h2>\n<p data-sourcepos=\"78:1-78:331\">deploy-stageパイプラインはステージング環境用。現在Herokuを本番環境で利用しているので、デプロイごとにそれをフォークして環境構築しています。また、Railsのアセットプリコンパイルの時間短縮はほかのCIと同様にキャッシュを利用しています。</p>\n<p data-sourcepos=\"80:1-80:130\">他のPaaSに移った場合に現在行っている本番環境のフォークをどうするかが検討課題となります。</p>\n<div class=\"code-block\" data-sourcepos=\"82:1-164:3\">\n<div class=\"code-filename\">\n<i class=\"fa fa-file-code-o\"></i>yaml</div>\n<div class=\"highlight\"><pre class=\"highlight yaml\"><code><span class=\"na\">deploy-stage-heroku</span><span class=\"pi\">:</span>\n  <span class=\"na\">steps</span><span class=\"pi\">:</span>\n    <span class=\"pi\">-</span> <span class=\"s\">bundle-install</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Install NodeJS</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">apt-get update</span>\n          <span class=\"s\">apt-get install -y nodejs</span>\n    <span class=\"pi\">-</span> <span class=\"s\">nabinno/heroku-install</span><span class=\"pi\">:</span>\n        <span class=\"na\">key</span><span class=\"pi\">:</span> <span class=\"s\">$HEROKU_KEY</span>\n        <span class=\"na\">user</span><span class=\"pi\">:</span> <span class=\"s\">$HEROKU_USER</span>\n        <span class=\"na\">app-name</span><span class=\"pi\">:</span> <span class=\"s\">$HEROKU_APP_NAME</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Fork Application - destroy application</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">heroku apps:destroy --app $HEROKU_APP_NAME --confirm $HEROKU_APP_NAME</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Fork Application - fork</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">heroku fork --from $FROM_HEROKU_APP_NAME --to $HEROKU_APP_NAME</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Fork Application - setup addons of rediscloud</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">heroku addons:create rediscloud:30 --app $HEROKU_APP_NAME</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Fork Application -change dynos</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">heroku ps:scale web=1:Free worker=1:Free --app $HEROKU_APP_NAME</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Fork Application - change environment variables</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">_rediscloud_url=$(heroku run 'env | grep -e REDISCLOUD_.*_URL' --app $HEROKU_APP_NAME | awk -F= '{print $2}')</span>\n          <span class=\"s\">heroku config:set \\</span>\n            <span class=\"s\">S3_BUCKET=$S3_BUCKET \\</span>\n            <span class=\"s\">HEROKU_APP=$HEROKU_APP_NAME \\</span>\n            <span class=\"s\">REDISCLOUD_URL=$_rediscloud_url \\</span>\n            <span class=\"s\">--app $HEROKU_APP_NAME</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Assets Precompile - restore assets cache</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">[ -e $WERCKER_CACHE_DIR/public/assets ] &amp;&amp; cp -fr $WERCKER_CACHE_DIR/public/assets $WERCKER_SOURCE_DIR/public || true</span>\n          <span class=\"s\">mkdir -p $WERCKER_SOURCE_DIR/tmp/cache</span>\n          <span class=\"s\">[ -e $WERCKER_CACHE_DIR/tmp/cache/assets ] &amp;&amp; cp -fr $WERCKER_CACHE_DIR/tmp/cache/assets $WERCKER_SOURCE_DIR/tmp/cache || true</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Assets Precompile - main process</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">RAILS_ENV=production bundle exec rake assets:precompile --trace</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Assets Precompile - store assets cache</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">mkdir -p $WERCKER_CACHE_DIR/public/assets</span>\n          <span class=\"s\">cp -fr $WERCKER_SOURCE_DIR/public/assets $WERCKER_CACHE_DIR/public</span>\n          <span class=\"s\">mkdir -p $WERCKER_CACHE_DIR/tmp/cache/assets</span>\n          <span class=\"s\">cp -fr $WERCKER_SOURCE_DIR/tmp/cache/assets $WERCKER_CACHE_DIR/tmp/cache</span>\n    <span class=\"pi\">-</span> <span class=\"na\">add-ssh-key</span><span class=\"pi\">:</span>\n        <span class=\"na\">host</span><span class=\"pi\">:</span> <span class=\"s\">github.com</span>\n        <span class=\"na\">keyname</span><span class=\"pi\">:</span> <span class=\"s\">GITHUB</span>\n    <span class=\"pi\">-</span> <span class=\"na\">add-to-known_hosts</span><span class=\"pi\">:</span>\n        <span class=\"na\">hostname</span><span class=\"pi\">:</span> <span class=\"s\">github.com</span>\n        <span class=\"na\">fingerprint</span><span class=\"pi\">:</span> <span class=\"s\">16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Assets Precompile - git commit</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">{</span>\n            <span class=\"s\">git add public/assets/.sprockets-manifest-*.json</span>\n            <span class=\"s\">git commit -m 'Run `rake assets:precompile` on Wercker.'</span>\n          <span class=\"s\">} || {</span>\n            <span class=\"s\">echo 'Skip: keep precompiled assets manifest.'</span>\n          <span class=\"s\">}</span>\n    <span class=\"pi\">-</span> <span class=\"na\">heroku-deploy</span><span class=\"pi\">:</span>\n        <span class=\"na\">key</span><span class=\"pi\">:</span> <span class=\"s\">$HEROKU_KEY</span>\n        <span class=\"na\">user</span><span class=\"pi\">:</span> <span class=\"s\">$HEROKU_USER</span>\n        <span class=\"na\">app-name</span><span class=\"pi\">:</span> <span class=\"s\">$HEROKU_APP_NAME</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">DB Migrate</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">heroku run 'bundle exec rake db:migrate --trace' --app $HEROKU_APP_NAME</span>\n  <span class=\"na\">after-steps</span><span class=\"pi\">:</span>\n    <span class=\"pi\">-</span> <span class=\"s\">wantedly/pretty-slack-notify</span><span class=\"pi\">:</span>\n        <span class=\"na\">webhook_url</span><span class=\"pi\">:</span> <span class=\"s\">${SLACK_WEBHOOK_URL}</span>\n        <span class=\"na\">channel</span><span class=\"pi\">:</span> <span class=\"s\">general</span>\n</code></pre></div>\n</div>\n<h2 data-sourcepos=\"166:1-166:39\" id=\"2-4-0\" name=\"2-4-0\">\n<a class=\"anchor\" id=\"deploy-prod-herokuパイプライン\" name=\"deploy-prod-heroku%E3%83%91%E3%82%A4%E3%83%97%E3%83%A9%E3%82%A4%E3%83%B3\" href=\"#deploy-prod-heroku%E3%83%91%E3%82%A4%E3%83%97%E3%83%A9%E3%82%A4%E3%83%B3\" data-position=\"2-4-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"deploy-prod-herokuパイプライン\"> &gt; deploy-prod-herokuパイプライン</span></a>deploy-prod-herokuパイプライン</h2>\n<p data-sourcepos=\"167:1-167:150\">deploy-prod-herokuパイプラインは本番環境へのリリース用。環境変数以外はdeploy-stageパイプラインと同じものです。</p>\n<div class=\"code-block\" data-sourcepos=\"169:1-231:3\">\n<div class=\"code-filename\">\n<i class=\"fa fa-file-code-o\"></i>yaml</div>\n<div class=\"highlight\"><pre class=\"highlight yaml\"><code><span class=\"na\">deploy-prod-heroku</span><span class=\"pi\">:</span>\n  <span class=\"na\">steps</span><span class=\"pi\">:</span>\n    <span class=\"pi\">-</span> <span class=\"s\">bundle-install</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Install NodeJS</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">apt-get update</span>\n          <span class=\"s\">apt-get install -y nodejs</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Assets Precompile - restore assets cache</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">[ -e $WERCKER_CACHE_DIR/public/assets ] &amp;&amp; cp -fr $WERCKER_CACHE_DIR/public/assets $WERCKER_SOURCE_DIR/public || true</span>\n          <span class=\"s\">mkdir -p $WERCKER_SOURCE_DIR/tmp/cache</span>\n          <span class=\"s\">[ -e $WERCKER_CACHE_DIR/tmp/cache/assets ] &amp;&amp; cp -fr $WERCKER_CACHE_DIR/tmp/cache/assets $WERCKER_SOURCE_DIR/tmp/cache || true</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Assets Precompile - main process</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">RAILS_ENV=production bundle exec rake assets:precompile --trace</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Assets Precompile - store assets cache</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">mkdir -p $WERCKER_CACHE_DIR/public/assets</span>\n          <span class=\"s\">cp -fr $WERCKER_SOURCE_DIR/public/assets $WERCKER_CACHE_DIR/public</span>\n          <span class=\"s\">mkdir -p $WERCKER_CACHE_DIR/tmp/cache/assets</span>\n          <span class=\"s\">cp -fr $WERCKER_SOURCE_DIR/tmp/cache/assets $WERCKER_CACHE_DIR/tmp/cache</span>\n    <span class=\"pi\">-</span> <span class=\"na\">add-ssh-key</span><span class=\"pi\">:</span>\n        <span class=\"na\">host</span><span class=\"pi\">:</span> <span class=\"s\">github.com</span>\n        <span class=\"na\">keyname</span><span class=\"pi\">:</span> <span class=\"s\">GITHUB</span>\n    <span class=\"pi\">-</span> <span class=\"na\">add-to-known_hosts</span><span class=\"pi\">:</span>\n        <span class=\"na\">hostname</span><span class=\"pi\">:</span> <span class=\"s\">github.com</span>\n        <span class=\"na\">fingerprint</span><span class=\"pi\">:</span> <span class=\"s\">16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Assets Precompile - git commit</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">{</span>\n            <span class=\"s\">git add public/assets/.sprockets-manifest-*.json</span>\n            <span class=\"s\">git commit -m 'Run `rake assets:precompile` on Wercker.'</span>\n          <span class=\"s\">} || {</span>\n            <span class=\"s\">echo 'Skip: keep precompiled assets manifest.'</span>\n          <span class=\"s\">}</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Add git-tag</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">_tag=$(date -u -d '9 hours' +%Y-%m-%d-%H-%M-%S)</span>\n          <span class=\"s\">git config --global user.email 'wercker@blahfe.com'</span>\n          <span class=\"s\">git config --global user.name 'Wercker Bot'</span>\n          <span class=\"s\">git tag -a $_tag master -m 'wercker deploy'</span>\n          <span class=\"s\">git push origin $_tag</span>\n    <span class=\"pi\">-</span> <span class=\"na\">heroku-deploy</span><span class=\"pi\">:</span>\n        <span class=\"na\">key</span><span class=\"pi\">:</span> <span class=\"s\">$HEROKU_KEY</span>\n        <span class=\"na\">user</span><span class=\"pi\">:</span> <span class=\"s\">$HEROKU_USER</span>\n        <span class=\"na\">app-name</span><span class=\"pi\">:</span> <span class=\"s\">$HEROKU_APP_NAME</span>\n        <span class=\"na\">install-toolbelt</span><span class=\"pi\">:</span> <span class=\"no\">true</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">DB Migrate</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">heroku run 'bundle exec rake db:migrate --trace' --app $HEROKU_APP_NAME</span>\n  <span class=\"na\">after-steps</span><span class=\"pi\">:</span>\n    <span class=\"pi\">-</span> <span class=\"s\">wantedly/pretty-slack-notify</span><span class=\"pi\">:</span>\n        <span class=\"na\">webhook_url</span><span class=\"pi\">:</span> <span class=\"s\">${SLACK_WEBHOOK_URL}</span>\n        <span class=\"na\">channel</span><span class=\"pi\">:</span> <span class=\"s\">general</span>\n</code></pre></div>\n</div>\n<h2 data-sourcepos=\"233:1-233:36\" id=\"2-5-0\" name=\"2-5-0\">\n<a class=\"anchor\" id=\"deploy-prod-gaeパイプライン\" name=\"deploy-prod-gae%E3%83%91%E3%82%A4%E3%83%97%E3%83%A9%E3%82%A4%E3%83%B3\" href=\"#deploy-prod-gae%E3%83%91%E3%82%A4%E3%83%97%E3%83%A9%E3%82%A4%E3%83%B3\" data-position=\"2-5-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"deploy-prod-gaeパイプライン\"> &gt; deploy-prod-gaeパイプライン</span></a>deploy-prod-gaeパイプライン</h2>\n<p data-sourcepos=\"234:1-234:186\">deploy-prod-gaeパイプラインはdeploy-prod-herokuパイプラインと同じく本番環境へのリリース用。GAEにいつでも移行できるように走らせています。</p>\n<p data-sourcepos=\"236:1-236:787\">GAEのデプロイは癖があって、<code>gcloud app deploy</code>コマンドをつかってDockerビルドを走らせますが、その時にDocker内に外部から環境変数を設定することができません。そのため、アセットプリコンパイルのビルドの際、<code>asset_sync</code>を使っていると別サーバーへ同期に失敗します。また、パイプライン上の別ステップに環境変数を当てて行うことはできるが、<code>gcloud</code>のデプロイステップとアセットプリコンパイルが重複して適切なダイジェストを発行できません。従って、GAEをつかう場合は <code>./public</code> ディレクトリをつかうのが現状の正解です。HerokuのSlugの取り扱い方針と違うので注意が必要です。</p>\n<p data-sourcepos=\"238:1-238:138\">GAEのコンテナの中身は、<code>gcloud beta app gen-config --runtime=ruby --custom</code> で出力されるDockerfileを参照ください。</p>\n<div class=\"code-block\" data-sourcepos=\"240:1-281:3\">\n<div class=\"code-filename\">\n<i class=\"fa fa-file-code-o\"></i>yaml</div>\n<div class=\"highlight\"><pre class=\"highlight yaml\"><code><span class=\"na\">deploy-prod-gae</span><span class=\"pi\">:</span>\n  <span class=\"na\">steps</span><span class=\"pi\">:</span>\n    <span class=\"pi\">-</span> <span class=\"s\">bundle-install</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Install ImageMagick</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">apt-get update</span>\n          <span class=\"s\">apt-get install -y nodejs imagemagick</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Echo Ruby information</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">env</span>\n          <span class=\"s\">echo \"ruby version $(ruby --version) running!\"</span>\n          <span class=\"s\">echo \"from location $(which ruby)\"</span>\n          <span class=\"s\">echo -p \"gem list: $(gem list)\"</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">DB Migrate</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">RAILS_ENV=production \\</span>\n            <span class=\"s\">DATABASE_URL=${DATABASE_URL} \\</span>\n            <span class=\"s\">bundle exec rake db:create db:migrate --trace</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Install gcloud</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">curl https://sdk.cloud.google.com | bash</span>\n          <span class=\"s\">source ~/.bashrc</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Authenticate gcloud</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">gcloud config set project utagaki-v2</span>\n          <span class=\"s\">openssl aes-256-cbc -k ${DECRYPT_KEY} -d -in ./gcloud.json.encrypted -out ./gcloud.json</span>\n          <span class=\"s\">gcloud auth activate-service-account --key-file ./gcloud.json</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Deploy app to Google App Engine</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">gcloud app deploy ./app.yaml --promote --stop-previous-version</span>\n  <span class=\"na\">after-steps</span><span class=\"pi\">:</span>\n    <span class=\"pi\">-</span> <span class=\"s\">wantedly/pretty-slack-notify</span><span class=\"pi\">:</span>\n        <span class=\"na\">webhook_url</span><span class=\"pi\">:</span> <span class=\"s\">${SLACK_WEBHOOK_URL}</span>\n        <span class=\"na\">channel</span><span class=\"pi\">:</span> <span class=\"s\">general</span>\n</code></pre></div>\n</div>\n<h2 data-sourcepos=\"283:1-283:32\" id=\"2-6-0\" name=\"2-6-0\">\n<a class=\"anchor\" id=\"post-deployパイプライン\" name=\"post-deploy%E3%83%91%E3%82%A4%E3%83%97%E3%83%A9%E3%82%A4%E3%83%B3\" href=\"#post-deploy%E3%83%91%E3%82%A4%E3%83%97%E3%83%A9%E3%82%A4%E3%83%B3\" data-position=\"2-6-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"post-deployパイプライン\"> &gt; post-deployパイプライン</span></a>post-deployパイプライン</h2>\n<p data-sourcepos=\"284:1-284:142\">post-deployパイプラインは本番環境にデプロイした後の後処理用です。参考程度に <code>git tag</code> をつけています。</p>\n<div class=\"code-block\" data-sourcepos=\"286:1-308:3\">\n<div class=\"code-filename\">\n<i class=\"fa fa-file-code-o\"></i>yaml</div>\n<div class=\"highlight\"><pre class=\"highlight yaml\"><code><span class=\"na\">post-deploy</span><span class=\"pi\">:</span>\n  <span class=\"na\">steps</span><span class=\"pi\">:</span>\n    <span class=\"pi\">-</span> <span class=\"na\">add-ssh-key</span><span class=\"pi\">:</span>\n        <span class=\"na\">host</span><span class=\"pi\">:</span> <span class=\"s\">github.com</span>\n        <span class=\"na\">keyname</span><span class=\"pi\">:</span> <span class=\"s\">GITHUB</span>\n    <span class=\"pi\">-</span> <span class=\"na\">add-to-known_hosts</span><span class=\"pi\">:</span>\n        <span class=\"na\">hostname</span><span class=\"pi\">:</span> <span class=\"s\">github.com</span>\n        <span class=\"na\">fingerprint</span><span class=\"pi\">:</span> <span class=\"s\">16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48</span>\n    <span class=\"pi\">-</span> <span class=\"na\">script</span><span class=\"pi\">:</span>\n        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Add git-tag</span>\n        <span class=\"na\">code</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">_tag=$(date -u -d '9 hours' +%Y-%m-%d-%H-%M-%S)</span>\n          <span class=\"s\">git remote add origin git@github.com:nabinno/utagaki.git</span>\n          <span class=\"s\">git config --global user.email 'wercker@blahfe.com'</span>\n          <span class=\"s\">git config --global user.name 'Wercker Bot'</span>\n          <span class=\"s\">git tag -a $_tag master -m 'wercker deploy'</span>\n          <span class=\"s\">git push origin $_tag</span>\n  <span class=\"na\">after-steps</span><span class=\"pi\">:</span>\n    <span class=\"pi\">-</span> <span class=\"s\">wantedly/pretty-slack-notify</span><span class=\"pi\">:</span>\n        <span class=\"na\">webhook_url</span><span class=\"pi\">:</span> <span class=\"s\">${SLACK_WEBHOOK_URL}</span>\n        <span class=\"na\">channel</span><span class=\"pi\">:</span> <span class=\"s\">general</span>\n</code></pre></div>\n</div>\n<h1 data-sourcepos=\"310:1-310:8\" id=\"3-0-0\" name=\"3-0-0\">\n<a class=\"anchor\" id=\"WRAPUP\" name=\"WRAPUP\" href=\"#WRAPUP\" data-position=\"3-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"WRAPUP\"> &gt; WRAPUP</span></a>WRAPUP</h1>\n<p data-sourcepos=\"311:1-311:276\">こうしてWerckerの設定ファイルを書いてみるに、どのCI、どの仮想環境も同じ書き味ということが分かります。当処懸念していたDocker化することによる嵌まり事はなく、すんなり移行することができました。</p>\n<p data-sourcepos=\"313:1-313:104\">手軽さ、管理のしやすさから、今後はすべてのCIがDockerに移行するでしょう。</p>\n","tags":["wercker","docker","heroku","google-app-engine"],"updated_at":"2021-01-16T12:13:04+09:00","childPublishedDate":{"published_on":"2017-02-07T00:00:00.000Z"},"updated_by":{"name":"なびの👷","screen_name":"nabinno","icon":"https://img.esa.io/uploads/production/members/94286/icon/thumb_m_ef5f024307008aa399b91f87fa5f64e8.jpg"}},"relatedPosts":{"edges":[{"node":{"number":65,"relative_category":"blog/backend","fields":{"title":"LYSE本を読む","excerpt":"Elixirの存在を知ったのが2014年7月14日。それからおよそ3年経つというのに一向に理解した気になれないでいます。特にSLAナイン・ナインはなぜその数値なのか腑に落ちないでいました。今回『Learn You Some Erlang for Great Good!（通称LYSE本）』を読むことで積年の謎を解明してみようと臨みました。   > PROBLEMPROBLEM \n\n- Elixirをさわりはじめてしばらく経つけどふかく理解した気になれない\n- Phoenixやほかのフレームワークに頼られないケースが出てきたとき自由な発想ができるようになっておきたい\n- 巷でいわれているSLAナイン・ナイン（99.9999999%）などの実際がどうなのか腹落ちしてない   > TLDRTLDR \n\n- 下記Erlang機能を中心に高いSLAを提供する素地をなしている 分散システム Erlang Port Mapper Daemon（EPMD） 他の言語・フレームワークが「分散コンピューティングの落とし穴」「CAP定理」にどのように対応している比較すると、Erlangの特徴がより見えてくる。 EMPDの特徴 耐障害性（スケーリングはやや弱い） マルチプロセス ネットワークの障害監視 ライフサイクル、再起動戦略を備えたライブラリ（分散OTP） CPシステムでNoSQLデータベース「Mnesia」 \n- 分散システム Erlang Port Mapper Daemon（EPMD） 他の言語・フレームワークが「分散コンピューティングの落とし穴」「CAP定理」にどのように対応している比較すると、Erlangの特徴がより見えてくる。 EMPDの特徴 耐障害性（スケーリングはやや弱い） マルチプロセス ネットワークの障害監視 \n- 他の言語・フレームワークが「分散コンピューティングの落とし穴」「CAP定理」にどのように対応している比較すると、Erlangの特徴がより見えてくる。\n- EMPDの特徴 耐障害性（スケーリングはやや弱い） マルチプロセス ネットワークの障害監視 \n- 耐障害性（スケーリングはやや弱い）\n- マルチプロセス\n- ネットワークの障害監視\n- ライフサイクル、再起動戦略を備えたライブラリ（分散OTP）\n- CPシステムでNoSQLデータベース「Mnesia」   > SOLUTIONSOLUTION \n\nというわけで、「LYSE本」を読むことにしました。各セクションにはElixirに関係ありそうな箇所を抜粋しています。長い長いメモになるので、TLDRだけで済ませて問題ありません。結論、輪郭は見えてきましたがまだその探求の入り口に来たに過ぎないのだということは理解しました。   > 1-3 Erlang概要1-3 Erlang概要   > 1.2 Erlangって何？1.2 Erlangって何？ \n\n- 関数型言語 純粋主義（参照透過性、破壊的データを避けるなど）に従いつつ、実世界で問題が発生した場合はそれを取り払う \n- 純粋主義（参照透過性、破壊的データを避けるなど）に従いつつ、実世界で問題が発生した場合はそれを取り払う\n- アクターモデル 同時並行性 高可用性 Ex: Blue-Green deployment Log management Policy: Let it crash - クラッシュするならさせておけ As bad as anything else let it crashが生んだ誤解 \n- 同時並行性\n- 高可用性\n- Ex: Blue-Green deployment Log management \n- Blue-Green deployment\n- Log management\n- Policy: Let it crash - クラッシュするならさせておけ As bad as anything else let it crashが生んだ誤解 \n- Let it crash - クラッシュするならさせておけ As bad as anything else let it crashが生んだ誤解 \n- As bad as anything else\n- let it crashが生んだ誤解\n- 開発環境 クロスプラットフォーム BEAM 開発ツール コンパイラ デバッガ プロファイラ テストフレームワーク \n- クロスプラットフォーム BEAM \n- BEAM\n- 開発ツール コンパイラ デバッガ プロファイラ テストフレームワーク \n- コンパイラ\n- デバッガ\n- プロファイラ\n- テストフレームワーク\n- ライブラリ OTPフレームワーク Webサーバー パーサジェネレータ Mnesiaデータベース \n- OTPフレームワーク\n- Webサーバー\n- パーサジェネレータ\n- Mnesiaデータベース   > 1.3 Don't drink too much Kool-Aid1.3 Don't drink too much Kool-Aid \n\n- 軽量プロセスによるスケール タスクを細かく分けすぎる＝むやみに並行処理させると処理速度に影響がでる \n- タスクを細かく分けすぎる＝むやみに並行処理させると処理速度に影響がでる\n- CPUコア数によるスケール すべてを同時に稼働させることができない \n- すべてを同時に稼働させることができない\n- 技術領域 適切でない技術領域 画像処理 信号処理 OSのデバイスドライバ 適切な技術領域 巨大なサーバソフトウェア - QMS, MapReduce 多言語との接続 高レベルプロトコルの実装 Ex: IANOというUNICTチームが作成したロボット Wings 3D \n- 適切でない技術領域 画像処理 信号処理 OSのデバイスドライバ \n- 画像処理\n- 信号処理\n- OSのデバイスドライバ\n- 適切な技術領域 巨大なサーバソフトウェア - QMS, MapReduce 多言語との接続 高レベルプロトコルの実装 Ex: IANOというUNICTチームが作成したロボット Wings 3D \n- 巨大なサーバソフトウェア - QMS, MapReduce\n- 多言語との接続\n- 高レベルプロトコルの実装\n- Ex: IANOというUNICTチームが作成したロボット Wings 3D \n- IANOというUNICTチームが作成したロボット\n- Wings 3D   > 3.2. 変化できない変数3.2. 変化できない変数 \n\n- パターンマッチング（= 演算子） 比較の役割も果たしている 値が違っていたらエラーを出す 値が同じだったら当該の値を返す \n- 比較の役割も果たしている 値が違っていたらエラーを出す 値が同じだったら当該の値を返す \n- 値が違っていたらエラーを出す\n- 値が同じだったら当該の値を返す   erlang \n\n> 47 = 45 + 2. > 47 = 45 + 3. ** exception error: no match of right hand side value 48   \n\n- アンダースコア変数（_） 使用はできるが値の格納はできない \n- 使用はできるが値の格納はできない   erlang \n\n> _ = 14+3. 17 > _. * 1: variable '_' is unbound     > 3.3. アトム3.3. アトム \n\n- アトムと予約語 いくつかのアトムは予約語 after and andalso band begin bnot bor bsl bsr bxor case catch cond div end fun if let not of or orelse query receive rem try when xor false true \n- いくつかのアトムは予約語 after and andalso band begin bnot bor bsl bsr bxor case catch cond div end fun if let not of or orelse query receive rem try when xor false true \n- after and andalso band begin bnot bor bsl bsr bxor case catch cond div end fun if let not of or orelse query receive rem try when xor false true   > 3.4. ブール代数と比較演算子3.4. ブール代数と比較演算子 \n\n- false trueはアトムなので数値の代替にはならない\n- アトムなどのほかの型も比較対象になる number < atom < reference < fun < port < pid < tuple < list < bit string \n- number < atom < reference < fun < port < pid < tuple < list < bit string   erlang \n\n> 0 == false. false > 1 < false. true     > 3.8. ビット構文!3.8. ビット構文! \n\n- Erlangはおもいデータを数値処理するにはむいてない\n- 一方、数値処理が必要ないアプリケーションの中では速い 次のような処理にむいている イベントに反応する イベントをミリ秒単位でしょりできリアルタイムアプリケーションに適している メッセージングパッシング アトムをつかうと軽く処理できる \n- 次のような処理にむいている イベントに反応する イベントをミリ秒単位でしょりできリアルタイムアプリケーションに適している メッセージングパッシング アトムをつかうと軽く処理できる \n- イベントに反応する イベントをミリ秒単位でしょりできリアルタイムアプリケーションに適している \n- イベントをミリ秒単位でしょりできリアルタイムアプリケーションに適している\n- メッセージングパッシング アトムをつかうと軽く処理できる \n- アトムをつかうと軽く処理できる\n- 軽量なビット文字列 Pros リストで表現する文字列は1文字につき1ノード ビット文字列はC言語の配列のようなもの - <<\"this is a bit string!\">> Cons パターンマッチなどの捜査の際に単純さが失われる \n- Pros リストで表現する文字列は1文字につき1ノード ビット文字列はC言語の配列のようなもの - <<\"this is a bit string!\">> \n- リストで表現する文字列は1文字につき1ノード\n- ビット文字列はC言語の配列のようなもの - <<\"this is a bit string!\">> \n- Cons パターンマッチなどの捜査の際に単純さが失われる \n- パターンマッチなどの捜査の際に単純さが失われる   > 4-5 パターンマッチング4-5 パターンマッチング \n\n4-5章からIDEがないとreplなどに時間がとられるので整備しておこう。Emacsならerlang.elがある。インデント、フィルコメント、コメントアウト、OTPなどのscafold、Eshell、コンパイル等ひととおりそろっている。   > 5.5. 関数呼び出しによるパターンマッチガードはcase文よりも優れているのか？5.5. 関数呼び出しによるパターンマッチガードはcase文よりも優れているのか？ \n\nまず、パフォーマンス上かわらない。 \n\nつぎに、引数が複数あるときは関数をつかう。   erlang \n\nbeach(Temperature) -> case Temperature of {celsius, N} when N > 20 andalso N =< 45 -> 'favorable'; {kelvin, N} when N >= 293 andalso N =< 318 -> 'scientifically favorable'; {fahrenheit, N} when N >= 68 andalso N =< 113 -> 'favorable in the US'; _ -> 'avoid beach' end.   \n\n上記のようだと可読性がさがる、冗長的。以下のように関数でまとめる。   erlang \n\nbeachf({celsius, N}) when N >= 20 andalso N =< 45 -> 'favorable'; beachf({kelvin, N}) when N >=293 andalso N =< 318 -> 'scientifically favorable'; beachf({fahrenheit, N}) when N >= 68 andalso N =< 113 -> 'favorable in the US'; beachf(_) -> 'avoid beach'.   \n\nただし、引数が評価関数の対象の場合はcase文が向いている。   erlang \n\nprepend(X, []) -> [X]; prepend(X, Set) -> case lists:member(X, Set) of true -> Set; false -> [X | Set] end.     > 6-11 文法6-11 文法 \n\n- 今回は標準文法について Erlangの特徴はざっと次の通り 型変換の関数が素朴 erlang:<type>_to_<type> という形式をとっているため、型が追加されるたびに変換用関数を BIF (built-in function) に追加しなければいけない 再帰、無名関数、エラーは普通、Ruby, JSっぽい レコードによってインターフェイスを定義できる データ構造にキーバリューストア、セット、配列、有効グラフ、キューがある ただ配列は、他の手続き型言語の配列とは逆に、一定時間での挿入や検索ができない Erlangでなされるプログラミングスタイルでは配列や行列と結びつける必要がなく、実際にはめったに使われないため \n- Erlangの特徴はざっと次の通り 型変換の関数が素朴 erlang:<type>_to_<type> という形式をとっているため、型が追加されるたびに変換用関数を BIF (built-in function) に追加しなければいけない 再帰、無名関数、エラーは普通、Ruby, JSっぽい レコードによってインターフェイスを定義できる データ構造にキーバリューストア、セット、配列、有効グラフ、キューがある ただ配列は、他の手続き型言語の配列とは逆に、一定時間での挿入や検索ができない Erlangでなされるプログラミングスタイルでは配列や行列と結びつける必要がなく、実際にはめったに使われないため \n- 型変換の関数が素朴 erlang:<type>_to_<type> という形式をとっているため、型が追加されるたびに変換用関数を BIF (built-in function) に追加しなければいけない \n- erlang:<type>_to_<type> という形式をとっているため、型が追加されるたびに変換用関数を BIF (built-in function) に追加しなければいけない\n- 再帰、無名関数、エラーは普通、Ruby, JSっぽい\n- レコードによってインターフェイスを定義できる\n- データ構造にキーバリューストア、セット、配列、有効グラフ、キューがある ただ配列は、他の手続き型言語の配列とは逆に、一定時間での挿入や検索ができない Erlangでなされるプログラミングスタイルでは配列や行列と結びつける必要がなく、実際にはめったに使われないため \n- ただ配列は、他の手続き型言語の配列とは逆に、一定時間での挿入や検索ができない Erlangでなされるプログラミングスタイルでは配列や行列と結びつける必要がなく、実際にはめったに使われないため \n- Erlangでなされるプログラミングスタイルでは配列や行列と結びつける必要がなく、実際にはめったに使われないため   > 7. 再帰7. 再帰 \n\n- lists モジュール sort/1 join/2 last/1 flatten/1 all/1 reverse/1 map/2 filter/2 \n- sort/1\n- join/2\n- last/1\n- flatten/1\n- all/1\n- reverse/1\n- map/2\n- filter/2\n- gb_tree モジュール lookup/2 map/2 \n- lookup/2\n- map/2   > 8.2. 無名関数8.2. 無名関数   erlang \n\n> (fun() -> a end)(). a > lists:filter(fun(X) -> X rem 2 == 0 end, lists:seq(1, 10)). [2,4,6,8,10]     > 9. エラー9. エラー コンパイル時エラー    type error description     Module Module name 'madule' does not match file name 'module'  -module 属性内に書いたモジュール名がファイル名と一致していない   Function Warning: function somefunction/0 is unused 関数を公開していない、あるいはその関数が使われている場所が間違った関数名やアリティになっている   Function function somefunction/1 undefined 関数が存在していない:  -export 属性内あるいは関数を宣言するときに間違った関数名やアリティを書いてる   Function head mismatch 関数定義を他の関数での先頭の節の間に差し込んでいる   Syntax syntax error before: 'SomeCharacterOrWord' Ex: 括弧の閉じ忘れやタプルやおかしな式接尾辞、予約語・おかしな文字コードにエンコードされたUnicode文字の使用   Syntax syntax error before: 行末がおかしい   Variable Warning: this expression will fail with a 'badarith' exception Ex: llama + 5    Variable Warning: a term is constructed, but never used 関数の中に、リス作成、タプル宣言、どんな変数にも束縛されていない無名関数・自身を返す無名関数の宣言がある   Variable Warning: variable 'Var' is unused 使わない変数を宣言している   Variable Warning: this clause cannot match because a previous clause at line 4 always matches モジュール内で定義された関数が catch-all 節のあとに特定の節を持っている   Variable variable 'A' unsafe in 'case'  case ... of の中で宣言されている変数を、その外側で使っている    ランタイムエラー (exception error)    type error description     function clause no function clause matching somefunction 関数内のすべてのガード節で失敗、あるいはすべてのパターンマッチで失敗   case clause no case clause matching 'value' 条件の書き忘れ、誤った種類のデータ送信、 catch-all 節が必要な場合   if clause no true branch found when evaluating an if expression 条件の書き忘れ、 catch-all 節が必要な場合   badmatch no match of right hand side value 無理なパターンマッチ、変数束縛の繰り返し   badarg bad argument 誤った引数の呼び出し   undef undefined function somefunction 未定義関数の呼び出し   badarith bad argument in an arithmetic expression 誤った算術演算   badfun bad function 変数を関数として呼び出した場合   badarity interpreted function with arity 1 called with two arguments 誤ったアリティ    例外処理   erlang \n\n1> erlang:error(badarith). ** exception error: bad argument in an arithmetic expression 2> erlang:error(custom_error). ** exception error: custom_error     > 11.2 レコード11.2 レコード   erlang \n\n-record(robot, {name, type=industrial, hobbies, details=[]}).     erlang \n\n5> Crusher = #robot{name=\"Crusher\", hobbies=[\"Crushing people\",\"petting cats\"]}. #robot{name = \"Crusher\",type = industrial, hobbies = [\"Crushing people\",\"petting cats\"], details = []} 6> Crusher#robot.hobbies. %% 参照 [\"Crushing people\",\"petting cats\"] 7> NestedBot = #robot{details=#robot{name=\"erNest\"}}. #robot{name = undefined,type = industrial, hobbies = undefined, details = #robot{name = \"erNest\",type = industrial, hobbies = undefined,details = []}} 8> NestedBot#robot.details#robot.name. %% ネスト参照 \"erNest\"     > 11.3. キーバリューストア11.3. キーバリューストア \n\nキーバリューストアは4つのモジュールで提供されている。    module methods description     proplist  get_value/2, get_all_values/2, lookup/2, lookup_all/2  少量データ向け, 緩いデータ構造   orddict  store/3, find/2, fetch/2, erase/2  少量データ向け（75要素くらい）   dict  store/3, find/2, fetch/2, erase/2, map/2, fold/2  大量データ向け、ordict と同じインターフェイス   gb_trees  enter/2, lookup/2, delete_any/2, insert/3, get/2, update/3, delete/2  大量データ向け、データ構造の入出力がわかるスマートモードとわからないネイティブモードがあるため状況に応じて安全性とパフォーマンスのバランスを取ることができる      > 11.5.セット11.5.セット \n\nセット（集合）は4つのモジュールで提供されている。    module methods description     ordsets  new/0, is_element/2, add_element/2, del_element/2, union/1, intersection/1  少量セット向け、遅いが可読性が高い   sets - 大量セット向け、ordsets と同じインターフェイス   gb_sets - 大量セット向け、スマートモード・ネイティブモードがあるため状況に応じ安全性とパフォーマンスのバランスを取ることができる   sofs - 一意な要素の集合だけではなく、数学的な概念として集合が必要な場合      > 11.6. 有効グラフ11.6. 有効グラフ \n\n有効グラフは2つのモジュールで提供されている。    module description     digraph 生成、変更、エッジ・辺の操作、経路・周の検索   digraph_utils グラフの誘導、木のテスト、隣接ノードの検索      > 11.7. キュー11.7. キュー \n\nqueue モジュール    api methods description     Original API  new/0, in/2, out/1  キューの作成・削除   Extended API  get/1, peek/1, drop/1  キューの中身の確認   Okasaki API - 関数型データ構造にもとづく      > 12-13 並列性について12-13 並列性について   > 12.2.1. 並列性の概念12.2.1. 並列性の概念 \n\n- Erlangの開発の背景 大抵の人は並行ソフトウェアを書くことにうんざりしてる 並行の解決策のほとんどがロックやミューテックスと呼ばれる小さな理論を扱うことに終始する 通信業界では並行性・並列性をめざす文化があった PLEX AXE \n- 大抵の人は並行ソフトウェアを書くことにうんざりしてる 並行の解決策のほとんどがロックやミューテックスと呼ばれる小さな理論を扱うことに終始する \n- 並行の解決策のほとんどがロックやミューテックスと呼ばれる小さな理論を扱うことに終始する\n- 通信業界では並行性・並列性をめざす文化があった PLEX AXE \n- PLEX\n- AXE\n- 満たすべき要求 スケーラビリティ リニアスケールが可能 実装方針 小さなプロセス プロセスに共有メモリの使用を禁じる フォールトレランス (交換機上の何千ものユーザをサポートすること) クラッシュが可能 クラッシュ後リスタートが可能 実装方針 分散 非同期メッセージングパッシング \n- スケーラビリティ リニアスケールが可能 実装方針 小さなプロセス プロセスに共有メモリの使用を禁じる \n- リニアスケールが可能\n- 実装方針 小さなプロセス プロセスに共有メモリの使用を禁じる \n- 小さなプロセス\n- プロセスに共有メモリの使用を禁じる\n- フォールトレランス (交換機上の何千ものユーザをサポートすること) クラッシュが可能 クラッシュ後リスタートが可能 実装方針 分散 非同期メッセージングパッシング \n- クラッシュが可能\n- クラッシュ後リスタートが可能\n- 実装方針 分散 非同期メッセージングパッシング \n- 分散\n- 非同期メッセージングパッシング\n- 実装 並列・並行に最適化されたVM コア1つに対してスケジューラとして1つのスケジューラを起動 実行キューにあるタスクが多すぎた場合、他スレッドのスケジューラに移される 過負荷なプロセスに対して送れるメッセージ量を制御 \n- 並列・並行に最適化されたVM コア1つに対してスケジューラとして1つのスケジューラを起動 実行キューにあるタスクが多すぎた場合、他スレッドのスケジューラに移される 過負荷なプロセスに対して送れるメッセージ量を制御 \n- コア1つに対してスケジューラとして1つのスケジューラを起動\n- 実行キューにあるタスクが多すぎた場合、他スレッドのスケジューラに移される\n- 過負荷なプロセスに対して送れるメッセージ量を制御   > 12.3. すべてが線形にスケールするわけではない12.3. すべてが線形にスケールするわけではない \n\n- アムダールの法則 50%並行にしたコードは2倍ほど速くなる 95%並行にしたコードは20倍ほど速くなる \n- 50%並行にしたコードは2倍ほど速くなる\n- 95%並行にしたコードは20倍ほど速くなる   > 14 プロセス間通信14 プロセス間通信 \n\n- 今回は2つのプロセス間通信のプロセス管理について 片方のプロセスがエラーになっても、もう片方のプロセスが死なないようにする プロセスがエラーになったものはクラッシュさせる クラッシュしたプロセスをリスタートさせる また、そのクラッシュ情報をもう片方にメッセージとして送る \n- 片方のプロセスがエラーになっても、もう片方のプロセスが死なないようにする プロセスがエラーになったものはクラッシュさせる クラッシュしたプロセスをリスタートさせる また、そのクラッシュ情報をもう片方にメッセージとして送る \n- プロセスがエラーになったものはクラッシュさせる クラッシュしたプロセスをリスタートさせる \n- クラッシュしたプロセスをリスタートさせる\n- また、そのクラッシュ情報をもう片方にメッセージとして送る   > エラーとプロセスエラーとプロセス \n\n以下、3つの関数をつかい実装する。 \n\n1. erlang:exit(Pid, Why) - Pid に対して自分が異常終了で死んだとつたえる。自身は死なない。\n2. erlang:process_flag(trap_exit, Value) - Value が true ならシステムプロセスとなり、 false ならシステムプロセスでなくなる。デフォルトは false。この関数によりクラッシュしたプロセスをリスタートさせる\n3. erlang:register(Atom, Pid) と erlang:make_ref() - register/2 で予測不可能な Pid を Atom として登録し、make_ref/0 で生成された Reference をもとにメッセージ送信をおこなう。なお、ここで生成される Reference は同一Erlang VM上、あるいはクラスタリングしたVM上のみでユニークになる。   erlang \n\nstart_critic2() -> spawn(?MODULE, restarter, []). restarter() -> process_flag(trap_exit, true), Pid = spawn_link(?MODULE, critic2, []), register(critic2, Pid), receive {'EXIT', Pid, normal} -> % not a crash  ok; {'EXIT', Pid, shutdown} -> % manual termination, not a crash  ok; {'EXIT', Pid, _} -> restarter() end. judge2(Band, Album) -> Ref = make_ref(), critic2 ! {self(), Ref, {Band, Album}}, receive {Ref, Criticism} -> Criticism after 2000 -> timeout end. critic2() -> receive {From, Ref, {\"Rage Against the Turing Machine\", \"Unit Testify\"}} -> From ! {Ref, \"They are great!\"}; {From, Ref, {\"System of a Downtime\", \"Memoize\"}} -> From ! {Ref, \"They're not Johnny Crash but they're good.\"}; {From, Ref, {\"Johnny Crash\", \"The Token Ring of Fire\"}} -> From ! {Ref, \"Simply incredible.\"}; {From, Ref, {_Band, _Album}} -> From ! {Ref, \"They are terrible!\"} end, critic2().     erlang \n\n27> functions:start_critic2(). <0.125.0> 28> functions:judge2(\"The Doors\", \"Light my Firewall\"). \"They are terrible!\" 29> exit(whereis(critic2), kill). true 30> whereis(critic2). <0.129.0> 31> functions:judge2(\"The Doors\", \"Light my Firewall\"). \"They are terrible!\"     > 15 アプリケーションを作成する15 アプリケーションを作成する   > リマインダーアプリケーションリマインダーアプリケーション \n\n- 仕様 イベントを追加 イベントには締切り（警告する時間）、イベント名、詳細が含まれます イベントの時間が来たら警告 イベント名でイベントをキャンセル 永続的なディスク保存先を持たない 注 これは今回見ようとしているのアーキテクチャの概念を示すのに必要ありません これは実際のアプリケーションを作るなら全然ダメなことですが、代わりにもし実装したくなったらその機能はどこに挿入されるかを示して、ちょっとだけその実装の手助けになる関数も示します 永続化保存先がないとした場合、実行中にコードを更新しなければいけません ソフトウェアとのやりとりはコマンドライン経由で あとでこれは拡張できる たとえばGUI、Webページアクセス、IMソフト、メールなど \n- イベントを追加 イベントには締切り（警告する時間）、イベント名、詳細が含まれます \n- イベントには締切り（警告する時間）、イベント名、詳細が含まれます\n- イベントの時間が来たら警告\n- イベント名でイベントをキャンセル\n- 永続的なディスク保存先を持たない 注 これは今回見ようとしているのアーキテクチャの概念を示すのに必要ありません これは実際のアプリケーションを作るなら全然ダメなことですが、代わりにもし実装したくなったらその機能はどこに挿入されるかを示して、ちょっとだけその実装の手助けになる関数も示します 永続化保存先がないとした場合、実行中にコードを更新しなければいけません \n- 注 これは今回見ようとしているのアーキテクチャの概念を示すのに必要ありません これは実際のアプリケーションを作るなら全然ダメなことですが、代わりにもし実装したくなったらその機能はどこに挿入されるかを示して、ちょっとだけその実装の手助けになる関数も示します \n- これは今回見ようとしているのアーキテクチャの概念を示すのに必要ありません\n- これは実際のアプリケーションを作るなら全然ダメなことですが、代わりにもし実装したくなったらその機能はどこに挿入されるかを示して、ちょっとだけその実装の手助けになる関数も示します\n- 永続化保存先がないとした場合、実行中にコードを更新しなければいけません\n- ソフトウェアとのやりとりはコマンドライン経由で あとでこれは拡張できる たとえばGUI、Webページアクセス、IMソフト、メールなど \n- あとでこれは拡張できる たとえばGUI、Webページアクセス、IMソフト、メールなど \n- たとえばGUI、Webページアクセス、IMソフト、メールなど\n- ユースケース Client イベントサーバをサブスクライブして、メッセージとして通知を受ける こうすることで、すべてイベントサーバをサブスクライブしている多くのクライアントを設計するのが簡単になる 各クライアントは潜在的に、前述した異なるゲートウェイとなる GUI、Webページ、IMソフト、メールなど サーバにイベントを詳細情報とともに追加するように依頼 サーバにイベントをキャンセルするように依頼 サーバを（落ちたかどうか知る為に）監視 必要があればイベントサーバを終了 Event Server メソッド クライアントからのサブスクライブを受取 イベントプロセスから出された通知を各サブスクライバに転送 イベントを追加するためにメッセージを受取 必要なX, Y, Zプロセスを起動 イベントキャンセルのメッセージを受取 イベントプロセスを殺す クライアントから終了できる シェルから自分自身のコードを再読込出来る Process X, Y, Z 発報が待たれる通知を表す 天気にはイベントサーバにリンクされたタイマーに過ぎない 時間が来たらイベントサーバにメッセージを送る キャンセルのメッセージを受け取って死ぬ \n- Client イベントサーバをサブスクライブして、メッセージとして通知を受ける こうすることで、すべてイベントサーバをサブスクライブしている多くのクライアントを設計するのが簡単になる 各クライアントは潜在的に、前述した異なるゲートウェイとなる GUI、Webページ、IMソフト、メールなど サーバにイベントを詳細情報とともに追加するように依頼 サーバにイベントをキャンセルするように依頼 サーバを（落ちたかどうか知る為に）監視 必要があればイベントサーバを終了 \n- イベントサーバをサブスクライブして、メッセージとして通知を受ける こうすることで、すべてイベントサーバをサブスクライブしている多くのクライアントを設計するのが簡単になる 各クライアントは潜在的に、前述した異なるゲートウェイとなる GUI、Webページ、IMソフト、メールなど \n- こうすることで、すべてイベントサーバをサブスクライブしている多くのクライアントを設計するのが簡単になる\n- 各クライアントは潜在的に、前述した異なるゲートウェイとなる GUI、Webページ、IMソフト、メールなど \n- GUI、Webページ、IMソフト、メールなど\n- サーバにイベントを詳細情報とともに追加するように依頼\n- サーバにイベントをキャンセルするように依頼\n- サーバを（落ちたかどうか知る為に）監視\n- 必要があればイベントサーバを終了\n- Event Server メソッド クライアントからのサブスクライブを受取 イベントプロセスから出された通知を各サブスクライバに転送 イベントを追加するためにメッセージを受取 必要なX, Y, Zプロセスを起動 イベントキャンセルのメッセージを受取 イベントプロセスを殺す クライアントから終了できる シェルから自分自身のコードを再読込出来る Process X, Y, Z 発報が待たれる通知を表す 天気にはイベントサーバにリンクされたタイマーに過ぎない 時間が来たらイベントサーバにメッセージを送る キャンセルのメッセージを受け取って死ぬ \n- メソッド クライアントからのサブスクライブを受取 イベントプロセスから出された通知を各サブスクライバに転送 イベントを追加するためにメッセージを受取 必要なX, Y, Zプロセスを起動 イベントキャンセルのメッセージを受取 イベントプロセスを殺す クライアントから終了できる シェルから自分自身のコードを再読込出来る \n- クライアントからのサブスクライブを受取\n- イベントプロセスから出された通知を各サブスクライバに転送\n- イベントを追加するためにメッセージを受取 必要なX, Y, Zプロセスを起動 \n- 必要なX, Y, Zプロセスを起動\n- イベントキャンセルのメッセージを受取 イベントプロセスを殺す \n- イベントプロセスを殺す\n- クライアントから終了できる\n- シェルから自分自身のコードを再読込出来る\n- Process X, Y, Z 発報が待たれる通知を表す 天気にはイベントサーバにリンクされたタイマーに過ぎない 時間が来たらイベントサーバにメッセージを送る キャンセルのメッセージを受け取って死ぬ \n- 発報が待たれる通知を表す 天気にはイベントサーバにリンクされたタイマーに過ぎない \n- 天気にはイベントサーバにリンクされたタイマーに過ぎない\n- 時間が来たらイベントサーバにメッセージを送る\n- キャンセルのメッセージを受け取って死ぬ\n- 実装 ディレクトリ構成 ebin/ include/ priv/ src/ event.erl - event module loop/1 normalize/1 start/2 start_link/2 cancel/1 time_to_go/1 init/3 evserv.erl - event server loop/1 valid_datetime/1 valid_time/1 valid_time/3 send_to_clients/2 start/0 start_link/0 terminate/0 subscribe/1 add_event/3 add_event2/3 cancel/1 listen/1 init/0 sup.erl - supervisor start/2 start_link/2 init/1 loop/1 Emakefile{'src/*', [debug_info, {i, \"src\"}, {i, \"include\"}, {outdir, \"ebin\"}]}. \n- ディレクトリ構成 ebin/ include/ priv/ src/ event.erl - event module loop/1 normalize/1 start/2 start_link/2 cancel/1 time_to_go/1 init/3 evserv.erl - event server loop/1 valid_datetime/1 valid_time/1 valid_time/3 send_to_clients/2 start/0 start_link/0 terminate/0 subscribe/1 add_event/3 add_event2/3 cancel/1 listen/1 init/0 sup.erl - supervisor start/2 start_link/2 init/1 loop/1 Emakefile{'src/*', [debug_info, {i, \"src\"}, {i, \"include\"}, {outdir, \"ebin\"}]}. \n- ebin/\n- include/\n- priv/\n- src/ event.erl - event module loop/1 normalize/1 start/2 start_link/2 cancel/1 time_to_go/1 init/3 evserv.erl - event server loop/1 valid_datetime/1 valid_time/1 valid_time/3 send_to_clients/2 start/0 start_link/0 terminate/0 subscribe/1 add_event/3 add_event2/3 cancel/1 listen/1 init/0 sup.erl - supervisor start/2 start_link/2 init/1 loop/1 \n- event.erl - event module loop/1 normalize/1 start/2 start_link/2 cancel/1 time_to_go/1 init/3 \n- loop/1\n- normalize/1\n- start/2\n- start_link/2\n- cancel/1\n- time_to_go/1\n- init/3\n- evserv.erl - event server loop/1 valid_datetime/1 valid_time/1 valid_time/3 send_to_clients/2 start/0 start_link/0 terminate/0 subscribe/1 add_event/3 add_event2/3 cancel/1 listen/1 init/0 \n- loop/1\n- valid_datetime/1\n- valid_time/1\n- valid_time/3\n- send_to_clients/2\n- start/0\n- start_link/0\n- terminate/0\n- subscribe/1\n- add_event/3\n- add_event2/3\n- cancel/1\n- listen/1\n- init/0\n- sup.erl - supervisor start/2 start_link/2 init/1 loop/1 \n- start/2\n- start_link/2\n- init/1\n- loop/1\n- Emakefile{'src/*', [debug_info, {i, \"src\"}, {i, \"include\"}, {outdir, \"ebin\"}]}.    sh \n\n$ erl -make && erl -pa ebin/ Erlang/OTP 19 [erts-8.1] [source] [64-bit] [smp:2:2] [async-threads:10] [kernel-poll:false] Eshell V8.1 (abort with ^G) 1> evserv:start(). <0.59.0> 2> evserv:subscribe(self()). {ok,#Ref<0.0.2.84>} 3> evserv:add_event(\"Hey there3\", \"test\", { {2017, 7, 9}, {1, 23, 59} }). ok 4> evserv:listen(2000). [{done,\"Hey there3\",\"test\"}]     > TIPSTIPS \n\n- Erlangのタイムアウト値はミリ秒でおよそ50日に制限されている   > 16 OTP16 OTP   > OTPとはなにかOTPとはなにか \n\n- Erlangの特徴 並列・分散 エラー処理 \n- 並列・分散\n- エラー処理\n- 組込関数 リンク モニター タイムアウト 終了の補足 \n- リンク\n- モニター\n- タイムアウト\n- 終了の補足\n- OTP 下記のようなバグになりやすい箇所をモジュールとして吸収 プロセスの順番 競合条件をどのように避けるか プロセスはいつでも死ぬ可能性があること ホットコードローディング 名前付きプロセス Supervisor Pros バグを解決するための時間を大幅に減らせる 個々のモジュールのテストが行いやすい 個々のモジュールの最適化が利用者全員の恩恵となる \n- 下記のようなバグになりやすい箇所をモジュールとして吸収 プロセスの順番 競合条件をどのように避けるか プロセスはいつでも死ぬ可能性があること ホットコードローディング 名前付きプロセス Supervisor \n- プロセスの順番\n- 競合条件をどのように避けるか プロセスはいつでも死ぬ可能性があること \n- プロセスはいつでも死ぬ可能性があること\n- ホットコードローディング\n- 名前付きプロセス\n- Supervisor\n- Pros バグを解決するための時間を大幅に減らせる 個々のモジュールのテストが行いやすい 個々のモジュールの最適化が利用者全員の恩恵となる \n- バグを解決するための時間を大幅に減らせる\n- 個々のモジュールのテストが行いやすい\n- 個々のモジュールの最適化が利用者全員の恩恵となる   > 17 gen_server17 gen_server \n\n今回はよくつかわれるビヘイビア gen_server 。この汎用化によって、メンテナンス、コードの単純化、テストの簡易化へとつながる。下記に gen_server のコールバックの概要を記す。   > クライアントとサーバクライアントとサーバ \n\n- gen_server init/1 Return {ok, State} {ok, State, TimeOut} {ok, State, hibernate} {stop, Reason} ignore handle_call/3 Params Request, From, State Return {reply, Reply, NewState} {reply, Reply, NewState, Timeout} {reply, Reply, NewState, hibernate} {noreply, NewState} {noreply, NewState, Timeout} {noreply, NewState, hibernate} {stop, Reason, Reply, NewState} {stop, Reason, NewState} handle_cast/2 Params Message, State Return {noreply, NewState} {noreply, NewState, Timeout} {noreply, NewState, hibernate} {stop, Reason, NewState} handle_info/2 Callback case bang operator (!) TimeOut モニター通知 'EXIT' シグナル Params Message, State Return {noreply, NewState} {noreply, NewState, Timeout} {noreply, NewState, hibernate} {stop, Reason, NewState} terminate/2 Callback case handle_* 関数の返値 {stop, Reason, NewState} {stop, Reason, Reply, NewState} 親が死んで、gen_serverが終了を補足していた場合 Params Reason, State Return init/1 の反対 VMがETS (erlang term storage) を削除 code_change/3 Params PreviousVersion {down, Version} State {ok, NewState} Extra \n- init/1 Return {ok, State} {ok, State, TimeOut} {ok, State, hibernate} {stop, Reason} ignore \n- Return {ok, State} {ok, State, TimeOut} {ok, State, hibernate} {stop, Reason} ignore \n- {ok, State}\n- {ok, State, TimeOut}\n- {ok, State, hibernate}\n- {stop, Reason}\n- ignore\n- handle_call/3 Params Request, From, State Return {reply, Reply, NewState} {reply, Reply, NewState, Timeout} {reply, Reply, NewState, hibernate} {noreply, NewState} {noreply, NewState, Timeout} {noreply, NewState, hibernate} {stop, Reason, Reply, NewState} {stop, Reason, NewState} \n- Params Request, From, State \n- Request, From, State\n- Return {reply, Reply, NewState} {reply, Reply, NewState, Timeout} {reply, Reply, NewState, hibernate} {noreply, NewState} {noreply, NewState, Timeout} {noreply, NewState, hibernate} {stop, Reason, Reply, NewState} {stop, Reason, NewState} \n- {reply, Reply, NewState}\n- {reply, Reply, NewState, Timeout}\n- {reply, Reply, NewState, hibernate}\n- {noreply, NewState}\n- {noreply, NewState, Timeout}\n- {noreply, NewState, hibernate}\n- {stop, Reason, Reply, NewState}\n- {stop, Reason, NewState}\n- handle_cast/2 Params Message, State Return {noreply, NewState} {noreply, NewState, Timeout} {noreply, NewState, hibernate} {stop, Reason, NewState} \n- Params Message, State \n- Message, State\n- Return {noreply, NewState} {noreply, NewState, Timeout} {noreply, NewState, hibernate} {stop, Reason, NewState} \n- {noreply, NewState}\n- {noreply, NewState, Timeout}\n- {noreply, NewState, hibernate}\n- {stop, Reason, NewState}\n- handle_info/2 Callback case bang operator (!) TimeOut モニター通知 'EXIT' シグナル Params Message, State Return {noreply, NewState} {noreply, NewState, Timeout} {noreply, NewState, hibernate} {stop, Reason, NewState} \n- Callback case bang operator (!) TimeOut モニター通知 'EXIT' シグナル \n- bang operator (!)\n- TimeOut\n- モニター通知\n- 'EXIT' シグナル\n- Params Message, State \n- Message, State\n- Return {noreply, NewState} {noreply, NewState, Timeout} {noreply, NewState, hibernate} {stop, Reason, NewState} \n- {noreply, NewState}\n- {noreply, NewState, Timeout}\n- {noreply, NewState, hibernate}\n- {stop, Reason, NewState}\n- terminate/2 Callback case handle_* 関数の返値 {stop, Reason, NewState} {stop, Reason, Reply, NewState} 親が死んで、gen_serverが終了を補足していた場合 Params Reason, State Return init/1 の反対 VMがETS (erlang term storage) を削除 \n- Callback case handle_* 関数の返値 {stop, Reason, NewState} {stop, Reason, Reply, NewState} 親が死んで、gen_serverが終了を補足していた場合 \n- handle_* 関数の返値 {stop, Reason, NewState} {stop, Reason, Reply, NewState} \n- {stop, Reason, NewState}\n- {stop, Reason, Reply, NewState}\n- 親が死んで、gen_serverが終了を補足していた場合\n- Params Reason, State \n- Reason, State\n- Return init/1 の反対 VMがETS (erlang term storage) を削除 \n- init/1 の反対\n- VMがETS (erlang term storage) を削除\n- code_change/3 Params PreviousVersion {down, Version} State {ok, NewState} Extra \n- Params PreviousVersion {down, Version} State {ok, NewState} Extra \n- PreviousVersion {down, Version} \n- {down, Version}\n- State {ok, NewState} \n- {ok, NewState}\n- Extra   > 18 gen_fsm18 gen_fsm \n\n今回は有限ステートマシン (finite state machine)。ビヘイビア gen_fsm をとりあげる。このビヘイビアは gen_server に基本似た挙動をするが、呼び出しやメッセージ投入をあつかうのではなく同期や非同期のイベントをあつう。   > 18.1. 有限ステートマシン18.1. 有限ステートマシン \n\n- 状態遷移図 (state diagram) による記述\n- シーケンス図による記述\n- gen_fsm init/1 Return {ok, StateName, Data} {ok, StateName, Data, Timeout} {ok, StateName, Data, hibernate} {stop, Reason} StateName/2 非同期イベント Params Event, StateData Return {next_state, NextStateName, NewData} {next_state, NextStateName, NewData, Timeout} {next_state, NextStateName, hibernate} {stop, Reason, Data} StateName/3 同期イベント Params Event, From, StateData Return {reply, Reply, NextStateName, NewStateData} {reply, Reply, NextStateName, NewStateData, Timeout} {reply, Reply, NextStateName, NewStateData, hibernate} {next_state, NextStateName, NewStateData} {next_state, NextStateName, NewStateData, Timeout} {next_state, NextStateName, NewStateData, hibernate} {stop, Reason, Reply, NewStateData} {stop, Reason, NewStateData} handle_event/3 非同期イベント、グローバルイベント Params Event, StateData Return {next_state, NextStateName, NewData} {next_state, NextStateName, NewData, Timeout} {next_state, NextStateName, hibernate} {stop, Reason, Data} handle_sync_event/4 同期イベント、グローバルイベント Params Event, From, StateData Return {reply, Reply, NextStateName, NewStateData} {reply, Reply, NextStateName, NewStateData, Timeout} {reply, Reply, NextStateName, NewStateData, hibernate} {next_state, NextStateName, NewStateData} {next_state, NextStateName, NewStateData, Timeout} {next_state, NextStateName, NewStateData, hibernate} {stop, Reason, Reply, NewStateData} {stop, Reason, NewStateData} code_change/4 Params OldVersion, StateName, Data, Extra Return {ok, NextStateName, NewStateData} terminate/3 init/1 と逆の挙動をする \n- init/1 Return {ok, StateName, Data} {ok, StateName, Data, Timeout} {ok, StateName, Data, hibernate} {stop, Reason} \n- Return {ok, StateName, Data} {ok, StateName, Data, Timeout} {ok, StateName, Data, hibernate} {stop, Reason} \n- {ok, StateName, Data}\n- {ok, StateName, Data, Timeout}\n- {ok, StateName, Data, hibernate}\n- {stop, Reason}\n- StateName/2 非同期イベント Params Event, StateData Return {next_state, NextStateName, NewData} {next_state, NextStateName, NewData, Timeout} {next_state, NextStateName, hibernate} {stop, Reason, Data} \n- 非同期イベント\n- Params Event, StateData \n- Event, StateData\n- Return {next_state, NextStateName, NewData} {next_state, NextStateName, NewData, Timeout} {next_state, NextStateName, hibernate} {stop, Reason, Data} \n- {next_state, NextStateName, NewData}\n- {next_state, NextStateName, NewData, Timeout}\n- {next_state, NextStateName, hibernate}\n- {stop, Reason, Data}\n- StateName/3 同期イベント Params Event, From, StateData Return {reply, Reply, NextStateName, NewStateData} {reply, Reply, NextStateName, NewStateData, Timeout} {reply, Reply, NextStateName, NewStateData, hibernate} {next_state, NextStateName, NewStateData} {next_state, NextStateName, NewStateData, Timeout} {next_state, NextStateName, NewStateData, hibernate} {stop, Reason, Reply, NewStateData} {stop, Reason, NewStateData} \n- 同期イベント\n- Params Event, From, StateData \n- Event, From, StateData\n- Return {reply, Reply, NextStateName, NewStateData} {reply, Reply, NextStateName, NewStateData, Timeout} {reply, Reply, NextStateName, NewStateData, hibernate} {next_state, NextStateName, NewStateData} {next_state, NextStateName, NewStateData, Timeout} {next_state, NextStateName, NewStateData, hibernate} {stop, Reason, Reply, NewStateData} {stop, Reason, NewStateData} \n- {reply, Reply, NextStateName, NewStateData}\n- {reply, Reply, NextStateName, NewStateData, Timeout}\n- {reply, Reply, NextStateName, NewStateData, hibernate}\n- {next_state, NextStateName, NewStateData}\n- {next_state, NextStateName, NewStateData, Timeout}\n- {next_state, NextStateName, NewStateData, hibernate}\n- {stop, Reason, Reply, NewStateData}\n- {stop, Reason, NewStateData}\n- handle_event/3 非同期イベント、グローバルイベント Params Event, StateData Return {next_state, NextStateName, NewData} {next_state, NextStateName, NewData, Timeout} {next_state, NextStateName, hibernate} {stop, Reason, Data} \n- 非同期イベント、グローバルイベント\n- Params Event, StateData \n- Event, StateData\n- Return {next_state, NextStateName, NewData} {next_state, NextStateName, NewData, Timeout} {next_state, NextStateName, hibernate} {stop, Reason, Data} \n- {next_state, NextStateName, NewData}\n- {next_state, NextStateName, NewData, Timeout}\n- {next_state, NextStateName, hibernate}\n- {stop, Reason, Data}\n- handle_sync_event/4 同期イベント、グローバルイベント Params Event, From, StateData Return {reply, Reply, NextStateName, NewStateData} {reply, Reply, NextStateName, NewStateData, Timeout} {reply, Reply, NextStateName, NewStateData, hibernate} {next_state, NextStateName, NewStateData} {next_state, NextStateName, NewStateData, Timeout} {next_state, NextStateName, NewStateData, hibernate} {stop, Reason, Reply, NewStateData} {stop, Reason, NewStateData} \n- 同期イベント、グローバルイベント\n- Params Event, From, StateData \n- Event, From, StateData\n- Return {reply, Reply, NextStateName, NewStateData} {reply, Reply, NextStateName, NewStateData, Timeout} {reply, Reply, NextStateName, NewStateData, hibernate} {next_state, NextStateName, NewStateData} {next_state, NextStateName, NewStateData, Timeout} {next_state, NextStateName, NewStateData, hibernate} {stop, Reason, Reply, NewStateData} {stop, Reason, NewStateData} \n- {reply, Reply, NextStateName, NewStateData}\n- {reply, Reply, NextStateName, NewStateData, Timeout}\n- {reply, Reply, NextStateName, NewStateData, hibernate}\n- {next_state, NextStateName, NewStateData}\n- {next_state, NextStateName, NewStateData, Timeout}\n- {next_state, NextStateName, NewStateData, hibernate}\n- {stop, Reason, Reply, NewStateData}\n- {stop, Reason, NewStateData}\n- code_change/4 Params OldVersion, StateName, Data, Extra Return {ok, NextStateName, NewStateData} \n- Params OldVersion, StateName, Data, Extra \n- OldVersion, StateName, Data, Extra\n- Return {ok, NextStateName, NewStateData} \n- {ok, NextStateName, NewStateData}\n- terminate/3 init/1 と逆の挙動をする \n- init/1 と逆の挙動をする\n- イベント送信関数 ローカル send_event/2 sync_send_event/2-3 グローバル send_all_state_event/2-3 sync_send_event/2-3 \n- ローカル send_event/2 sync_send_event/2-3 \n- send_event/2\n- sync_send_event/2-3\n- グローバル send_all_state_event/2-3 sync_send_event/2-3 \n- send_all_state_event/2-3\n- sync_send_event/2-3   > 18.2. ユーザー同士の取引システム例18.2. ユーザー同士の取引システム例 \n\n- \n-    > 19 gen_event19 gen_event \n\n今回はイベントハンドラ。ビヘイビアは gen_event をつかう。 \n\n- 人々（あるいは、あるプロセスやアプリケーション）にイベントが起きたことを知らせる機能の実装方法 単純出力方式 結果を出力するのみ 単純サブスクライバ方式 メッセージ送信前にサブスクライバのPidを取得 Cons コールバックのために待機プロセスが必要 イベントマネージャ方式 関数をうけとるプロセスをたて、すべてのイベントに対して当該関数をはしらせる Pros サーバのサブスクライバがたくさんあっても稼働し続けられる すべてのコールバックは同じインスタンスで操作される 短命なタスクに対して新しいプロセスを生成する必要がない Cons 関数が長時間動作する必要があった場合、お互いブロックしあう イベントマネージャをイベントフォワーダにすれば防ぐことができる 無限ループする関数はクラッシュするまで新規イベントをブロックする \n- 単純出力方式 結果を出力するのみ \n- 結果を出力するのみ\n- 単純サブスクライバ方式 メッセージ送信前にサブスクライバのPidを取得 Cons コールバックのために待機プロセスが必要 \n- メッセージ送信前にサブスクライバのPidを取得\n- Cons コールバックのために待機プロセスが必要 \n- コールバックのために待機プロセスが必要\n- イベントマネージャ方式 関数をうけとるプロセスをたて、すべてのイベントに対して当該関数をはしらせる Pros サーバのサブスクライバがたくさんあっても稼働し続けられる すべてのコールバックは同じインスタンスで操作される 短命なタスクに対して新しいプロセスを生成する必要がない Cons 関数が長時間動作する必要があった場合、お互いブロックしあう イベントマネージャをイベントフォワーダにすれば防ぐことができる 無限ループする関数はクラッシュするまで新規イベントをブロックする \n- 関数をうけとるプロセスをたて、すべてのイベントに対して当該関数をはしらせる\n- Pros サーバのサブスクライバがたくさんあっても稼働し続けられる すべてのコールバックは同じインスタンスで操作される 短命なタスクに対して新しいプロセスを生成する必要がない \n- サーバのサブスクライバがたくさんあっても稼働し続けられる\n- すべてのコールバックは同じインスタンスで操作される\n- 短命なタスクに対して新しいプロセスを生成する必要がない\n- Cons 関数が長時間動作する必要があった場合、お互いブロックしあう イベントマネージャをイベントフォワーダにすれば防ぐことができる 無限ループする関数はクラッシュするまで新規イベントをブロックする \n- 関数が長時間動作する必要があった場合、お互いブロックしあう イベントマネージャをイベントフォワーダにすれば防ぐことができる \n- イベントマネージャをイベントフォワーダにすれば防ぐことができる\n- 無限ループする関数はクラッシュするまで新規イベントをブロックする   > 19.2. 汎用イベントハンドラ gen_event19.2. 汎用イベントハンドラ gen_event  \n\n- gen_event の各関数 init/1 Response {ok, State} terminate/2 handle_event/2 非同期 すべてのイベントマネージャは戻り値を返さないことで呼び出しプロセスをブロックする Params Event, State Response {ok, NewState} gen_server:handle_cast/2 と似た動作 {ok, NewState, hibernate} {remove_handler} イベントマネージャからハンドラを削除する {swap_handler, Args1, NewState, NewHandler, Args2} 今あるイベントハンドラを削除して新しいものに置き換える notify/2 すべての流入イベントを通知する (非同期) sync_notify/2 すべての流入イベントを通知する (同期) cast/2 非同期 handle_call gen_server:handle_call コールバックに似ているがレスポンスが異なる gen_server:call/3-4 が呼び出しに使われている Response {ok, Reply, NewState} {ok, Reply, NewState, hibernate} {remove_handler, Reply} {swap_handler, Reply, Args1, NewState, Handle_Call} handle_info/2 hendle_event と同じレスポンスだが、終了シグナルや ! 演算子でイベントマネージャに贈られたメッセージのみを扱う点で異なる code_change/3 gen_server:code_change と同じ動作をする Params OldVsn バージョン番号, State ハンドラの状態, Extra Response {ok, NewState} \n- init/1 Response {ok, State} \n- Response {ok, State} \n- {ok, State}\n- terminate/2\n- handle_event/2 非同期 すべてのイベントマネージャは戻り値を返さないことで呼び出しプロセスをブロックする Params Event, State Response {ok, NewState} gen_server:handle_cast/2 と似た動作 {ok, NewState, hibernate} {remove_handler} イベントマネージャからハンドラを削除する {swap_handler, Args1, NewState, NewHandler, Args2} 今あるイベントハンドラを削除して新しいものに置き換える \n- 非同期 すべてのイベントマネージャは戻り値を返さないことで呼び出しプロセスをブロックする \n- すべてのイベントマネージャは戻り値を返さないことで呼び出しプロセスをブロックする\n- Params Event, State \n- Event, State\n- Response {ok, NewState} gen_server:handle_cast/2 と似た動作 {ok, NewState, hibernate} {remove_handler} イベントマネージャからハンドラを削除する {swap_handler, Args1, NewState, NewHandler, Args2} 今あるイベントハンドラを削除して新しいものに置き換える \n- {ok, NewState} gen_server:handle_cast/2 と似た動作 \n- gen_server:handle_cast/2 と似た動作\n- {ok, NewState, hibernate}\n- {remove_handler} イベントマネージャからハンドラを削除する \n- イベントマネージャからハンドラを削除する\n- {swap_handler, Args1, NewState, NewHandler, Args2} 今あるイベントハンドラを削除して新しいものに置き換える \n- 今あるイベントハンドラを削除して新しいものに置き換える\n- notify/2 すべての流入イベントを通知する (非同期) \n- すべての流入イベントを通知する (非同期)\n- sync_notify/2 すべての流入イベントを通知する (同期) \n- すべての流入イベントを通知する (同期)\n- cast/2 非同期 \n- 非同期\n- handle_call gen_server:handle_call コールバックに似ているがレスポンスが異なる gen_server:call/3-4 が呼び出しに使われている Response {ok, Reply, NewState} {ok, Reply, NewState, hibernate} {remove_handler, Reply} {swap_handler, Reply, Args1, NewState, Handle_Call} \n- gen_server:handle_call コールバックに似ているがレスポンスが異なる\n- gen_server:call/3-4 が呼び出しに使われている\n- Response {ok, Reply, NewState} {ok, Reply, NewState, hibernate} {remove_handler, Reply} {swap_handler, Reply, Args1, NewState, Handle_Call} \n- {ok, Reply, NewState}\n- {ok, Reply, NewState, hibernate}\n- {remove_handler, Reply}\n- {swap_handler, Reply, Args1, NewState, Handle_Call}\n- handle_info/2 hendle_event と同じレスポンスだが、終了シグナルや ! 演算子でイベントマネージャに贈られたメッセージのみを扱う点で異なる \n- hendle_event と同じレスポンスだが、終了シグナルや ! 演算子でイベントマネージャに贈られたメッセージのみを扱う点で異なる\n- code_change/3 gen_server:code_change と同じ動作をする Params OldVsn バージョン番号, State ハンドラの状態, Extra Response {ok, NewState} \n- gen_server:code_change と同じ動作をする\n- Params OldVsn バージョン番号, State ハンドラの状態, Extra \n- OldVsn バージョン番号, State ハンドラの状態, Extra\n- Response {ok, NewState} \n- {ok, NewState}   > 20 supervisor20 supervisor \n\n今回のビヘイビアはスーパバイザ supervisor。 監視戦略の概要にふれてみる。 \n\n- init/1 レスポンス {ok, { {RestartStrategy, MaxRestart, MaxTime}, [{ChildId, StartFunc, Restart, Shutdown, Type, Modules}] } }. 例 {ok, { {one_for_all, 5, 60}, [ {fake_id, {fake_mod, start_link, [SomeArg]}, permanent, 5000, worker, [fake_mod]}, {other_id, {event_manager_mod, start_link, []}, transient, infinity, worker, dynamic} ] } }. 再起動戦略 one_for_one 1つのワーカがクラッシュしたら当該ワーカを再起動する 各々のワーカが独立している、互いが関係していない、あるいは、ワーカが再起動して状態が消えても隣のワーカに影響を与えない場合につかう one_for_all 1つのワーカがクラッシュしたらすべてのワーカをクラッシュさせて再起動する 各々のワーカが互いに強く依存している場合につかう rest_for_one 1つのワーカがクラッシュした当該ワーカのら子ワーカたちをクラッシュさせて再起動する 各々のワーカがチェーン状態に依存している場合につかう simple_one_for_one one_for_one はワーカのリストを起動した順で保持している一方 、simple_one_for_one はワーカへの定義を dict で保持している 再起動制限 MaxTime 秒以内に MaxRestart 回起動したら、スーパバイザは再起動をやめて自身をシャットダウンする ワーカ (子プロセス) 構成要素 ChildId StartFunc スーパバイザの起動方法をつたえるためのタプル {M, F, A} Restart 再起動戦略 permanent 常に再起動 temporary 再起動しない transient 正常終了の場合は再起動しない 異常終了の場合は再起動する Shutdown 終了期限 Type 子プロセスの種類 ワーカ スーパバイザ Modules コールバックモジュールのリスト \n- レスポンス {ok, { {RestartStrategy, MaxRestart, MaxTime}, [{ChildId, StartFunc, Restart, Shutdown, Type, Modules}] } }. 例 {ok, { {one_for_all, 5, 60}, [ {fake_id, {fake_mod, start_link, [SomeArg]}, permanent, 5000, worker, [fake_mod]}, {other_id, {event_manager_mod, start_link, []}, transient, infinity, worker, dynamic} ] } }. 再起動戦略 one_for_one 1つのワーカがクラッシュしたら当該ワーカを再起動する 各々のワーカが独立している、互いが関係していない、あるいは、ワーカが再起動して状態が消えても隣のワーカに影響を与えない場合につかう one_for_all 1つのワーカがクラッシュしたらすべてのワーカをクラッシュさせて再起動する 各々のワーカが互いに強く依存している場合につかう rest_for_one 1つのワーカがクラッシュした当該ワーカのら子ワーカたちをクラッシュさせて再起動する 各々のワーカがチェーン状態に依存している場合につかう simple_one_for_one one_for_one はワーカのリストを起動した順で保持している一方 、simple_one_for_one はワーカへの定義を dict で保持している 再起動制限 MaxTime 秒以内に MaxRestart 回起動したら、スーパバイザは再起動をやめて自身をシャットダウンする ワーカ (子プロセス) 構成要素 ChildId StartFunc スーパバイザの起動方法をつたえるためのタプル {M, F, A} Restart 再起動戦略 permanent 常に再起動 temporary 再起動しない transient 正常終了の場合は再起動しない 異常終了の場合は再起動する Shutdown 終了期限 Type 子プロセスの種類 ワーカ スーパバイザ Modules コールバックモジュールのリスト \n- {ok, { {RestartStrategy, MaxRestart, MaxTime}, [{ChildId, StartFunc, Restart, Shutdown, Type, Modules}] } }. 例 {ok, { {one_for_all, 5, 60}, [ {fake_id, {fake_mod, start_link, [SomeArg]}, permanent, 5000, worker, [fake_mod]}, {other_id, {event_manager_mod, start_link, []}, transient, infinity, worker, dynamic} ] } }. 再起動戦略 one_for_one 1つのワーカがクラッシュしたら当該ワーカを再起動する 各々のワーカが独立している、互いが関係していない、あるいは、ワーカが再起動して状態が消えても隣のワーカに影響を与えない場合につかう one_for_all 1つのワーカがクラッシュしたらすべてのワーカをクラッシュさせて再起動する 各々のワーカが互いに強く依存している場合につかう rest_for_one 1つのワーカがクラッシュした当該ワーカのら子ワーカたちをクラッシュさせて再起動する 各々のワーカがチェーン状態に依存している場合につかう simple_one_for_one one_for_one はワーカのリストを起動した順で保持している一方 、simple_one_for_one はワーカへの定義を dict で保持している 再起動制限 MaxTime 秒以内に MaxRestart 回起動したら、スーパバイザは再起動をやめて自身をシャットダウンする ワーカ (子プロセス) 構成要素 ChildId StartFunc スーパバイザの起動方法をつたえるためのタプル {M, F, A} Restart 再起動戦略 permanent 常に再起動 temporary 再起動しない transient 正常終了の場合は再起動しない 異常終了の場合は再起動する Shutdown 終了期限 Type 子プロセスの種類 ワーカ スーパバイザ Modules コールバックモジュールのリスト \n- 例 {ok, { {one_for_all, 5, 60}, [ {fake_id, {fake_mod, start_link, [SomeArg]}, permanent, 5000, worker, [fake_mod]}, {other_id, {event_manager_mod, start_link, []}, transient, infinity, worker, dynamic} ] } }. \n- {ok, { {one_for_all, 5, 60}, [ {fake_id, {fake_mod, start_link, [SomeArg]}, permanent, 5000, worker, [fake_mod]}, {other_id, {event_manager_mod, start_link, []}, transient, infinity, worker, dynamic} ] } }.\n- 再起動戦略 one_for_one 1つのワーカがクラッシュしたら当該ワーカを再起動する 各々のワーカが独立している、互いが関係していない、あるいは、ワーカが再起動して状態が消えても隣のワーカに影響を与えない場合につかう one_for_all 1つのワーカがクラッシュしたらすべてのワーカをクラッシュさせて再起動する 各々のワーカが互いに強く依存している場合につかう rest_for_one 1つのワーカがクラッシュした当該ワーカのら子ワーカたちをクラッシュさせて再起動する 各々のワーカがチェーン状態に依存している場合につかう simple_one_for_one one_for_one はワーカのリストを起動した順で保持している一方 、simple_one_for_one はワーカへの定義を dict で保持している \n- one_for_one 1つのワーカがクラッシュしたら当該ワーカを再起動する 各々のワーカが独立している、互いが関係していない、あるいは、ワーカが再起動して状態が消えても隣のワーカに影響を与えない場合につかう \n- 1つのワーカがクラッシュしたら当該ワーカを再起動する\n- 各々のワーカが独立している、互いが関係していない、あるいは、ワーカが再起動して状態が消えても隣のワーカに影響を与えない場合につかう\n- one_for_all 1つのワーカがクラッシュしたらすべてのワーカをクラッシュさせて再起動する 各々のワーカが互いに強く依存している場合につかう \n- 1つのワーカがクラッシュしたらすべてのワーカをクラッシュさせて再起動する\n- 各々のワーカが互いに強く依存している場合につかう\n- rest_for_one 1つのワーカがクラッシュした当該ワーカのら子ワーカたちをクラッシュさせて再起動する 各々のワーカがチェーン状態に依存している場合につかう \n- 1つのワーカがクラッシュした当該ワーカのら子ワーカたちをクラッシュさせて再起動する\n- 各々のワーカがチェーン状態に依存している場合につかう\n- simple_one_for_one one_for_one はワーカのリストを起動した順で保持している一方 、simple_one_for_one はワーカへの定義を dict で保持している \n- one_for_one はワーカのリストを起動した順で保持している一方 、simple_one_for_one はワーカへの定義を dict で保持している\n- 再起動制限 MaxTime 秒以内に MaxRestart 回起動したら、スーパバイザは再起動をやめて自身をシャットダウンする \n- MaxTime 秒以内に MaxRestart 回起動したら、スーパバイザは再起動をやめて自身をシャットダウンする\n- ワーカ (子プロセス) 構成要素 ChildId StartFunc スーパバイザの起動方法をつたえるためのタプル {M, F, A} Restart 再起動戦略 permanent 常に再起動 temporary 再起動しない transient 正常終了の場合は再起動しない 異常終了の場合は再起動する Shutdown 終了期限 Type 子プロセスの種類 ワーカ スーパバイザ Modules コールバックモジュールのリスト \n- 構成要素 ChildId StartFunc スーパバイザの起動方法をつたえるためのタプル {M, F, A} Restart 再起動戦略 permanent 常に再起動 temporary 再起動しない transient 正常終了の場合は再起動しない 異常終了の場合は再起動する Shutdown 終了期限 Type 子プロセスの種類 ワーカ スーパバイザ Modules コールバックモジュールのリスト \n- ChildId\n- StartFunc スーパバイザの起動方法をつたえるためのタプル {M, F, A} \n- スーパバイザの起動方法をつたえるためのタプル {M, F, A}\n- Restart 再起動戦略 permanent 常に再起動 temporary 再起動しない transient 正常終了の場合は再起動しない 異常終了の場合は再起動する \n- 再起動戦略 permanent 常に再起動 temporary 再起動しない transient 正常終了の場合は再起動しない 異常終了の場合は再起動する \n- permanent 常に再起動 \n- 常に再起動\n- temporary 再起動しない \n- 再起動しない\n- transient 正常終了の場合は再起動しない 異常終了の場合は再起動する \n- 正常終了の場合は再起動しない\n- 異常終了の場合は再起動する\n- Shutdown 終了期限 \n- 終了期限\n- Type 子プロセスの種類 ワーカ スーパバイザ \n- 子プロセスの種類 ワーカ スーパバイザ \n- ワーカ\n- スーパバイザ\n- Modules コールバックモジュールのリスト \n- コールバックモジュールのリスト   > 21 プロセスプールをつくる21 プロセスプールをつくる \n\n今回はプロセスプール管理アプリケーションをOTPを使ってつくる。   > 要件要件 \n\n- サーバを最大でN個の並列接続に制限\n- アプリケーションによって開かれるファイルの数を制限\n- サブシステムに優先順位を与える\n- 不定期なアクセス負荷に対してキューにタスクを貯めることで、可用性を高める   > 実装実装 \n\n機能 \n\n- アプリケーション 起動 停止 \n- 起動\n- 停止\n- 特定のプロセスプール 起動 停止 \n- 起動\n- 停止\n- プール内のタスク プールに余裕がある場合 実行 タスクが実行されたら呼び出し元は解放 できる限りタスクを非同期に実行 プールに余裕がない場合 起動できないと告げる タスクがキューの中にある間は呼び出し元のプロセスを待たせておく タスクをキューに貯める \n- プールに余裕がある場合 実行 タスクが実行されたら呼び出し元は解放 できる限りタスクを非同期に実行 \n- 実行\n- タスクが実行されたら呼び出し元は解放\n- できる限りタスクを非同期に実行\n- プールに余裕がない場合 起動できないと告げる タスクがキューの中にある間は呼び出し元のプロセスを待たせておく タスクをキューに貯める \n- 起動できないと告げる\n- タスクがキューの中にある間は呼び出し元のプロセスを待たせておく\n- タスクをキューに貯める \n\n状態 \n\n- 静的な状態 下記から容易に取得 設定ファイル 他のプロセス アプリケーションを再起動しているスーパーバイザ \n- 下記から容易に取得 設定ファイル 他のプロセス アプリケーションを再起動しているスーパーバイザ \n- 設定ファイル\n- 他のプロセス\n- アプリケーションを再起動しているスーパーバイザ\n- 動的な状態 再計算できるデータから取得 状態の種類 初期からの状態 現在までの状態 変換すべき状態 \n- 再計算できるデータから取得\n- 状態の種類 初期からの状態 現在までの状態 変換すべき状態 \n- 初期からの状態\n- 現在までの状態\n- 変換すべき状態\n- 再計算できない動的なデータ 下記から取得 ユーザの入力 生のデータ 逐次的な外部イベント など 保存方法 データベースに登録 \n- 下記から取得 ユーザの入力 生のデータ 逐次的な外部イベント など \n- ユーザの入力\n- 生のデータ\n- 逐次的な外部イベント\n- など\n- 保存方法 データベースに登録 \n- データベースに登録    > 25 ホットコードローディング25 ホットコードローディング \n\n- 今回はホットコードローディング（更新）についてかんがえる。\n- ホットコードローディングはホットスワップの1種でElixir/Erlangの信頼性につながっている。\n- ホットコードローディングは systools により複数の appup から relup として構成されている。   > リリースの更新リリースの更新 \n\nバージョンがあがるほどリリースの更新は煩雑になっていく。 \n\n- OTPアプリケーションを書く (ver. 1.0.0) それらをリリースにする \n- それらをリリースにする\n- 1つ以上のOTPアプリケーションのバージョンを更新する (ver. 1.1.0) そのアプリケーションの古いバージョンから新しいバージョンへの遷移を行うために、何を変更すべきかを説明した appup ファイルを作成する \n- そのアプリケーションの古いバージョンから新しいバージョンへの遷移を行うために、何を変更すべきかを説明した appup ファイルを作成する\n- 新しいアプリケーションで新しいリリースを作る (ver. 1.2.0) appup ファイルをこれらのリリースから生成する 新しいアプリケーションを稼働しているErlangシェルにインストールする \n- appup ファイルをこれらのリリースから生成する\n- 新しいアプリケーションを稼働しているErlangシェルにインストールする \n\nリリース作業として以下の通り。relup 構成ツールとして、Erlangは relx 、Elixirは distillery がある。 \n\n- 巻き戻しできるようアップグレードとダウングレード双方を appup ファイルに記述\n- モジュールによるリリース構成を config ファイルに記述\n- systools:make_relup で relup を作成\n- release_hanlder によって更新   appup \n\n%% {NewVersion, %% [{VersionUpgradingFrom, [Instructions]}] %% [{VersionDownGradingTo, [Instructions]}]}. {\"1.1.0\", [{\"1.0.0\", [{add_module, pq_quest}, {load_module, pq_enemy}, {load_module, pq_events}, {update, pq_player, {advanced, []}, [pq_quest, pq_events]}]}], [{\"1.0.0\", [{update, pq_player, {advanced, []}}, {delete_module, pq_quest}, {load_module, pq_enemy}, {load_module, pq_events}]}]}. {\"1.0.1\", [{\"1.0.0\", [{load_module, sockserv_serv}]}], [{\"1.0.0\", [{load_module, sockserv_serv}]}]}.     > 27 EUnit27 EUnit \n\n- 今回は単体テストEUnitについてかんがえる。   > EUnitの特徴EUnitの特徴 \n\n- eunit:test(モジュール名, [verbose]) で実行\n- postfixがtestの関数 _test() に対してテストをおこなう\n- モジュールの内外ともにテストコードをかける\n- モジュール外に書いた場合プライベート関数に対するテストはできなくなる\n- テスト用モジュールはpostfixがtestsとなる _tests.erl    > EUnitの関数EUnitの関数 \n\n- 表現系 テスト foo_test -> ?assert(is_number(ops:add(1, 2))), ?assertEqual(4, ops:add(2, 2)). テストジェネレータ foo_test_ -> [test_them_1(), test_them_2, ?_assertError(badarith, 1/0)]. フィクスチャー setup {setup, Setup, Instantiator} {setup, Setup, Cleanup, Instantiator} {setup, Where, Setup, Instantiator} {setup, Where, Setup, Cleanup, Instantiator} foreach {foreach, Setup, [Instantiator]} {foreach, Setup, Cleanup, [Instantiator]} {foreach, Where, Setup, [Instantiator]} {foreach, Where, Setup, Cleanup, [Instantiator]} instantiator制御 {spawn, TestSet} - 並行処理 {timeout, (時間 秒), TestSet} - 時間指定処理 {inorder, TestSet} - 逐次処理 {inparallel, TestSet} - 並列処理 コメント {Comment, Fixture} \n- テスト foo_test -> ?assert(is_number(ops:add(1, 2))), ?assertEqual(4, ops:add(2, 2)). \n- foo_test -> ?assert(is_number(ops:add(1, 2))), ?assertEqual(4, ops:add(2, 2)).\n- テストジェネレータ foo_test_ -> [test_them_1(), test_them_2, ?_assertError(badarith, 1/0)]. \n- foo_test_ -> [test_them_1(), test_them_2, ?_assertError(badarith, 1/0)].\n- フィクスチャー setup {setup, Setup, Instantiator} {setup, Setup, Cleanup, Instantiator} {setup, Where, Setup, Instantiator} {setup, Where, Setup, Cleanup, Instantiator} foreach {foreach, Setup, [Instantiator]} {foreach, Setup, Cleanup, [Instantiator]} {foreach, Where, Setup, [Instantiator]} {foreach, Where, Setup, Cleanup, [Instantiator]} instantiator制御 {spawn, TestSet} - 並行処理 {timeout, (時間 秒), TestSet} - 時間指定処理 {inorder, TestSet} - 逐次処理 {inparallel, TestSet} - 並列処理 コメント {Comment, Fixture} \n- setup {setup, Setup, Instantiator} {setup, Setup, Cleanup, Instantiator} {setup, Where, Setup, Instantiator} {setup, Where, Setup, Cleanup, Instantiator} \n- {setup, Setup, Instantiator}\n- {setup, Setup, Cleanup, Instantiator}\n- {setup, Where, Setup, Instantiator}\n- {setup, Where, Setup, Cleanup, Instantiator}\n- foreach {foreach, Setup, [Instantiator]} {foreach, Setup, Cleanup, [Instantiator]} {foreach, Where, Setup, [Instantiator]} {foreach, Where, Setup, Cleanup, [Instantiator]} \n- {foreach, Setup, [Instantiator]}\n- {foreach, Setup, Cleanup, [Instantiator]}\n- {foreach, Where, Setup, [Instantiator]}\n- {foreach, Where, Setup, Cleanup, [Instantiator]}\n- instantiator制御 {spawn, TestSet} - 並行処理 {timeout, (時間 秒), TestSet} - 時間指定処理 {inorder, TestSet} - 逐次処理 {inparallel, TestSet} - 並列処理 \n- {spawn, TestSet} - 並行処理\n- {timeout, (時間 秒), TestSet} - 時間指定処理\n- {inorder, TestSet} - 逐次処理\n- {inparallel, TestSet} - 並列処理\n- コメント {Comment, Fixture} \n- {Comment, Fixture}\n- アサーション系 ?assert(expression) ?assertNot(expression) ?assertEqual(A, B) ?assertMatch(Pattern, Expression) ?assertError(Pattern, Expression) ?assertThrow(Pattern, Expression) ?assertExit(Pattern, Expression) ?assertException(Class, Pattern, Expression) \n- ?assert(expression)\n- ?assertNot(expression)\n- ?assertEqual(A, B)\n- ?assertMatch(Pattern, Expression)\n- ?assertError(Pattern, Expression)\n- ?assertThrow(Pattern, Expression)\n- ?assertExit(Pattern, Expression)\n- ?assertException(Class, Pattern, Expression) \n\nフィクスチャー (foreach) をつかったテストジェネレータ   erlang \n\n-define(setup(F), {setup, fun start/0, fun stop/1, F}). %% 関数some2について some2_test_() -> [{\"SetupData1を適切に評価できること\", {foreach, ?setup(fun (SetupData1) -> [some_instantiator1(SetupData1), some_instantiator2(SetupData1), ... some_instantiatorN(SetupData1)] end}}, {\"SetupData2を並列処理で適切に評価できること\", {foreach, ?setup(fun (SetupData2) -> {inparallel, [some_instantiator1(SetupData2), some_instantiator2(SetupData2), ... some_instantiatorN(SetupData2)]} end)}}].   \n\n並列・並行でテストする際の注意点 \n\n- 名前をa、b、cのようにハードコードすると、並列で走らせている際、名前の衝突が起きる可能性がある。可能な限り名前はハードコードせずに make_ref() によって一意の値をつかうこと。   > 28 インメモリーデータベース ETS28 インメモリーデータベース ETS   > ETSの特徴ETSの特徴 \n\n- データへの並列平行なアクセスが可能 ただし、安全性と並行性が低下する可能性がある ETSのデフォルト使用数は1400 erl -env ERL_MAX_ETS_TABLES Number で設定 \n- ただし、安全性と並行性が低下する可能性がある\n- ETSのデフォルト使用数は1400 erl -env ERL_MAX_ETS_TABLES Number で設定 \n- erl -env ERL_MAX_ETS_TABLES Number で設定   > ETSのテーブル種類ETSのテーブル種類 \n\n- set 標準 \n- 標準\n- ordered_set テーブルデータのソート機能あり ユースケース: 範囲指定してデータ取得する (ただし、アクセス時間が遅くなる O(log N)) \n- テーブルデータのソート機能あり\n- ユースケース: 範囲指定してデータ取得する (ただし、アクセス時間が遅くなる O(log N))\n- bag 同一キーのタプル（レコード）を保持可能 \n- 同一キーのタプル（レコード）を保持可能\n- duplicate_bag 同一内容のタプル（レコード）を保持可能 \n- 同一内容のタプル（レコード）を保持可能\n- 共通機能 テーブル所有権 ETSテーブル起動関数であらたにコールしたプロセスがそのテーブルの所有者 権限 protected level 所有者 read, write その他 read public level 所有者 read, write その他 read, write private level 所有者 read, write その他 n/a テーブルの移譲 ETSテーブルはプロセスが死ぬと消滅する 移譲の種類 都度指定する移譲 プロセスが死んだ場合の自動移譲 \n- テーブル所有権 ETSテーブル起動関数であらたにコールしたプロセスがそのテーブルの所有者 権限 protected level 所有者 read, write その他 read public level 所有者 read, write その他 read, write private level 所有者 read, write その他 n/a \n- ETSテーブル起動関数であらたにコールしたプロセスがそのテーブルの所有者\n- 権限 protected level 所有者 read, write その他 read public level 所有者 read, write その他 read, write private level 所有者 read, write その他 n/a \n- protected level 所有者 read, write その他 read \n- 所有者 read, write\n- その他 read\n- public level 所有者 read, write その他 read, write \n- 所有者 read, write\n- その他 read, write\n- private level 所有者 read, write その他 n/a \n- 所有者 read, write\n- その他 n/a\n- テーブルの移譲 ETSテーブルはプロセスが死ぬと消滅する 移譲の種類 都度指定する移譲 プロセスが死んだ場合の自動移譲 \n- ETSテーブルはプロセスが死ぬと消滅する\n- 移譲の種類 都度指定する移譲 プロセスが死んだ場合の自動移譲 \n- 都度指定する移譲\n- プロセスが死んだ場合の自動移譲   > ETSの関数ETSの関数 \n\n- テーブル作成・削除 ets:new/2 \n- ets:new/2\n- データ挿入・参照 ets:insert(Table, ObjectOrObjects) ets:lookup(Table, Key) \n- ets:insert(Table, ObjectOrObjects)\n- ets:lookup(Table, Key)\n- その他 ets:delete(Table, Key) ets:match(Table, MatchClause) ets:match_object(Table, MatchClause) ets:fun2ms(MatchSpecClause) \n- ets:delete(Table, Key)\n- ets:match(Table, MatchClause)\n- ets:match_object(Table, MatchClause)\n- ets:fun2ms(MatchSpecClause) \n\nsetテーブルでnamed_tableオプションをつける場合   erlang \n\n21> ets:new(ingredients, [set, named_table]). ingredients 22> ets:insert(ingredients, {bacon, great}). true 23> ets:lookup(ingredients, bacon). [{bacon,great}] 24> ets:insert(ingredients, [{bacon, awesome}, {cabbage, alright}]). true 25> ets:lookup(ingredients, bacon). [{bacon,awesome}] 26> ets:lookup(ingredients, cabbage). [{cabbage,alright}] 27> ets:delete(ingredients, cabbage). true 28> ets:delete(ingredients, cabbage). true 29> ets:lookup(ingredients, cabbage). [] 32> ets:insert_new(ingredients, {tomato, hey}). true 33> ets:insert_new(ingredients, {tomato, hey}). false   \n\nbagテーブルでnamed_tableオプションをつけない場合   erlang \n\n34> TabId = ets:new(ingredients, [bag]). 16401 35> ets:insert(TabId, {bacon, delicious}). true 36> ets:insert(TabId, {bacon, fat}). true 37> ets:insert(TabId, {bacon, fat}). true 38> ets:lookup(TabId, bacon). [{bacon,delicious},{bacon,fat}]   \n\nordered_setターブルで、named_tableオプションをつける場合   erlang \n\n42> ets:new(ingredients, [ordered_set, named_table]). ingredients 43> ets:insert(ingredients, [{ketchup, \"not much\"}, {mustard, \"a lot\"}, {cheese, \"yes\", \"goat\"}, {patty, \"moose\"}, {onions, \"a lot\", \"caramelized\"}]). true 44> Res1 = ets:first(ingredients). cheese 45> Res2 = ets:next(ingredients, Res1). ketchup 46> Res3 = ets:next(ingredients, Res2). mustard 47> ets:last(ingredients). patty 48> ets:prev(ingredients, ets:last(ingredients)). onions   \n\nnamed_tableオプションつきbagテーブルでパターンマッチをする   erlang \n\n53> ets:new(table, [named_table, bag]). table 54> ets:insert(table, [{items, a, b, c, d}, {items, a, b, c, a}, {cat, brown, soft, loveable, selfish}, {friends, [jem, jeff, etc]}, {items, 1, 2, 3, 1}]). true 55> ets:match(table, {items, '$1', '$2', '_', '$1'}). [[a,b],[1,2]] 56> ets:match(table, {items, '$114', '$212', '_', '$6'}). [[d,a,b],[a,a,b],[1,1,2]] 57> ets:match_object(table, {items, '$1', '$2', '_', '$1'}). [{items,a,b,c,a},{items,1,2,3,1}] 58> ets:delete(table). true     > 29 分散システム EPMD29 分散システム EPMD \n\n- 今回は分散システム Erlang Port Mapper Daemon (EPMD) についてかんがえる。今回の章がSLAにもっとも関係しているといえそうである。ほかの言語・フレームワークが「分散コンピューティングの落とし穴」「CAP定理」にどのように対応している比較すると、Erlangの特徴がより見えてくるだろう。   > 分散システムEPMDの特徴分散システムEPMDの特徴 \n\n前提 \n\n- 分散システムによるFault toleranceについて ソフトウェアの稼働状況と対ハードウェア障害リスク マシン1台 リスク対策できない マシン複数台 アプリケーションが正しく構築されない場合、リスク対策できない \n- ソフトウェアの稼働状況と対ハードウェア障害リスク マシン1台 リスク対策できない マシン複数台 アプリケーションが正しく構築されない場合、リスク対策できない \n- マシン1台 リスク対策できない \n- リスク対策できない\n- マシン複数台 アプリケーションが正しく構築されない場合、リスク対策できない \n- アプリケーションが正しく構築されない場合、リスク対策できない\n- 「分散コンピューティングの落とし穴」へのErlangの対応 ネットワークは信頼できる Erlangの対応 非同期通信モード（リンクやモニタ）により、メッセージを送信に正常な場合に必ず返信するように設計 ただし、ノード間でリンクやモニタを張った際にネットワーク障害起きた場合、リンクやモニタが一斉にトリガーされシステムに予期しない負荷をかけることになる レイテンシはゼロである Erlangの対応 タイムアウト、リンク、モニタ、非同期パターンにより遅延を想定し設計 帯域幅は無限である Erlangの対応 大きなメッセージを送らない ネットワークはセキュアである Erlangの対応 Erlangはネットワークの安全性を確認しないため 異なるデータセンター間で自動的にクラスタ化しない あるいは、SSLに切り替える 安全なチャンネル越しにトンネルする ノード間の通信プロトコルを再実装する ネットワーク構成は変化せず一定である Erlangの対応 アプリケーションでネットワーク構成（トポロジー）を管理しない 管理者は1人である Erlangの対応 デバッグツールによる個別障害対応 ノード監視ツールによるシステム運用状況の共有 実装プロトコルやAPIのバージョン管理 転送コストはゼロである Erlangの対応 Erlangはほかのノードに渡されるメッセージを圧縮しないため 送るメッセージを小さくする あるいは、独自の通信レイヤを実装する ネットワークは均質である Erlangの対応 Erlangノードと同じプロトコル形式にして通信 Cノード BERT BERT-RPC \n- ネットワークは信頼できる Erlangの対応 非同期通信モード（リンクやモニタ）により、メッセージを送信に正常な場合に必ず返信するように設計 ただし、ノード間でリンクやモニタを張った際にネットワーク障害起きた場合、リンクやモニタが一斉にトリガーされシステムに予期しない負荷をかけることになる \n- Erlangの対応 非同期通信モード（リンクやモニタ）により、メッセージを送信に正常な場合に必ず返信するように設計 ただし、ノード間でリンクやモニタを張った際にネットワーク障害起きた場合、リンクやモニタが一斉にトリガーされシステムに予期しない負荷をかけることになる \n- 非同期通信モード（リンクやモニタ）により、メッセージを送信に正常な場合に必ず返信するように設計\n- ただし、ノード間でリンクやモニタを張った際にネットワーク障害起きた場合、リンクやモニタが一斉にトリガーされシステムに予期しない負荷をかけることになる\n- レイテンシはゼロである Erlangの対応 タイムアウト、リンク、モニタ、非同期パターンにより遅延を想定し設計 \n- Erlangの対応 タイムアウト、リンク、モニタ、非同期パターンにより遅延を想定し設計 \n- タイムアウト、リンク、モニタ、非同期パターンにより遅延を想定し設計\n- 帯域幅は無限である Erlangの対応 大きなメッセージを送らない \n- Erlangの対応 大きなメッセージを送らない \n- 大きなメッセージを送らない\n- ネットワークはセキュアである Erlangの対応 Erlangはネットワークの安全性を確認しないため 異なるデータセンター間で自動的にクラスタ化しない あるいは、SSLに切り替える 安全なチャンネル越しにトンネルする ノード間の通信プロトコルを再実装する \n- Erlangの対応 Erlangはネットワークの安全性を確認しないため 異なるデータセンター間で自動的にクラスタ化しない あるいは、SSLに切り替える 安全なチャンネル越しにトンネルする ノード間の通信プロトコルを再実装する \n- Erlangはネットワークの安全性を確認しないため 異なるデータセンター間で自動的にクラスタ化しない あるいは、SSLに切り替える 安全なチャンネル越しにトンネルする ノード間の通信プロトコルを再実装する \n- 異なるデータセンター間で自動的にクラスタ化しない\n- あるいは、SSLに切り替える\n- 安全なチャンネル越しにトンネルする\n- ノード間の通信プロトコルを再実装する\n- ネットワーク構成は変化せず一定である Erlangの対応 アプリケーションでネットワーク構成（トポロジー）を管理しない \n- Erlangの対応 アプリケーションでネットワーク構成（トポロジー）を管理しない \n- アプリケーションでネットワーク構成（トポロジー）を管理しない\n- 管理者は1人である Erlangの対応 デバッグツールによる個別障害対応 ノード監視ツールによるシステム運用状況の共有 実装プロトコルやAPIのバージョン管理 \n- Erlangの対応 デバッグツールによる個別障害対応 ノード監視ツールによるシステム運用状況の共有 実装プロトコルやAPIのバージョン管理 \n- デバッグツールによる個別障害対応\n- ノード監視ツールによるシステム運用状況の共有\n- 実装プロトコルやAPIのバージョン管理\n- 転送コストはゼロである Erlangの対応 Erlangはほかのノードに渡されるメッセージを圧縮しないため 送るメッセージを小さくする あるいは、独自の通信レイヤを実装する \n- Erlangの対応 Erlangはほかのノードに渡されるメッセージを圧縮しないため 送るメッセージを小さくする あるいは、独自の通信レイヤを実装する \n- Erlangはほかのノードに渡されるメッセージを圧縮しないため 送るメッセージを小さくする あるいは、独自の通信レイヤを実装する \n- 送るメッセージを小さくする\n- あるいは、独自の通信レイヤを実装する\n- ネットワークは均質である Erlangの対応 Erlangノードと同じプロトコル形式にして通信 Cノード BERT BERT-RPC \n- Erlangの対応 Erlangノードと同じプロトコル形式にして通信 Cノード BERT BERT-RPC \n- Erlangノードと同じプロトコル形式にして通信 Cノード BERT BERT-RPC \n- Cノード\n- BERT\n- BERT-RPC\n- 障害（ノードの応答不能）への対応 下記の中から原因を特定するが確実には対応できない ハードウェア障害 アプリケーションクラッシュ ネットワーク分断 輻輳 遮断 ゾンビ化するということ ネットワーク分断が起きている間アプリケーションが生きていた場合 当該ノードで保持していたデータがクラスタ間で保持していたデータと整合性がとれず、欠損扱いになる（一貫性の欠如） 当該ノードからレスポンスが返ってこないため生きているか死んでいるかわからない（可用性の欠如） CAP（Consistency, Availability, Partition Tolerance）定理 ノード間において、同時に下記3つの要素を保証することはできない 一貫性 Consistency すべてのデータ読み込みにおいて、最新の書き込みデータもしくはエラーのどちらかを受け取れること 可用性 Availability システム要求に応答できること（SPOFがない） 分断耐性 Partition tolerance ネットワーク分断時でもシステムを継続して運用できること 組合せ、採用条件、採用ケース CA 採用条件 ネットワークが絶対に落ちない場合 ネットワークが1つの塊として動作している場合 データの読み書きが多い場合 採用ケース RDBMS NFS AP 採用条件 ネットワーク分断が起きやすい場合 SPOFがない場合 ネットワーク分断時データ変更不可だと問題がある場合 結果整合性を適用可能な場合 時間ベース 個別にコンフリクト解消 全ノードによる合意 合意割合による調整 問い合わせ対象による調整 採用ケース Amazon SimpleDB Apache Cassandra DNS HTTPキャッシュ CP 採用条件 ネットワーク分断が起きやすい場合 SPOFがある場合 ネットワーク分断時データ変更不可でも問題ない場合 採用ケース Mnesia Apache HBase \n- 下記の中から原因を特定するが確実には対応できない ハードウェア障害 アプリケーションクラッシュ ネットワーク分断 輻輳 遮断 \n- ハードウェア障害\n- アプリケーションクラッシュ\n- ネットワーク分断 輻輳 遮断 \n- 輻輳\n- 遮断\n- ゾンビ化するということ ネットワーク分断が起きている間アプリケーションが生きていた場合 当該ノードで保持していたデータがクラスタ間で保持していたデータと整合性がとれず、欠損扱いになる（一貫性の欠如） 当該ノードからレスポンスが返ってこないため生きているか死んでいるかわからない（可用性の欠如） \n- ネットワーク分断が起きている間アプリケーションが生きていた場合 当該ノードで保持していたデータがクラスタ間で保持していたデータと整合性がとれず、欠損扱いになる（一貫性の欠如） 当該ノードからレスポンスが返ってこないため生きているか死んでいるかわからない（可用性の欠如） \n- 当該ノードで保持していたデータがクラスタ間で保持していたデータと整合性がとれず、欠損扱いになる（一貫性の欠如）\n- 当該ノードからレスポンスが返ってこないため生きているか死んでいるかわからない（可用性の欠如）\n- CAP（Consistency, Availability, Partition Tolerance）定理 ノード間において、同時に下記3つの要素を保証することはできない 一貫性 Consistency すべてのデータ読み込みにおいて、最新の書き込みデータもしくはエラーのどちらかを受け取れること 可用性 Availability システム要求に応答できること（SPOFがない） 分断耐性 Partition tolerance ネットワーク分断時でもシステムを継続して運用できること 組合せ、採用条件、採用ケース CA 採用条件 ネットワークが絶対に落ちない場合 ネットワークが1つの塊として動作している場合 データの読み書きが多い場合 採用ケース RDBMS NFS AP 採用条件 ネットワーク分断が起きやすい場合 SPOFがない場合 ネットワーク分断時データ変更不可だと問題がある場合 結果整合性を適用可能な場合 時間ベース 個別にコンフリクト解消 全ノードによる合意 合意割合による調整 問い合わせ対象による調整 採用ケース Amazon SimpleDB Apache Cassandra DNS HTTPキャッシュ CP 採用条件 ネットワーク分断が起きやすい場合 SPOFがある場合 ネットワーク分断時データ変更不可でも問題ない場合 採用ケース Mnesia Apache HBase \n- ノード間において、同時に下記3つの要素を保証することはできない 一貫性 Consistency すべてのデータ読み込みにおいて、最新の書き込みデータもしくはエラーのどちらかを受け取れること 可用性 Availability システム要求に応答できること（SPOFがない） 分断耐性 Partition tolerance ネットワーク分断時でもシステムを継続して運用できること \n- 一貫性 Consistency すべてのデータ読み込みにおいて、最新の書き込みデータもしくはエラーのどちらかを受け取れること \n- すべてのデータ読み込みにおいて、最新の書き込みデータもしくはエラーのどちらかを受け取れること\n- 可用性 Availability システム要求に応答できること（SPOFがない） \n- システム要求に応答できること（SPOFがない）\n- 分断耐性 Partition tolerance ネットワーク分断時でもシステムを継続して運用できること \n- ネットワーク分断時でもシステムを継続して運用できること\n- 組合せ、採用条件、採用ケース CA 採用条件 ネットワークが絶対に落ちない場合 ネットワークが1つの塊として動作している場合 データの読み書きが多い場合 採用ケース RDBMS NFS AP 採用条件 ネットワーク分断が起きやすい場合 SPOFがない場合 ネットワーク分断時データ変更不可だと問題がある場合 結果整合性を適用可能な場合 時間ベース 個別にコンフリクト解消 全ノードによる合意 合意割合による調整 問い合わせ対象による調整 採用ケース Amazon SimpleDB Apache Cassandra DNS HTTPキャッシュ CP 採用条件 ネットワーク分断が起きやすい場合 SPOFがある場合 ネットワーク分断時データ変更不可でも問題ない場合 採用ケース Mnesia Apache HBase \n- CA 採用条件 ネットワークが絶対に落ちない場合 ネットワークが1つの塊として動作している場合 データの読み書きが多い場合 採用ケース RDBMS NFS \n- 採用条件 ネットワークが絶対に落ちない場合 ネットワークが1つの塊として動作している場合 データの読み書きが多い場合 \n- ネットワークが絶対に落ちない場合\n- ネットワークが1つの塊として動作している場合\n- データの読み書きが多い場合\n- 採用ケース RDBMS NFS \n- RDBMS\n- NFS\n- AP 採用条件 ネットワーク分断が起きやすい場合 SPOFがない場合 ネットワーク分断時データ変更不可だと問題がある場合 結果整合性を適用可能な場合 時間ベース 個別にコンフリクト解消 全ノードによる合意 合意割合による調整 問い合わせ対象による調整 採用ケース Amazon SimpleDB Apache Cassandra DNS HTTPキャッシュ \n- 採用条件 ネットワーク分断が起きやすい場合 SPOFがない場合 ネットワーク分断時データ変更不可だと問題がある場合 結果整合性を適用可能な場合 時間ベース 個別にコンフリクト解消 全ノードによる合意 合意割合による調整 問い合わせ対象による調整 \n- ネットワーク分断が起きやすい場合\n- SPOFがない場合\n- ネットワーク分断時データ変更不可だと問題がある場合\n- 結果整合性を適用可能な場合 時間ベース 個別にコンフリクト解消 全ノードによる合意 合意割合による調整 問い合わせ対象による調整 \n- 時間ベース\n- 個別にコンフリクト解消\n- 全ノードによる合意 合意割合による調整 問い合わせ対象による調整 \n- 合意割合による調整\n- 問い合わせ対象による調整\n- 採用ケース Amazon SimpleDB Apache Cassandra DNS HTTPキャッシュ \n- Amazon SimpleDB\n- Apache Cassandra\n- DNS\n- HTTPキャッシュ\n- CP 採用条件 ネットワーク分断が起きやすい場合 SPOFがある場合 ネットワーク分断時データ変更不可でも問題ない場合 採用ケース Mnesia Apache HBase \n- 採用条件 ネットワーク分断が起きやすい場合 SPOFがある場合 ネットワーク分断時データ変更不可でも問題ない場合 \n- ネットワーク分断が起きやすい場合\n- SPOFがある場合\n- ネットワーク分断時データ変更不可でも問題ない場合\n- 採用ケース Mnesia Apache HBase \n- Mnesia\n- Apache HBase \n\nErlangが提供する道具 \n\n- ノードとEPMD 特徴 ノードとはErlang VMのインスタンスのこと 各ノードはEPMDに接続されている 新しいノードは自動的にErlangクラスタに接続され、各ノードに接続される 接続されているノードでも完全に独立している 各ノードが固有に保持しているもの プロセスレジストリ ETSテーブル 読み込んだモジュール EPMDはErlangクラスタの一部として、各コンピューター上で稼働する EPMDは名前サーバとして機能する Pros Fault tolerance Cons 1ノードにつき1エフェメラルポートが必要になるため、Scalingに制限がある 対処として、ノードのグループを小さなクラスタに分割 \n- 特徴 ノードとはErlang VMのインスタンスのこと 各ノードはEPMDに接続されている 新しいノードは自動的にErlangクラスタに接続され、各ノードに接続される 接続されているノードでも完全に独立している 各ノードが固有に保持しているもの プロセスレジストリ ETSテーブル 読み込んだモジュール EPMDはErlangクラスタの一部として、各コンピューター上で稼働する EPMDは名前サーバとして機能する \n- ノードとはErlang VMのインスタンスのこと\n- 各ノードはEPMDに接続されている 新しいノードは自動的にErlangクラスタに接続され、各ノードに接続される \n- 新しいノードは自動的にErlangクラスタに接続され、各ノードに接続される\n- 接続されているノードでも完全に独立している 各ノードが固有に保持しているもの プロセスレジストリ ETSテーブル 読み込んだモジュール \n- 各ノードが固有に保持しているもの プロセスレジストリ ETSテーブル 読み込んだモジュール \n- プロセスレジストリ\n- ETSテーブル\n- 読み込んだモジュール\n- EPMDはErlangクラスタの一部として、各コンピューター上で稼働する\n- EPMDは名前サーバとして機能する\n- Pros Fault tolerance \n- Fault tolerance\n- Cons 1ノードにつき1エフェメラルポートが必要になるため、Scalingに制限がある 対処として、ノードのグループを小さなクラスタに分割 \n- 1ノードにつき1エフェメラルポートが必要になるため、Scalingに制限がある 対処として、ノードのグループを小さなクラスタに分割 \n- 対処として、ノードのグループを小さなクラスタに分割\n- シリアライズ、デシリアライズ\n- マルチプロセス\n- ネットワークの障害監視 \n\nErlangクラスタを設定する \n\n- ノードの名前解決 長い名前 aaa.bbb.cccのような完全修飾ドメイン名 DNSリゾルバによって解決 erl -name LongName 短い名前 ピリオドがないホスト名 ホストファイルやDNSエントリによって解決 erl -sname ShortName 注意点 1台のコンピューター上でErlangノードを設定する際は通常短い名前をつかう 長い名前と短い名前、双方でのやり取りはできない \n- 長い名前 aaa.bbb.cccのような完全修飾ドメイン名 DNSリゾルバによって解決 erl -name LongName \n- aaa.bbb.cccのような完全修飾ドメイン名\n- DNSリゾルバによって解決\n- erl -name LongName\n- 短い名前 ピリオドがないホスト名 ホストファイルやDNSエントリによって解決 erl -sname ShortName \n- ピリオドがないホスト名\n- ホストファイルやDNSエントリによって解決\n- erl -sname ShortName\n- 注意点 1台のコンピューター上でErlangノードを設定する際は通常短い名前をつかう 長い名前と短い名前、双方でのやり取りはできない \n- 1台のコンピューター上でErlangノードを設定する際は通常短い名前をつかう\n- 長い名前と短い名前、双方でのやり取りはできない\n- 関数 net_kernel:connect_node/1 - ノード接続 ノード名参照 node/0 - 現在のノード名を参照 nodes/0 - 接続ノード参照 リンクとモニタ link - ノードをまたいだリンク erlang:monitor/2 - ノードをまたいだモニタ（ネットワーク分断時に一斉に活性化し負荷が増加する可能性あり） erlang:monitor_node/2 - ノードを指定したモニタ 遠隔操作 spawn/2 spawn/4 spawn_link/2 spawn_link/4 \n- net_kernel:connect_node/1 - ノード接続\n- ノード名参照 node/0 - 現在のノード名を参照 nodes/0 - 接続ノード参照 \n- node/0 - 現在のノード名を参照\n- nodes/0 - 接続ノード参照\n- リンクとモニタ link - ノードをまたいだリンク erlang:monitor/2 - ノードをまたいだモニタ（ネットワーク分断時に一斉に活性化し負荷が増加する可能性あり） erlang:monitor_node/2 - ノードを指定したモニタ \n- link - ノードをまたいだリンク\n- erlang:monitor/2 - ノードをまたいだモニタ（ネットワーク分断時に一斉に活性化し負荷が増加する可能性あり）\n- erlang:monitor_node/2 - ノードを指定したモニタ\n- 遠隔操作 spawn/2 spawn/4 spawn_link/2 spawn_link/4 \n- spawn/2\n- spawn/4\n- spawn_link/2\n- spawn_link/4\n- クラスタのUIDトークンとしてのCookie 関数 erl -sname ShortName -setcookie CookieName erlang:get_cookei/0 erlang:set_cookei/2 \n- 関数 erl -sname ShortName -setcookie CookieName erlang:get_cookei/0 erlang:set_cookei/2 \n- erl -sname ShortName -setcookie CookieName\n- erlang:get_cookei/0\n- erlang:set_cookei/2\n- 隠しノード クラスタを介してノード接続すると、クラスタ間で予期しないメッセージ通信がおこなわれる可能性があるため、それを防止する策としてクラスタを介さず接続可能な隠しノード機能がある 関数 erlang:send(Dest, Message, [noconnect]) - クラスタを介さずにノードに接続 erl -sname ShortName -hidden - クラスタを介さずに隠しノードに接続 nodes(hidden) - 隠しノードを参照 \n- クラスタを介してノード接続すると、クラスタ間で予期しないメッセージ通信がおこなわれる可能性があるため、それを防止する策としてクラスタを介さず接続可能な隠しノード機能がある\n- 関数 erlang:send(Dest, Message, [noconnect]) - クラスタを介さずにノードに接続 erl -sname ShortName -hidden - クラスタを介さずに隠しノードに接続 nodes(hidden) - 隠しノードを参照 \n- erlang:send(Dest, Message, [noconnect]) - クラスタを介さずにノードに接続\n- erl -sname ShortName -hidden - クラスタを介さずに隠しノードに接続\n- nodes(hidden) - 隠しノードを参照\n- ポート範囲指定 EPMDのポート番号は 4369 設定方法 erl -name LongName -kernel inet_dist_listen_min 9100 -kernel inet_dist_listen_max 9115 erl -name LongName -config ports ports.config: [{kernel, [{inet_dist_listen_min, 9100}, {inet_dist_listen_max, 9115}]}]. \n- EPMDのポート番号は 4369 \n- 設定方法 erl -name LongName -kernel inet_dist_listen_min 9100 -kernel inet_dist_listen_max 9115 erl -name LongName -config ports ports.config: [{kernel, [{inet_dist_listen_min, 9100}, {inet_dist_listen_max, 9115}]}]. \n- erl -name LongName -kernel inet_dist_listen_min 9100 -kernel inet_dist_listen_max 9115\n- erl -name LongName -config ports ports.config: [{kernel, [{inet_dist_listen_min, 9100}, {inet_dist_listen_max, 9115}]}]. \n- ports.config: [{kernel, [{inet_dist_listen_min, 9100}, {inet_dist_listen_max, 9115}]}]. \n- 分散用モジュール net_kernel start([Name, Type, HeartbeatInMilliseconds]) - インスタンスを一時的にノード化 set_net_ticktime(Milliseconds) - Ticktime（ハートビートを4倍した時間、ノードの死亡判定時間）を設定変更 global - プロセスレジストリの代替 register_name(Name, Pid) - gloabl登録し名前変更 unregister_name(Name, Pid) - globalから名前解除 re_register_name(Name, Pid) - 参照先の喪失を防ぎながらglobal登録し名前変更 whereis_name(Name) - PID探索 send(Name, Message) - メッセージ送信 random_exit_name/3 - ランダムにプロセスをkillする random_notify_name/3 - 2つのプロセスのうちいかすプロセスをランダムに1つ選び、globalから解除されるプロセスに {global_name_conflict, Name} というメッセージを送信 notify_all_name/3 - 指定したPIDプロセスをglobalから解除し、 {global_name_conflict, Name, OtherPid} というメッセージを送信、コンフリクト解消を促す rpc call(Node, Module, Function, Args[, Timout]) async_call(Node, Mod, Fun, Args[, Timout]) yield(AsyncPid) nb_yield(AsyncPid[, Timeout]) - ポーリング、ロングポーリング cast(Node, Mod, Fun, Args) - 返値なしのコール multicall(Nodes, Mod, Fun, Args) - 複数ノードへのコール eval_everywhere(Nodes, Mod, Fun, Args) - 複数ノードへの命令（コールとほぼ同じ） \n- net_kernel start([Name, Type, HeartbeatInMilliseconds]) - インスタンスを一時的にノード化 set_net_ticktime(Milliseconds) - Ticktime（ハートビートを4倍した時間、ノードの死亡判定時間）を設定変更 \n- start([Name, Type, HeartbeatInMilliseconds]) - インスタンスを一時的にノード化\n- set_net_ticktime(Milliseconds) - Ticktime（ハートビートを4倍した時間、ノードの死亡判定時間）を設定変更\n- global - プロセスレジストリの代替 register_name(Name, Pid) - gloabl登録し名前変更 unregister_name(Name, Pid) - globalから名前解除 re_register_name(Name, Pid) - 参照先の喪失を防ぎながらglobal登録し名前変更 whereis_name(Name) - PID探索 send(Name, Message) - メッセージ送信 random_exit_name/3 - ランダムにプロセスをkillする random_notify_name/3 - 2つのプロセスのうちいかすプロセスをランダムに1つ選び、globalから解除されるプロセスに {global_name_conflict, Name} というメッセージを送信 notify_all_name/3 - 指定したPIDプロセスをglobalから解除し、 {global_name_conflict, Name, OtherPid} というメッセージを送信、コンフリクト解消を促す \n- register_name(Name, Pid) - gloabl登録し名前変更\n- unregister_name(Name, Pid) - globalから名前解除\n- re_register_name(Name, Pid) - 参照先の喪失を防ぎながらglobal登録し名前変更\n- whereis_name(Name) - PID探索\n- send(Name, Message) - メッセージ送信\n- random_exit_name/3 - ランダムにプロセスをkillする\n- random_notify_name/3 - 2つのプロセスのうちいかすプロセスをランダムに1つ選び、globalから解除されるプロセスに {global_name_conflict, Name} というメッセージを送信\n- notify_all_name/3 - 指定したPIDプロセスをglobalから解除し、 {global_name_conflict, Name, OtherPid} というメッセージを送信、コンフリクト解消を促す\n- rpc call(Node, Module, Function, Args[, Timout]) async_call(Node, Mod, Fun, Args[, Timout]) yield(AsyncPid) nb_yield(AsyncPid[, Timeout]) - ポーリング、ロングポーリング cast(Node, Mod, Fun, Args) - 返値なしのコール multicall(Nodes, Mod, Fun, Args) - 複数ノードへのコール eval_everywhere(Nodes, Mod, Fun, Args) - 複数ノードへの命令（コールとほぼ同じ） \n- call(Node, Module, Function, Args[, Timout])\n- async_call(Node, Mod, Fun, Args[, Timout])\n- yield(AsyncPid)\n- nb_yield(AsyncPid[, Timeout]) - ポーリング、ロングポーリング\n- cast(Node, Mod, Fun, Args) - 返値なしのコール\n- multicall(Nodes, Mod, Fun, Args) - 複数ノードへのコール\n- eval_everywhere(Nodes, Mod, Fun, Args) - 複数ノードへの命令（コールとほぼ同じ）   > 30 分散OTP30 分散OTP \n\n- 前回の分散の章でnine ninesのなぞが見えてきた。今回はそれを補完する分散OTPについてかんがえる。   > 分散アプリケーションの特徴分散アプリケーションの特徴 \n\n構成 \n\n- 標準アプリケーション アプリケーションコントローラ（ノード） アプリケーションマスタ スーパーバイザ \n- アプリケーションコントローラ（ノード） アプリケーションマスタ スーパーバイザ \n- アプリケーションマスタ スーパーバイザ \n- スーパーバイザ\n- 分散アプリケーション アプリケーションコントローラ（ノード） アプリケーションマスタ スーパーバイザ \n- アプリケーションコントローラ（ノード） アプリケーションマスタ スーパーバイザ \n- アプリケーションマスタ スーパーバイザ \n- スーパーバイザ \n\nライフサイクル \n\n- 標準アプリケーション 1. 読込中2. 起動中3. 停止中4. 解放中 \n- 分散アプリケーション 1. 読込中2. 起動中 稼働中の分散ノードが死んだら稼働中ステータスに移行 3. 稼働中の分散ノードが死んだら稼働中ステータスに移行4. 稼働中 稼働中ステータスは1つのノードのみ 5. 稼働中ステータスは1つのノードのみ6. 停止中7. 解放中  \n\n再起動戦略 \n\n- 特徴 ハードウェア障害を前提にしたCAシステムでよくとられます ネットワーク分断を前提にしたCPシステムの場合は採用を熟慮すること \n- ハードウェア障害を前提にしたCAシステムでよくとられます\n- ネットワーク分断を前提にしたCPシステムの場合は採用を熟慮すること\n- 2つの戦略 フェイルオーバー アプリケーション停止後、別の場所で再起動する戦略 メインとバックアップを入れ替える方法 複数台サーバを立ち上げて相互に負荷を補完しあう方法 テイクオーバー アプリケーション復活後、バックアップからメインに移行する戦略 \n- フェイルオーバー アプリケーション停止後、別の場所で再起動する戦略 メインとバックアップを入れ替える方法 複数台サーバを立ち上げて相互に負荷を補完しあう方法 \n- アプリケーション停止後、別の場所で再起動する戦略 メインとバックアップを入れ替える方法 複数台サーバを立ち上げて相互に負荷を補完しあう方法 \n- メインとバックアップを入れ替える方法\n- 複数台サーバを立ち上げて相互に負荷を補完しあう方法\n- テイクオーバー アプリケーション復活後、バックアップからメインに移行する戦略 \n- アプリケーション復活後、バックアップからメインに移行する戦略   > 32 Mnesia32 Mnesia   > Mnesiaの特徴Mnesiaの特徴 \n\n- Pros CPシステム（NoSQL） トランザクション機能 (ACID) ネットワーク分断につよい ただし、10ノード前後が実用上の限界と考えられている \n- CPシステム（NoSQL） トランザクション機能 (ACID) ネットワーク分断につよい ただし、10ノード前後が実用上の限界と考えられている \n- トランザクション機能 (ACID)\n- ネットワーク分断につよい ただし、10ノード前後が実用上の限界と考えられている \n- ただし、10ノード前後が実用上の限界と考えられている\n- Cons 各テーブルにつき2Gの容量制限 Table Frangmentation機能で回避可能 厳密なシステム要求に応答することはむずかしい 数テラバイトの大きなデータをあつかうのに向いていない 組込型制限がない \n- 各テーブルにつき2Gの容量制限 Table Frangmentation機能で回避可能 \n- Table Frangmentation機能で回避可能\n- 厳密なシステム要求に応答することはむずかしい\n- 数テラバイトの大きなデータをあつかうのに向いていない\n- 組込型制限がない \n\n適切なユースケース \n\n- 下記条件をみたした場合 ノード数、データ量双方を見積もることが可能 ETS/DETS（タプル）形式でアクセス可能 \n- ノード数、データ量双方を見積もることが可能\n- ETS/DETS（タプル）形式でアクセス可能 \n\nテーブルオプション \n\n- 保存方法 ram_copies - データをETS（メモリ）にのみ保存、32ビットマシンで4Gの容量制限 disc_only_copies - データをDETSにのみ保存、2Gの容量制限 disc_copies - データをETSとDETS双方に保存、DETSの2G容量制限はない、通常はこちらはつかう \n- ram_copies - データをETS（メモリ）にのみ保存、32ビットマシンで4Gの容量制限\n- disc_only_copies - データをDETSにのみ保存、2Gの容量制限\n- disc_copies - データをETSとDETS双方に保存、DETSの2G容量制限はない、通常はこちらはつかう\n- テーブル種類 set bag ordered_set \n- set\n- bag\n- ordered_set \n\nCLI \n\n- erl -name LongName -mnesia dir path/to/db - dir 変数でスキーマ保存場所を指定 \n\n関数 \n\n- mnesia create_schema(ListOfNodes) create_table(TableName, Option) オプション {attributes, List} - テーブルのカラム名 {disc_copies, NodeList} {disc_only_copies, NodeList} {ram_copies, NodeList} - テーブルの保存場所 {index, ListOfIntegers} - インデックスをはる {record_name, Atom} - テーブルの別名（非推奨） {type, Type} - テーブル種類 (set, ordered_set, bag) {local_content, Boolean} - デフォルト false。true にすると、多数のノード上に共有されない固有のローカルテーブルを作成する wait_for_tables - テーブル読込完了まで待機 activity(AccessContext, Fun[, Args]) - クエリの実行方法を指定 AccessContextの種類 transaction - 非同期トランザクション、トランザクションの完了を待つわけではないので正確ではない sync_transaction - 同期トランザクション async_dirty - 非同期のロックなし処理 sync_dirty - 同期のロックなし処理 ets - MnesiaをつかわずETSテーブルで処理 write delete read match_object select \n- create_schema(ListOfNodes)\n- create_table(TableName, Option) オプション {attributes, List} - テーブルのカラム名 {disc_copies, NodeList} {disc_only_copies, NodeList} {ram_copies, NodeList} - テーブルの保存場所 {index, ListOfIntegers} - インデックスをはる {record_name, Atom} - テーブルの別名（非推奨） {type, Type} - テーブル種類 (set, ordered_set, bag) {local_content, Boolean} - デフォルト false。true にすると、多数のノード上に共有されない固有のローカルテーブルを作成する \n- オプション {attributes, List} - テーブルのカラム名 {disc_copies, NodeList} {disc_only_copies, NodeList} {ram_copies, NodeList} - テーブルの保存場所 {index, ListOfIntegers} - インデックスをはる {record_name, Atom} - テーブルの別名（非推奨） {type, Type} - テーブル種類 (set, ordered_set, bag) {local_content, Boolean} - デフォルト false。true にすると、多数のノード上に共有されない固有のローカルテーブルを作成する \n- {attributes, List} - テーブルのカラム名\n- {disc_copies, NodeList} {disc_only_copies, NodeList} {ram_copies, NodeList} - テーブルの保存場所\n- {index, ListOfIntegers} - インデックスをはる\n- {record_name, Atom} - テーブルの別名（非推奨）\n- {type, Type} - テーブル種類 (set, ordered_set, bag)\n- {local_content, Boolean} - デフォルト false。true にすると、多数のノード上に共有されない固有のローカルテーブルを作成する\n- wait_for_tables - テーブル読込完了まで待機\n- activity(AccessContext, Fun[, Args]) - クエリの実行方法を指定 AccessContextの種類 transaction - 非同期トランザクション、トランザクションの完了を待つわけではないので正確ではない sync_transaction - 同期トランザクション async_dirty - 非同期のロックなし処理 sync_dirty - 同期のロックなし処理 ets - MnesiaをつかわずETSテーブルで処理 \n- AccessContextの種類 transaction - 非同期トランザクション、トランザクションの完了を待つわけではないので正確ではない sync_transaction - 同期トランザクション async_dirty - 非同期のロックなし処理 sync_dirty - 同期のロックなし処理 ets - MnesiaをつかわずETSテーブルで処理 \n- transaction - 非同期トランザクション、トランザクションの完了を待つわけではないので正確ではない\n- sync_transaction - 同期トランザクション\n- async_dirty - 非同期のロックなし処理\n- sync_dirty - 同期のロックなし処理\n- ets - MnesiaをつかわずETSテーブルで処理\n- write\n- delete\n- read\n- match_object\n- select\n- application set_env(mnesia, dir, \"path/to/db\") - スキーマ保存場所を指定 \n- set_env(mnesia, dir, \"path/to/db\") - スキーマ保存場所を指定 \n\nクエリリスト内包表記 \n\n- qlc q(Fun, Generator) - クエリハンドル eval(QueryHandle) - 評価 fold(Fun, Dict, QueryHandle) \n- q(Fun, Generator) - クエリハンドル\n- eval(QueryHandle) - 評価\n- fold(Fun, Dict, QueryHandle)   > 33 Dialyzer33 Dialyzer \n\n今回は静的型チェッカーDialyzerについてかんがえる。   > Dialyzerの特徴Dialyzerの特徴 \n\nCLI \n\n- PLT (Persistent Lookup Table 永続的探索表) dialyzer --build_plt --apps erts kernel stdlib mnesia sasl common_test eunit - PLT作成 dialyzer --add_to_plt --apps reltool - PLT追加 \n- dialyzer --build_plt --apps erts kernel stdlib mnesia sasl common_test eunit - PLT作成\n- dialyzer --add_to_plt --apps reltool - PLT追加\n- 型チェック dialyzer foo/src/bar.erl - ファイルを解析 dialyzer -r foo/src bar/src --src - ディレクトリ指定してerlファイルを解析 \n- dialyzer foo/src/bar.erl - ファイルを解析\n- dialyzer -r foo/src bar/src --src - ディレクトリ指定してerlファイルを解析 \n\nErlangの型 \n\n- シングルトン型 - それ自体が型を示すオブジェクト 'some atom - アトム 42 - 整数 [] - 空リスト {} - 空タプル <<>> - 空バイナリ \n- 'some atom - アトム\n- 42 - 整数\n- [] - 空リスト\n- {} - 空タプル\n- <<>> - 空バイナリ\n- BIF型 any() none() pid() port() reference() atom() atom() binary() <<_:Integer>> - 特定サイズのバイナリ <<_:*Integer>> - 特定のユニットサイズで長さは指定されていないバイナリ <<_:Integer, _:_*OtherInteger>> - 上記2つの組み合わせ、バイナリの最小の長さを指定する形式 integer() N..M - 整数の範囲 non_neg_integer() pos_integer() - ゼロより大きい自然数 neg_integer() - 負の整数 float() fun() - あらゆる種類の関数 fun((...) -> Type) - 引数のアリティが決まっていない、特定の肩を返す無名関数 fun(() -> Type) fun((Type1, Type2, ..., TypeN) -> Type) [Type()] - 特定の型を持つリスト [Type(), ...] - 特定の型を持つリスト、またリストが空でないことを示す tuple() {Type1, Type2, ..., TypeN} - 全要素の型とサイズがわかっているタプル \n- any()\n- none()\n- pid()\n- port()\n- reference()\n- atom()\n- atom()\n- binary()\n- <<_:Integer>> - 特定サイズのバイナリ\n- <<_:*Integer>> - 特定のユニットサイズで長さは指定されていないバイナリ\n- <<_:Integer, _:_*OtherInteger>> - 上記2つの組み合わせ、バイナリの最小の長さを指定する形式\n- integer()\n- N..M - 整数の範囲\n- non_neg_integer()\n- pos_integer() - ゼロより大きい自然数\n- neg_integer() - 負の整数\n- float()\n- fun() - あらゆる種類の関数\n- fun((...) -> Type) - 引数のアリティが決まっていない、特定の肩を返す無名関数\n- fun(() -> Type)\n- fun((Type1, Type2, ..., TypeN) -> Type)\n- [Type()] - 特定の型を持つリスト\n- [Type(), ...] - 特定の型を持つリスト、またリストが空でないことを示す\n- tuple()\n- {Type1, Type2, ..., TypeN} - 全要素の型とサイズがわかっているタプル\n- エイリアス型 term() boolean() - 'true' | 'false' byte() - 0..255 char() - 0..16#10ffff number() - integer() | float() maybe_improper_list() - maybe_improper_list(any(), any()) maybe_improper_list(T) - maybe_improper_list(T, any()) string() - [char()] iolist() - maybe_improper_list(char() | binary() | iolist(), binary() | []) module() - atom() timeout() - non_neg_integer() node() - アトム no_return() - none() \n- term()\n- boolean() - 'true' | 'false' \n- byte() - 0..255 \n- char() - 0..16#10ffff \n- number() - integer() | float() \n- maybe_improper_list() - maybe_improper_list(any(), any()) \n- maybe_improper_list(T) - maybe_improper_list(T, any()) \n- string() - [char()] \n- iolist() - maybe_improper_list(char() | binary() | iolist(), binary() | []) \n- module() - atom() \n- timeout() - non_neg_integer() \n- node() - アトム\n- no_return() - none()  \n\n判定できない例と対策   erlang \n\n-module(cards). -export([kind/1, main/0]). -type suit() :: spades | clubs | hearts | diamonds. -type value() :: 1..10 | j | q | k. -type card() :: {suit(), value()}. -spec kind(card()) -> 'face' | 'number'. % 注釈をくわえることでdialyzerに警告させる kind({_, A}) when A >= 1, A =< 10 -> number; kind(_) -> face. main() -> number = kind({spades, 7}), face = kind({hearts, k}), number = kind({rubies, 4}), % タプルの中の型が違う  face = kind({clubs, q}).     erlang \n\n-module(convert). -export([main/0]). %% 注釈をつけないとdialyzerは下記のように判定する % -spec convert(list() | tuple()) -> list() | tuple(). -spec convert(tuple()) -> list(); (list()) -> tuple(). main() -> [_, _] = convert({a, b}), {_, _} = convert([a, b]), [_, _] = convert([a, b]), {_, _} = convert({a, b}). %% private convert(Tup) when is_tuple(Tup) -> tuple_to_list(Tup); convert(L=[_|_]) -> list_to_tuple(L)."},"name":"[2017-04-29]LYSE本を読む","tags":["erlang","elixir"],"childPublishedDate":{"published_on":"2017-04-29T00:00:00.000Z","published_on_unix":1493424000}}},{"node":{"number":49,"relative_category":"blog/backend","fields":{"title":"HydeをつかってEmacsをJekyllクライアントにする","excerpt":"Emacianとしてその殻の中に閉じこもっていたいです。だけど、世間がそれを許さず次々と無理難題を押しつけてくるのです。今回はタスク等から出てきた備忘禄をGitHub Pages（Jekyll）で管理しようと重い腰を上げました。   > PROBLEMPROBLEM \n\n- タスクメモがAsanaなどのタスク管理ツールに散在している\n- ブラウザをつかって文章を書くのがつらい\n- Gist/Yagist等でもいいのだけど編集がめんどうとか個人だとオーバースペックとか   > SOLUTIONSOLUTION \n\nというわけで、GitHub Pages（Jekyll）をEmacsで楽に管理できないかと以前から考えていたのですが、いい塩梅のライブラリを発見しました。JekyllだからHydeと言います。名前が jekyll doctor (hyde)とかぶっていますがここでは気にしません。 \n\nHydeのPros/Consは以下の通りです。 \n\nPros \n\n- gitの自動コメント\n- jekyll build、jekyll serveのショートカット \n\nCons \n\n- キーバインドが既存のものとかぶる\n- hyde-homeがカスタム変数ではない\n- add-hookが効かない   > Hydeの設定Hydeの設定 \n\nHydeの設定は基本いじることもなくJekyllを使うことが出来ます。下記記載するのはConsつぶしですが、ここはお好みです。 \n\nまず、キーバインド操作。Hyde本体がキーバインドをdefvarで割り当てているので、init.elの設定でrequire前に割り込みevalして、hyde関数にhyde-home引数をわたすことで解決します。あと、折り返し回りは別設定になっているのでadaptive-wrapやtruncate-linesを設定しています。   emacs-lisp \n\n;;; Hyde (Jekyll client) (require-package 'adaptive-wrap) (defun hyde/open-post-maybe-into-other-window (pos) \"Opens the post under cursor in the editor (POS).\" (interactive \"d\") (let ((post-file-name (nth 1 (split-string (strip-string (thing-at-point 'line)) \" : \"))) (dir (get-text-property pos 'dir))) (let ((hyde-buffer (current-buffer))) (find-file-other-window (strip-string (concat hyde-home \"/\" dir \"/\" post-file-name))) (hyde-markdown-activate-mode hyde-buffer) (adaptive-wrap-prefix-mode t) (set-default 'truncate-lines nil)))) (defun hyde/quit-wrap () \"Quits hyde.\" (interactive) (progn (delete-other-windows) (kill-buffer (current-buffer)))) (defun create-markdown-scratch () \"Create a markdown scratch buffer.\" (interactive) (switch-to-buffer (get-buffer-create \"*markdown*\")) (markdown-mode)) (defun hyde/nabinno () \"Run hyde-wrap with home parameter.\" (interactive) (progn (delete-other-windows) (create-markdown-scratch) (split-window-horizontally) (other-window 1) (hyde \"~/nabinno.github.io/\"))) (defvar hyde-mode-map (let ((hyde-mode-map (make-sparse-keymap))) (define-key hyde-mode-map (kbd \"N\") 'hyde/new-post) (define-key hyde-mode-map (kbd \"G\") 'hyde/load-posts) (define-key hyde-mode-map (kbd \"C\") 'hyde/hyde-commit-post) (define-key hyde-mode-map (kbd \"P\") 'hyde/hyde-push) (define-key hyde-mode-map (kbd \"J\") 'hyde/run-jekyll) (define-key hyde-mode-map (kbd \"S\") 'hyde/serve) (define-key hyde-mode-map (kbd \"K\") 'hyde/stop-serve) (define-key hyde-mode-map (kbd \"d\") 'hyde/deploy) (define-key hyde-mode-map (kbd \"D\") 'hyde/delete-post) (define-key hyde-mode-map (kbd \"U\") 'hyde/promote-to-post) (define-key hyde-mode-map (kbd \"X\") 'hyde/quit-wrap) (define-key hyde-mode-map (kbd \"O\") 'hyde/open-post-maybe-into-other-window) hyde-mode-map) \"Keymap for Hyde\") (global-set-key (kbd \"C-c ; j\") 'hyde/nabinno) (require-package 'hyde) (require 'hyde)   \n\n次に、ホストIPの操作。Jekyllのルートにおく.hyde.elの中身です。JekyllはWebrickを使っているので、VMなどでホストをいじっている場合はhyde/serve-commandにホストIPを0.0.0.0（jekyll s -H 0.0.0.0）に変更する必要があります。   emacs-lisp \n\n(setq hyde-deploy-dir \"_site\" hyde-posts-dir \"_posts\" hyde-drafts-dir \"_drafts\" hyde-images-dir \"images\" hyde/git/remote \"upstream\" ; The name of the remote to which we should push hyde/git/branch \"master\" ; The name of the branch on which your blog resides hyde/jekyll-command \"jekyll b\" ; Command to build hyde/serve-command \"jekyll s -H 0.0.0.0 --force_polling\" ; Command to serve hyde-custom-params '((\"category\" \"personal\") (\"tags\" \"\") (\"cover\" \"false\") (\"cover-image\" \"\")))     > WRAPUPWRAPUP \n\nHydeを介してEmacsでJekyllを操作できるのは、やはり快適です。特にorg-modeとMarkdownの相性が良く。org-modeで管理していた備忘をMarkdownに変換し、Jekyll（GitHub Pages）にパブリッシュというワークフローが引けたのが良かったです。数年間はお世話になると思います。"},"name":"[2017-02-01]HydeをつかってEmacsをJekyllクライアントにする","tags":["emacs","jekyll","hyde","github-pages"],"childPublishedDate":{"published_on":"2017-02-01T00:00:00.000Z","published_on_unix":1485907200}}},{"node":{"number":61,"relative_category":"blog/health","fields":{"title":"ElixirとRaspberry PiでPM2.5などの環境データを定点観察し、目・喉の痛みに備える","excerpt":"皆さんは体調管理どうされていますか。一度痛い目に遭うと日常の細かい差異が気になってきて、そこをどうにか解決したいというのが人情です。今回は自分の咽頭痛の解消のため一つ実験をしてみました。   > PROBLEMPROBLEM \n\n- 以前からオフィスに行くと目や喉が痛くなることがあったので、自分の体調なのか環境なのか原因を切り分けるために汚染計測器「Dienmern DM106A」を購入 ただ、DM106Aの計測はその時その時のスナップショットなので傾向を読み解きづらい、また、都度実施する手間がかかる \n- ただ、DM106Aの計測はその時その時のスナップショットなので傾向を読み解きづらい、また、都度実施する手間がかかる   > SOLUTIONSOLUTION \n\nというわけで、DM106AのセンサーデータをRaspberry Piで定期取得することにしました。設置方法の詳細はGitHubレポジトリを参照ください。下記、実装概要になります。   > 電子部品の構成電子部品の構成    item description     Raspberry Pi 3 Model B+    Aosong DHT11 気温・湿度センサー、GPIO   Nova SDS021 PM2.5・PM10センサー、UART   ams CCS811 TVOC・CO2eセンサー、I2C    \n\nまず、電子工作は素人ゆえどのセンサーを買えばいいか分からなかったのでDM106Aを分解して各センサーの型番を調べました。DHT011、SDS021はDM106Aとおなじセンサー、HCHOセンサーは信頼性があり手ごろなのがうまく見つけられませんでした。TVOCセンサーはAdafruitが推しているCCS811を採用しました。   > コードの構成コードの構成    item description     AirElixir.Application アプリケーション管理   AirElixir.GoogleSpreadsheets センサーデータ記録   AirElixirSensor.Publisher センサーデータ発行・送信   AirElixirSensor.Subscriber センサーデータ購読・受信    \n\n次に、基本構成はGrovePiを参考にしました。発行処理はElixirでうまくいかないケースがあったのでまずはPython/ErlPortで行いました。後々Elixirに移行できるようにマクロにしました。   > 5日ほど稼働してわかったこと・見立て、今後の課題5日ほど稼働してわかったこと・見立て、今後の課題  \n\n最後に、分かったこと、見立てですが、3点あります。2番目に関しては予想通りだったのですが、1番目、3番目に関しては意外であり、疑り深い私としては特に空気清浄機がきちんと機能していたことに驚きました。 \n\n1. オフィスの空気清浄機「Hitachi EP-LVG110」はPMをきちんとフィルターしていた ただし、空気清浄機はTVOCには効果がなく、これはTroia氏や加藤氏・苅部氏の考察でも言及されている \n2. ただし、空気清浄機はTVOCには効果がなく、これはTroia氏や加藤氏・苅部氏の考察でも言及されている\n3. 人の入りが多い時間帯に空気（TVOCやCO2e）が汚れる 人が「出る」時よりも「入る」際に濃度があがるのは、外のVOCが服などに付着しているためと推察 \n4. 人が「出る」時よりも「入る」際に濃度があがるのは、外のVOCが服などに付着しているためと推察\n5. TVOCやCO2eはPMのうごきに連動している（かも） チャート上はEP-LVG110がPM除去しているためわからないが、日本気象協会のPM2.5分布予測に照らしてみるとPM濃度が高い日にTVOC濃度があがっていた TODO: PMがVOCを運んでいる可能性があるので、IQAirなどのAPIから周辺環境のPMデータも取得したいところ \n6. チャート上はEP-LVG110がPM除去しているためわからないが、日本気象協会のPM2.5分布予測に照らしてみるとPM濃度が高い日にTVOC濃度があがっていた TODO: PMがVOCを運んでいる可能性があるので、IQAirなどのAPIから周辺環境のPMデータも取得したいところ \n7. TODO: PMがVOCを運んでいる可能性があるので、IQAirなどのAPIから周辺環境のPMデータも取得したいところ \n\n課題としてはその性質からして仕方ないのですがTVOCの変動が大きすぎて解読を難しかったです。計測方法等を再度見直す必要がありそうです。 \n\n- TVOCの変動が大きすぎる ポーリング・出力を20分ごとからポーリング3秒ごと・出力20分ごとに変更した、出力データは20分の平均 \n- ポーリング・出力を20分ごとからポーリング3秒ごと・出力20分ごとに変更した、出力データは20分の平均\n- TVOCのスパイクを抑えたい TODO: ファイトレメディエーションによる効果を見ていきたいところ \n- TODO: ファイトレメディエーションによる効果を見ていきたいところ   > WRAPUPWRAPUP \n\n今回の実験はこれが言いたかっただけという指摘をされるとぐうの音も出ませんが、はっきり言わせてください。そう、Elixirは健康管理に向いています。   txt \n\n「なんか体調がすぐれないなあ...」 「Elixirちょうだい!」   \n\nという感じです、はい。"},"name":"[2018-12-22]ElixirとRaspberry PiでPM2.5などの環境データを定点観察し、目・喉の痛みに備える","tags":["elixir","raspberry-pi","particulates","physiology"],"childPublishedDate":{"published_on":"2018-12-22T00:00:00.000Z","published_on_unix":1545436800}}}]}},"pageContext":{"number":52}},"staticQueryHashes":[]}