{"componentChunkName":"component---src-templates-post-tsx","path":"/posts/61","result":{"data":{"esaPost":{"number":61,"relative_category":"blog/health","fields":{"title":"ElixirとRaspberry PiでPM2.5などの環境データを定点観察し、目・喉の痛みに備える","excerpt":"皆さんは体調管理どうされていますか。一度痛い目に遭うと日常の細かい差異が気になってきて、そこをどうにか解決したいというのが人情です。今回は自分の咽頭痛の解消のため一つ実験をしてみました。   > PROBLEMPROBLEM \n\n- 以前からオフィスに行くと目や喉が痛くなることがあったので、自分の体調なのか環境なのか原因を切り分けるために汚染計測器「Dienmern DM106A」を購入 ただ、DM106Aの計測はその時その時のスナップショットなので傾向を読み解きづらい、また、都度実施する手間がかかる \n- ただ、DM106Aの計測はその時その時のスナップショットなので傾向を読み解きづらい、また、都度実施する手間がかかる   > SOLUTIONSOLUTION \n\nというわけで、DM106AのセンサーデータをRaspberry Piで定期取得することにしました。設置方法の詳細はGitHubレポジトリを参照ください。下記、実装概要になります。   > 電子部品の構成電子部品の構成    item description     Raspberry Pi 3 Model B+    Aosong DHT11 気温・湿度センサー、GPIO   Nova SDS021 PM2.5・PM10センサー、UART   ams CCS811 TVOC・CO2eセンサー、I2C    \n\nまず、電子工作は素人ゆえどのセンサーを買えばいいか分からなかったのでDM106Aを分解して各センサーの型番を調べました。DHT011、SDS021はDM106Aとおなじセンサー、HCHOセンサーは信頼性があり手ごろなのがうまく見つけられませんでした。TVOCセンサーはAdafruitが推しているCCS811を採用しました。   > コードの構成コードの構成    item description     AirElixir.Application アプリケーション管理   AirElixir.GoogleSpreadsheets センサーデータ記録   AirElixirSensor.Publisher センサーデータ発行・送信   AirElixirSensor.Subscriber センサーデータ購読・受信    \n\n次に、基本構成はGrovePiを参考にしました。発行処理はElixirでうまくいかないケースがあったのでまずはPython/ErlPortで行いました。後々Elixirに移行できるようにマクロにしました。   > 5日ほど稼働してわかったこと・見立て、今後の課題5日ほど稼働してわかったこと・見立て、今後の課題  \n\n最後に、分かったこと、見立てですが、3点あります。2番目に関しては予想通りだったのですが、1番目、3番目に関しては意外であり、疑り深い私としては特に空気清浄機がきちんと機能していたことに驚きました。 \n\n1. オフィスの空気清浄機「Hitachi EP-LVG110」はPMをきちんとフィルターしていた ただし、空気清浄機はTVOCには効果がなく、これはTroia氏や加藤氏・苅部氏の考察でも言及されている \n2. ただし、空気清浄機はTVOCには効果がなく、これはTroia氏や加藤氏・苅部氏の考察でも言及されている\n3. 人の入りが多い時間帯に空気（TVOCやCO2e）が汚れる 人が「出る」時よりも「入る」際に濃度があがるのは、外のVOCが服などに付着しているためと推察 \n4. 人が「出る」時よりも「入る」際に濃度があがるのは、外のVOCが服などに付着しているためと推察\n5. TVOCやCO2eはPMのうごきに連動している（かも） チャート上はEP-LVG110がPM除去しているためわからないが、日本気象協会のPM2.5分布予測に照らしてみるとPM濃度が高い日にTVOC濃度があがっていた TODO: PMがVOCを運んでいる可能性があるので、IQAirなどのAPIから周辺環境のPMデータも取得したいところ \n6. チャート上はEP-LVG110がPM除去しているためわからないが、日本気象協会のPM2.5分布予測に照らしてみるとPM濃度が高い日にTVOC濃度があがっていた TODO: PMがVOCを運んでいる可能性があるので、IQAirなどのAPIから周辺環境のPMデータも取得したいところ \n7. TODO: PMがVOCを運んでいる可能性があるので、IQAirなどのAPIから周辺環境のPMデータも取得したいところ \n\n課題としてはその性質からして仕方ないのですがTVOCの変動が大きすぎて解読を難しかったです。計測方法等を再度見直す必要がありそうです。 \n\n- TVOCの変動が大きすぎる ポーリング・出力を20分ごとからポーリング3秒ごと・出力20分ごとに変更した、出力データは20分の平均 \n- ポーリング・出力を20分ごとからポーリング3秒ごと・出力20分ごとに変更した、出力データは20分の平均\n- TVOCのスパイクを抑えたい TODO: ファイトレメディエーションによる効果を見ていきたいところ \n- TODO: ファイトレメディエーションによる効果を見ていきたいところ   > WRAPUPWRAPUP \n\n今回の実験はこれが言いたかっただけという指摘をされるとぐうの音も出ませんが、はっきり言わせてください。そう、Elixirは健康管理に向いています。   txt \n\n「なんか体調がすぐれないなあ...」 「Elixirちょうだい!」   \n\nという感じです、はい。","thumbnail":"https://img.esa.io/uploads/production/attachments/16651/2021/01/12/97367/53e18bfb-5979-43a7-8e40-ce8e389eac39.png"},"wip":false,"body_md":"皆さんは体調管理どうされていますか。一度痛い目に遭うと日常の細かい差異が気になってきて、そこをどうにか解決したいというのが人情です。今回は自分の咽頭痛の解消のため一つ実験をしてみました。\r\n\r\n# PROBLEM\r\n- 以前からオフィスに行くと目や喉が痛くなることがあったので、自分の体調なのか環境なのか原因を切り分けるために汚染計測器「Dienmern DM106A」を購入\r\n    - ただ、DM106Aの計測はその時その時のスナップショットなので傾向を読み解きづらい、また、都度実施する手間がかかる\r\n\r\n# SOLUTION\r\nというわけで、DM106AのセンサーデータをRaspberry Piで定期取得することにしました。設置方法の詳細は[GitHubレポジトリ](https://github.com/nabinno/air_elixir)を参照ください。下記、実装概要になります。\r\n\r\n## 電子部品の構成\r\n\r\n| item                    | description               |\r\n|-------------------------|---------------------------|\r\n| Raspberry Pi 3 Model B+ |                           |\r\n| Aosong DHT11            | 気温・湿度センサー、GPIO  |\r\n| Nova SDS021             | PM2.5・PM10センサー、UART |\r\n| ams CCS811              | TVOC・CO2eセンサー、I2C   |\r\n\r\nまず、電子工作は素人ゆえどのセンサーを買えばいいか分からなかったのでDM106Aを分解して各センサーの型番を調べました。DHT011、SDS021はDM106Aとおなじセンサー、HCHOセンサーは信頼性があり手ごろなのがうまく見つけられませんでした。TVOCセンサーはAdafruitが推しているCCS811を採用しました。\r\n\r\n## コードの構成\r\n\r\n| item                         | description              |\r\n|------------------------------|--------------------------|\r\n| AirElixir.Application        | アプリケーション管理     |\r\n| AirElixir.GoogleSpreadsheets | センサーデータ記録       |\r\n| AirElixirSensor.Publisher    | センサーデータ発行・送信 |\r\n| AirElixirSensor.Subscriber   | センサーデータ購読・受信 |\r\n\r\n次に、基本構成はGrovePiを参考にしました。発行処理はElixirでうまくいかないケースがあったのでまずはPython/ErlPortで行いました。後々Elixirに移行できるようにマクロにしました。\r\n\r\n## 5日ほど稼働してわかったこと・見立て、今後の課題\r\n<img width=\"1983\" alt=\"thumbnail\" src=\"https://img.esa.io/uploads/production/attachments/16651/2021/01/12/97367/53e18bfb-5979-43a7-8e40-ce8e389eac39.png\">\r\n\r\n最後に、分かったこと、見立てですが、3点あります。2番目に関しては予想通りだったのですが、1番目、3番目に関しては意外であり、疑り深い私としては特に空気清浄機がきちんと機能していたことに驚きました。\r\n\r\n1. オフィスの空気清浄機「Hitachi EP-LVG110」はPMをきちんとフィルターしていた\r\n    - ただし、空気清浄機はTVOCには効果がなく、これは[Troia氏](https://www.quantifiedbob.com/understanding-my-indoor-environment-part-1-air-quality/)や[加藤氏・苅部氏](https://www.nippon-chem.co.jp/dcms_media/other/cre2000-9.pdf)の考察でも言及されている\r\n2. 人の入りが多い時間帯に空気（TVOCやCO2e）が汚れる\r\n    - 人が「出る」時よりも「入る」際に濃度があがるのは、外のVOCが服などに付着しているためと推察\r\n3. TVOCやCO2eはPMのうごきに連動している（かも）\r\n    - チャート上はEP-LVG110がPM除去しているためわからないが、日本気象協会の[PM2.5分布予測](https://tenki.jp/pm25/)に照らしてみるとPM濃度が高い日にTVOC濃度があがっていた\r\n        - **TODO:** PMがVOCを運んでいる可能性があるので、IQAirなどのAPIから周辺環境のPMデータも取得したいところ\r\n\r\n課題としてはその性質からして仕方ないのですがTVOCの変動が大きすぎて解読を難しかったです。計測方法等を再度見直す必要がありそうです。\r\n\r\n- TVOCの変動が大きすぎる\r\n    - ポーリング・出力を20分ごとからポーリング3秒ごと・出力20分ごとに変更した、出力データは20分の平均\r\n- TVOCのスパイクを抑えたい\r\n    - **TODO:** [ファイトレメディエーション](https://ja.wikipedia.org/wiki/%E3%83%95%E3%82%A1%E3%82%A4%E3%83%88%E3%83%AC%E3%83%A1%E3%83%87%E3%82%A3%E3%82%A8%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3)による効果を見ていきたいところ\r\n\r\n# WRAPUP\r\n今回の実験はこれが言いたかっただけという指摘をされるとぐうの音も出ませんが、はっきり言わせてください。そう、Elixirは健康管理に向いています。\r\n\r\n```txt\r\n「なんか体調がすぐれないなあ...」\r\n「Elixirちょうだい!」\r\n```\r\n\r\nという感じです、はい。\r\n","body_html":"<p data-sourcepos=\"1:1-1:279\">皆さんは体調管理どうされていますか。一度痛い目に遭うと日常の細かい差異が気になってきて、そこをどうにか解決したいというのが人情です。今回は自分の咽頭痛の解消のため一つ実験をしてみました。</p>\n<h1 data-sourcepos=\"3:1-3:9\" id=\"1-0-0\" name=\"1-0-0\">\n<a class=\"anchor\" id=\"PROBLEM\" name=\"PROBLEM\" href=\"#PROBLEM\" data-position=\"1-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"PROBLEM\"> &gt; PROBLEM</span></a>PROBLEM</h1>\n<ul data-sourcepos=\"4:1-6:0\">\n<li data-sourcepos=\"4:1-6:0\">以前からオフィスに行くと目や喉が痛くなることがあったので、自分の体調なのか環境なのか原因を切り分けるために汚染計測器「Dienmern DM106A」を購入\n<ul data-sourcepos=\"5:5-6:0\">\n<li data-sourcepos=\"5:5-6:0\">ただ、DM106Aの計測はその時その時のスナップショットなので傾向を読み解きづらい、また、都度実施する手間がかかる</li>\n</ul>\n</li>\n</ul>\n<h1 data-sourcepos=\"7:1-7:10\" id=\"2-0-0\" name=\"2-0-0\">\n<a class=\"anchor\" id=\"SOLUTION\" name=\"SOLUTION\" href=\"#SOLUTION\" data-position=\"2-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"SOLUTION\"> &gt; SOLUTION</span></a>SOLUTION</h1>\n<p data-sourcepos=\"8:1-8:260\">というわけで、DM106AのセンサーデータをRaspberry Piで定期取得することにしました。設置方法の詳細は<a href=\"https://github.com/nabinno/air_elixir\" target=\"_blank\" rel=\"noopener noreferrer\">GitHubレポジトリ</a>を参照ください。下記、実装概要になります。</p>\n<h2 data-sourcepos=\"10:1-10:24\" id=\"2-1-0\" name=\"2-1-0\">\n<a class=\"anchor\" id=\"電子部品の構成\" name=\"%E9%9B%BB%E5%AD%90%E9%83%A8%E5%93%81%E3%81%AE%E6%A7%8B%E6%88%90\" href=\"#%E9%9B%BB%E5%AD%90%E9%83%A8%E5%93%81%E3%81%AE%E6%A7%8B%E6%88%90\" data-position=\"2-1-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"電子部品の構成\"> &gt; 電子部品の構成</span></a>電子部品の構成</h2>\n<table data-sourcepos=\"12:1-17:61\">\n<thead>\n<tr data-sourcepos=\"12:1-12:55\">\n<th data-sourcepos=\"12:2-12:26\">item</th>\n<th data-sourcepos=\"12:28-12:54\">description</th>\n</tr>\n</thead>\n<tbody>\n<tr data-sourcepos=\"14:1-14:55\">\n<td data-sourcepos=\"14:2-14:26\">Raspberry Pi 3 Model B+</td>\n<td data-sourcepos=\"14:28-14:54\"></td>\n</tr>\n<tr data-sourcepos=\"15:1-15:65\">\n<td data-sourcepos=\"15:2-15:26\">Aosong DHT11</td>\n<td data-sourcepos=\"15:28-15:64\">気温・湿度センサー、GPIO</td>\n</tr>\n<tr data-sourcepos=\"16:1-16:61\">\n<td data-sourcepos=\"16:2-16:26\">Nova SDS021</td>\n<td data-sourcepos=\"16:28-16:60\">PM2.5・PM10センサー、UART</td>\n</tr>\n<tr data-sourcepos=\"17:1-17:61\">\n<td data-sourcepos=\"17:2-17:26\">ams CCS811</td>\n<td data-sourcepos=\"17:28-17:60\">TVOC・CO2eセンサー、I2C</td>\n</tr>\n</tbody>\n</table>\n<p data-sourcepos=\"19:1-19:394\">まず、電子工作は素人ゆえどのセンサーを買えばいいか分からなかったのでDM106Aを分解して各センサーの型番を調べました。DHT011、SDS021はDM106Aとおなじセンサー、HCHOセンサーは信頼性があり手ごろなのがうまく見つけられませんでした。TVOCセンサーはAdafruitが推しているCCS811を採用しました。</p>\n<h2 data-sourcepos=\"21:1-21:21\" id=\"2-2-0\" name=\"2-2-0\">\n<a class=\"anchor\" id=\"コードの構成\" name=\"%E3%82%B3%E3%83%BC%E3%83%89%E3%81%AE%E6%A7%8B%E6%88%90\" href=\"#%E3%82%B3%E3%83%BC%E3%83%89%E3%81%AE%E6%A7%8B%E6%88%90\" data-position=\"2-2-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"コードの構成\"> &gt; コードの構成</span></a>コードの構成</h2>\n<table data-sourcepos=\"23:1-28:71\">\n<thead>\n<tr data-sourcepos=\"23:1-23:59\">\n<th data-sourcepos=\"23:2-23:31\">item</th>\n<th data-sourcepos=\"23:33-23:58\">description</th>\n</tr>\n</thead>\n<tbody>\n<tr data-sourcepos=\"25:1-25:69\">\n<td data-sourcepos=\"25:2-25:31\">AirElixir.Application</td>\n<td data-sourcepos=\"25:33-25:68\">アプリケーション管理</td>\n</tr>\n<tr data-sourcepos=\"26:1-26:68\">\n<td data-sourcepos=\"26:2-26:31\">AirElixir.GoogleSpreadsheets</td>\n<td data-sourcepos=\"26:33-26:67\">センサーデータ記録</td>\n</tr>\n<tr data-sourcepos=\"27:1-27:71\">\n<td data-sourcepos=\"27:2-27:31\">AirElixirSensor.Publisher</td>\n<td data-sourcepos=\"27:33-27:70\">センサーデータ発行・送信</td>\n</tr>\n<tr data-sourcepos=\"28:1-28:71\">\n<td data-sourcepos=\"28:2-28:31\">AirElixirSensor.Subscriber</td>\n<td data-sourcepos=\"28:33-28:70\">センサーデータ購読・受信</td>\n</tr>\n</tbody>\n</table>\n<p data-sourcepos=\"30:1-30:240\">次に、基本構成はGrovePiを参考にしました。発行処理はElixirでうまくいかないケースがあったのでまずはPython/ErlPortで行いました。後々Elixirに移行できるようにマクロにしました。</p>\n<h2 data-sourcepos=\"32:1-32:73\" id=\"2-3-0\" name=\"2-3-0\">\n<a class=\"anchor\" id=\"5日ほど稼働してわかったこと・見立て、今後の課題\" name=\"5%E6%97%A5%E3%81%BB%E3%81%A9%E7%A8%BC%E5%83%8D%E3%81%97%E3%81%A6%E3%82%8F%E3%81%8B%E3%81%A3%E3%81%9F%E3%81%93%E3%81%A8%E3%83%BB%E8%A6%8B%E7%AB%8B%E3%81%A6%E3%80%81%E4%BB%8A%E5%BE%8C%E3%81%AE%E8%AA%B2%E9%A1%8C\" href=\"#5%E6%97%A5%E3%81%BB%E3%81%A9%E7%A8%BC%E5%83%8D%E3%81%97%E3%81%A6%E3%82%8F%E3%81%8B%E3%81%A3%E3%81%9F%E3%81%93%E3%81%A8%E3%83%BB%E8%A6%8B%E7%AB%8B%E3%81%A6%E3%80%81%E4%BB%8A%E5%BE%8C%E3%81%AE%E8%AA%B2%E9%A1%8C\" data-position=\"2-3-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"5日ほど稼働してわかったこと・見立て、今後の課題\"> &gt; 5日ほど稼働してわかったこと・見立て、今後の課題</span></a>5日ほど稼働してわかったこと・見立て、今後の課題</h2>\n<a href=\"https://img.esa.io/uploads/production/attachments/16651/2021/01/12/97367/53e18bfb-5979-43a7-8e40-ce8e389eac39.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img width=\"1983\" alt=\"thumbnail\" src=\"https://img.esa.io/uploads/production/attachments/16651/2021/01/12/97367/53e18bfb-5979-43a7-8e40-ce8e389eac39.png\"></a>\n<p data-sourcepos=\"35:1-35:289\">最後に、分かったこと、見立てですが、3点あります。2番目に関しては予想通りだったのですが、1番目、3番目に関しては意外であり、疑り深い私としては特に空気清浄機がきちんと機能していたことに驚きました。</p>\n<ol data-sourcepos=\"37:1-44:0\">\n<li data-sourcepos=\"37:1-38:294\">オフィスの空気清浄機「Hitachi EP-LVG110」はPMをきちんとフィルターしていた\n<ul data-sourcepos=\"38:5-38:294\">\n<li data-sourcepos=\"38:5-38:294\">ただし、空気清浄機はTVOCには効果がなく、これは<a href=\"https://www.quantifiedbob.com/understanding-my-indoor-environment-part-1-air-quality/\" target=\"_blank\" rel=\"noopener noreferrer\">Troia氏</a>や<a href=\"https://www.nippon-chem.co.jp/dcms_media/other/cre2000-9.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">加藤氏・苅部氏</a>の考察でも言及されている</li>\n</ul>\n</li>\n<li data-sourcepos=\"39:1-40:138\">人の入りが多い時間帯に空気（TVOCやCO2e）が汚れる\n<ul data-sourcepos=\"40:5-40:138\">\n<li data-sourcepos=\"40:5-40:138\">人が「出る」時よりも「入る」際に濃度があがるのは、外のVOCが服などに付着しているためと推察</li>\n</ul>\n</li>\n<li data-sourcepos=\"41:1-44:0\">TVOCやCO2eはPMのうごきに連動している（かも）\n<ul data-sourcepos=\"42:5-44:0\">\n<li data-sourcepos=\"42:5-44:0\">チャート上はEP-LVG110がPM除去しているためわからないが、日本気象協会の<a href=\"https://tenki.jp/pm25/\" target=\"_blank\" rel=\"noopener noreferrer\">PM2.5分布予測</a>に照らしてみるとPM濃度が高い日にTVOC濃度があがっていた\n<ul data-sourcepos=\"43:9-44:0\">\n<li data-sourcepos=\"43:9-44:0\">\n<strong>TODO:</strong> PMがVOCを運んでいる可能性があるので、IQAirなどのAPIから周辺環境のPMデータも取得したいところ</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<p data-sourcepos=\"45:1-45:193\">課題としてはその性質からして仕方ないのですがTVOCの変動が大きすぎて解読を難しかったです。計測方法等を再度見直す必要がありそうです。</p>\n<ul data-sourcepos=\"47:1-51:0\">\n<li data-sourcepos=\"47:1-48:145\">TVOCの変動が大きすぎる\n<ul data-sourcepos=\"48:5-48:145\">\n<li data-sourcepos=\"48:5-48:145\">ポーリング・出力を20分ごとからポーリング3秒ごと・出力20分ごとに変更した、出力データは20分の平均</li>\n</ul>\n</li>\n<li data-sourcepos=\"49:1-51:0\">TVOCのスパイクを抑えたい\n<ul data-sourcepos=\"50:5-51:0\">\n<li data-sourcepos=\"50:5-51:0\">\n<strong>TODO:</strong> <a href=\"https://ja.wikipedia.org/wiki/%E3%83%95%E3%82%A1%E3%82%A4%E3%83%88%E3%83%AC%E3%83%A1%E3%83%87%E3%82%A3%E3%82%A8%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3\" target=\"_blank\" rel=\"noopener noreferrer\">ファイトレメディエーション</a>による効果を見ていきたいところ</li>\n</ul>\n</li>\n</ul>\n<h1 data-sourcepos=\"52:1-52:8\" id=\"3-0-0\" name=\"3-0-0\">\n<a class=\"anchor\" id=\"WRAPUP\" name=\"WRAPUP\" href=\"#WRAPUP\" data-position=\"3-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"WRAPUP\"> &gt; WRAPUP</span></a>WRAPUP</h1>\n<p data-sourcepos=\"53:1-53:207\">今回の実験はこれが言いたかっただけという指摘をされるとぐうの音も出ませんが、はっきり言わせてください。そう、Elixirは健康管理に向いています。</p>\n<div class=\"code-block\" data-sourcepos=\"55:1-58:3\">\n<div class=\"code-filename\">\n<i class=\"fa fa-file-code-o\"></i>txt</div>\n<div class=\"highlight\"><pre class=\"highlight text\"><code>「なんか体調がすぐれないなあ...」\n「Elixirちょうだい!」\n</code></pre></div>\n</div>\n<p data-sourcepos=\"60:1-60:33\">という感じです、はい。</p>\n","tags":["elixir","raspberry-pi","particulates","physiology"],"updated_at":"2021-01-16T11:16:48+09:00","childPublishedDate":{"published_on":"2018-12-22T00:00:00.000Z"},"updated_by":{"name":"なびの👷","screen_name":"nabinno","icon":"https://img.esa.io/uploads/production/members/94286/icon/thumb_m_ef5f024307008aa399b91f87fa5f64e8.jpg"}},"relatedPosts":{"edges":[{"node":{"number":93,"relative_category":"blog/backend","fields":{"title":"AWS CloudTrail用のコスパの良いSIEMを探す","excerpt":"IT統制において証跡管理の充実という観点から、また、ゼロトラストの強化という観点からSIEMの導入が必要になってきた。今回はAWS CloudTrail用のSIEMについてざっと調べました。   > PROBLEMPROBLEM \n\n- AWS CloudTrailのログをセキュリティアカウントに集約しているが、深く監視しきれていない 可能ならアカウントが不審な操作をした場合にアラートを飛ばしたい 可能ならCloudTrail以外のIaaSリソースを監視対象にしたい NewRelicのように人のコストをかけずに管理したい \n- 可能ならアカウントが不審な操作をした場合にアラートを飛ばしたい\n- 可能ならCloudTrail以外のIaaSリソースを監視対象にしたい NewRelicのように人のコストをかけずに管理したい \n- NewRelicのように人のコストをかけずに管理したい  > SOLUTIONSOLUTION \n\nと言うわけで、コスパが良いと噂のSumo LogicとAzure Sentinelを比較評価します。  > Azure SentinelAzure Sentinel  > 料金料金 \n\n- Azure Sentinel の価格 | Microsoft Azure\n- 価格 - Azure Monitor | Microsoft Azure  > SIEMからCloudTrailへの接続方法SIEMからCloudTrailへの接続方法 \n\n1. 下記設定でLog Analyticsワークスペースを作成 サブスクリプション 無料試用版 リソース グループ production 名前 prod-sentinel 地域 東日本 \n2. サブスクリプション 無料試用版\n3. リソース グループ production\n4. 名前 prod-sentinel\n5. 地域 東日本\n6. [ワークスペースprod-sentinel - データコネクタ] にて [アマゾンウェブサービス] コネクタページを開く\n7. [AWSアカウント - IAM - ロール] にて下記設定で [別のAWSアカウント] を作成 アカウントID {Microsoft account ID} オプション 外部IDが必要 をチェック 外部ID {外部ID (ワークスペースID)} パーミッションポリシーを適用 AWSCloudTrailReadOnlyAccess ロール名 AzureSentinel ※ Cf. AWS CloudTrail を Azure Sentinel に接続する | Microsoft Docs アマゾン ウェブ サービス (AWS) のための MCAS と Azure Sentinel - Azure Solution Ideas | Microsoft Docs Security-JAWS 第21回レポート #secjaws #secjaws21 #jawsug | DevelopersIO \n8. アカウントID {Microsoft account ID}\n9. オプション 外部IDが必要 をチェック 外部ID {外部ID (ワークスペースID)} \n10. 外部IDが必要 をチェック\n11. 外部ID {外部ID (ワークスペースID)}\n12. パーミッションポリシーを適用 AWSCloudTrailReadOnlyAccess\n13. ロール名 AzureSentinel\n14. ※ Cf. AWS CloudTrail を Azure Sentinel に接続する | Microsoft Docs アマゾン ウェブ サービス (AWS) のための MCAS と Azure Sentinel - Azure Solution Ideas | Microsoft Docs Security-JAWS 第21回レポート #secjaws #secjaws21 #jawsug | DevelopersIO \n15. AWS CloudTrail を Azure Sentinel に接続する | Microsoft Docs\n16. アマゾン ウェブ サービス (AWS) のための MCAS と Azure Sentinel - Azure Solution Ideas | Microsoft Docs\n17. Security-JAWS 第21回レポート #secjaws #secjaws21 #jawsug | DevelopersIO  > SIEM機能 (AWS CloudTrail)SIEM機能 (AWS CloudTrail) \n\n- デフォルト監視対象 時間経過に伴うイベントアラート 悪意ある可能性があるイベント 最近のインシデント データソースの異常 \n- 時間経過に伴うイベントアラート\n- 悪意ある可能性があるイベント\n- 最近のインシデント\n- データソースの異常\n- ログクエリ Audit Network Security \n- Audit\n- Network\n- Security\n- 脅威管理 インシデント ブック ... 簡易な分析情報を提供 AWSネットワークアクティビティ ... SG、ネットワークACL、IGW、ELB、VPC、サブネット、NIの作成・更新・削除など、AWS ネットワーク関連のリソースアクティビティに関する分析情報を得ます。 AWSユーザーアクティビティ ... 失敗したサインイン試行、IP アドレス、リージョン、ユーザー エージェント、ID の種類、また想定されたロールを持つ悪意のある可能性があるユーザー アクティビティなど、AWS ユーザー アクティビティに関する分析情報を得ます。 ハンティング ... 脅威判定となるログクエリを提供 Changes made to AWS IAM policy Tracking Privileged Account Rare Activity Exploit and Pentest Framework User Agent IAM Privilege Escalation by Instance Profile attachment Privileged role attached to Instance Suspicious credential token access of valid IAM Roles Unused or Unsupported Cloud Regions ノートブック ... Jupyter Notebookによる分析を提供 \n- インシデント\n- ブック ... 簡易な分析情報を提供 AWSネットワークアクティビティ ... SG、ネットワークACL、IGW、ELB、VPC、サブネット、NIの作成・更新・削除など、AWS ネットワーク関連のリソースアクティビティに関する分析情報を得ます。 AWSユーザーアクティビティ ... 失敗したサインイン試行、IP アドレス、リージョン、ユーザー エージェント、ID の種類、また想定されたロールを持つ悪意のある可能性があるユーザー アクティビティなど、AWS ユーザー アクティビティに関する分析情報を得ます。 \n- AWSネットワークアクティビティ ... SG、ネットワークACL、IGW、ELB、VPC、サブネット、NIの作成・更新・削除など、AWS ネットワーク関連のリソースアクティビティに関する分析情報を得ます。\n- AWSユーザーアクティビティ ... 失敗したサインイン試行、IP アドレス、リージョン、ユーザー エージェント、ID の種類、また想定されたロールを持つ悪意のある可能性があるユーザー アクティビティなど、AWS ユーザー アクティビティに関する分析情報を得ます。\n- ハンティング ... 脅威判定となるログクエリを提供 Changes made to AWS IAM policy Tracking Privileged Account Rare Activity Exploit and Pentest Framework User Agent IAM Privilege Escalation by Instance Profile attachment Privileged role attached to Instance Suspicious credential token access of valid IAM Roles Unused or Unsupported Cloud Regions \n- Changes made to AWS IAM policy\n- Tracking Privileged Account Rare Activity\n- Exploit and Pentest Framework User Agent\n- IAM Privilege Escalation by Instance Profile attachment\n- Privileged role attached to Instance\n- Suspicious credential token access of valid IAM Roles\n- Unused or Unsupported Cloud Regions\n- ノートブック ... Jupyter Notebookによる分析を提供\n- ソリューション ... 外部のエンドポイントセキュリティツールと連携することが可能 Trend Micro Apex One McAfee Network Security Platform \n- Trend Micro Apex One\n- McAfee Network Security Platform  > Sumo LogicSumo Logic  > 料金料金 \n\n- Sumo Logic 料金表  > SIEMからCloudTrailへの接続方法SIEMからCloudTrailへの接続方法 \n\n1. [AWSアカウントSecurity - S3] にてバケット cloudtrail-accumulativelogs-{account-id} を下記設定にて作成 パブリックアクセスをすべてブロック オフ バケットポリシー json{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"AWSCloudTrailAclCheck20150319\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"s3:GetBucketAcl\", \"Resource\": \"arn:aws:s3:::cloudtrail-accumulativelogs-{account-id}\" }, { \"Sid\": \"AWSCloudTrailWrite20150319\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"s3:PutObject\", \"Resource\": \"arn:aws:s3:::cloudtrail-accumulativelogs-{account-id}/AWSLogs/{organization-id}/*\", \"Condition\": { \"StringEquals\": { \"s3:x-amz-acl\": \"bucket-owner-full-control\" } } } ] } \n2. パブリックアクセスをすべてブロック オフ\n3. バケットポリシー json{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"AWSCloudTrailAclCheck20150319\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"s3:GetBucketAcl\", \"Resource\": \"arn:aws:s3:::cloudtrail-accumulativelogs-{account-id}\" }, { \"Sid\": \"AWSCloudTrailWrite20150319\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"s3:PutObject\", \"Resource\": \"arn:aws:s3:::cloudtrail-accumulativelogs-{account-id}/AWSLogs/{organization-id}/*\", \"Condition\": { \"StringEquals\": { \"s3:x-amz-acl\": \"bucket-owner-full-control\" } } } ] } \n4. [親AWSアカウント - KMS] にて下記設定でKSMを作成 キーのタイプ 対称 キーマテリアルオリジン KMS リージョンごと 単一リージョン エイリアス名 cloudtrail-kms キーポリシー json{ \"Version\": \"2012-10-17\", \"Id\": \"Key policy created by CloudTrail\", \"Statement\": [ { \"Sid\": \"Enable IAM User Permissions\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": \"kms:*\", \"Resource\": \"*\" }, { \"Sid\": \"Allow CloudTrail to encrypt logs\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"kms:GenerateDataKey*\", \"Resource\": \"*\", \"Condition\": { \"StringLike\": { \"kms:EncryptionContext:aws:cloudtrail:arn\": \"arn:aws:cloudtrail:*:{account-id}:trail/*\" } } }, { \"Sid\": \"Allow CloudTrail to describe key\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"kms:DescribeKey\", \"Resource\": \"*\" }, { \"Sid\": \"Allow principals in the account to decrypt log files\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": [ \"kms:Decrypt\", \"kms:ReEncryptFrom\" ], \"Resource\": \"*\", \"Condition\": { \"StringEquals\": { \"kms:CallerAccount\": \"{account-id}\" }, \"StringLike\": { \"kms:EncryptionContext:aws:cloudtrail:arn\": \"arn:aws:cloudtrail:*:{account-id}:trail/*\" } } }, { \"Sid\": \"Allow alias creation during setup\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": \"kms:CreateAlias\", \"Resource\": \"*\", \"Condition\": { \"StringEquals\": { \"kms:CallerAccount\": \"{account-id}\", \"kms:ViaService\": \"ec2.ap-northeast-1.amazonaws.com\" } } }, { \"Sid\": \"Enable cross account log decryption\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": [ \"kms:Decrypt\", \"kms:ReEncryptFrom\" ], \"Resource\": \"*\", \"Condition\": { \"StringEquals\": { \"kms:CallerAccount\": \"{account-id}\" }, \"StringLike\": { \"kms:EncryptionContext:aws:cloudtrail:arn\": \"arn:aws:cloudtrail:*:{account-id}:trail/*\" } } } ] } \n5. キーのタイプ 対称\n6. キーマテリアルオリジン KMS\n7. リージョンごと 単一リージョン\n8. エイリアス名 cloudtrail-kms\n9. キーポリシー json{ \"Version\": \"2012-10-17\", \"Id\": \"Key policy created by CloudTrail\", \"Statement\": [ { \"Sid\": \"Enable IAM User Permissions\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": \"kms:*\", \"Resource\": \"*\" }, { \"Sid\": \"Allow CloudTrail to encrypt logs\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"kms:GenerateDataKey*\", \"Resource\": \"*\", \"Condition\": { \"StringLike\": { \"kms:EncryptionContext:aws:cloudtrail:arn\": \"arn:aws:cloudtrail:*:{account-id}:trail/*\" } } }, { \"Sid\": \"Allow CloudTrail to describe key\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"kms:DescribeKey\", \"Resource\": \"*\" }, { \"Sid\": \"Allow principals in the account to decrypt log files\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": [ \"kms:Decrypt\", \"kms:ReEncryptFrom\" ], \"Resource\": \"*\", \"Condition\": { \"StringEquals\": { \"kms:CallerAccount\": \"{account-id}\" }, \"StringLike\": { \"kms:EncryptionContext:aws:cloudtrail:arn\": \"arn:aws:cloudtrail:*:{account-id}:trail/*\" } } }, { \"Sid\": \"Allow alias creation during setup\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": \"kms:CreateAlias\", \"Resource\": \"*\", \"Condition\": { \"StringEquals\": { \"kms:CallerAccount\": \"{account-id}\", \"kms:ViaService\": \"ec2.ap-northeast-1.amazonaws.com\" } } }, { \"Sid\": \"Enable cross account log decryption\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": [ \"kms:Decrypt\", \"kms:ReEncryptFrom\" ], \"Resource\": \"*\", \"Condition\": { \"StringEquals\": { \"kms:CallerAccount\": \"{account-id}\" }, \"StringLike\": { \"kms:EncryptionContext:aws:cloudtrail:arn\": \"arn:aws:cloudtrail:*:{account-id}:trail/*\" } } } ] } \n10. [親AWSアカウント - CloudTrail] にて下記設定で証跡を作成 全般的な詳細 証跡名 cloudtrail-logs 組織に証跡を適用 はい ストレージの場所 既存のS3バケットを使用する 証跡ログバケット名 cloudtrail-accumulativelogs-{account-id} ログファイルのSSE-KMS暗号化 有効 カスタマー管理のAWS KMSキー 新規 AWS KMSエイリアス arn:aws:kms:{region}:{account-id}:key/{kms-id} ログファイルの検証 有効 管理イベント APIアクティビティ すべて \n11. 全般的な詳細 証跡名 cloudtrail-logs 組織に証跡を適用 はい ストレージの場所 既存のS3バケットを使用する 証跡ログバケット名 cloudtrail-accumulativelogs-{account-id} ログファイルのSSE-KMS暗号化 有効 カスタマー管理のAWS KMSキー 新規 AWS KMSエイリアス arn:aws:kms:{region}:{account-id}:key/{kms-id} ログファイルの検証 有効 \n12. 証跡名 cloudtrail-logs\n13. 組織に証跡を適用 はい\n14. ストレージの場所 既存のS3バケットを使用する\n15. 証跡ログバケット名 cloudtrail-accumulativelogs-{account-id}\n16. ログファイルのSSE-KMS暗号化 有効\n17. カスタマー管理のAWS KMSキー 新規\n18. AWS KMSエイリアス arn:aws:kms:{region}:{account-id}:key/{kms-id}\n19. ログファイルの検証 有効\n20. 管理イベント APIアクティビティ すべて \n21. APIアクティビティ すべて\n22. [Sumo Logic - Setup Wizard - Start streaming data to Sumo Logic - CloudTrail] にて下記設定でCloudTrailデータタイプを作成 Source Category aws/cloudtrail S3 Bucket S3 Bucket Name cloudtrail-accumulativelogs-{account-id} Path Expression AWSLogs/{organization-id}/* S3 Region Asia Pacific (Tokyo) How do you want the user to access the S3 Bucket? Role-based access 指定されたCFnテンプレートでIAMロールを作成 \n23. Source Category aws/cloudtrail\n24. S3 Bucket S3 Bucket Name cloudtrail-accumulativelogs-{account-id} Path Expression AWSLogs/{organization-id}/* S3 Region Asia Pacific (Tokyo) How do you want the user to access the S3 Bucket? Role-based access 指定されたCFnテンプレートでIAMロールを作成 \n25. S3 Bucket Name cloudtrail-accumulativelogs-{account-id}\n26. Path Expression AWSLogs/{organization-id}/*\n27. S3 Region Asia Pacific (Tokyo)\n28. How do you want the user to access the S3 Bucket? Role-based access 指定されたCFnテンプレートでIAMロールを作成 \n29. 指定されたCFnテンプレートでIAMロールを作成  > SIEM機能 (AWS CloudTrail)SIEM機能 (AWS CloudTrail) \n\nデフォルト監視対象 \n\n- Console Logins Geo Location of All Users Login Events By User Logins Over Time Logins from Multiple IP Logins from Outside the USA Outlier - Success Login Outlier - Failed Login Login Results - One Day Time Comparison Logins without MFA \n- Geo Location of All Users\n- Login Events By User\n- Logins Over Time\n- Logins from Multiple IP\n- Logins from Outside the USA\n- Outlier - Success Login\n- Outlier - Failed Login\n- Login Results - One Day Time Comparison\n- Logins without MFA\n- Network and Security Authorization Failures from All Countries Network and Security Events Over Time Authorization Failures Over Time Network ACL with All Allowed Ingress/Egress Recent Authorization Failures Recent Security Group and Network ACL Changes Created and Deleted Network and Security Events Short Lived Critical Operations \n- Authorization Failures from All Countries\n- Network and Security Events Over Time\n- Authorization Failures Over Time\n- Network ACL with All Allowed Ingress/Egress\n- Recent Authorization Failures\n- Recent Security Group and Network ACL Changes\n- Created and Deleted Network and Security Events\n- Short Lived Critical Operations\n- Operations Action Events Requested AWS Services Over Time Events by AWS Region Recent Elastic IP Address Operations Created Resources Over Time Deleted Resources Over Time \n- Action Events\n- Requested AWS Services Over Time\n- Events by AWS Region\n- Recent Elastic IP Address Operations\n- Created Resources Over Time\n- Deleted Resources Over Time\n- Overview Geo Location of All Users Created Resources Deleted Resources Over Time Top 10 Users Failed Logins Created and Deleted Network and Security Events \n- Geo Location of All Users\n- Created Resources\n- Deleted Resources Over Time\n- Top 10 Users\n- Failed Logins\n- Created and Deleted Network and Security Events\n- S3 Public Objects and Buckets New Public Objects New Public Object by Object-Bucket New Public Objects Table Public Buckets Public Buckets Table Modified Public Objects Modified Public Objects by Object-Buket Modified Public Objects Table \n- New Public Objects\n- New Public Object by Object-Bucket\n- New Public Objects Table\n- Public Buckets\n- Public Buckets Table\n- Modified Public Objects\n- Modified Public Objects by Object-Buket\n- Modified Public Objects Table\n- User Monitoring Geo Location of All Users Top 10 Users Launched and Terminated Instances by User Administrative Activities Over Time Top 10 Activities by Administrative User Recent Activity by Administrative Users \n- Geo Location of All Users\n- Top 10 Users\n- Launched and Terminated Instances by User\n- Administrative Activities Over Time\n- Top 10 Activities by Administrative User\n- Recent Activity by Administrative Users  > 総評総評  > 使用コスト使用コスト \n\n初期導入の段階ではSumo LogicよりAzure Sentinelの方が倍のコストがかかります。    ログ取込量/日 Azure Sentinel月額 Sumo Logic月額     100MB 2,396 JPY 0 USD   500MB 11,978 JPY 0 USD   3GB 71,870 JPY 332 USD    \n\n※ Azure Sentinelの内訳は「 ((GB当たりのAzure Sentinel取込量347.20円) + (GB当たりのLog Analytics取込量451.36円) * 取込量GB 」  > 導入コスト導入コスト \n\n一度の設定で完了するSumo Logicの方が導入コストが低いです。Azure SentinelはIAMロールのみで済むという点で導入は楽ですがAWSアカウントごとに設定する必要があるので手離れが悪いです。  > SIEM機能SIEM機能 \n\nAzure Sentinelの方が分析機能が充実しています。Sumo Logicが大まかな脅威をログクエリからしか拾えないのに対し、Azure Sentinelは細かな脅威判定をログクエリで提供しているのに加え、Jupyter Notebookや外部のエンドポイントセキュリティツールを提供しています。また、デフォルトの監視対象も時間経過に伴うイベントアラート、悪意ある可能性があるイベント、最近のインシデント等必要十分な情報を提供しています。 \n\nまた、対象のデータソースはAzure SentinelがAWS CloudTrail、Google Workspace、Office 365、Azure AD等と幅広く用意しているのに対し、Sumo LogicはSIEMという観点では実質AWS CloudTrail専用のツールに落ち着いています。  > WRAPUPWRAPUP \n\nメインプロダクトがまだ2-3しかない状況でSIEMをAWSだけに限定する場合はSumo Logicで十分でしょう。使用コスト、導入コストともに低く抑えることができるので、しばらくはSumo Logicで運用し、プロダクトがスケールする段階でAzure Sentinelを移行するのが現実的だと思いました。"},"name":"[2021-08-15]AWS CloudTrail用のコスパの良いSIEMを探す","tags":["siem","aws-cloudtrail","azure-sentinel","sumo-logic"],"childPublishedDate":{"published_on":"2021-08-15T00:00:00.000Z","published_on_unix":1628985600}}},{"node":{"number":91,"relative_category":"blog/backend","fields":{"title":"Hardware-Accelerated GPU Scheduling機能を使ったWSL2はどのくらいパフォーマンスが向上するか","excerpt":"新しいPC端末を購入したところ「Hardware-Accerlarated GPU Scheduling」機能があることに気づきました。使用したところ気持ち速くなったように感じたのでどのくらいパフォーマンスが向上したか調べてみました。   > PROBLEMPROBLEM \n\n- システム設定で「Hardware-Accerlarated GPU Scheduling（HAGS）」機能を使ったところWSL2のパフォーマンスが体感的に速くなったように感じた 他の端末にもHAGSを展開していきたいので実際にどのらくらいパフォーマンスが向上するか検証したい \n- 他の端末にもHAGSを展開していきたいので実際にどのらくらいパフォーマンスが向上するか検証したい  > SOLUTIONSOLUTION \n\nと言うわけで、以前Phoronixによって書かれた「WSLとWSL2とのベンチマーク比較の記事」を参考にPhoronix Test SuiteでHAGSのオン・オフのベンチマーク比較を行います。  > 検証端末の環境検証端末の環境    Item Content     Processor AMD Ryzen 9 5900X 12-Core (12 Cores / 24 Threads)   Memory 52 GB   Disk 2 x 275GB Virtual Disk   OS Ubuntu 20.04   Kernel 5.4.72-microsoft-standard-WSL2 (x86_64)   Display Server X Server   Compiler GCC 9.3.0   File System ext4   System Layer wsl     > Phoronix Test SuiteをインストールするPhoronix Test Suiteをインストールする sh\n\nbrew install phoronix-test-suite sudo apt install php php-gd php-xml php-curl   > 実行するベンチマークテストを選定する実行するベンチマークテストを選定する \n\nまず実行可能なテストとテストスーツを確認します、テストスーツは関連テストのグループになります。 sh\n\nphoronix-test-suite list-available-tests phoronix-test-suite list-available-suite  \n\n今回は開発する際に関係がある下記のテストを選定しました。テストスーツは数時間では完了しないケースがあったので今回の対象から外しています。 \n\n- pts/build-gcc\n- pts/compress-gzip\n- pts/system-decompress-gzip\n- pts/gnupg\n- pts/mutex\n- pts/openssl\n- pts/git\n- pts/pybench\n- pts/nginx\n- pts/node-web-tooling  > ベンチマーク結果ベンチマーク結果    Item HAGSオン HAGSオフ     pts/build-gcc 717.39 sec 715.56 sec   pts/compress-gzip 29.10 sec 29.36 sec   pts/system-decompress-gzip 2.397 sec 2.427 sec   pts/mutex Lock Shared 15.2 sec 15.2 sec   pts/mutex Unlock spinlock 33.1 sec 33.4 sec   pts/mutex Unlock std::mutex 14.8 sec 14.7 sec   pts/mutex Semaphore Release And Acquire 8.44 sec 8.36 sec   pts/mutex Unlock pthread_mutex 8.45 sec 8.34 sec   pts/openssl 3704.3 sign/sec 3694 sign/sec   pts/git 39.01 sec 38.85 sec   pts/pybench 869 msec 877 msec   pts/nginx 70124.29 req/sec 71919.70 req/sec   pts/node-web-tooling 16.71 sec 17.01 sec     > WRAPUPWRAPUP \n\n残念ながらベンチマーク結果からHAGSのオンとオフの間に大きなパフォーマンスの変化は見られませんでした。通常の開発の場合はほぼ恩恵を受けられないと言って問題ないでしょう。 \n\n結論として、他の端末へのHAGSの展開はお薦めしません。不具合等の口コミも散見されるので使用端末との相性を見ながら導入するのが良さそうです。個人的にはChromeのハードウェアアクセラレーション機能との相性を見つつしばらく運用しようと思います。"},"name":"[2021-08-01]Hardware-Accelerated GPU Scheduling機能を使ったWSL2はどのくらいパフォーマンスが向上するか","tags":[],"childPublishedDate":{"published_on":"2021-08-01T00:00:00.000Z","published_on_unix":1627776000}}},{"node":{"number":89,"relative_category":"blog/backend","fields":{"title":"imi-enrichment-addressは住所のバリデーションチェックでどの程度使えるか","excerpt":"コロナ禍であらゆる流通がオンラインに移行する中、正しい住所を使うことはいっそう求められています。ユーザーが配送用に住所を入力する時そのデータが正しいとどうやって判定するのでしょうか。今回はOSSライブラリimi-enrichment-addressが住所のバリデーションチェックでどの程度使えるか検証してみました。   > PROBLEMPROBLEM \n\n- 住所の不備が至るところで起きている 特に町名番地の抜けもれや不備が多くこの点をどうにか拾いたい 可能ならユーザーの入力時点でFEあるいはBE側でバリデーションチェックしたい まずはOSSのライブラリで検証したい \n- 特に町名番地の抜けもれや不備が多くこの点をどうにか拾いたい\n- 可能ならユーザーの入力時点でFEあるいはBE側でバリデーションチェックしたい まずはOSSのライブラリで検証したい \n- まずはOSSのライブラリで検証したい  > SOLUTIONSOLUTION \n\nというわけで、昨年（2020年）経産省IMI（情報共有基盤）から公開された住所変換コンポーネント「IMI-Tool-Project/imi-enrichment-address」がバリデーションチェックでどの程度使えるか検証します。  > imi-enrichment-addressとはimi-enrichment-addressとは \n\n経産省IMIツールプロジェクトで公開された住所変換コンポーネントです。CLIとサーバーが用意されていますが、今回はCLIを見ていきます。 \n\nヘルプを見ると住所を引数として渡すことで処理されることが分かります。 sh\n\n$ npm install -g https://info.gbiz.go.jp/tools/imi_tools/resource/imi-enrichment-address/imi-enrichment-address-2.0.0.tgz $ imi-enrichment-address --help imi-enrichment-address 住所文字列をもとに住所型・場所型の情報を補完します オプション -h, --help このヘルプを表示します -f, --file file 変換対象とする JSON ファイル -s, --string string 変換対象とする住所文字列 -i, --indent number 出力する JSON のインデント (default 2) 実行例 ヘルプの表示 $ imi-enrichment-address -h 文字列の処理 $ imi-enrichment-address -s 霞が関2 ファイルの処理 $ imi-enrichment-address input.json 標準入力の処理 $ cat input.json | imi-enrichment-address  \n\n実行すると正確な住所を渡したときと不正確な住所を渡したときで異なった結果を返すことが分かります。今回はこの正確・不正確の異なった結果を利用して検証していこうと思います。 sh\n\n$ imi-enrichment-address -s 長野県長野市大字長野旭町1108 { \"@context\": \"https://imi.go.jp/ns/core/context.jsonld\", \"@type\": \"場所型\", \"住所\": { \"@type\": \"住所型\", \"表記\": \"長野県長野市大字長野旭町1108\", \"都道府県\": \"長野県\", \"都道府県コード\": \"http://data.e-stat.go.jp/lod/sac/C20000\", \"市区町村\": \"長野市\", \"市区町村コード\": \"http://data.e-stat.go.jp/lod/sac/C20201\", \"町名\": \"大字長野\" }, \"地理座標\": { \"@type\": \"座標型\", \"緯度\": \"36.674892\", \"経度\": \"138.178449\" } } $ imi-enrichment-address -s 長野県長野市旭町1108 { \"@context\": \"https://imi.go.jp/ns/core/context.jsonld\", \"@type\": \"場所型\", \"住所\": { \"@type\": \"住所型\", \"表記\": \"長野県長野市旭町1108\", \"都道府県\": \"長野県\", \"都道府県コード\": \"http://data.e-stat.go.jp/lod/sac/C20000\", \"市区町村\": \"長野市\", \"市区町村コード\": \"http://data.e-stat.go.jp/lod/sac/C20201\" }, \"メタデータ\": { \"@type\": \"文書型\", \"説明\": \"該当する町名が見つかりません\" } }  \n\nなお、GitHubコードを見るとimi-enrichment-addressは街区レベル位置参照情報を利用して実装しています。このことを考えるとバリデーションチェックで積極的につかうのは難しく、ユースケースとしては下記2点に落ち着くと考えます。 \n\n- ユーザーに住所の再確認を促す\n- 入力後の住所不備について人が目検で確認する前段階で利用  > 検証用データ検証用データ \n\nさて、検証に進みましょう。imi-enrichment-addressで検証するデータは簡易に使える住所.jp、その中の事業所住所22402件を使います。他にも検証データはありますが、コストもそれほどかけられないのでコマンドだけで完結するものを選んでいます。 sh\n\n$ curl -sSL http://jusyo.jp/downloads/new/csv/csv_zenkoku.zip -o csv_zenkoku.zip $ unzip csv_zenkoku.zip $ go get github.com/mithrandie/csvq $ csvq -f CSV \"SELECT COUNT(*) FROM zenkoku WHERE 事業所住所 IS NOT NULL\" COUNT(*) 22402   > imi-enrichment-addressで検証用データを確認するimi-enrichment-addressで検証用データを確認する \n\n今回実行したCLIはNodeJSであることと数時間で処理できるという点で逐次で済ませました。 sh\n\n$ for i in $( csvq -f CSV \"SELECT 都道府県,市区町村,事業所住所 FROM zenkoku WHERE 事業所住所 IS NOT NULL\" \\ | sed 's/,//g' \\ | tail +2 \\ ); do imi-enrichment-address -s $i \\ | jq -r ' [ .[\"住所\"][\"表記\"], ( if .[\"地理座標\"] != null then true else false end ), .[\"メタデータ\"][\"説明\"] ] | @csv ' >>output.csv; done &   > バリデーションチェックの結果を確認するバリデーションチェックの結果を確認する \n\nimi-enrichment-addressの出力結果を確認したところ全国で9.25%が無効、下記の通り町名番地の表記揺れに弱いことが分かりました。特に町字（まちあざ）省略によるバリデーションエラーの比率が高く、青森、長野、沖縄等複数の県の住所が実用に耐えない結果となりました。 \n\nバリデーションエラーになった原因 \n\n- 各地方の字・大字の省略\n- 京都の通り上る・下るの表記\n- 北海道の条、線の表記揺れ\n- 茨城、岐阜等の町名省略\n- 茨城、神奈川、岐阜、石川等の区画整理地    都道府県 無効割合（%） 備考     青森県 54.42 字省略により無効   長野県 44.28 字省略により無効   沖縄県 43.55 字省略により無効   大分県 38.96 字省略により無効   京都府 36.86 字省略、通りにより無効   佐賀県 33.33 字省略により無効   奈良県 29.94 字省略により無効   福島県 29.18 字省略により無効   宮崎県 27.71 字省略により無効   埼玉県 23.08 字省略により無効   山口県 22.65 字省略により無効   和歌山県 17.78 字省略により無効   群馬県 17.08 字省略、ノ町により無効   茨城県 15.51 字省略、町名省略、区画整理により無効   熊本県 14.89 字省略により無効   山形県 14.38 字省略により無効   北海道 13.76 字省略、条、線により無効   栃木県 13.6 字省略により無効   新潟県 13.19 字省略により無効   鳥取県 9.57 字省略により無効   全国 9.25    福岡県 9 字省略により無効   三重県 7.74 字省略により無効   愛知県 7.4 字省略により無効   鹿児島県 7.09 字省略により無効   山梨県 6.8 字省略により無効   宮城県 6.37 字省略により無効   岩手県 6.28 字省略により無効   岐阜県 5.67 字省略、町名省略、区画整理により無効   香川県 4.71 字省略により無効   石川県 4.7 字省略、区画整理により無効   愛媛県 4.39 字省略により無効   秋田県 4.17 字省略により無効   滋賀県 3.76 字省略により無効   広島県 3.74 字省略により無効   高知県 3.38 字省略により無効   大阪府 3.28 字省略により無効   兵庫県 2.71 字省略により無効   島根県 2.04 字省略により無効   岡山県 1.81 字省略により無効   神奈川県 1.72 字省略、区画整理により無効   徳島県 1.64 字省略により無効   富山県 1.14 字省略により無効   静岡県 1.06 字省略、町名省略、区画整理により無効   東京都 0.89 字省略により無効   福井県 0.71 字省略により無効   千葉県 0.64 字省略により無効   長崎県 0      > WRAPUPWRAPUP \n\nimi-enrichment-addressは町名番地の判定に素の街区レベル位置参照情報を使用しているため、町字（まちあざ）の省略に弱いことが分かりました。 \n\n- ユーザーに住所の再確認を促す\n- 入力後の住所不備について人が目検で確認する前段階で利用 \n\nまず、想定したユースケースの内1つ「ユーザーに住所の再確認を促す」については、配送で使う住所の場合「町字の省略は影響ない」ので機能として適切ではありません。ユーザーが東京に集中している場合は関係ないですが、「町字が存在するさいたま市、川崎市、名古屋市、広島市、北九州市、福岡市、熊本市等の政令指定都市」や長野市のように住所が町字の組み合わせで2つ以上存在する都市の場合、使い勝手の悪い機能となります。 \n\n次に「入力後の住所不備について人が目検で確認する前段階で利用」については多少は有効に機能するでしょう。ただし、町字が多い地域では上記同様に使い勝手が悪くなります。 \n\n今回の検証の結果、現状の仕様ではimi-enrichment-addressを使うケースは限定せざるを得ず、一旦使用を見送りとします。とは言え、街区レベル位置参照情報にある町名番地から町字を除けば活用範囲が広がる可能性も確認できました。幸いなことにライブラリはMITライセンスで公開されています。"},"name":"[2021-07-24]imi-enrichment-addressは住所のバリデーションチェックでどの程度使えるか","tags":["imi-enrichment-address","mlit-isj"],"childPublishedDate":{"published_on":"2021-07-24T00:00:00.000Z","published_on_unix":1627084800}}}]}},"pageContext":{"number":61}},"staticQueryHashes":[]}