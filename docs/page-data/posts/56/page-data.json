{"componentChunkName":"component---src-templates-post-tsx","path":"/posts/56","result":{"data":{"esaPost":{"number":56,"relative_category":"blog/backend","fields":{"title":"RubyのCSVパースをPyCallで実行する（ベンチマーク）","excerpt":"先日RubyからPythonにアクセスできるPyCallというライブラリの存在を知り、ぜひともベンチマークを取りたいと思った次第です。現状RubyのCSVの読み込みに不満を持っており、そこをどうにか解消したいと考えています。   > PROBLEMPROBLEM \n\n- 大量のCSVを読み込む際、毎回時間がかかる   > SOLUTIONSOLUTION \n\nというわけで、「Dalibor Nasevicのベンチマーク記事」にPyCallのベンチマークをくわえて比較してみることにしました。記事では下記の通り CSV.foreach が速いとの結論でした。    kind_of_parse time (real) memory (MB)     1. CSV.read  39.13 866.6   2. CSV.parse  36.16 936.87   3. line by line from String Object 23.39 73.42   4. line by line from IO Object 24.55 0.0   5. CSV.foreach  24.04 0.0      > PyCallのベンチマークPyCallのベンチマーク \n\nそれでは、PyCallのベンチマークを計りましょう。コードは下記のようになります。   ruby \n\nrequire_relative './helpers' require 'pycall/import' include PyCall::Import pyimport :pandas, as: :pd print_memory_usage do print_time_spent do csv = pd.read_csv.('data.csv') sum = csv['id'].sum.() puts \"Sum: #{sum}\" end end   \n\nPyCallは pyenv との相性が悪いのでSystemインストールしたPythonでたたきます。   sh \n\n$ PYTHON=/usr/bin/python3.4 ruby parse_6_pycall.rb Sum: 499999500000 Time: 1.49 Memory: 54.99 MB   \n\n結果    kind_of_parse time (real) memory (MB)     1. CSV.read  39.13 866.6   2. CSV.parse  36.16 936.87   3. line by line from String Object 23.39 73.42   4. line by line from IO Object 24.55 0.0   5. CSV.foreach  24.04 0.0   6. PyCall 1.49 54.99    \n\nはい、結果が出ました。Daliborのベンチマーク記事で一番速かった CSV.foreach より16倍の実行速度となりました。   > WRAPUPWRAPUP \n\nPyCallのオブジェクトが PyObjectとActiveRecordと相性が悪そうなのと、PythonとRuby双方のメモリー管理が運用を難しくすることから、安易に本番環境のRailsに導入するのは厳しいと思います。 \n\nただし、実行回数が限定されたスクリプトなら積極的に使って良いでしょう。","thumbnail":"https://img.esa.io/uploads/production/attachments/16651/2021/01/11/97367/180665c6-7370-4579-8340-7be6254834e8.png"},"wip":false,"body_md":"<img width=\"1920\" alt=\"thumbnail\" src=\"https://img.esa.io/uploads/production/attachments/16651/2021/01/11/97367/180665c6-7370-4579-8340-7be6254834e8.png\">\r\n\r\n先日RubyからPythonにアクセスできるPyCallというライブラリの存在を知り、ぜひともベンチマークを取りたいと思った次第です。現状RubyのCSVの読み込みに不満を持っており、そこをどうにか解消したいと考えています。\r\n\r\n# PROBLEM\r\n- 大量のCSVを読み込む際、毎回時間がかかる\r\n\r\n# SOLUTION\r\nというわけで、「[Dalibor Nasevicのベンチマーク記事](https://dalibornasevic.com/posts/68-processing-large-csv-files-with-ruby)」にPyCallのベンチマークをくわえて比較してみることにしました。記事では下記の通り `CSV.foreach` が速いとの結論でした。\r\n\r\n| kind_of_parse                      | time (real) | memory (MB) |\r\n|------------------------------------|-------------|-------------|\r\n| 1. `CSV.read`                      |       39.13 |       866.6 |\r\n| 2. `CSV.parse`                     |       36.16 |      936.87 |\r\n| 3. line by line from String Object |       23.39 |       73.42 |\r\n| 4. line by line from IO Object     |       24.55 |         0.0 |\r\n| 5. `CSV.foreach`                   |       24.04 |         0.0 |\r\n\r\n## PyCallのベンチマーク\r\nそれでは、PyCallのベンチマークを計りましょう。コードは下記のようになります。\r\n\r\n```ruby\r\nrequire_relative './helpers'\r\nrequire 'pycall/import'\r\ninclude PyCall::Import\r\npyimport :pandas, as: :pd\r\n\r\nprint_memory_usage do\r\n  print_time_spent do\r\n    csv = pd.read_csv.('data.csv')\r\n    sum = csv['id'].sum.()\r\n    puts \"Sum: #{sum}\"\r\n  end\r\nend\r\n```\r\n\r\nPyCallは `pyenv` との相性が悪いのでSystemインストールしたPythonでたたきます。\r\n\r\n```sh\r\n$ PYTHON=/usr/bin/python3.4 ruby parse_6_pycall.rb\r\nSum: 499999500000\r\nTime: 1.49\r\nMemory: 54.99 MB\r\n```\r\n\r\n**結果**\r\n\r\n| kind_of_parse                      | time (real) | memory (MB) |\r\n|------------------------------------|-------------|-------------|\r\n| 1. `CSV.read`                      |       39.13 |       866.6 |\r\n| 2. `CSV.parse`                     |       36.16 |      936.87 |\r\n| 3. line by line from String Object |       23.39 |       73.42 |\r\n| 4. line by line from IO Object     |       24.55 |         0.0 |\r\n| 5. `CSV.foreach`                   |       24.04 |         0.0 |\r\n| 6. PyCall                          |        1.49 |       54.99 |\r\n\r\nはい、結果が出ました。Daliborのベンチマーク記事で一番速かった `CSV.foreach` より16倍の実行速度となりました。\r\n\r\n# WRAPUP\r\nPyCallのオブジェクトが `PyObject`とActiveRecordと相性が悪そうなのと、PythonとRuby双方のメモリー管理が運用を難しくすることから、安易に本番環境のRailsに導入するのは厳しいと思います。\r\n\r\nただし、実行回数が限定されたスクリプトなら積極的に使って良いでしょう。\r\n","body_html":"<a href=\"https://img.esa.io/uploads/production/attachments/16651/2021/01/11/97367/180665c6-7370-4579-8340-7be6254834e8.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img width=\"1920\" alt=\"thumbnail\" src=\"https://img.esa.io/uploads/production/attachments/16651/2021/01/11/97367/180665c6-7370-4579-8340-7be6254834e8.png\"></a>\n<p data-sourcepos=\"3:1-3:290\">先日RubyからPythonにアクセスできるPyCallというライブラリの存在を知り、ぜひともベンチマークを取りたいと思った次第です。現状RubyのCSVの読み込みに不満を持っており、そこをどうにか解消したいと考えています。</p>\n<h1 data-sourcepos=\"5:1-5:9\" id=\"1-0-0\" name=\"1-0-0\">\n<a class=\"anchor\" id=\"PROBLEM\" name=\"PROBLEM\" href=\"#PROBLEM\" data-position=\"1-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"PROBLEM\"> &gt; PROBLEM</span></a>PROBLEM</h1>\n<ul data-sourcepos=\"6:1-7:0\">\n<li data-sourcepos=\"6:1-7:0\">大量のCSVを読み込む際、毎回時間がかかる</li>\n</ul>\n<h1 data-sourcepos=\"8:1-8:10\" id=\"2-0-0\" name=\"2-0-0\">\n<a class=\"anchor\" id=\"SOLUTION\" name=\"SOLUTION\" href=\"#SOLUTION\" data-position=\"2-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"SOLUTION\"> &gt; SOLUTION</span></a>SOLUTION</h1>\n<p data-sourcepos=\"9:1-9:307\">というわけで、「<a href=\"https://dalibornasevic.com/posts/68-processing-large-csv-files-with-ruby\" target=\"_blank\" rel=\"noopener noreferrer\">Dalibor Nasevicのベンチマーク記事</a>」にPyCallのベンチマークをくわえて比較してみることにしました。記事では下記の通り <code>CSV.foreach</code> が速いとの結論でした。</p>\n<table data-sourcepos=\"11:1-17:66\">\n<thead>\n<tr data-sourcepos=\"11:1-11:66\">\n<th data-sourcepos=\"11:2-11:37\">kind_of_parse</th>\n<th data-sourcepos=\"11:39-11:51\">time (real)</th>\n<th data-sourcepos=\"11:53-11:65\">memory (MB)</th>\n</tr>\n</thead>\n<tbody>\n<tr data-sourcepos=\"13:1-13:66\">\n<td data-sourcepos=\"13:2-13:37\">1. <code>CSV.read</code>\n</td>\n<td data-sourcepos=\"13:39-13:51\">39.13</td>\n<td data-sourcepos=\"13:53-13:65\">866.6</td>\n</tr>\n<tr data-sourcepos=\"14:1-14:66\">\n<td data-sourcepos=\"14:2-14:37\">2. <code>CSV.parse</code>\n</td>\n<td data-sourcepos=\"14:39-14:51\">36.16</td>\n<td data-sourcepos=\"14:53-14:65\">936.87</td>\n</tr>\n<tr data-sourcepos=\"15:1-15:66\">\n<td data-sourcepos=\"15:2-15:37\">3. line by line from String Object</td>\n<td data-sourcepos=\"15:39-15:51\">23.39</td>\n<td data-sourcepos=\"15:53-15:65\">73.42</td>\n</tr>\n<tr data-sourcepos=\"16:1-16:66\">\n<td data-sourcepos=\"16:2-16:37\">4. line by line from IO Object</td>\n<td data-sourcepos=\"16:39-16:51\">24.55</td>\n<td data-sourcepos=\"16:53-16:65\">0.0</td>\n</tr>\n<tr data-sourcepos=\"17:1-17:66\">\n<td data-sourcepos=\"17:2-17:37\">5. <code>CSV.foreach</code>\n</td>\n<td data-sourcepos=\"17:39-17:51\">24.04</td>\n<td data-sourcepos=\"17:53-17:65\">0.0</td>\n</tr>\n</tbody>\n</table>\n<h2 data-sourcepos=\"19:1-19:30\" id=\"2-1-0\" name=\"2-1-0\">\n<a class=\"anchor\" id=\"PyCallのベンチマーク\" name=\"PyCall%E3%81%AE%E3%83%99%E3%83%B3%E3%83%81%E3%83%9E%E3%83%BC%E3%82%AF\" href=\"#PyCall%E3%81%AE%E3%83%99%E3%83%B3%E3%83%81%E3%83%9E%E3%83%BC%E3%82%AF\" data-position=\"2-1-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"PyCallのベンチマーク\"> &gt; PyCallのベンチマーク</span></a>PyCallのベンチマーク</h2>\n<p data-sourcepos=\"20:1-20:111\">それでは、PyCallのベンチマークを計りましょう。コードは下記のようになります。</p>\n<div class=\"code-block\" data-sourcepos=\"22:1-35:3\">\n<div class=\"code-filename\">\n<i class=\"fa fa-file-code-o\"></i>ruby</div>\n<div class=\"highlight\"><pre class=\"highlight ruby\"><code><span class=\"nb\">require_relative</span> <span class=\"s1\">'./helpers'</span>\n<span class=\"nb\">require</span> <span class=\"s1\">'pycall/import'</span>\n<span class=\"kp\">include</span> <span class=\"no\">PyCall</span><span class=\"o\">::</span><span class=\"no\">Import</span>\n<span class=\"n\">pyimport</span> <span class=\"ss\">:pandas</span><span class=\"p\">,</span> <span class=\"ss\">as: :pd</span>\n\n<span class=\"n\">print_memory_usage</span> <span class=\"k\">do</span>\n  <span class=\"n\">print_time_spent</span> <span class=\"k\">do</span>\n    <span class=\"n\">csv</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"nf\">read_csv</span><span class=\"o\">.</span><span class=\"p\">(</span><span class=\"s1\">'data.csv'</span><span class=\"p\">)</span>\n    <span class=\"n\">sum</span> <span class=\"o\">=</span> <span class=\"n\">csv</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">].</span><span class=\"nf\">sum</span><span class=\"o\">.</span><span class=\"p\">()</span>\n    <span class=\"nb\">puts</span> <span class=\"s2\">\"Sum: </span><span class=\"si\">#{</span><span class=\"n\">sum</span><span class=\"si\">}</span><span class=\"s2\">\"</span>\n  <span class=\"k\">end</span>\n<span class=\"k\">end</span>\n</code></pre></div>\n</div>\n<p data-sourcepos=\"37:1-37:102\">PyCallは <code>pyenv</code> との相性が悪いのでSystemインストールしたPythonでたたきます。</p>\n<div class=\"code-block\" data-sourcepos=\"39:1-44:3\">\n<div class=\"code-filename\">\n<i class=\"fa fa-file-code-o\"></i>sh</div>\n<div class=\"highlight\"><pre class=\"highlight shell\"><code><span class=\"nv\">$ PYTHON</span><span class=\"o\">=</span>/usr/bin/python3.4 ruby parse_6_pycall.rb\nSum: 499999500000\nTime: 1.49\nMemory: 54.99 MB\n</code></pre></div>\n</div>\n<p data-sourcepos=\"46:1-46:10\"><strong>結果</strong></p>\n<table data-sourcepos=\"48:1-55:66\">\n<thead>\n<tr data-sourcepos=\"48:1-48:66\">\n<th data-sourcepos=\"48:2-48:37\">kind_of_parse</th>\n<th data-sourcepos=\"48:39-48:51\">time (real)</th>\n<th data-sourcepos=\"48:53-48:65\">memory (MB)</th>\n</tr>\n</thead>\n<tbody>\n<tr data-sourcepos=\"50:1-50:66\">\n<td data-sourcepos=\"50:2-50:37\">1. <code>CSV.read</code>\n</td>\n<td data-sourcepos=\"50:39-50:51\">39.13</td>\n<td data-sourcepos=\"50:53-50:65\">866.6</td>\n</tr>\n<tr data-sourcepos=\"51:1-51:66\">\n<td data-sourcepos=\"51:2-51:37\">2. <code>CSV.parse</code>\n</td>\n<td data-sourcepos=\"51:39-51:51\">36.16</td>\n<td data-sourcepos=\"51:53-51:65\">936.87</td>\n</tr>\n<tr data-sourcepos=\"52:1-52:66\">\n<td data-sourcepos=\"52:2-52:37\">3. line by line from String Object</td>\n<td data-sourcepos=\"52:39-52:51\">23.39</td>\n<td data-sourcepos=\"52:53-52:65\">73.42</td>\n</tr>\n<tr data-sourcepos=\"53:1-53:66\">\n<td data-sourcepos=\"53:2-53:37\">4. line by line from IO Object</td>\n<td data-sourcepos=\"53:39-53:51\">24.55</td>\n<td data-sourcepos=\"53:53-53:65\">0.0</td>\n</tr>\n<tr data-sourcepos=\"54:1-54:66\">\n<td data-sourcepos=\"54:2-54:37\">5. <code>CSV.foreach</code>\n</td>\n<td data-sourcepos=\"54:39-54:51\">24.04</td>\n<td data-sourcepos=\"54:53-54:65\">0.0</td>\n</tr>\n<tr data-sourcepos=\"55:1-55:66\">\n<td data-sourcepos=\"55:2-55:37\">6. PyCall</td>\n<td data-sourcepos=\"55:39-55:51\">1.49</td>\n<td data-sourcepos=\"55:53-55:65\">54.99</td>\n</tr>\n</tbody>\n</table>\n<p data-sourcepos=\"57:1-57:150\">はい、結果が出ました。Daliborのベンチマーク記事で一番速かった <code>CSV.foreach</code> より16倍の実行速度となりました。</p>\n<h1 data-sourcepos=\"59:1-59:8\" id=\"3-0-0\" name=\"3-0-0\">\n<a class=\"anchor\" id=\"WRAPUP\" name=\"WRAPUP\" href=\"#WRAPUP\" data-position=\"3-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"WRAPUP\"> &gt; WRAPUP</span></a>WRAPUP</h1>\n<p data-sourcepos=\"60:1-60:248\">PyCallのオブジェクトが <code>PyObject</code>とActiveRecordと相性が悪そうなのと、PythonとRuby双方のメモリー管理が運用を難しくすることから、安易に本番環境のRailsに導入するのは厳しいと思います。</p>\n<p data-sourcepos=\"62:1-62:105\">ただし、実行回数が限定されたスクリプトなら積極的に使って良いでしょう。</p>\n","tags":["ruby","benchmark","pycall"],"updated_at":"2021-01-16T10:27:34+09:00","childPublishedDate":{"published_on":"2017-06-05T00:00:00.000Z"},"updated_by":{"name":"なびの👷","screen_name":"nabinno","icon":"https://img.esa.io/uploads/production/members/94286/icon/thumb_m_ef5f024307008aa399b91f87fa5f64e8.jpg"}},"relatedPosts":{"edges":[{"node":{"number":49,"relative_category":"blog/backend","fields":{"title":"HydeをつかってEmacsをJekyllクライアントにする","excerpt":"Emacianとしてその殻の中に閉じこもっていたいです。だけど、世間がそれを許さず次々と無理難題を押しつけてくるのです。今回はタスク等から出てきた備忘禄をGitHub Pages（Jekyll）で管理しようと重い腰を上げました。   > PROBLEMPROBLEM \n\n- タスクメモがAsanaなどのタスク管理ツールに散在している\n- ブラウザをつかって文章を書くのがつらい\n- Gist/Yagist等でもいいのだけど編集がめんどうとか個人だとオーバースペックとか   > SOLUTIONSOLUTION \n\nというわけで、GitHub Pages（Jekyll）をEmacsで楽に管理できないかと以前から考えていたのですが、いい塩梅のライブラリを発見しました。JekyllだからHydeと言います。名前が jekyll doctor (hyde)とかぶっていますがここでは気にしません。 \n\nHydeのPros/Consは以下の通りです。 \n\nPros \n\n- gitの自動コメント\n- jekyll build、jekyll serveのショートカット \n\nCons \n\n- キーバインドが既存のものとかぶる\n- hyde-homeがカスタム変数ではない\n- add-hookが効かない   > Hydeの設定Hydeの設定 \n\nHydeの設定は基本いじることもなくJekyllを使うことが出来ます。下記記載するのはConsつぶしですが、ここはお好みです。 \n\nまず、キーバインド操作。Hyde本体がキーバインドをdefvarで割り当てているので、init.elの設定でrequire前に割り込みevalして、hyde関数にhyde-home引数をわたすことで解決します。あと、折り返し回りは別設定になっているのでadaptive-wrapやtruncate-linesを設定しています。   emacs-lisp \n\n;;; Hyde (Jekyll client) (require-package 'adaptive-wrap) (defun hyde/open-post-maybe-into-other-window (pos) \"Opens the post under cursor in the editor (POS).\" (interactive \"d\") (let ((post-file-name (nth 1 (split-string (strip-string (thing-at-point 'line)) \" : \"))) (dir (get-text-property pos 'dir))) (let ((hyde-buffer (current-buffer))) (find-file-other-window (strip-string (concat hyde-home \"/\" dir \"/\" post-file-name))) (hyde-markdown-activate-mode hyde-buffer) (adaptive-wrap-prefix-mode t) (set-default 'truncate-lines nil)))) (defun hyde/quit-wrap () \"Quits hyde.\" (interactive) (progn (delete-other-windows) (kill-buffer (current-buffer)))) (defun create-markdown-scratch () \"Create a markdown scratch buffer.\" (interactive) (switch-to-buffer (get-buffer-create \"*markdown*\")) (markdown-mode)) (defun hyde/nabinno () \"Run hyde-wrap with home parameter.\" (interactive) (progn (delete-other-windows) (create-markdown-scratch) (split-window-horizontally) (other-window 1) (hyde \"~/nabinno.github.io/\"))) (defvar hyde-mode-map (let ((hyde-mode-map (make-sparse-keymap))) (define-key hyde-mode-map (kbd \"N\") 'hyde/new-post) (define-key hyde-mode-map (kbd \"G\") 'hyde/load-posts) (define-key hyde-mode-map (kbd \"C\") 'hyde/hyde-commit-post) (define-key hyde-mode-map (kbd \"P\") 'hyde/hyde-push) (define-key hyde-mode-map (kbd \"J\") 'hyde/run-jekyll) (define-key hyde-mode-map (kbd \"S\") 'hyde/serve) (define-key hyde-mode-map (kbd \"K\") 'hyde/stop-serve) (define-key hyde-mode-map (kbd \"d\") 'hyde/deploy) (define-key hyde-mode-map (kbd \"D\") 'hyde/delete-post) (define-key hyde-mode-map (kbd \"U\") 'hyde/promote-to-post) (define-key hyde-mode-map (kbd \"X\") 'hyde/quit-wrap) (define-key hyde-mode-map (kbd \"O\") 'hyde/open-post-maybe-into-other-window) hyde-mode-map) \"Keymap for Hyde\") (global-set-key (kbd \"C-c ; j\") 'hyde/nabinno) (require-package 'hyde) (require 'hyde)   \n\n次に、ホストIPの操作。Jekyllのルートにおく.hyde.elの中身です。JekyllはWebrickを使っているので、VMなどでホストをいじっている場合はhyde/serve-commandにホストIPを0.0.0.0（jekyll s -H 0.0.0.0）に変更する必要があります。   emacs-lisp \n\n(setq hyde-deploy-dir \"_site\" hyde-posts-dir \"_posts\" hyde-drafts-dir \"_drafts\" hyde-images-dir \"images\" hyde/git/remote \"upstream\" ; The name of the remote to which we should push hyde/git/branch \"master\" ; The name of the branch on which your blog resides hyde/jekyll-command \"jekyll b\" ; Command to build hyde/serve-command \"jekyll s -H 0.0.0.0 --force_polling\" ; Command to serve hyde-custom-params '((\"category\" \"personal\") (\"tags\" \"\") (\"cover\" \"false\") (\"cover-image\" \"\")))     > WRAPUPWRAPUP \n\nHydeを介してEmacsでJekyllを操作できるのは、やはり快適です。特にorg-modeとMarkdownの相性が良く。org-modeで管理していた備忘をMarkdownに変換し、Jekyll（GitHub Pages）にパブリッシュというワークフローが引けたのが良かったです。数年間はお世話になると思います。"},"name":"[2017-02-01]HydeをつかってEmacsをJekyllクライアントにする","tags":["emacs","jekyll","hyde","github-pages"],"childPublishedDate":{"published_on":"2017-02-01T00:00:00.000Z","published_on_unix":1485907200}}},{"node":{"number":52,"relative_category":"blog/backend","fields":{"title":"HerokuとGAEのCIをDockerとパイプラインから構成されたWerckerで管理する","excerpt":"Continuous Integration (CI) が徐々にDockerに対応し始める機運です。先行してWerckerがDocker対応を始めたので、その流れに乗るべくWerckerをDocker化してみました。   > PROBLEMPROBLEM \n\n- パフォーマンス改善のための開発環境がいけてない\n- 別PaaSへ移行するための開発環境が汎用化できてない、つらい   > SOLUTIONSOLUTION \n\nというわけで、まずはCI上のDockerに載せてから次の手（GAEあたり）を考えることにしました。CIはWerckerを使用。以前から使っていたのですが、今回はボックスがDockerになったのでそちらに対応しました。 \n\nまず、Werckerは「Docker」「環境変数」による環境管理、「パイプライン」によるワークフロー管理を行っています。 \n\n1. Dockerで環境を管理。 今回は対応していないですが、GAEのコンテナ（gcr.io/google_appengine/ruby:xxx）と共通化することもできます。ただし、HerokuのHobby Dynosはプロセス数に制限があるのでコンテナ運用は工夫が必要です。\n2. 異なるサービス間のネットワークをWerckerが生成する環境変数で管理。 Dockerのネットワーク設定の煩雑さを解消します。\n3. タスクをワークフローとしてパイプラインで条件付け管理。 パイプラインごとにコンテナを立ち上げているので、同じDocker環境でもパイプラインごとに環境変数を分けることが可能です。Herokuのパイプラインでもいいですが、今後別PaaSに移行する可能性を考えてCI管理にbetしました。 \n\n次に、Werckerのふるまいを定義するwercker.ymlは、下記シークエンス図のようにパイプラインごとに記述されています。今回は各パイプラインの詳細を見ていくことにします。    > devパイプラインdevパイプライン \n\ndevパイプラインは wercker dev コマンドをローカルでたたく際に使います。下記の例だとRSpec走らせているだけなのでおまけ程度。ただ、ローカル開発でDockerを使うことになったらこういう提案もありだと思います。プロジェクトレポジトリすべてをDockerにしてローカル開発するペイン、所謂git-dockerのバージョン管理問題があるので代替案として。   yaml \n\nbox: ruby:2.3.1 services: - postgres:9.6.1 - redis:3.0.3 dev: steps: - bundle-install - script: name: Install ImageMagick code: | apt-get update apt-get install -y nodejs imagemagick - script: name: Setup database code: | RAILS_ENV=test bundle exec rake db:create db:migrate - internal/watch: name: Run rspec code: | RAILS_ENV=test bundle exec rake spec reload: true     > buildパイプラインbuildパイプライン \n\nbuildパイプラインもdevパイプラインと同じDockerボックスを使っています。やっていることはdevパイプラインと変わらず、すべてのブランチで走ります。   yaml \n\nbuild: steps: - bundle-install - script: name: Install ImageMagick code: | apt-get update apt-get install -y nodejs imagemagick - script: name: Echo Ruby information code: | env echo \"ruby version $(ruby --version) running!\" echo \"from location $(which ruby)\" echo -p \"gem list: $(gem list)\" - script: name: Setup database code: | RAILS_ENV=test bundle exec rake db:create db:migrate - script: name: Run rspec code: | RAILS_ENV=test bundle exec rake spec     > deploy-stageパイプラインdeploy-stageパイプライン \n\ndeploy-stageパイプラインはステージング環境用。現在Herokuを本番環境で利用しているので、デプロイごとにそれをフォークして環境構築しています。また、Railsのアセットプリコンパイルの時間短縮はほかのCIと同様にキャッシュを利用しています。 \n\n他のPaaSに移った場合に現在行っている本番環境のフォークをどうするかが検討課題となります。   yaml \n\ndeploy-stage-heroku: steps: - bundle-install - script: name: Install NodeJS code: | apt-get update apt-get install -y nodejs - nabinno/heroku-install: key: $HEROKU_KEY user: $HEROKU_USER app-name: $HEROKU_APP_NAME - script: name: Fork Application - destroy application code: | heroku apps:destroy --app $HEROKU_APP_NAME --confirm $HEROKU_APP_NAME - script: name: Fork Application - fork code: | heroku fork --from $FROM_HEROKU_APP_NAME --to $HEROKU_APP_NAME - script: name: Fork Application - setup addons of rediscloud code: | heroku addons:create rediscloud:30 --app $HEROKU_APP_NAME - script: name: Fork Application -change dynos code: | heroku ps:scale web=1:Free worker=1:Free --app $HEROKU_APP_NAME - script: name: Fork Application - change environment variables code: | _rediscloud_url=$(heroku run 'env | grep -e REDISCLOUD_.*_URL' --app $HEROKU_APP_NAME | awk -F= '{print $2}') heroku config:set \\ S3_BUCKET=$S3_BUCKET \\ HEROKU_APP=$HEROKU_APP_NAME \\ REDISCLOUD_URL=$_rediscloud_url \\ --app $HEROKU_APP_NAME - script: name: Assets Precompile - restore assets cache code: | [ -e $WERCKER_CACHE_DIR/public/assets ] && cp -fr $WERCKER_CACHE_DIR/public/assets $WERCKER_SOURCE_DIR/public || true mkdir -p $WERCKER_SOURCE_DIR/tmp/cache [ -e $WERCKER_CACHE_DIR/tmp/cache/assets ] && cp -fr $WERCKER_CACHE_DIR/tmp/cache/assets $WERCKER_SOURCE_DIR/tmp/cache || true - script: name: Assets Precompile - main process code: | RAILS_ENV=production bundle exec rake assets:precompile --trace - script: name: Assets Precompile - store assets cache code: | mkdir -p $WERCKER_CACHE_DIR/public/assets cp -fr $WERCKER_SOURCE_DIR/public/assets $WERCKER_CACHE_DIR/public mkdir -p $WERCKER_CACHE_DIR/tmp/cache/assets cp -fr $WERCKER_SOURCE_DIR/tmp/cache/assets $WERCKER_CACHE_DIR/tmp/cache - add-ssh-key: host: github.com keyname: GITHUB - add-to-known_hosts: hostname: github.com fingerprint: 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48 - script: name: Assets Precompile - git commit code: | { git add public/assets/.sprockets-manifest-*.json git commit -m 'Run `rake assets:precompile` on Wercker.' } || { echo 'Skip: keep precompiled assets manifest.' } - heroku-deploy: key: $HEROKU_KEY user: $HEROKU_USER app-name: $HEROKU_APP_NAME - script: name: DB Migrate code: | heroku run 'bundle exec rake db:migrate --trace' --app $HEROKU_APP_NAME after-steps: - wantedly/pretty-slack-notify: webhook_url: ${SLACK_WEBHOOK_URL} channel: general     > deploy-prod-herokuパイプラインdeploy-prod-herokuパイプライン \n\ndeploy-prod-herokuパイプラインは本番環境へのリリース用。環境変数以外はdeploy-stageパイプラインと同じものです。   yaml \n\ndeploy-prod-heroku: steps: - bundle-install - script: name: Install NodeJS code: | apt-get update apt-get install -y nodejs - script: name: Assets Precompile - restore assets cache code: | [ -e $WERCKER_CACHE_DIR/public/assets ] && cp -fr $WERCKER_CACHE_DIR/public/assets $WERCKER_SOURCE_DIR/public || true mkdir -p $WERCKER_SOURCE_DIR/tmp/cache [ -e $WERCKER_CACHE_DIR/tmp/cache/assets ] && cp -fr $WERCKER_CACHE_DIR/tmp/cache/assets $WERCKER_SOURCE_DIR/tmp/cache || true - script: name: Assets Precompile - main process code: | RAILS_ENV=production bundle exec rake assets:precompile --trace - script: name: Assets Precompile - store assets cache code: | mkdir -p $WERCKER_CACHE_DIR/public/assets cp -fr $WERCKER_SOURCE_DIR/public/assets $WERCKER_CACHE_DIR/public mkdir -p $WERCKER_CACHE_DIR/tmp/cache/assets cp -fr $WERCKER_SOURCE_DIR/tmp/cache/assets $WERCKER_CACHE_DIR/tmp/cache - add-ssh-key: host: github.com keyname: GITHUB - add-to-known_hosts: hostname: github.com fingerprint: 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48 - script: name: Assets Precompile - git commit code: | { git add public/assets/.sprockets-manifest-*.json git commit -m 'Run `rake assets:precompile` on Wercker.' } || { echo 'Skip: keep precompiled assets manifest.' } - script: name: Add git-tag code: | _tag=$(date -u -d '9 hours' +%Y-%m-%d-%H-%M-%S) git config --global user.email 'wercker@blahfe.com' git config --global user.name 'Wercker Bot' git tag -a $_tag master -m 'wercker deploy' git push origin $_tag - heroku-deploy: key: $HEROKU_KEY user: $HEROKU_USER app-name: $HEROKU_APP_NAME install-toolbelt: true - script: name: DB Migrate code: | heroku run 'bundle exec rake db:migrate --trace' --app $HEROKU_APP_NAME after-steps: - wantedly/pretty-slack-notify: webhook_url: ${SLACK_WEBHOOK_URL} channel: general     > deploy-prod-gaeパイプラインdeploy-prod-gaeパイプライン \n\ndeploy-prod-gaeパイプラインはdeploy-prod-herokuパイプラインと同じく本番環境へのリリース用。GAEにいつでも移行できるように走らせています。 \n\nGAEのデプロイは癖があって、gcloud app deployコマンドをつかってDockerビルドを走らせますが、その時にDocker内に外部から環境変数を設定することができません。そのため、アセットプリコンパイルのビルドの際、asset_syncを使っていると別サーバーへ同期に失敗します。また、パイプライン上の別ステップに環境変数を当てて行うことはできるが、gcloudのデプロイステップとアセットプリコンパイルが重複して適切なダイジェストを発行できません。従って、GAEをつかう場合は ./public ディレクトリをつかうのが現状の正解です。HerokuのSlugの取り扱い方針と違うので注意が必要です。 \n\nGAEのコンテナの中身は、gcloud beta app gen-config --runtime=ruby --custom で出力されるDockerfileを参照ください。   yaml \n\ndeploy-prod-gae: steps: - bundle-install - script: name: Install ImageMagick code: | apt-get update apt-get install -y nodejs imagemagick - script: name: Echo Ruby information code: | env echo \"ruby version $(ruby --version) running!\" echo \"from location $(which ruby)\" echo -p \"gem list: $(gem list)\" - script: name: DB Migrate code: | RAILS_ENV=production \\ DATABASE_URL=${DATABASE_URL} \\ bundle exec rake db:create db:migrate --trace - script: name: Install gcloud code: | curl https://sdk.cloud.google.com | bash source ~/.bashrc - script: name: Authenticate gcloud code: | gcloud config set project utagaki-v2 openssl aes-256-cbc -k ${DECRYPT_KEY} -d -in ./gcloud.json.encrypted -out ./gcloud.json gcloud auth activate-service-account --key-file ./gcloud.json - script: name: Deploy app to Google App Engine code: | gcloud app deploy ./app.yaml --promote --stop-previous-version after-steps: - wantedly/pretty-slack-notify: webhook_url: ${SLACK_WEBHOOK_URL} channel: general     > post-deployパイプラインpost-deployパイプライン \n\npost-deployパイプラインは本番環境にデプロイした後の後処理用です。参考程度に git tag をつけています。   yaml \n\npost-deploy: steps: - add-ssh-key: host: github.com keyname: GITHUB - add-to-known_hosts: hostname: github.com fingerprint: 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48 - script: name: Add git-tag code: | _tag=$(date -u -d '9 hours' +%Y-%m-%d-%H-%M-%S) git remote add origin git@github.com:nabinno/utagaki.git git config --global user.email 'wercker@blahfe.com' git config --global user.name 'Wercker Bot' git tag -a $_tag master -m 'wercker deploy' git push origin $_tag after-steps: - wantedly/pretty-slack-notify: webhook_url: ${SLACK_WEBHOOK_URL} channel: general     > WRAPUPWRAPUP \n\nこうしてWerckerの設定ファイルを書いてみるに、どのCI、どの仮想環境も同じ書き味ということが分かります。当処懸念していたDocker化することによる嵌まり事はなく、すんなり移行することができました。 \n\n手軽さ、管理のしやすさから、今後はすべてのCIがDockerに移行するでしょう。"},"name":"[2017-02-07]HerokuとGAEのCIをDockerとパイプラインから構成されたWerckerで管理する","tags":["wercker","docker","heroku","google-app-engine"],"childPublishedDate":{"published_on":"2017-02-07T00:00:00.000Z","published_on_unix":1486425600}}},{"node":{"number":61,"relative_category":"blog/health","fields":{"title":"ElixirとRaspberry PiでPM2.5などの環境データを定点観察し、目・喉の痛みに備える","excerpt":"皆さんは体調管理どうされていますか。一度痛い目に遭うと日常の細かい差異が気になってきて、そこをどうにか解決したいというのが人情です。今回は自分の咽頭痛の解消のため一つ実験をしてみました。   > PROBLEMPROBLEM \n\n- 以前からオフィスに行くと目や喉が痛くなることがあったので、自分の体調なのか環境なのか原因を切り分けるために汚染計測器「Dienmern DM106A」を購入 ただ、DM106Aの計測はその時その時のスナップショットなので傾向を読み解きづらい、また、都度実施する手間がかかる \n- ただ、DM106Aの計測はその時その時のスナップショットなので傾向を読み解きづらい、また、都度実施する手間がかかる   > SOLUTIONSOLUTION \n\nというわけで、DM106AのセンサーデータをRaspberry Piで定期取得することにしました。設置方法の詳細はGitHubレポジトリを参照ください。下記、実装概要になります。   > 電子部品の構成電子部品の構成    item description     Raspberry Pi 3 Model B+    Aosong DHT11 気温・湿度センサー、GPIO   Nova SDS021 PM2.5・PM10センサー、UART   ams CCS811 TVOC・CO2eセンサー、I2C    \n\nまず、電子工作は素人ゆえどのセンサーを買えばいいか分からなかったのでDM106Aを分解して各センサーの型番を調べました。DHT011、SDS021はDM106Aとおなじセンサー、HCHOセンサーは信頼性があり手ごろなのがうまく見つけられませんでした。TVOCセンサーはAdafruitが推しているCCS811を採用しました。   > コードの構成コードの構成    item description     AirElixir.Application アプリケーション管理   AirElixir.GoogleSpreadsheets センサーデータ記録   AirElixirSensor.Publisher センサーデータ発行・送信   AirElixirSensor.Subscriber センサーデータ購読・受信    \n\n次に、基本構成はGrovePiを参考にしました。発行処理はElixirでうまくいかないケースがあったのでまずはPython/ErlPortで行いました。後々Elixirに移行できるようにマクロにしました。   > 5日ほど稼働してわかったこと・見立て、今後の課題5日ほど稼働してわかったこと・見立て、今後の課題  \n\n最後に、分かったこと、見立てですが、3点あります。2番目に関しては予想通りだったのですが、1番目、3番目に関しては意外であり、疑り深い私としては特に空気清浄機がきちんと機能していたことに驚きました。 \n\n1. オフィスの空気清浄機「Hitachi EP-LVG110」はPMをきちんとフィルターしていた ただし、空気清浄機はTVOCには効果がなく、これはTroia氏や加藤氏・苅部氏の考察でも言及されている \n2. ただし、空気清浄機はTVOCには効果がなく、これはTroia氏や加藤氏・苅部氏の考察でも言及されている\n3. 人の入りが多い時間帯に空気（TVOCやCO2e）が汚れる 人が「出る」時よりも「入る」際に濃度があがるのは、外のVOCが服などに付着しているためと推察 \n4. 人が「出る」時よりも「入る」際に濃度があがるのは、外のVOCが服などに付着しているためと推察\n5. TVOCやCO2eはPMのうごきに連動している（かも） チャート上はEP-LVG110がPM除去しているためわからないが、日本気象協会のPM2.5分布予測に照らしてみるとPM濃度が高い日にTVOC濃度があがっていた TODO: PMがVOCを運んでいる可能性があるので、IQAirなどのAPIから周辺環境のPMデータも取得したいところ \n6. チャート上はEP-LVG110がPM除去しているためわからないが、日本気象協会のPM2.5分布予測に照らしてみるとPM濃度が高い日にTVOC濃度があがっていた TODO: PMがVOCを運んでいる可能性があるので、IQAirなどのAPIから周辺環境のPMデータも取得したいところ \n7. TODO: PMがVOCを運んでいる可能性があるので、IQAirなどのAPIから周辺環境のPMデータも取得したいところ \n\n課題としてはその性質からして仕方ないのですがTVOCの変動が大きすぎて解読を難しかったです。計測方法等を再度見直す必要がありそうです。 \n\n- TVOCの変動が大きすぎる ポーリング・出力を20分ごとからポーリング3秒ごと・出力20分ごとに変更した、出力データは20分の平均 \n- ポーリング・出力を20分ごとからポーリング3秒ごと・出力20分ごとに変更した、出力データは20分の平均\n- TVOCのスパイクを抑えたい TODO: ファイトレメディエーションによる効果を見ていきたいところ \n- TODO: ファイトレメディエーションによる効果を見ていきたいところ   > WRAPUPWRAPUP \n\n今回の実験はこれが言いたかっただけという指摘をされるとぐうの音も出ませんが、はっきり言わせてください。そう、Elixirは健康管理に向いています。   txt \n\n「なんか体調がすぐれないなあ...」 「Elixirちょうだい!」   \n\nという感じです、はい。"},"name":"[2018-12-22]ElixirとRaspberry PiでPM2.5などの環境データを定点観察し、目・喉の痛みに備える","tags":["elixir","raspberry-pi","particulates","physiology"],"childPublishedDate":{"published_on":"2018-12-22T00:00:00.000Z","published_on_unix":1545436800}}}]}},"pageContext":{"number":56}},"staticQueryHashes":[]}