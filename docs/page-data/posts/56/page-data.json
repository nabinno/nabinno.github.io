{"componentChunkName":"component---src-templates-post-tsx","path":"/posts/56","result":{"data":{"esaPost":{"number":56,"relative_category":"blog/backend","fields":{"title":"RubyのCSVパースをPyCallで実行する（ベンチマーク）","excerpt":"先日RubyからPythonにアクセスできるPyCallというライブラリの存在を知り、ぜひともベンチマークを取りたいと思った次第です。現状RubyのCSVの読み込みに不満を持っており、そこをどうにか解消したいと考えています。   > PROBLEMPROBLEM \n\n- 大量のCSVを読み込む際、毎回時間がかかる   > SOLUTIONSOLUTION \n\nというわけで、「Dalibor Nasevicのベンチマーク記事」にPyCallのベンチマークをくわえて比較してみることにしました。記事では下記の通り CSV.foreach が速いとの結論でした。    kind_of_parse time (real) memory (MB)     1. CSV.read  39.13 866.6   2. CSV.parse  36.16 936.87   3. line by line from String Object 23.39 73.42   4. line by line from IO Object 24.55 0.0   5. CSV.foreach  24.04 0.0      > PyCallのベンチマークPyCallのベンチマーク \n\nそれでは、PyCallのベンチマークを計りましょう。コードは下記のようになります。   ruby \n\nrequire_relative './helpers' require 'pycall/import' include PyCall::Import pyimport :pandas, as: :pd print_memory_usage do print_time_spent do csv = pd.read_csv.('data.csv') sum = csv['id'].sum.() puts \"Sum: #{sum}\" end end   \n\nPyCallは pyenv との相性が悪いのでSystemインストールしたPythonでたたきます。   sh \n\n$ PYTHON=/usr/bin/python3.4 ruby parse_6_pycall.rb Sum: 499999500000 Time: 1.49 Memory: 54.99 MB   \n\n結果    kind_of_parse time (real) memory (MB)     1. CSV.read  39.13 866.6   2. CSV.parse  36.16 936.87   3. line by line from String Object 23.39 73.42   4. line by line from IO Object 24.55 0.0   5. CSV.foreach  24.04 0.0   6. PyCall 1.49 54.99    \n\nはい、結果が出ました。Daliborのベンチマーク記事で一番速かった CSV.foreach より16倍の実行速度となりました。   > WRAPUPWRAPUP \n\nPyCallのオブジェクトが PyObjectとActiveRecordと相性が悪そうなのと、PythonとRuby双方のメモリー管理が運用を難しくすることから、安易に本番環境のRailsに導入するのは厳しいと思います。 \n\nただし、実行回数が限定されたスクリプトなら積極的に使って良いでしょう。","thumbnail":"https://img.esa.io/uploads/production/attachments/16651/2021/01/11/97367/180665c6-7370-4579-8340-7be6254834e8.png"},"wip":false,"body_md":"<img width=\"1920\" alt=\"thumbnail\" src=\"https://img.esa.io/uploads/production/attachments/16651/2021/01/11/97367/180665c6-7370-4579-8340-7be6254834e8.png\">\r\n\r\n先日RubyからPythonにアクセスできるPyCallというライブラリの存在を知り、ぜひともベンチマークを取りたいと思った次第です。現状RubyのCSVの読み込みに不満を持っており、そこをどうにか解消したいと考えています。\r\n\r\n# PROBLEM\r\n- 大量のCSVを読み込む際、毎回時間がかかる\r\n\r\n# SOLUTION\r\nというわけで、「[Dalibor Nasevicのベンチマーク記事](https://dalibornasevic.com/posts/68-processing-large-csv-files-with-ruby)」にPyCallのベンチマークをくわえて比較してみることにしました。記事では下記の通り `CSV.foreach` が速いとの結論でした。\r\n\r\n| kind_of_parse                      | time (real) | memory (MB) |\r\n|------------------------------------|-------------|-------------|\r\n| 1. `CSV.read`                      |       39.13 |       866.6 |\r\n| 2. `CSV.parse`                     |       36.16 |      936.87 |\r\n| 3. line by line from String Object |       23.39 |       73.42 |\r\n| 4. line by line from IO Object     |       24.55 |         0.0 |\r\n| 5. `CSV.foreach`                   |       24.04 |         0.0 |\r\n\r\n## PyCallのベンチマーク\r\nそれでは、PyCallのベンチマークを計りましょう。コードは下記のようになります。\r\n\r\n```ruby\r\nrequire_relative './helpers'\r\nrequire 'pycall/import'\r\ninclude PyCall::Import\r\npyimport :pandas, as: :pd\r\n\r\nprint_memory_usage do\r\n  print_time_spent do\r\n    csv = pd.read_csv.('data.csv')\r\n    sum = csv['id'].sum.()\r\n    puts \"Sum: #{sum}\"\r\n  end\r\nend\r\n```\r\n\r\nPyCallは `pyenv` との相性が悪いのでSystemインストールしたPythonでたたきます。\r\n\r\n```sh\r\n$ PYTHON=/usr/bin/python3.4 ruby parse_6_pycall.rb\r\nSum: 499999500000\r\nTime: 1.49\r\nMemory: 54.99 MB\r\n```\r\n\r\n**結果**\r\n\r\n| kind_of_parse                      | time (real) | memory (MB) |\r\n|------------------------------------|-------------|-------------|\r\n| 1. `CSV.read`                      |       39.13 |       866.6 |\r\n| 2. `CSV.parse`                     |       36.16 |      936.87 |\r\n| 3. line by line from String Object |       23.39 |       73.42 |\r\n| 4. line by line from IO Object     |       24.55 |         0.0 |\r\n| 5. `CSV.foreach`                   |       24.04 |         0.0 |\r\n| 6. PyCall                          |        1.49 |       54.99 |\r\n\r\nはい、結果が出ました。Daliborのベンチマーク記事で一番速かった `CSV.foreach` より16倍の実行速度となりました。\r\n\r\n# WRAPUP\r\nPyCallのオブジェクトが `PyObject`とActiveRecordと相性が悪そうなのと、PythonとRuby双方のメモリー管理が運用を難しくすることから、安易に本番環境のRailsに導入するのは厳しいと思います。\r\n\r\nただし、実行回数が限定されたスクリプトなら積極的に使って良いでしょう。\r\n","body_html":"<a href=\"https://img.esa.io/uploads/production/attachments/16651/2021/01/11/97367/180665c6-7370-4579-8340-7be6254834e8.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img width=\"1920\" alt=\"thumbnail\" src=\"https://img.esa.io/uploads/production/attachments/16651/2021/01/11/97367/180665c6-7370-4579-8340-7be6254834e8.png\"></a>\n<p data-sourcepos=\"3:1-3:290\">先日RubyからPythonにアクセスできるPyCallというライブラリの存在を知り、ぜひともベンチマークを取りたいと思った次第です。現状RubyのCSVの読み込みに不満を持っており、そこをどうにか解消したいと考えています。</p>\n<h1 data-sourcepos=\"5:1-5:9\" id=\"1-0-0\" name=\"1-0-0\">\n<a class=\"anchor\" id=\"PROBLEM\" name=\"PROBLEM\" href=\"#PROBLEM\" data-position=\"1-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"PROBLEM\"> &gt; PROBLEM</span></a>PROBLEM</h1>\n<ul data-sourcepos=\"6:1-7:0\">\n<li data-sourcepos=\"6:1-7:0\">大量のCSVを読み込む際、毎回時間がかかる</li>\n</ul>\n<h1 data-sourcepos=\"8:1-8:10\" id=\"2-0-0\" name=\"2-0-0\">\n<a class=\"anchor\" id=\"SOLUTION\" name=\"SOLUTION\" href=\"#SOLUTION\" data-position=\"2-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"SOLUTION\"> &gt; SOLUTION</span></a>SOLUTION</h1>\n<p data-sourcepos=\"9:1-9:307\">というわけで、「<a href=\"https://dalibornasevic.com/posts/68-processing-large-csv-files-with-ruby\" target=\"_blank\" rel=\"noopener noreferrer\">Dalibor Nasevicのベンチマーク記事</a>」にPyCallのベンチマークをくわえて比較してみることにしました。記事では下記の通り <code>CSV.foreach</code> が速いとの結論でした。</p>\n<table data-sourcepos=\"11:1-17:66\">\n<thead>\n<tr data-sourcepos=\"11:1-11:66\">\n<th data-sourcepos=\"11:2-11:37\">kind_of_parse</th>\n<th data-sourcepos=\"11:39-11:51\">time (real)</th>\n<th data-sourcepos=\"11:53-11:65\">memory (MB)</th>\n</tr>\n</thead>\n<tbody>\n<tr data-sourcepos=\"13:1-13:66\">\n<td data-sourcepos=\"13:2-13:37\">1. <code>CSV.read</code>\n</td>\n<td data-sourcepos=\"13:39-13:51\">39.13</td>\n<td data-sourcepos=\"13:53-13:65\">866.6</td>\n</tr>\n<tr data-sourcepos=\"14:1-14:66\">\n<td data-sourcepos=\"14:2-14:37\">2. <code>CSV.parse</code>\n</td>\n<td data-sourcepos=\"14:39-14:51\">36.16</td>\n<td data-sourcepos=\"14:53-14:65\">936.87</td>\n</tr>\n<tr data-sourcepos=\"15:1-15:66\">\n<td data-sourcepos=\"15:2-15:37\">3. line by line from String Object</td>\n<td data-sourcepos=\"15:39-15:51\">23.39</td>\n<td data-sourcepos=\"15:53-15:65\">73.42</td>\n</tr>\n<tr data-sourcepos=\"16:1-16:66\">\n<td data-sourcepos=\"16:2-16:37\">4. line by line from IO Object</td>\n<td data-sourcepos=\"16:39-16:51\">24.55</td>\n<td data-sourcepos=\"16:53-16:65\">0.0</td>\n</tr>\n<tr data-sourcepos=\"17:1-17:66\">\n<td data-sourcepos=\"17:2-17:37\">5. <code>CSV.foreach</code>\n</td>\n<td data-sourcepos=\"17:39-17:51\">24.04</td>\n<td data-sourcepos=\"17:53-17:65\">0.0</td>\n</tr>\n</tbody>\n</table>\n<h2 data-sourcepos=\"19:1-19:30\" id=\"2-1-0\" name=\"2-1-0\">\n<a class=\"anchor\" id=\"PyCallのベンチマーク\" name=\"PyCall%E3%81%AE%E3%83%99%E3%83%B3%E3%83%81%E3%83%9E%E3%83%BC%E3%82%AF\" href=\"#PyCall%E3%81%AE%E3%83%99%E3%83%B3%E3%83%81%E3%83%9E%E3%83%BC%E3%82%AF\" data-position=\"2-1-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"PyCallのベンチマーク\"> &gt; PyCallのベンチマーク</span></a>PyCallのベンチマーク</h2>\n<p data-sourcepos=\"20:1-20:111\">それでは、PyCallのベンチマークを計りましょう。コードは下記のようになります。</p>\n<div class=\"code-block\" data-sourcepos=\"22:1-35:3\">\n<div class=\"code-filename\">\n<i class=\"fa fa-file-code-o\"></i>ruby</div>\n<div class=\"highlight\"><pre class=\"highlight ruby\"><code><span class=\"nb\">require_relative</span> <span class=\"s1\">'./helpers'</span>\n<span class=\"nb\">require</span> <span class=\"s1\">'pycall/import'</span>\n<span class=\"kp\">include</span> <span class=\"no\">PyCall</span><span class=\"o\">::</span><span class=\"no\">Import</span>\n<span class=\"n\">pyimport</span> <span class=\"ss\">:pandas</span><span class=\"p\">,</span> <span class=\"ss\">as: :pd</span>\n\n<span class=\"n\">print_memory_usage</span> <span class=\"k\">do</span>\n  <span class=\"n\">print_time_spent</span> <span class=\"k\">do</span>\n    <span class=\"n\">csv</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"nf\">read_csv</span><span class=\"o\">.</span><span class=\"p\">(</span><span class=\"s1\">'data.csv'</span><span class=\"p\">)</span>\n    <span class=\"n\">sum</span> <span class=\"o\">=</span> <span class=\"n\">csv</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">].</span><span class=\"nf\">sum</span><span class=\"o\">.</span><span class=\"p\">()</span>\n    <span class=\"nb\">puts</span> <span class=\"s2\">\"Sum: </span><span class=\"si\">#{</span><span class=\"n\">sum</span><span class=\"si\">}</span><span class=\"s2\">\"</span>\n  <span class=\"k\">end</span>\n<span class=\"k\">end</span>\n</code></pre></div>\n</div>\n<p data-sourcepos=\"37:1-37:102\">PyCallは <code>pyenv</code> との相性が悪いのでSystemインストールしたPythonでたたきます。</p>\n<div class=\"code-block\" data-sourcepos=\"39:1-44:3\">\n<div class=\"code-filename\">\n<i class=\"fa fa-file-code-o\"></i>sh</div>\n<div class=\"highlight\"><pre class=\"highlight shell\"><code><span class=\"nv\">$ PYTHON</span><span class=\"o\">=</span>/usr/bin/python3.4 ruby parse_6_pycall.rb\nSum: 499999500000\nTime: 1.49\nMemory: 54.99 MB\n</code></pre></div>\n</div>\n<p data-sourcepos=\"46:1-46:10\"><strong>結果</strong></p>\n<table data-sourcepos=\"48:1-55:66\">\n<thead>\n<tr data-sourcepos=\"48:1-48:66\">\n<th data-sourcepos=\"48:2-48:37\">kind_of_parse</th>\n<th data-sourcepos=\"48:39-48:51\">time (real)</th>\n<th data-sourcepos=\"48:53-48:65\">memory (MB)</th>\n</tr>\n</thead>\n<tbody>\n<tr data-sourcepos=\"50:1-50:66\">\n<td data-sourcepos=\"50:2-50:37\">1. <code>CSV.read</code>\n</td>\n<td data-sourcepos=\"50:39-50:51\">39.13</td>\n<td data-sourcepos=\"50:53-50:65\">866.6</td>\n</tr>\n<tr data-sourcepos=\"51:1-51:66\">\n<td data-sourcepos=\"51:2-51:37\">2. <code>CSV.parse</code>\n</td>\n<td data-sourcepos=\"51:39-51:51\">36.16</td>\n<td data-sourcepos=\"51:53-51:65\">936.87</td>\n</tr>\n<tr data-sourcepos=\"52:1-52:66\">\n<td data-sourcepos=\"52:2-52:37\">3. line by line from String Object</td>\n<td data-sourcepos=\"52:39-52:51\">23.39</td>\n<td data-sourcepos=\"52:53-52:65\">73.42</td>\n</tr>\n<tr data-sourcepos=\"53:1-53:66\">\n<td data-sourcepos=\"53:2-53:37\">4. line by line from IO Object</td>\n<td data-sourcepos=\"53:39-53:51\">24.55</td>\n<td data-sourcepos=\"53:53-53:65\">0.0</td>\n</tr>\n<tr data-sourcepos=\"54:1-54:66\">\n<td data-sourcepos=\"54:2-54:37\">5. <code>CSV.foreach</code>\n</td>\n<td data-sourcepos=\"54:39-54:51\">24.04</td>\n<td data-sourcepos=\"54:53-54:65\">0.0</td>\n</tr>\n<tr data-sourcepos=\"55:1-55:66\">\n<td data-sourcepos=\"55:2-55:37\">6. PyCall</td>\n<td data-sourcepos=\"55:39-55:51\">1.49</td>\n<td data-sourcepos=\"55:53-55:65\">54.99</td>\n</tr>\n</tbody>\n</table>\n<p data-sourcepos=\"57:1-57:150\">はい、結果が出ました。Daliborのベンチマーク記事で一番速かった <code>CSV.foreach</code> より16倍の実行速度となりました。</p>\n<h1 data-sourcepos=\"59:1-59:8\" id=\"3-0-0\" name=\"3-0-0\">\n<a class=\"anchor\" id=\"WRAPUP\" name=\"WRAPUP\" href=\"#WRAPUP\" data-position=\"3-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"WRAPUP\"> &gt; WRAPUP</span></a>WRAPUP</h1>\n<p data-sourcepos=\"60:1-60:248\">PyCallのオブジェクトが <code>PyObject</code>とActiveRecordと相性が悪そうなのと、PythonとRuby双方のメモリー管理が運用を難しくすることから、安易に本番環境のRailsに導入するのは厳しいと思います。</p>\n<p data-sourcepos=\"62:1-62:105\">ただし、実行回数が限定されたスクリプトなら積極的に使って良いでしょう。</p>\n","tags":["ruby","benchmark","pycall"],"updated_at":"2021-01-16T10:27:34+09:00","childPublishedDate":{"published_on":"2017-06-05T00:00:00.000Z"},"updated_by":{"name":"なびの👷","screen_name":"nabinno","icon":"https://img.esa.io/uploads/production/members/94286/icon/thumb_m_ef5f024307008aa399b91f87fa5f64e8.jpg"}},"relatedPosts":{"edges":[{"node":{"number":44,"relative_category":"blog/organization","fields":{"title":"整理したい私はITILをかぶる、PlantUMLへの愛","excerpt":"現在ネクイノでエンジニアリングマネージャー、バックエンドエンジニア、インフラエンジニアを担当しています。入社後8ヶ月、年の瀬ということで振り返り記事を書くことにしました。テーマを一つに絞らないと記事にならないので今回はPlantUMLに絞ります。断りとして、この記事で書いてあることはITILプラクティスを一部なぞっているに過ぎません。PlantUMLが全知全能のツールということを主張したいわけではないです、ただ愛しています。   > PROBLEMPROBLEM \n\n- 開発人数が増えるにあたり、チームとして機能していない 管理規程はあるものの 業務フローが明示化されておらず、誰が何を何の目的で業務を回しているか分からない 可視化されていないプロセスが問題になるケースが増えてきた \n- 管理規程はあるものの 業務フローが明示化されておらず、誰が何を何の目的で業務を回しているか分からない 可視化されていないプロセスが問題になるケースが増えてきた \n- 可視化されていないプロセスが問題になるケースが増えてきた  > SOLUTIONSOLUTION \n\nと言うわけで、入社早々PlantUMLで業務フローを可視化することを始めました。  > PlantUMLとはPlantUMLとは \n\nPlantUMLはオープンソースのUMLダイアグラム作成用のテキストベースの言語です。シークエンス図、ユースケース図、アクティビティ図、クラス図のようなダイアグラムをシンプルで直感的に書くことができます。 \n\n2009年リリースされており、私が使うようになったのは、Emacsのorg-babelで実装されてからなので2014年くらい1。2016-7年にesa.ioやVS Code等で実装されてから爆発的に普及したと記憶しています。「esa.ioはオンラインのorg-modeになるべくPlantUMLを実装すべき」と要望したのは良い思い出です。  > やったことやったこと \n\nさて、私はネクイノに入社早々既存システムの運用開発と情シス（業務運用）の部長職にアサインされました。既存システムの運用開発は新しく外部のパートナーが入ると言うことで、開発フローが大きく変わる節目にありました。  > 開発フローを整備する開発フローを整備する \n\n話を聞くに新しく入る外部パートナーはプロジェクトマネージャ、ブリッジエンジニア・コミュニケーター、モバイルエンジニア、バックエンドエンジニア、フロントエンジニア、品質チェック含め20名程の体制でした。また、既存システムの運用開発ではプロダクトマネジャー、プロダクトオーナーが各開発者とともに企画策定を行うことが慣習として存在していました。私はまず企画から実装、レビュー、リリースまでの流れを整理します。 Jira上の大まかな流れ \n\n 開発の流れ \n\n  > 要望フローを整備する要望フローを整備する \n\n次に、機能要望、バグ報告、改善要望がSlackチャンネルの至る所に散在している上、チケット化されないケースがありました。突貫ではありますが、GoogleフォームとJira連携を行いました2。 \n\nプロダクトマネジャーの体制が整備されてからは、機能要望のフォームは使われることはなくなりましたが、バグ報告、改善要望は要所要所で使われ、トリアージという形で定期的に活用されています。 \n\n  > デプロイフローを整備するデプロイフローを整備する \n\n開発が進んでいくと、今度は開発環境が足りなくなりました。当時はステージング環境と本番環境しかなく、かつ、ステージング環境がテスト環境兼デモ環境の役割を呈しており、ステージング環境おテストで不具合を起こすとデモに影響が出るという状態が続いておりました。また、外部パートナーが開発するに当たり繊細なステージング環境を使うのが難しいため進捗に影響が出始めておりました。 \n\n急を要する事態のためAWS CDKでステージング環境とは別に結合環境を用意し3、デプロイフローを整備しました。 \n\n  > 障害対応フローを整備する障害対応フローを整備する \n\nさて、運用開発が順調に進んでいくと、今度は障害が頻繁に起きていることに気づきました。いいえ、薄々気づいていたのですが多忙にかまけて蓋をしておりました。ここに関しては本腰を入れてAWSサポートプランをビジネスに変更し原因を突き止めました。協力いただいた各位には感謝です。 \n\nまた、今まで見過ごされていたGoogle Workspace等の業務運用のシステムも含め障害報告の体制を敷くとともに、監視体制も強化しました。 \n\n  > 業務フローを整理する業務フローを整理する \n\nまだまだあります。業務内容に関しては詳細は書けませんが、部内の業務から他部署の業務まで安全に生産性を高めるため整理を行いました。まだまだ行います。  > リモート飲みのフローを整備するリモート飲みのフローを整備する \n\nいよいよ疲れてきたのでお酒が飲みたくなりました。飲み会フローを作ってみましたが思いの外手間がかかることが分かりあまり活用できておりません。その代わり社内でオンラインシャッフルランチという制度ができました。 \n\n  > 分かったこと分かったこと \n\nはい、こうして振り返ると入社時に感じていた雑然さは業務フローが明確でない状態のことでした。開発者なら分かると思いますが、企画段階で思い描く構成図は実装する段になるとあまり意味をなさず、結局は頭の中はシークエンス図でいっぱいになります。それと同じで、登場人物、登場人物間のメッセージ、メッセージの大枠が関係者に共有されていないと、いくらリソースが投下されても不安定で生産性に伸び悩むのです。つまり、雑然とした環境を整理すると言うことはシークエンス図を書くことに他なりません。 \n\nしかしながら、当該環境一つ一つを俯瞰的に見るとITILプラクティスそのものであることにも気づきます。 \n\nITILとはITサービスマネジメントのベストプラクティスフレームワークのこと。何らかの高い技術を持っていても、投資対効果を考えていなければ赤字になりビジネスと成り立ちませんし、顧客のことを考えずに作ったものに価値はありませんし、サービスの評価を落とすことになります。このようなことを防ぐには顧客目線やビジネス的な観点が必要で、そのノウハウがまとまったものがITILです。  > 今回対応したプラクティス今回対応したプラクティス \n\n今回の振り返りでは具体的に次のプラクティスをなぞっておりました。    振り返り ITILプラクティス     開発フローを整備する 継続的サービス改善   要望フローを整備する 要求管理、問題管理   デプロイフローを整備する リリース管理及び展開管理   障害対応フローを整備する インシデント管理   業務フローを整理する CMMI   リモート飲みのフローを整備する 組織変更管理    \n\nCMMIと組織変更管理が分かりづらいの少し補足します。 \n\n- CMMIとは能力成熟度モデル統合のことで、業務フローを評価し5段階で成熟度レベルを出す手法です。現状はレベル1-2（初期段階）のものがほとんどなのでまずはPlantUMLを使い共通認識を作るところから始めました。\n- 組織変更管理とは経営学で言うところのチェンジマネジメントに当たります。ここでは各種フローを整備しメンバー全員に落とし込むことを目指します。『Fearless Change』では今回のリモート飲み以外にも多くのパターンランゲージが紹介されています。  > WRAPUPWRAPUP  > 次にすること次にすること \n\nネクストアクションですが、採用フローを考えています。 \n\n（読者の皆様はどんなシークエンス図を思い浮かべましたか?） \n\nというわけで、ネクイノはPlantUMLを愛している開発者を募集中です。  > PR__colon__ ネクイノとはPR: ネクイノとは \n\n「世界中の医療空間と体験を再定義する」をミッションに、人々と医療の間にICTのチカラで橋をかける遠隔医療ソリューションを手掛けている会社です。医療というと高齢の患者さんをイメージされるかもしれませんが、我らがターゲットとしているのは現役世代の方。病気を治療するというより、現役世代がQOLを高めるためのサポートを目的としています。 \n\nメインサービスは、女性に特化したピルのオンライン診療アプリ「スマルナ」。ピルを飲まれている人だけでなく、受診や服用に抵抗がある方にも気軽に利用していただけたらと思いサービス提供しています。診察室の手前に助産師と薬剤師を配置した相談室を設ける等、受診のハードルを下げる工夫をそこかしこに施しているのが特徴です。 \n\n様々なメディカルコミュニケーションを行っています - 専門家相談 - カスタマーサポート - ユーザーコミュニティ  \n\n妻からは「10年前にサービスがあったら良かったのに」とお墨付きをいただいており、興味をもった方は詳しくはこちらをご覧下さい。 https://smaluna.com/  \n\n1. [B! plantuml] nabinnoのブックマーク ↩ \n2. https://github.com/nabinno/google-forms-to-jira-slack ↩ \n3. CDKはaws-rails-provisionerを参考に ecs_patterns.ApplicationLoadBalancedFargateService を実装しました ↩"},"name":"[2020-12-30]整理したい私はITILをかぶる、PlantUMLへの愛","tags":["team-building"],"childPublishedDate":{"published_on":"2020-12-30T00:00:00.000Z","published_on_unix":1609286400}}},{"node":{"number":124,"relative_category":"blog/backend","fields":{"title":"Increment Pは住所のバリデーションチェックでどの程度使えるか","excerpt":"7月に調査した「imi-enrichment-addressは住所のバリデーションチェックでどの程度使えるか」の続きになります。コロナ禍であらゆる流通がオンラインに移行する中、正しい住所を使うことはいっそう求められています。ユーザーが配送用に住所を入力する時そのデータが正しいとどうやって判定するのでしょうか。今回は商用サービスIncrement Pが住所のバリデーションチェックでどの程度使えるか検証してみました。   > PROBLEMPROBLEM \n\n- 住所の不備が至るところで起きている 特に町名番地の抜けもれや不備が多くこの点をどうにか拾いたい 可能ならユーザーの入力時点でFEあるいはBE側でバリデーションチェックしたい imi-enrichment-addressで精度が思わしくなかったので今回は商用サービスで検証したい \n- 特に町名番地の抜けもれや不備が多くこの点をどうにか拾いたい\n- 可能ならユーザーの入力時点でFEあるいはBE側でバリデーションチェックしたい imi-enrichment-addressで精度が思わしくなかったので今回は商用サービスで検証したい \n- imi-enrichment-addressで精度が思わしくなかったので今回は商用サービスで検証したい  > SOLUTIONSOLUTION \n\nというわけで、住所のバリデーションチェックで商用版「Increment P」がどの程度使えるか検証します。  > Increment PとはIncrement Pとは \n\n住所をAPIを介すことで正規化することができます。APIの返値に解析レベル・解析ログを加えることでより柔軟な検証をおこなうことができるようになっています。 \n\n解析レベルとは、対象住所のマッチ度合いを都道府県・市区町村・町域・丁目・番地・号というレベルで分けたものです。APIの結果が解析レベル5「番地・番」以上になっていれば配送が確実に為されると言うように、配送の確実性を前提にして住所の入力者とやりとりを実現します。また、解析ログメッセージとは、住所の正規化を試みた際のログであり、バリデーションを調整する際に頻繁に確認するものです。詳細は「ドキュメント」をご覧下さい。    解析レベル レベルの数字 説明     都道府県 1 県レベルでマッチしました   市区町村 2 市区町村レベルでマッチしました   町域 (大字) 3 町域レベルでマッチしました   丁目 / 小字 4 丁目または小字レベルでマッチしました   番地（番） 5 番地（番）レベルでマッチしました   号情報が存在しない番地 7 番地（番）レベルでマッチしました（号情報が存在しない地域）   号 8 号レベルでマッチしました   不明 -1 不明    \n\n試しにIncrement Pを実行してみましょう。正確な住所を渡したときと不正確な住所を渡したときで解析レベルが5と3と異なった結果を返すことが見て取れます。 sh\n\n$ curl \"https://api-anorm.mapfan.com/v1/$(echo -n 長野県長野市大字長野旭町1108 | jq -sRr @uri).json\" \\ -H 'x-api-key: <api-key>' \\ -H 'Content-Type: application/json' | jq -r { \"type\": \"FeatureCollection\", \"query\": [ \"長野県長野市大字長野旭町1108\" ], \"features\": [ { \"type\": \"Feature\", \"geometry\": null, \"properties\": { \"query\": \"長野県長野市大字長野旭町1108\", \"place_name\": \"長野県長野市長野旭町 1108\", \"pref\": \"長野県\", \"pref_kana\": \"ナガノケン\", \"city\": \"長野市\", \"city_kana\": \"ナガノシ\", \"area\": \"長野\", \"area_kana\": \"ナガノ\", \"koaza_chome\": \"旭町\", \"koaza_chome_kana\": \"アサヒマチ\", \"banchi_go\": \"1108\", \"building\": \"\", \"building_number\": \"\", \"zipcode\": \"3800846\", \"geocoding_level\": 5, \"geocoding_level_desc\": \"番地（番）レベルでマッチしました(5)\", \"log\": \"RM002:[大字(字)]の文字を除去しました\", \"not_normalized\": \"\" } } ], \"attribution\": \"(c) INCREMENT P CORPORATION\" } $ curl \"https://api-anorm.mapfan.com/v1/$(echo -n 長野県長野市旭町1108 | jq -sRr @uri).json\" \\ -H 'x-api-key: <api-key>' \\ -H 'Content-Type: application/json' | jq -r { \"type\": \"FeatureCollection\", \"query\": [ \"長野県長野市旭町1108\" ], \"features\": [ { \"type\": \"Feature\", \"geometry\": null, \"properties\": { \"query\": \"長野県長野市旭町1108\", \"place_name\": \"長野県長野市旭町\", \"pref\": \"長野県\", \"pref_kana\": \"ナガノケン\", \"city\": \"長野市\", \"city_kana\": \"ナガノシ\", \"area\": \"旭町\", \"area_kana\": \"アサヒマチ\", \"koaza_chome\": \"\", \"koaza_chome_kana\": \"\", \"banchi_go\": \"\", \"building\": \"\", \"building_number\": \"\", \"zipcode\": \"3800846\", \"geocoding_level\": 3, \"geocoding_level_desc\": \"町域レベルでマッチしました(3)\", \"log\": \"NT001:正規化処理状況が建物名正規化処理の必要条件を満たさないので建物名正規化は行われません\", \"not_normalized\": \"1108\" } } ], \"attribution\": \"(c) INCREMENT P CORPORATION\" }  \n\nなお、上記結果を見て分かるとおり、Increment Pは大字省略には強そうですが町域自体の省略は苦手なようです。imi-enrichment-addressより柔軟ですが、基本は街区レベル位置参照情報を利用しているように推察されます。  > 検証用データ検証用データ \n\nさて、検証用データですが、imi-enrichment-addressの検証データと合わせて住所.jpを使います。今回はトライアルが1000件と制限があるので、imi-enrichment-addressで無効割合が54.42%と一番多かった青森県と住所の登録数が多い東京・愛知・北海道・大阪・福岡・神奈川、さらに通りが独特な京都、町字の組み合わせで住所が2つ以上存在する長野に対象を絞ります。各々100件ずつの検証になります。 sh\n\n$ { curl -sSL http://jusyo.jp/downloads/new/csv/csv_zenkoku.zip -o csv_zenkoku.zip; unzip -p csv_zenkoku.zip | nkf -w; rm csv_zenkoku.zip } >zenkoku.csv $ brew install noborus/tap/trdsql $ trdsql \" SELECT COUNT(*) FROM zenkoku.csv WHERE c21 <> '' \" 22431 $ trdsql -otbln \" SELECT c8, count(*) cn FROM zenkoku.csv WHERE c21 != '' GROUP BY c8 ORDER BY cn DESC\" | 都道府県 | count(*) | | --- | --- | | 東京都 | 4734 | | 愛知県 | 1541 | | 北海道 | 1251 | | 大阪府 | 884 | | 福岡県 | 845 | | 神奈川県 | 820 | [..] | 長野県 | 594 | [..] | 京都府 | 255 | [..] | 青森県 | 216 |   > Increment Pで検証用データを確認するIncrement Pで検証用データを確認する sh\n\n$ for p in 東京都 愛知県 北海道 大阪府 福岡県 神奈川県 青森県 京都府 長野県; do for a in $(trdsql \" SELECT c8||c10||c21 FROM zenkoku.csv WHERE c21 != '' AND c8 = '$p' ORDER BY RANDOM() LIMIT 100 \"); do curl -w'\\n' \"https://api-anorm.mapfan.com/v1/$(echo -n $a | jq -sRr @uri).json\" \\ -H 'x-api-key: <api-key>' \\ -H 'Content-Type: application/json' >>output.jsonl; done & done &   > 解析結果を確認する解析結果を確認する \n\nIncrement Pの解析結果を確認したところ、imi-enrichment-addressと比べると大方改善しました。特に青森県、北海道の改善率は高く字・条・線に対して有効に機能していることが伺えます。一方、京都や長野のように特殊な住所がある府県については改善が思うように行かないケースもあるようです。 sh\n\n$ cat output.jsonl \\ | jq -r '[ .features[].properties.pref, .features[].properties.query, .features[].properties.geocoding_level, .features[].properties.log ] | @csv' \\ | trdsql -otbln \" SELECT c1, COUNT(*) cn FROM - WHERE c3 >= 5 GROUP BY c1 ORDER BY cn DESC \"  \n\n解析レベル5「番地・番」以上の場合（※ 参考値はimi-enrichment-addressの有効割合）    都道府県 有効割合 参考値     東京都 100 99.11   大阪府 100 96.72   福岡県 95 91   神奈川県 95 98.28   愛知県 92 92.6   青森県 90 45.58   長野県 84 55.72   北海道 80 86.24   京都府 79 63.14    \n\n解析レベル4「丁目/小字」以上の場合（※ 参考値はimi-enrichment-addressの有効割合）    都道府県 有効割合 参考値     東京都 100 99.11   大阪府 100 96.72   北海道 98 86.24   愛知県 97 92.6   福岡県 96 91   神奈川県 95 98.28   青森県 93 45.58   長野県 84 55.72   京都府 79 63.14     > WRAPUPWRAPUP \n\n青森県の有効率が45.58%だったimi-enrichment-addressと比べると、Increment Pは調査した大凡の都道府県で改善し70%以上の有効割合を出していました。バリデーションチェックで使えるのかというと全ての都道府県で100%になっていないため心許ない状況ではあるものの、解析レベル4「丁目/小字」以下の住所については最終確認を促すフローを入れる等ひと手間加えれば実用に耐えうると考えます。"},"name":"[2021-11-23]Increment Pは住所のバリデーションチェックでどの程度使えるか","tags":["incrementp"],"childPublishedDate":{"published_on":"2021-11-23T00:00:00.000Z","published_on_unix":1637625600}}},{"node":{"number":119,"relative_category":"blog/backend","fields":{"title":"踏み台をSSM Session ManagerとAWS SSOで実現する","excerpt":"踏み台のユーザーが増えてきたため公開鍵管理や監視と運用負荷が上がってきました。オペミスが発生しやすい上 監査的な意味で無視できない状況になってきたので重い腰を上げることにしました。   > PROBLEMPROBLEM \n\n- EC2インスタンスの踏み台運用がつらい 公開鍵管理がつらい 提出・設定・確認ともに運用コストがかかる AWSアカウント数 x ユーザー数で指数関数的に運用コストが増していくことが想定される インフラ管理が分散していると、提出側・設定側ともに重複コストが発生する 監視運用がつらい 定期的に踏み台がブルートフォース攻撃を受けており、脅威が低いとは言えストレスがかかる 踏み台アクセスへの監査ログが不十分 \n- 公開鍵管理がつらい 提出・設定・確認ともに運用コストがかかる AWSアカウント数 x ユーザー数で指数関数的に運用コストが増していくことが想定される インフラ管理が分散していると、提出側・設定側ともに重複コストが発生する \n- 提出・設定・確認ともに運用コストがかかる\n- AWSアカウント数 x ユーザー数で指数関数的に運用コストが増していくことが想定される\n- インフラ管理が分散していると、提出側・設定側ともに重複コストが発生する\n- 監視運用がつらい 定期的に踏み台がブルートフォース攻撃を受けており、脅威が低いとは言えストレスがかかる 踏み台アクセスへの監査ログが不十分 \n- 定期的に踏み台がブルートフォース攻撃を受けており、脅威が低いとは言えストレスがかかる\n- 踏み台アクセスへの監査ログが不十分  > SOLUTIONSOLUTION \n\nというわけで、Session ManagerとSSOでアクセス管理の効率化を狙います。  > 踏み台サーバーの設定踏み台サーバーの設定 \n\nまず、データフローとしては下記の図の通りで、今回はプライベートサブネット上にEC2を置いて素のSession ManagerでDBへの接続することにします。当該インスタンスは AmazonSSMManagedInstanceCore ポリシー1を含んだロールを適用。なお、ECS ExecではSession Managerでポートフォワーディングを実現でき無かったことに加え、既存の踏み台資産を流用するため今回の実装対象から外しました。 \n\n  > SSOの設定SSOの設定 \n\n踏み台サーバーの設定が終わったら、次に当該インスタンスへ接続するためにSSOで渡すロールをアクセス権限セットに設定します。下記カスタムポリシーはEC2インスタンスにアクセスするための必要最低限のものになります。 カスタムポリシー json\n\n{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"cloudwatch:PutMetricData\", \"ds:CreateComputer\", \"ds:DescribeDirectories\", \"ec2:DescribeInstanceStatus\", \"logs:*\", \"ssm:*\", \"ec2messages:*\" ], \"Resource\": \"*\" }, { \"Effect\": \"Allow\", \"Action\": [ \"ssm:StartSession\" ], \"Resource\": [ \"arn:aws:ssm:*:*:session/<EC2インスタンスID>\", \"arn:aws:ec2:*:*:instance/<EC2インスタンスID>\" ] }, { \"Effect\": \"Deny\", \"Action\": [ \"ssm:Describe*\", \"ssm:Get*\", \"ssm:List*\", \"logs:Describe*\", \"logs:Get*\", \"logs:List*\" ], \"Resource\": \"*\" }, { \"Effect\": \"Allow\", \"Action\": \"iam:CreateServiceLinkedRole\", \"Resource\": \"arn:aws:iam::*:role/aws-service-role/ssm.amazonaws.com/AWSServiceRoleForAmazonSSM*\", \"Condition\": { \"StringLike\": { \"iam:AWSServiceName\": \"ssm.amazonaws.com\" } } }, { \"Effect\": \"Allow\", \"Action\": \"iam:CreateServiceLinkedRole\", \"Resource\": \"arn:aws:iam::*:role/aws-service-role/ssm.amazonaws.com/AWSServiceRoleForAmazonSSM*\", \"Condition\": { \"StringLike\": { \"iam:AWSServiceName\": \"ssm.amazonaws.com\" } } }, { \"Effect\": \"Allow\", \"Action\": [ \"iam:DeleteServiceLinkedRole\", \"iam:GetServiceLinkedRoleDeletionStatus\" ], \"Resource\": \"arn:aws:iam::*:role/aws-service-role/ssm.amazonaws.com/AWSServiceRoleForAmazonSSM*\" }, { \"Effect\": \"Allow\", \"Action\": [ \"ssmmessages:CreateControlChannel\", \"ssmmessages:CreateDataChannel\", \"ssmmessages:OpenControlChannel\", \"ssmmessages:OpenDataChannel\" ], \"Resource\": \"*\" } ] }    > セッションを張るための事前準備セッションを張るための事前準備 \n\nセッションを張るためには下記3つの手順が必要になります。SSO経由のセッション設定が2通りありますが、クレデンシャル方式はセッションが切れる毎に変更する手間があるため、CLI方式をお薦めします。 \n\n1. AWS CLI v2をインストール\n2. 下記いずれかの方式でSSO経由のセッション設定を行う クレデンシャル方式 CLI（ aws sso login ）方式 \n3. クレデンシャル方式\n4. CLI（ aws sso login ）方式\n5. Session Manager プラグインをインストール  > DBクライアントの設定DBクライアントの設定 \n\n最後に、DBクライアントについて3つの手順を踏んで接続を試みます2。なお、ローカル環境でポートフォワーディングを都度行うのを省略したい方は、DataGripを利用すると良いでしょう。 \n\n1. ローカル環境にて ~/.ssh/config ファイルを編集 Session Managerにproxyと対象RDSのエンドポイントを記載 configHost <任意のhost名> HostName <※ 指定しなければlocalhostになる> User ec2-user ProxyCommand sh -c \"aws ssm start-session --target <接続する踏み台のインスタンスID> --document-name AWS-StartSSHSession --parameters 'portNumber=%p' --region ap-northeast-1 --profile <プロフィール>\" LocalForward <任意のポート> <RDSエンドポイント>:<RDSポート> IdentityFile ~/.ssh/<EC2に接続する秘密鍵> 設定したhost名でセッションマネージャー越しにssh接続できるかを確認 sh$ ssh <設定したhost名> \n2. Session Managerにproxyと対象RDSのエンドポイントを記載 configHost <任意のhost名> HostName <※ 指定しなければlocalhostになる> User ec2-user ProxyCommand sh -c \"aws ssm start-session --target <接続する踏み台のインスタンスID> --document-name AWS-StartSSHSession --parameters 'portNumber=%p' --region ap-northeast-1 --profile <プロフィール>\" LocalForward <任意のポート> <RDSエンドポイント>:<RDSポート> IdentityFile ~/.ssh/<EC2に接続する秘密鍵> \n3. 設定したhost名でセッションマネージャー越しにssh接続できるかを確認 sh$ ssh <設定したhost名> \n4. 手順1で設定したsshで接続することでポートフォワーディング\n5. DBクライアントで下記のように接続情報を設定し接続する Host: <手順1のconfigファイルにて任意指定したホスト名> Port: <手順4のconfigファイルにて任意指定したポート> 他項目: DB接続情報 \n6. Host: <手順1のconfigファイルにて任意指定したホスト名>\n7. Port: <手順4のconfigファイルにて任意指定したポート>\n8. 他項目: DB接続情報  > WRAPUPWRAPUP \n\nパブリックサブネット上の踏み台に慣れている方は馴染みのない方法に戸惑うかも知れませんが、踏み台資産を流用できるという意味で導入のコストもそれほどかかりませんし、ユーザーとしても利用の敷居は高くありませんでした。後々の管理コストを心配している方は一度検討してみてはいかがでしょうか。  \n\n1. AmazonEC2RoleforSSM は非推奨のため適用しないように注意します。 ↩ \n2. 今回はメンテナンスコストを避けるためSSH over SSMの関連ツール ssh-ssm.sh ssm-tool は使わない方針でいます。 ↩"},"name":"[2021-11-21]踏み台をSSM Session ManagerとAWS SSOで実現する","tags":["SessionManager","AWSSSO"],"childPublishedDate":{"published_on":"2021-11-21T00:00:00.000Z","published_on_unix":1637452800}}}]}},"pageContext":{"number":56}},"staticQueryHashes":[]}