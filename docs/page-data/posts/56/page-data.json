{"componentChunkName":"component---src-templates-post-tsx","path":"/posts/56","result":{"data":{"esaPost":{"number":56,"relative_category":"blog/backend","fields":{"title":"RubyのCSVパースをPyCallで実行する（ベンチマーク）","excerpt":"先日RubyからPythonにアクセスできるPyCallというライブラリの存在を知り、ぜひともベンチマークを取りたいと思った次第です。現状RubyのCSVの読み込みに不満を持っており、そこをどうにか解消したいと考えています。   > PROBLEMPROBLEM \n\n- 大量のCSVを読み込む際、毎回時間がかかる   > SOLUTIONSOLUTION \n\nというわけで、「Dalibor Nasevicのベンチマーク記事」にPyCallのベンチマークをくわえて比較してみることにしました。記事では下記の通り CSV.foreach が速いとの結論でした。    kind_of_parse time (real) memory (MB)     1. CSV.read  39.13 866.6   2. CSV.parse  36.16 936.87   3. line by line from String Object 23.39 73.42   4. line by line from IO Object 24.55 0.0   5. CSV.foreach  24.04 0.0      > PyCallのベンチマークPyCallのベンチマーク \n\nそれでは、PyCallのベンチマークを計りましょう。コードは下記のようになります。   ruby \n\nrequire_relative './helpers' require 'pycall/import' include PyCall::Import pyimport :pandas, as: :pd print_memory_usage do print_time_spent do csv = pd.read_csv.('data.csv') sum = csv['id'].sum.() puts \"Sum: #{sum}\" end end   \n\nPyCallは pyenv との相性が悪いのでSystemインストールしたPythonでたたきます。   sh \n\n$ PYTHON=/usr/bin/python3.4 ruby parse_6_pycall.rb Sum: 499999500000 Time: 1.49 Memory: 54.99 MB   \n\n結果    kind_of_parse time (real) memory (MB)     1. CSV.read  39.13 866.6   2. CSV.parse  36.16 936.87   3. line by line from String Object 23.39 73.42   4. line by line from IO Object 24.55 0.0   5. CSV.foreach  24.04 0.0   6. PyCall 1.49 54.99    \n\nはい、結果が出ました。Daliborのベンチマーク記事で一番速かった CSV.foreach より16倍の実行速度となりました。   > WRAPUPWRAPUP \n\nPyCallのオブジェクトが PyObjectとActiveRecordと相性が悪そうなのと、PythonとRuby双方のメモリー管理が運用を難しくすることから、安易に本番環境のRailsに導入するのは厳しいと思います。 \n\nただし、実行回数が限定されたスクリプトなら積極的に使って良いでしょう。","thumbnail":"https://img.esa.io/uploads/production/attachments/16651/2021/01/11/97367/180665c6-7370-4579-8340-7be6254834e8.png"},"wip":false,"body_md":"<img width=\"1920\" alt=\"thumbnail\" src=\"https://img.esa.io/uploads/production/attachments/16651/2021/01/11/97367/180665c6-7370-4579-8340-7be6254834e8.png\">\r\n\r\n先日RubyからPythonにアクセスできるPyCallというライブラリの存在を知り、ぜひともベンチマークを取りたいと思った次第です。現状RubyのCSVの読み込みに不満を持っており、そこをどうにか解消したいと考えています。\r\n\r\n# PROBLEM\r\n- 大量のCSVを読み込む際、毎回時間がかかる\r\n\r\n# SOLUTION\r\nというわけで、「[Dalibor Nasevicのベンチマーク記事](https://dalibornasevic.com/posts/68-processing-large-csv-files-with-ruby)」にPyCallのベンチマークをくわえて比較してみることにしました。記事では下記の通り `CSV.foreach` が速いとの結論でした。\r\n\r\n| kind_of_parse                      | time (real) | memory (MB) |\r\n|------------------------------------|-------------|-------------|\r\n| 1. `CSV.read`                      |       39.13 |       866.6 |\r\n| 2. `CSV.parse`                     |       36.16 |      936.87 |\r\n| 3. line by line from String Object |       23.39 |       73.42 |\r\n| 4. line by line from IO Object     |       24.55 |         0.0 |\r\n| 5. `CSV.foreach`                   |       24.04 |         0.0 |\r\n\r\n## PyCallのベンチマーク\r\nそれでは、PyCallのベンチマークを計りましょう。コードは下記のようになります。\r\n\r\n```ruby\r\nrequire_relative './helpers'\r\nrequire 'pycall/import'\r\ninclude PyCall::Import\r\npyimport :pandas, as: :pd\r\n\r\nprint_memory_usage do\r\n  print_time_spent do\r\n    csv = pd.read_csv.('data.csv')\r\n    sum = csv['id'].sum.()\r\n    puts \"Sum: #{sum}\"\r\n  end\r\nend\r\n```\r\n\r\nPyCallは `pyenv` との相性が悪いのでSystemインストールしたPythonでたたきます。\r\n\r\n```sh\r\n$ PYTHON=/usr/bin/python3.4 ruby parse_6_pycall.rb\r\nSum: 499999500000\r\nTime: 1.49\r\nMemory: 54.99 MB\r\n```\r\n\r\n**結果**\r\n\r\n| kind_of_parse                      | time (real) | memory (MB) |\r\n|------------------------------------|-------------|-------------|\r\n| 1. `CSV.read`                      |       39.13 |       866.6 |\r\n| 2. `CSV.parse`                     |       36.16 |      936.87 |\r\n| 3. line by line from String Object |       23.39 |       73.42 |\r\n| 4. line by line from IO Object     |       24.55 |         0.0 |\r\n| 5. `CSV.foreach`                   |       24.04 |         0.0 |\r\n| 6. PyCall                          |        1.49 |       54.99 |\r\n\r\nはい、結果が出ました。Daliborのベンチマーク記事で一番速かった `CSV.foreach` より16倍の実行速度となりました。\r\n\r\n# WRAPUP\r\nPyCallのオブジェクトが `PyObject`とActiveRecordと相性が悪そうなのと、PythonとRuby双方のメモリー管理が運用を難しくすることから、安易に本番環境のRailsに導入するのは厳しいと思います。\r\n\r\nただし、実行回数が限定されたスクリプトなら積極的に使って良いでしょう。\r\n","body_html":"<a href=\"https://img.esa.io/uploads/production/attachments/16651/2021/01/11/97367/180665c6-7370-4579-8340-7be6254834e8.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img width=\"1920\" alt=\"thumbnail\" src=\"https://img.esa.io/uploads/production/attachments/16651/2021/01/11/97367/180665c6-7370-4579-8340-7be6254834e8.png\"></a>\n<p data-sourcepos=\"3:1-3:290\">先日RubyからPythonにアクセスできるPyCallというライブラリの存在を知り、ぜひともベンチマークを取りたいと思った次第です。現状RubyのCSVの読み込みに不満を持っており、そこをどうにか解消したいと考えています。</p>\n<h1 data-sourcepos=\"5:1-5:9\" id=\"1-0-0\" name=\"1-0-0\">\n<a class=\"anchor\" id=\"PROBLEM\" name=\"PROBLEM\" href=\"#PROBLEM\" data-position=\"1-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"PROBLEM\"> &gt; PROBLEM</span></a>PROBLEM</h1>\n<ul data-sourcepos=\"6:1-7:0\">\n<li data-sourcepos=\"6:1-7:0\">大量のCSVを読み込む際、毎回時間がかかる</li>\n</ul>\n<h1 data-sourcepos=\"8:1-8:10\" id=\"2-0-0\" name=\"2-0-0\">\n<a class=\"anchor\" id=\"SOLUTION\" name=\"SOLUTION\" href=\"#SOLUTION\" data-position=\"2-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"SOLUTION\"> &gt; SOLUTION</span></a>SOLUTION</h1>\n<p data-sourcepos=\"9:1-9:307\">というわけで、「<a href=\"https://dalibornasevic.com/posts/68-processing-large-csv-files-with-ruby\" target=\"_blank\" rel=\"noopener noreferrer\">Dalibor Nasevicのベンチマーク記事</a>」にPyCallのベンチマークをくわえて比較してみることにしました。記事では下記の通り <code>CSV.foreach</code> が速いとの結論でした。</p>\n<table data-sourcepos=\"11:1-17:66\">\n<thead>\n<tr data-sourcepos=\"11:1-11:66\">\n<th data-sourcepos=\"11:2-11:37\">kind_of_parse</th>\n<th data-sourcepos=\"11:39-11:51\">time (real)</th>\n<th data-sourcepos=\"11:53-11:65\">memory (MB)</th>\n</tr>\n</thead>\n<tbody>\n<tr data-sourcepos=\"13:1-13:66\">\n<td data-sourcepos=\"13:2-13:37\">1. <code>CSV.read</code>\n</td>\n<td data-sourcepos=\"13:39-13:51\">39.13</td>\n<td data-sourcepos=\"13:53-13:65\">866.6</td>\n</tr>\n<tr data-sourcepos=\"14:1-14:66\">\n<td data-sourcepos=\"14:2-14:37\">2. <code>CSV.parse</code>\n</td>\n<td data-sourcepos=\"14:39-14:51\">36.16</td>\n<td data-sourcepos=\"14:53-14:65\">936.87</td>\n</tr>\n<tr data-sourcepos=\"15:1-15:66\">\n<td data-sourcepos=\"15:2-15:37\">3. line by line from String Object</td>\n<td data-sourcepos=\"15:39-15:51\">23.39</td>\n<td data-sourcepos=\"15:53-15:65\">73.42</td>\n</tr>\n<tr data-sourcepos=\"16:1-16:66\">\n<td data-sourcepos=\"16:2-16:37\">4. line by line from IO Object</td>\n<td data-sourcepos=\"16:39-16:51\">24.55</td>\n<td data-sourcepos=\"16:53-16:65\">0.0</td>\n</tr>\n<tr data-sourcepos=\"17:1-17:66\">\n<td data-sourcepos=\"17:2-17:37\">5. <code>CSV.foreach</code>\n</td>\n<td data-sourcepos=\"17:39-17:51\">24.04</td>\n<td data-sourcepos=\"17:53-17:65\">0.0</td>\n</tr>\n</tbody>\n</table>\n<h2 data-sourcepos=\"19:1-19:30\" id=\"2-1-0\" name=\"2-1-0\">\n<a class=\"anchor\" id=\"PyCallのベンチマーク\" name=\"PyCall%E3%81%AE%E3%83%99%E3%83%B3%E3%83%81%E3%83%9E%E3%83%BC%E3%82%AF\" href=\"#PyCall%E3%81%AE%E3%83%99%E3%83%B3%E3%83%81%E3%83%9E%E3%83%BC%E3%82%AF\" data-position=\"2-1-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"PyCallのベンチマーク\"> &gt; PyCallのベンチマーク</span></a>PyCallのベンチマーク</h2>\n<p data-sourcepos=\"20:1-20:111\">それでは、PyCallのベンチマークを計りましょう。コードは下記のようになります。</p>\n<div class=\"code-block\" data-sourcepos=\"22:1-35:3\">\n<div class=\"code-filename\">\n<i class=\"fa fa-file-code-o\"></i>ruby</div>\n<div class=\"highlight\"><pre class=\"highlight ruby\"><code><span class=\"nb\">require_relative</span> <span class=\"s1\">'./helpers'</span>\n<span class=\"nb\">require</span> <span class=\"s1\">'pycall/import'</span>\n<span class=\"kp\">include</span> <span class=\"no\">PyCall</span><span class=\"o\">::</span><span class=\"no\">Import</span>\n<span class=\"n\">pyimport</span> <span class=\"ss\">:pandas</span><span class=\"p\">,</span> <span class=\"ss\">as: :pd</span>\n\n<span class=\"n\">print_memory_usage</span> <span class=\"k\">do</span>\n  <span class=\"n\">print_time_spent</span> <span class=\"k\">do</span>\n    <span class=\"n\">csv</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"nf\">read_csv</span><span class=\"o\">.</span><span class=\"p\">(</span><span class=\"s1\">'data.csv'</span><span class=\"p\">)</span>\n    <span class=\"n\">sum</span> <span class=\"o\">=</span> <span class=\"n\">csv</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">].</span><span class=\"nf\">sum</span><span class=\"o\">.</span><span class=\"p\">()</span>\n    <span class=\"nb\">puts</span> <span class=\"s2\">\"Sum: </span><span class=\"si\">#{</span><span class=\"n\">sum</span><span class=\"si\">}</span><span class=\"s2\">\"</span>\n  <span class=\"k\">end</span>\n<span class=\"k\">end</span>\n</code></pre></div>\n</div>\n<p data-sourcepos=\"37:1-37:102\">PyCallは <code>pyenv</code> との相性が悪いのでSystemインストールしたPythonでたたきます。</p>\n<div class=\"code-block\" data-sourcepos=\"39:1-44:3\">\n<div class=\"code-filename\">\n<i class=\"fa fa-file-code-o\"></i>sh</div>\n<div class=\"highlight\"><pre class=\"highlight shell\"><code><span class=\"nv\">$ PYTHON</span><span class=\"o\">=</span>/usr/bin/python3.4 ruby parse_6_pycall.rb\nSum: 499999500000\nTime: 1.49\nMemory: 54.99 MB\n</code></pre></div>\n</div>\n<p data-sourcepos=\"46:1-46:10\"><strong>結果</strong></p>\n<table data-sourcepos=\"48:1-55:66\">\n<thead>\n<tr data-sourcepos=\"48:1-48:66\">\n<th data-sourcepos=\"48:2-48:37\">kind_of_parse</th>\n<th data-sourcepos=\"48:39-48:51\">time (real)</th>\n<th data-sourcepos=\"48:53-48:65\">memory (MB)</th>\n</tr>\n</thead>\n<tbody>\n<tr data-sourcepos=\"50:1-50:66\">\n<td data-sourcepos=\"50:2-50:37\">1. <code>CSV.read</code>\n</td>\n<td data-sourcepos=\"50:39-50:51\">39.13</td>\n<td data-sourcepos=\"50:53-50:65\">866.6</td>\n</tr>\n<tr data-sourcepos=\"51:1-51:66\">\n<td data-sourcepos=\"51:2-51:37\">2. <code>CSV.parse</code>\n</td>\n<td data-sourcepos=\"51:39-51:51\">36.16</td>\n<td data-sourcepos=\"51:53-51:65\">936.87</td>\n</tr>\n<tr data-sourcepos=\"52:1-52:66\">\n<td data-sourcepos=\"52:2-52:37\">3. line by line from String Object</td>\n<td data-sourcepos=\"52:39-52:51\">23.39</td>\n<td data-sourcepos=\"52:53-52:65\">73.42</td>\n</tr>\n<tr data-sourcepos=\"53:1-53:66\">\n<td data-sourcepos=\"53:2-53:37\">4. line by line from IO Object</td>\n<td data-sourcepos=\"53:39-53:51\">24.55</td>\n<td data-sourcepos=\"53:53-53:65\">0.0</td>\n</tr>\n<tr data-sourcepos=\"54:1-54:66\">\n<td data-sourcepos=\"54:2-54:37\">5. <code>CSV.foreach</code>\n</td>\n<td data-sourcepos=\"54:39-54:51\">24.04</td>\n<td data-sourcepos=\"54:53-54:65\">0.0</td>\n</tr>\n<tr data-sourcepos=\"55:1-55:66\">\n<td data-sourcepos=\"55:2-55:37\">6. PyCall</td>\n<td data-sourcepos=\"55:39-55:51\">1.49</td>\n<td data-sourcepos=\"55:53-55:65\">54.99</td>\n</tr>\n</tbody>\n</table>\n<p data-sourcepos=\"57:1-57:150\">はい、結果が出ました。Daliborのベンチマーク記事で一番速かった <code>CSV.foreach</code> より16倍の実行速度となりました。</p>\n<h1 data-sourcepos=\"59:1-59:8\" id=\"3-0-0\" name=\"3-0-0\">\n<a class=\"anchor\" id=\"WRAPUP\" name=\"WRAPUP\" href=\"#WRAPUP\" data-position=\"3-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"WRAPUP\"> &gt; WRAPUP</span></a>WRAPUP</h1>\n<p data-sourcepos=\"60:1-60:248\">PyCallのオブジェクトが <code>PyObject</code>とActiveRecordと相性が悪そうなのと、PythonとRuby双方のメモリー管理が運用を難しくすることから、安易に本番環境のRailsに導入するのは厳しいと思います。</p>\n<p data-sourcepos=\"62:1-62:105\">ただし、実行回数が限定されたスクリプトなら積極的に使って良いでしょう。</p>\n","tags":["ruby","benchmark","pycall"],"updated_at":"2021-01-16T10:27:34+09:00","childPublishedDate":{"published_on":"2017-06-05T00:00:00.000Z"},"updated_by":{"name":"なびの👷","screen_name":"nabinno","icon":"https://img.esa.io/uploads/production/members/94286/icon/thumb_m_ef5f024307008aa399b91f87fa5f64e8.jpg"}},"relatedPosts":{"edges":[{"node":{"number":62,"relative_category":"blog/backend","fields":{"title":"Elixirではてなブックマーク","excerpt":"紆余曲折合ってはてなブックマークの運用を見直す必要が出てきました。人の興味というのは尽きないもので知りたいことが次々出てきます。にも拘わらず人の時間は有限でそれにあがなうための手段を考えたわけです。   > PROBLEMPROBLEM \n\n- フィードリーダーで記事を読んだ後にはてなブックマーク（ブクマ）するとフィード消化するのに時間がかかる フィードをそのままブクマしていると下記の問題がでてくる あとで確認することができない 読みたくない記事をブクマしてしまう 適切でないURLでブクマしてしまう \n- フィードをそのままブクマしていると下記の問題がでてくる あとで確認することができない 読みたくない記事をブクマしてしまう 適切でないURLでブクマしてしまう \n- あとで確認することができない\n- 読みたくない記事をブクマしてしまう\n- 適切でないURLでブクマしてしまう   > SOLUTIONSOLUTION \n\nというわけで、下記の方針でブクマすることにしました。設置方法の詳細はGitHubレポジトリを参照ください。そして、方針は下記の通りになります。 \n\n方針 \n\n- フィードごとにタグづけする\n- ブクマ対象になる記事をリンクとタイトルで除外判定する\n- ブクマ対象になる記事をリンクから校正すべきものかリダイレクトすべきものか判定する\n- 上記設定はYAMLファイルで簡単に管理できるようにする\n- フィード読込とブクマを非同期処理できるようElixirで実装する   > ブクマの管理方法ブクマの管理方法 \n\nまずブクマの管理ですが、下記5つのYAMLファイルで構成しています、構造はマップとリストのみ。ブクマしたいと思う記事を読みすすめる中で気になるキーワードが出てきたら都度 feed.yaml を更新します。また、記事にノイズが多いようだったら傾向を分析して除外ファイル feed_excluded_link.yaml feed_excluded_title.yaml を更新します。    item description     feed.yaml フィードグループ名に対するリンク、タグのマップ   feed_excluded_link.yaml 除外すべきフィードリンクのリスト   feed_excluded_title.yaml 除外すべきフィードタイトルのリスト   feed_corrected_link.yaml フィードリンクに対するトリミングすべきパラメータのマップ   feed_redirected_link.yaml フィードリンクに対するリダイレクト先リンクのマップ      yaml \n\n# feed.yaml nabinno/sports/feed_group_name: tags: - ski links: - http://rss.example.com/ski_feed.rss - http://rss.example.com/snowboard_feed.rss - http://ski-status.example.com/rss # feed_excluded_link.yaml - anti-ski.example.com - awesome-snowboard.example.com # feed_excluded_title.yaml - queer - two-planker - beaver-tail # feed_corrected_link.yaml amazon.com: - ref - ie # feed_redirected_link.yaml ski-status.example.com: - Floki.find(fst, \".post__body a\")     > Elixirによる非同期処理Elixirによる非同期処理 \n\nElixirで非同期処理を行っているのですが、大きく分けて監視機構のSupervisorと非同期処理のTask.async_streamを使っています。   > 監視機構 Supervisor監視機構 Supervisor \n\nまず、Supervisor。Elixirには監視機構Supervisorがあり、それが各ワーカーを子プロセスとして管理しています。ここではフィード読込とブクマは別々のワーカーで処理しますが、キャッシュが暖気処理を別ワーカーで行っているため再起動戦略は「失敗したイベントの中にあるすべての子プロセスを再起動」（ one_for_all ）にしてあります。再起動戦略の詳細は「OTPスーパバイザ · Elixir School」を参照下さい。 \n\n下記のように Supervisor.start_link を Keshikimi2.Application.start に適用すると、アプリケーション開始（ mix run ）した時点で監視機構が起動されます。   ex \n\nSupervisor.start_link( [ :hackney_pool.child_spec(:hatena_bookmark_pool, timeout: 15_000, max_connections: 100), # @todo 当該ワーカーで暖気処理を行っていないので `one_for_one` にした場合、再起動時にほかに影響する supervisor(Cachex, [:feed, []]), supervisor(Keshikimi2Feed.Registry, [prefix]), # フィード読込処理 (PubSub) supervisor(Keshikimi2Feed.Subscriber, [prefix]), worker(Keshikimi2Feed.Worker, [prefix]), worker(Keshikimi2Feed.Publisher, [[prefix: prefix, poll_interval: 3_000]]), # ブクマ処理 worker(Keshikimi2.HatenaBookmark.AddEntry, [ [prefix: prefix, poll_interval: 3_000] ]) ], strategy: :one_for_all, name: name(prefix) )     > 非同期処理 Task.async_stream非同期処理 Task.async_stream \n\n次に、Task.async_stream。配列を引き回すリクエスト処理は Task.async_stream がうってつけです。下記ではキャッシュからブクマ対象になるフィードリンクを取り出し、除外処理、校正処理を加えて、ブクマのリクエストを出すという流れを組んでいます。Elixirでは、流れをひとまとめにして視覚的にわかりやすく非同期処理してくことができます。   ex \n\nCachex.keys!(:feed) |> Enum.reject(fn key -> key in [ \"excluded_links\", \"excluded_titles\", \"corrected_links\", \"redirected_links\", \"feed_group\", \"archived_links\" ] end) |> Task.async_stream( fn item_link -> with {:ok, [item_title, feed_tags]} <- Cachex.get(:feed, item_link), :ok <- validate_all(item_link, item_title), corrected_link <- correct_all(item_link), {:ok, payload} <- FormData.create( %{ url: corrected_link, comment: feed_tags |> Enum.map_join(fn tag -> \"[#{tag}]\" end), rks: System.get_env(\"HATENA_BOOKMARK_RKS\"), private: 0, keep_original_url: 1, with_status_op: 1, from: \"inplace\", post_twitter: 0, post_evernote: 0 }, :url_encoded, get: false ) do do_add_entries_to_hb(payload) Logger.info(\"add entry: #{item_link}\") end archive_link(item_link) end, timeout: 15_000 ) |> Stream.run()     > WRAPUPWRAPUP \n\nElixirの非同期処理を使うことではてなブックマークの運用がとても快適になりました。はてなブックマークとの今後の付き合い方は下記のように考えています。 \n\n- 手動でブクマ: 気になった記事があるごとに\n- ブクマの確認: 気になるタグごとにまとめて確認 \n\nブクマの確認については、例えば、CIでデプロイしている間に最近のGitHubの動向を確認したい場合は「nabinno/github」をみる、という感じの運用です。 \n\n融通が利かない点で途中運用が難しくなる気もしますが、しばらく回してみます。"},"name":"[2019-01-01]Elixirではてなブックマーク","tags":["elixir","hatena-bookmark"],"childPublishedDate":{"published_on":"2019-01-01T00:00:00.000Z","published_on_unix":1546300800}}},{"node":{"number":63,"relative_category":"blog/frontend","fields":{"title":"イケてるしヤバい言語REBOLの後継Redでクライアントソフトをつくった話","excerpt":"Redという言語はご存じでしょうか。癖になる手触りですぐに虜になりました。新年早々の恋になります。   > PROBLEMPROBLEM \n\n- クロスプラットフォーム用のクライアントソフトをつくるにあたり 重たいフレームワークが多い 汎用的な言語をつかってるものが多く、そのためライブラリー等の依存関係が多くなりやすい \n- 重たいフレームワークが多い\n- 汎用的な言語をつかってるものが多く、そのためライブラリー等の依存関係が多くなりやすい   > SOLUTIONSOLUTION \n\nというわけで、年明け見つけたRedがシンプルだったので使ってみました。題材は以前つくったEmacsライブラリ「esa.el」の移植です。 \n\n- https://github.com/nabinno/esa.red   > やったことやったこと   > エディターエディター \n\n構文がすなおなので特にエディタは関係なさそうでしたが、慣れ親しんでるEmacsに「Skrylar/red.el」を適用しました。その際、 red-font-lock-keywords と red-indent-line に足りない箇所があったのでオーバーライドしました。   > 糖衣構文の適用糖衣構文の適用 \n\nRedはコマンドラインREPLがつかえるので、doc.red-lang.orgとred-by-example.orgをみながらひとつひとつ挙動を確認しました。その中でどうしても慣れない表現が2つあったので糖衣構文を実装（nabinno/red-elixir）。 \n\n1. compose \n\nブロック内の変数を評価しブロックとして返す関数 compose は、VIDのフェイス更新によく使われます。HTML/JavaScripでいうところDOM更新にあたるものといえば分かるでしょうか。頻繁に「 compose [foo (bar)] 」のような表現がつづくとほかの変数や関数とまざり可読性がおちるので、Elixirのシジルを参考に compose 関数を省略しました。こんな感じです。 \n\n;-- before compose [foo (bar)] ;-- after ~c[foo (bar)]  \n\n2. 関数の入れ子 \n\n素のRedはイテレーター構文なので、関数の入れ子による可読性低下をおさえるため変数定義をよく使います。個人的には変数は意味のあるものだけ使いたい派なので、パイプを導入しました。といっても、フロントエンドの場合、データ加工はあまりやらないのでつかうケースはほぼありませんでした。あってもこのくらいです。   red \n\n;-- before rejoin collect [ foreach d data [ keep rejoin [d \" \"] ] ] ;-- after data .[ |> Series/map 'd [rejoin [d \" \"]] |> rejoin ]     > タスクランナーの用意タスクランナーの用意 \n\n今回は上で実装したライブラリ「red-elixir」のほかにHTTPリクエスト・JSONパーサーライブラリを使っています。ライブラリパッケージはインストールはgit submodulesで良いですが、呼び出しも考えると実装が冗長的になるのでパッケージ管理とタスクランナーをあわせて用意しました（nabinno/hot、nabinno/mods）。 \n\nタスクランナーインストール後、パッケージのインストールから呼び出しまでの流れ \n\nRedはGoとおなじくワンバイナリーなので、wgetやcurlだけでインストールが完了します。   sh \n\n> mkdir -p ~/.local/bin > wget https://github.com/nabinno/hot/releases/download/0.0.3/hot-linux -O ~/.local/bin/hot > chmod 744 ~/.local/bin/hot   \n\nパッケージ管理はElixirのmixを参考にタスクランナー管理ファイル内に定義します。   sh \n\n> hot cmd/install https://raw.githubusercontent.com/nabinno/mods/master/mods.red > cat hots.red Red [] hots: context [ mods: [ red-elixir #(init: %init.red git: https://github.com/nabinno/red-elixir) json #(init: %json.red git: https://github.com/rebolek/red-tools) http-tools #(init: %http-tools.red git: https://github.com/rebolek/red-tools) ] ] > hot mods/get   \n\nビルド時は #include をつかうのでパッケージ呼び出し機能は使えないですが、コマンドラインREPLで挙動確認している際は do/args %require を使います。   sh \n\n> red >> do/args %require [red-elixir] >> 1 .. 10 .[ |> Series/map 'i [i * 2] |> Series/map 'i [i + 1] ] == [3 5 7 9 11 13 15 17 19 21]     > WRAPUPWRAPUP \n\nクライアントソフトを作る中で感じたことは、この1点です。Redは既存のフレームワークと比べるとまだまだ機能不足感が拭えませんが、それを補えるだけの表現力を持っていました。手触りが本当に良い言語でした。"},"name":"[2019-03-31]イケてるしヤバい言語REBOLの後継Redでクライアントソフトをつくった話","tags":["red","esa"],"childPublishedDate":{"published_on":"2019-03-31T00:00:00.000Z","published_on_unix":1553990400}}},{"node":{"number":61,"relative_category":"blog/health","fields":{"title":"ElixirとRaspberry PiでPM2.5などの環境データを定点観察し、目・喉の痛みに備える","excerpt":"皆さんは体調管理どうされていますか? 一度痛い目に遭うと日常の細かい差異が気になってきて、そこをどうにか解決したいというのが人情です。今回は自分の咽頭痛の解消のため一つ実験をしてみました。   > PROBLEMPROBLEM \n\n- 以前からオフィスに行くと目や喉が痛くなることがあったので、自分の体調なのか環境なのか原因を切り分けるために汚染計測器「Dienmern DM106A」を購入 ただ、DM106Aの計測はその時その時のスナップショットなので傾向を読み解きづらい、また、都度実施する手間がかかる \n- ただ、DM106Aの計測はその時その時のスナップショットなので傾向を読み解きづらい、また、都度実施する手間がかかる   > SOLUTIONSOLUTION \n\nというわけで、DM106AのセンサーデータをRaspberry Piで定期取得することにしました。設置方法の詳細はGitHubレポジトリを参照ください。下記、実装概要になります。   > 電子部品の構成電子部品の構成    item description     Raspberry Pi 3 Model B+    Aosong DHT11 気温・湿度センサー、GPIO   Nova SDS021 PM2.5・PM10センサー、UART   ams CCS811 TVOC・CO2eセンサー、I2C    \n\nまず、電子工作は素人ゆえどのセンサーを買えばいいか分からなかったのでDM106Aを分解して各センサーの型番を調べました。DHT011、SDS021はDM106Aとおなじセンサー、HCHOセンサーは信頼性があり手ごろなのがうまく見つけられませんでした。TVOCセンサーはAdafruitが推しているCCS811を採用しました。   > コードの構成コードの構成    item description     AirElixir.Application アプリケーション管理   AirElixir.GoogleSpreadsheets センサーデータ記録   AirElixirSensor.Publisher センサーデータ発行・送信   AirElixirSensor.Subscriber センサーデータ購読・受信    \n\n次に、基本構成はGrovePiを参考にしました。発行処理はElixirでうまくいかないケースがあったのでまずはPython/ErlPortで行いました。後々Elixirに移行できるようにマクロにしました。   > 5日ほど稼働してわかったこと・見立て、今後の課題5日ほど稼働してわかったこと・見立て、今後の課題  \n\n最後に、分かったこと、見立てですが、3点あります。2番目に関しては予想通りだったのですが、1番目、3番目に関しては意外であり、疑り深い私としては特に空気清浄機がきちんと機能していたことに驚きました。 \n\n1. オフィスの空気清浄機「Hitachi EP-LVG110」はPMをきちんとフィルターしていた ただし、空気清浄機はTVOCには効果がなく、これはTroia氏や加藤氏・苅部氏の考察でも言及されている \n2. ただし、空気清浄機はTVOCには効果がなく、これはTroia氏や加藤氏・苅部氏の考察でも言及されている\n3. 人の入りが多い時間帯に空気（TVOCやCO2e）が汚れる 人が「出る」時よりも「入る」際に濃度があがるのは、外のVOCが服などに付着しているためと推察 \n4. 人が「出る」時よりも「入る」際に濃度があがるのは、外のVOCが服などに付着しているためと推察\n5. TVOCやCO2eはPMのうごきに連動している（かも） チャート上はEP-LVG110がPM除去しているためわからないが、日本気象協会のPM2.5分布予測に照らしてみるとPM濃度が高い日にTVOC濃度があがっていた TODO: PMがVOCを運んでいる可能性があるので、IQAirなどのAPIから周辺環境のPMデータも取得したいところ \n6. チャート上はEP-LVG110がPM除去しているためわからないが、日本気象協会のPM2.5分布予測に照らしてみるとPM濃度が高い日にTVOC濃度があがっていた TODO: PMがVOCを運んでいる可能性があるので、IQAirなどのAPIから周辺環境のPMデータも取得したいところ \n7. TODO: PMがVOCを運んでいる可能性があるので、IQAirなどのAPIから周辺環境のPMデータも取得したいところ \n\n課題としてはその性質からして仕方ないのですがTVOCの変動が大きすぎて解読を難しかったです。計測方法等を再度見直す必要がありそうです。 \n\n- TVOCの変動が大きすぎる ポーリング・出力を20分ごとからポーリング3秒ごと・出力20分ごとに変更した、出力データは20分の平均 \n- ポーリング・出力を20分ごとからポーリング3秒ごと・出力20分ごとに変更した、出力データは20分の平均\n- TVOCのスパイクを抑えたい TODO: ファイトレメディエーションによる効果を見ていきたいところ \n- TODO: ファイトレメディエーションによる効果を見ていきたいところ   > WRAPUPWRAPUP \n\n今回の実験はこれが言いたかっただけという指摘をされるとぐうの音も出ませんが、はっきり言わせてください。そう、Elixirは健康管理に向いています。   txt \n\n「なんか体調がすぐれないなあ...」 「Elixirちょうだい!」   \n\nという感じです、はい。"},"name":"[2018-12-22]ElixirとRaspberry PiでPM2.5などの環境データを定点観察し、目・喉の痛みに備える","tags":["elixir","raspberry-pi","particulates","physiology"],"childPublishedDate":{"published_on":"2018-12-22T00:00:00.000Z","published_on_unix":1545436800}}}]}},"pageContext":{"number":56}},"staticQueryHashes":[]}