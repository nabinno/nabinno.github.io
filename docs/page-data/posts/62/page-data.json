{"componentChunkName":"component---src-templates-post-tsx","path":"/posts/62","result":{"data":{"esaPost":{"number":62,"relative_category":"blog/backend","fields":{"title":"Elixirではてなブックマーク","excerpt":"紆余曲折合ってはてなブックマークの運用を見直す必要が出てきました。人の興味というのは尽きないもので知りたいことが次々出てきます。にも拘わらず人の時間は有限でそれにあがなうための手段を考えたわけです。   > PROBLEMPROBLEM \n\n- フィードリーダーで記事を読んだ後にはてなブックマーク（ブクマ）するとフィード消化するのに時間がかかる フィードをそのままブクマしていると下記の問題がでてくる あとで確認することができない 読みたくない記事をブクマしてしまう 適切でないURLでブクマしてしまう \n- フィードをそのままブクマしていると下記の問題がでてくる あとで確認することができない 読みたくない記事をブクマしてしまう 適切でないURLでブクマしてしまう \n- あとで確認することができない\n- 読みたくない記事をブクマしてしまう\n- 適切でないURLでブクマしてしまう   > SOLUTIONSOLUTION \n\nというわけで、下記の方針でブクマすることにしました。設置方法の詳細はGitHubレポジトリを参照ください。そして、方針は下記の通りになります。 \n\n方針 \n\n- フィードごとにタグづけする\n- ブクマ対象になる記事をリンクとタイトルで除外判定する\n- ブクマ対象になる記事をリンクから校正すべきものかリダイレクトすべきものか判定する\n- 上記設定はYAMLファイルで簡単に管理できるようにする\n- フィード読込とブクマを非同期処理できるようElixirで実装する   > ブクマの管理方法ブクマの管理方法 \n\nまずブクマの管理ですが、下記5つのYAMLファイルで構成しています、構造はマップとリストのみ。ブクマしたいと思う記事を読みすすめる中で気になるキーワードが出てきたら都度 feed.yaml を更新します。また、記事にノイズが多いようだったら傾向を分析して除外ファイル feed_excluded_link.yaml feed_excluded_title.yaml を更新します。    item description     feed.yaml フィードグループ名に対するリンク、タグのマップ   feed_excluded_link.yaml 除外すべきフィードリンクのリスト   feed_excluded_title.yaml 除外すべきフィードタイトルのリスト   feed_corrected_link.yaml フィードリンクに対するトリミングすべきパラメータのマップ   feed_redirected_link.yaml フィードリンクに対するリダイレクト先リンクのマップ      yaml \n\n# feed.yaml nabinno/sports/feed_group_name: tags: - ski links: - http://rss.example.com/ski_feed.rss - http://rss.example.com/snowboard_feed.rss - http://ski-status.example.com/rss # feed_excluded_link.yaml - anti-ski.example.com - awesome-snowboard.example.com # feed_excluded_title.yaml - queer - two-planker - beaver-tail # feed_corrected_link.yaml amazon.com: - ref - ie # feed_redirected_link.yaml ski-status.example.com: - Floki.find(fst, \".post__body a\")     > Elixirによる非同期処理Elixirによる非同期処理 \n\nElixirで非同期処理を行っているのですが、大きく分けて監視機構のSupervisorと非同期処理のTask.async_streamを使っています。   > 監視機構 Supervisor監視機構 Supervisor \n\nまず、Supervisor。Elixirには監視機構Supervisorがあり、それが各ワーカーを子プロセスとして管理しています。ここではフィード読込とブクマは別々のワーカーで処理しますが、キャッシュが暖気処理を別ワーカーで行っているため再起動戦略は「失敗したイベントの中にあるすべての子プロセスを再起動」（ one_for_all ）にしてあります。再起動戦略の詳細は「OTPスーパバイザ · Elixir School」を参照下さい。 \n\n下記のように Supervisor.start_link を Keshikimi2.Application.start に適用すると、アプリケーション開始（ mix run ）した時点で監視機構が起動されます。   ex \n\nSupervisor.start_link( [ :hackney_pool.child_spec(:hatena_bookmark_pool, timeout: 15_000, max_connections: 100), # @todo 当該ワーカーで暖気処理を行っていないので `one_for_one` にした場合、再起動時にほかに影響する supervisor(Cachex, [:feed, []]), supervisor(Keshikimi2Feed.Registry, [prefix]), # フィード読込処理 (PubSub) supervisor(Keshikimi2Feed.Subscriber, [prefix]), worker(Keshikimi2Feed.Worker, [prefix]), worker(Keshikimi2Feed.Publisher, [[prefix: prefix, poll_interval: 3_000]]), # ブクマ処理 worker(Keshikimi2.HatenaBookmark.AddEntry, [ [prefix: prefix, poll_interval: 3_000] ]) ], strategy: :one_for_all, name: name(prefix) )     > 非同期処理 Task.async_stream非同期処理 Task.async_stream \n\n次に、Task.async_stream。配列を引き回すリクエスト処理は Task.async_stream がうってつけです。下記ではキャッシュからブクマ対象になるフィードリンクを取り出し、除外処理、校正処理を加えて、ブクマのリクエストを出すという流れを組んでいます。Elixirでは、流れをひとまとめにして視覚的にわかりやすく非同期処理してくことができます。   ex \n\nCachex.keys!(:feed) |> Enum.reject(fn key -> key in [ \"excluded_links\", \"excluded_titles\", \"corrected_links\", \"redirected_links\", \"feed_group\", \"archived_links\" ] end) |> Task.async_stream( fn item_link -> with {:ok, [item_title, feed_tags]} <- Cachex.get(:feed, item_link), :ok <- validate_all(item_link, item_title), corrected_link <- correct_all(item_link), {:ok, payload} <- FormData.create( %{ url: corrected_link, comment: feed_tags |> Enum.map_join(fn tag -> \"[#{tag}]\" end), rks: System.get_env(\"HATENA_BOOKMARK_RKS\"), private: 0, keep_original_url: 1, with_status_op: 1, from: \"inplace\", post_twitter: 0, post_evernote: 0 }, :url_encoded, get: false ) do do_add_entries_to_hb(payload) Logger.info(\"add entry: #{item_link}\") end archive_link(item_link) end, timeout: 15_000 ) |> Stream.run()     > WRAPUPWRAPUP \n\nElixirの非同期処理を使うことではてなブックマークの運用がとても快適になりました。はてなブックマークとの今後の付き合い方は下記のように考えています。 \n\n- 手動でブクマ: 気になった記事があるごとに\n- ブクマの確認: 気になるタグごとにまとめて確認 \n\nブクマの確認については、例えば、CIでデプロイしている間に最近のGitHubの動向を確認したい場合は「nabinno/github」をみる、という感じの運用です。 \n\n融通が利かない点で途中運用が難しくなる気もしますが、しばらく回してみます。","thumbnail":"https://raw.githubusercontent.com/nabinno/keshikimi2/master/priv/img/diagram.png"},"wip":false,"body_md":"<img alt=thumbnail src=https://raw.githubusercontent.com/nabinno/keshikimi2/master/priv/img/diagram.png />\r\n\r\n紆余曲折合ってはてなブックマークの運用を見直す必要が出てきました。人の興味というのは尽きないもので知りたいことが次々出てきます。にも拘わらず人の時間は有限でそれにあがなうための手段を考えたわけです。\r\n\r\n# PROBLEM\r\n- フィードリーダーで記事を読んだ後にはてなブックマーク（ブクマ）するとフィード消化するのに時間がかかる\r\n    - フィードをそのままブクマしていると下記の問題がでてくる\r\n        - あとで確認することができない\r\n        - 読みたくない記事をブクマしてしまう\r\n        - 適切でないURLでブクマしてしまう\r\n\r\n# SOLUTION\r\nというわけで、下記の方針でブクマすることにしました。設置方法の詳細は[GitHubレポジトリ](https://github.com/nabinno/keshikimi2)を参照ください。そして、方針は下記の通りになります。\r\n\r\n**方針**\r\n\r\n- フィードごとにタグづけする\r\n- ブクマ対象になる記事をリンクとタイトルで除外判定する\r\n- ブクマ対象になる記事をリンクから校正すべきものかリダイレクトすべきものか判定する\r\n- 上記設定はYAMLファイルで簡単に管理できるようにする\r\n- フィード読込とブクマを非同期処理できるようElixirで実装する\r\n\r\n## ブクマの管理方法\r\nまずブクマの管理ですが、下記5つのYAMLファイルで構成しています、構造はマップとリストのみ。ブクマしたいと思う記事を読みすすめる中で気になるキーワードが出てきたら都度 `feed.yaml` を更新します。また、記事にノイズが多いようだったら傾向を分析して除外ファイル `feed_excluded_link.yaml` `feed_excluded_title.yaml` を更新します。\r\n\r\n| item                        | description                                              |\r\n|-----------------------------|----------------------------------------------------------|\r\n| `feed.yaml`                 | フィードグループ名に対するリンク、タグのマップ           |\r\n| `feed_excluded_link.yaml`   | 除外すべきフィードリンクのリスト                         |\r\n| `feed_excluded_title.yaml`  | 除外すべきフィードタイトルのリスト                       |\r\n| `feed_corrected_link.yaml`  | フィードリンクに対するトリミングすべきパラメータのマップ |\r\n| `feed_redirected_link.yaml` | フィードリンクに対するリダイレクト先リンクのマップ       |\r\n\r\n```yaml\r\n# feed.yaml\r\nnabinno/sports/feed_group_name:\r\n  tags:\r\n    - ski\r\n  links:\r\n    - http://rss.example.com/ski_feed.rss\r\n    - http://rss.example.com/snowboard_feed.rss\r\n    - http://ski-status.example.com/rss\r\n\r\n# feed_excluded_link.yaml\r\n- anti-ski.example.com\r\n- awesome-snowboard.example.com\r\n\r\n# feed_excluded_title.yaml\r\n- queer\r\n- two-planker\r\n- beaver-tail\r\n\r\n# feed_corrected_link.yaml\r\namazon.com:\r\n  - ref\r\n  - ie\r\n\r\n# feed_redirected_link.yaml\r\nski-status.example.com:\r\n  - Floki.find(fst, \".post__body a\")\r\n```\r\n\r\n## Elixirによる非同期処理\r\nElixirで非同期処理を行っているのですが、大きく分けて監視機構のSupervisorと非同期処理のTask.async_streamを使っています。\r\n\r\n### 監視機構 Supervisor\r\nまず、Supervisor。Elixirには監視機構Supervisorがあり、それが各ワーカーを子プロセスとして管理しています。ここではフィード読込とブクマは別々のワーカーで処理しますが、キャッシュが暖気処理を別ワーカーで行っているため再起動戦略は「失敗したイベントの中にあるすべての子プロセスを再起動」（ `one_for_all` ）にしてあります。再起動戦略の詳細は「[OTPスーパバイザ · Elixir School](https://elixirschool.com/ja/lessons/advanced/otp-supervisors/)」を参照下さい。\r\n\r\n下記のように `Supervisor.start_link` を `Keshikimi2.Application.start` に適用すると、アプリケーション開始（ `mix run` ）した時点で監視機構が起動されます。\r\n\r\n```ex\r\nSupervisor.start_link(\r\n  [\r\n    :hackney_pool.child_spec(:hatena_bookmark_pool, timeout: 15_000, max_connections: 100),\r\n    # @todo 当該ワーカーで暖気処理を行っていないので `one_for_one` にした場合、再起動時にほかに影響する\r\n    supervisor(Cachex, [:feed, []]),\r\n    supervisor(Keshikimi2Feed.Registry, [prefix]),\r\n\r\n    # フィード読込処理 (PubSub)\r\n    supervisor(Keshikimi2Feed.Subscriber, [prefix]),\r\n    worker(Keshikimi2Feed.Worker, [prefix]),\r\n    worker(Keshikimi2Feed.Publisher, [[prefix: prefix, poll_interval: 3_000]]),\r\n\r\n    # ブクマ処理\r\n    worker(Keshikimi2.HatenaBookmark.AddEntry, [\r\n      [prefix: prefix, poll_interval: 3_000]\r\n    ])\r\n  ],\r\n  strategy: :one_for_all,\r\n  name: name(prefix)\r\n)\r\n```\r\n\r\n### 非同期処理 Task.async_stream\r\n次に、Task.async_stream。配列を引き回すリクエスト処理は `Task.async_stream` がうってつけです。下記ではキャッシュからブクマ対象になるフィードリンクを取り出し、除外処理、校正処理を加えて、ブクマのリクエストを出すという流れを組んでいます。Elixirでは、流れをひとまとめにして視覚的にわかりやすく非同期処理してくことができます。\r\n\r\n```ex\r\nCachex.keys!(:feed)\r\n|> Enum.reject(fn key ->\r\n  key in [\r\n    \"excluded_links\",\r\n    \"excluded_titles\",\r\n    \"corrected_links\",\r\n    \"redirected_links\",\r\n    \"feed_group\",\r\n    \"archived_links\"\r\n  ]\r\nend)\r\n|> Task.async_stream(\r\n  fn item_link ->\r\n    with {:ok, [item_title, feed_tags]} <- Cachex.get(:feed, item_link),\r\n         :ok <- validate_all(item_link, item_title),\r\n         corrected_link <- correct_all(item_link),\r\n         {:ok, payload} <-\r\n           FormData.create(\r\n             %{\r\n               url: corrected_link,\r\n               comment: feed_tags |> Enum.map_join(fn tag -> \"[#{tag}]\" end),\r\n               rks: System.get_env(\"HATENA_BOOKMARK_RKS\"),\r\n               private: 0,\r\n               keep_original_url: 1,\r\n               with_status_op: 1,\r\n               from: \"inplace\",\r\n               post_twitter: 0,\r\n               post_evernote: 0\r\n             },\r\n             :url_encoded,\r\n             get: false\r\n           ) do\r\n      do_add_entries_to_hb(payload)\r\n      Logger.info(\"add entry: #{item_link}\")\r\n    end\r\n\r\n    archive_link(item_link)\r\n  end,\r\n  timeout: 15_000\r\n)\r\n|> Stream.run()\r\n```\r\n\r\n# WRAPUP\r\nElixirの非同期処理を使うことではてなブックマークの運用がとても快適になりました。はてなブックマークとの今後の付き合い方は下記のように考えています。\r\n\r\n- **手動でブクマ:** 気になった記事があるごとに\r\n- **ブクマの確認:** 気になるタグごとにまとめて確認\r\n\r\nブクマの確認については、例えば、CIでデプロイしている間に最近のGitHubの動向を確認したい場合は「[nabinno/github](http://b.hatena.ne.jp/nabinno/github)」をみる、という感じの運用です。\r\n\r\n融通が利かない点で途中運用が難しくなる気もしますが、しばらく回してみます。\r\n","body_html":"<a href=\"https://raw.githubusercontent.com/nabinno/keshikimi2/master/priv/img/diagram.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img alt=\"thumbnail\" src=\"https://raw.githubusercontent.com/nabinno/keshikimi2/master/priv/img/diagram.png\"></a>\n<p data-sourcepos=\"3:1-3:297\">紆余曲折合ってはてなブックマークの運用を見直す必要が出てきました。人の興味というのは尽きないもので知りたいことが次々出てきます。にも拘わらず人の時間は有限でそれにあがなうための手段を考えたわけです。</p>\n<h1 data-sourcepos=\"5:1-5:9\" id=\"1-0-0\" name=\"1-0-0\">\n<a class=\"anchor\" id=\"PROBLEM\" name=\"PROBLEM\" href=\"#PROBLEM\" data-position=\"1-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"PROBLEM\"> &gt; PROBLEM</span></a>PROBLEM</h1>\n<ul data-sourcepos=\"6:1-11:0\">\n<li data-sourcepos=\"6:1-11:0\">フィードリーダーで記事を読んだ後にはてなブックマーク（ブクマ）するとフィード消化するのに時間がかかる\n<ul data-sourcepos=\"7:5-11:0\">\n<li data-sourcepos=\"7:5-11:0\">フィードをそのままブクマしていると下記の問題がでてくる\n<ul data-sourcepos=\"8:9-11:0\">\n<li data-sourcepos=\"8:9-8:52\">あとで確認することができない</li>\n<li data-sourcepos=\"9:9-9:61\">読みたくない記事をブクマしてしまう</li>\n<li data-sourcepos=\"10:9-11:0\">適切でないURLでブクマしてしまう</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h1 data-sourcepos=\"12:1-12:10\" id=\"2-0-0\" name=\"2-0-0\">\n<a class=\"anchor\" id=\"SOLUTION\" name=\"SOLUTION\" href=\"#SOLUTION\" data-position=\"2-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"SOLUTION\"> &gt; SOLUTION</span></a>SOLUTION</h1>\n<p data-sourcepos=\"13:1-13:242\">というわけで、下記の方針でブクマすることにしました。設置方法の詳細は<a href=\"https://github.com/nabinno/keshikimi2\" target=\"_blank\" rel=\"noopener noreferrer\">GitHubレポジトリ</a>を参照ください。そして、方針は下記の通りになります。</p>\n<p data-sourcepos=\"15:1-15:10\"><strong>方針</strong></p>\n<ul data-sourcepos=\"17:1-22:0\">\n<li data-sourcepos=\"17:1-17:41\">フィードごとにタグづけする</li>\n<li data-sourcepos=\"18:1-18:80\">ブクマ対象になる記事をリンクとタイトルで除外判定する</li>\n<li data-sourcepos=\"19:1-19:122\">ブクマ対象になる記事をリンクから校正すべきものかリダイレクトすべきものか判定する</li>\n<li data-sourcepos=\"20:1-20:75\">上記設定はYAMLファイルで簡単に管理できるようにする</li>\n<li data-sourcepos=\"21:1-22:0\">フィード読込とブクマを非同期処理できるようElixirで実装する</li>\n</ul>\n<h2 data-sourcepos=\"23:1-23:27\" id=\"2-1-0\" name=\"2-1-0\">\n<a class=\"anchor\" id=\"ブクマの管理方法\" name=\"%E3%83%96%E3%82%AF%E3%83%9E%E3%81%AE%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95\" href=\"#%E3%83%96%E3%82%AF%E3%83%9E%E3%81%AE%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95\" data-position=\"2-1-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"ブクマの管理方法\"> &gt; ブクマの管理方法</span></a>ブクマの管理方法</h2>\n<p data-sourcepos=\"24:1-24:444\">まずブクマの管理ですが、下記5つのYAMLファイルで構成しています、構造はマップとリストのみ。ブクマしたいと思う記事を読みすすめる中で気になるキーワードが出てきたら都度 <code>feed.yaml</code> を更新します。また、記事にノイズが多いようだったら傾向を分析して除外ファイル <code>feed_excluded_link.yaml</code> <code>feed_excluded_title.yaml</code> を更新します。</p>\n<table data-sourcepos=\"26:1-32:115\">\n<thead>\n<tr data-sourcepos=\"26:1-26:90\">\n<th data-sourcepos=\"26:2-26:30\">item</th>\n<th data-sourcepos=\"26:32-26:89\">description</th>\n</tr>\n</thead>\n<tbody>\n<tr data-sourcepos=\"28:1-28:113\">\n<td data-sourcepos=\"28:2-28:30\"><code>feed.yaml</code></td>\n<td data-sourcepos=\"28:32-28:112\">フィードグループ名に対するリンク、タグのマップ</td>\n</tr>\n<tr data-sourcepos=\"29:1-29:106\">\n<td data-sourcepos=\"29:2-29:30\"><code>feed_excluded_link.yaml</code></td>\n<td data-sourcepos=\"29:32-29:105\">除外すべきフィードリンクのリスト</td>\n</tr>\n<tr data-sourcepos=\"30:1-30:107\">\n<td data-sourcepos=\"30:2-30:30\"><code>feed_excluded_title.yaml</code></td>\n<td data-sourcepos=\"30:32-30:106\">除外すべきフィードタイトルのリスト</td>\n</tr>\n<tr data-sourcepos=\"31:1-31:118\">\n<td data-sourcepos=\"31:2-31:30\"><code>feed_corrected_link.yaml</code></td>\n<td data-sourcepos=\"31:32-31:117\">フィードリンクに対するトリミングすべきパラメータのマップ</td>\n</tr>\n<tr data-sourcepos=\"32:1-32:115\">\n<td data-sourcepos=\"32:2-32:30\"><code>feed_redirected_link.yaml</code></td>\n<td data-sourcepos=\"32:32-32:114\">フィードリンクに対するリダイレクト先リンクのマップ</td>\n</tr>\n</tbody>\n</table>\n<div class=\"code-block\" data-sourcepos=\"34:1-61:3\">\n<div class=\"code-filename\">\n<i class=\"fa fa-file-code-o\"></i>yaml</div>\n<div class=\"highlight\"><pre class=\"highlight yaml\"><code><span class=\"c1\"># feed.yaml</span>\n<span class=\"s\">nabinno/sports/feed_group_name</span><span class=\"pi\">:</span>\n  <span class=\"na\">tags</span><span class=\"pi\">:</span>\n    <span class=\"pi\">-</span> <span class=\"s\">ski</span>\n  <span class=\"na\">links</span><span class=\"pi\">:</span>\n    <span class=\"pi\">-</span> <span class=\"s\">http://rss.example.com/ski_feed.rss</span>\n    <span class=\"pi\">-</span> <span class=\"s\">http://rss.example.com/snowboard_feed.rss</span>\n    <span class=\"pi\">-</span> <span class=\"s\">http://ski-status.example.com/rss</span>\n\n<span class=\"c1\"># feed_excluded_link.yaml</span>\n<span class=\"pi\">-</span> <span class=\"s\">anti-ski.example.com</span>\n<span class=\"pi\">-</span> <span class=\"s\">awesome-snowboard.example.com</span>\n\n<span class=\"c1\"># feed_excluded_title.yaml</span>\n<span class=\"pi\">-</span> <span class=\"s\">queer</span>\n<span class=\"pi\">-</span> <span class=\"s\">two-planker</span>\n<span class=\"pi\">-</span> <span class=\"s\">beaver-tail</span>\n\n<span class=\"c1\"># feed_corrected_link.yaml</span>\n<span class=\"s\">amazon.com</span><span class=\"pi\">:</span>\n  <span class=\"pi\">-</span> <span class=\"s\">ref</span>\n  <span class=\"pi\">-</span> <span class=\"s\">ie</span>\n\n<span class=\"c1\"># feed_redirected_link.yaml</span>\n<span class=\"s\">ski-status.example.com</span><span class=\"pi\">:</span>\n  <span class=\"pi\">-</span> <span class=\"s\">Floki.find(fst, \".post__body a\")</span>\n</code></pre></div>\n</div>\n<h2 data-sourcepos=\"63:1-63:33\" id=\"2-2-0\" name=\"2-2-0\">\n<a class=\"anchor\" id=\"Elixirによる非同期処理\" name=\"Elixir%E3%81%AB%E3%82%88%E3%82%8B%E9%9D%9E%E5%90%8C%E6%9C%9F%E5%87%A6%E7%90%86\" href=\"#Elixir%E3%81%AB%E3%82%88%E3%82%8B%E9%9D%9E%E5%90%8C%E6%9C%9F%E5%87%A6%E7%90%86\" data-position=\"2-2-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"Elixirによる非同期処理\"> &gt; Elixirによる非同期処理</span></a>Elixirによる非同期処理</h2>\n<p data-sourcepos=\"64:1-64:162\">Elixirで非同期処理を行っているのですが、大きく分けて監視機構のSupervisorと非同期処理のTask.async_streamを使っています。</p>\n<h3 data-sourcepos=\"66:1-66:27\" id=\"2-2-1\" name=\"2-2-1\">\n<a class=\"anchor\" id=\"監視機構 Supervisor\" name=\"%E7%9B%A3%E8%A6%96%E6%A9%9F%E6%A7%8B%20Supervisor\" href=\"#%E7%9B%A3%E8%A6%96%E6%A9%9F%E6%A7%8B%20Supervisor\" data-position=\"2-2-1\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"監視機構 Supervisor\"> &gt; 監視機構 Supervisor</span></a>監視機構 Supervisor</h3>\n<p data-sourcepos=\"67:1-67:609\">まず、Supervisor。Elixirには監視機構Supervisorがあり、それが各ワーカーを子プロセスとして管理しています。ここではフィード読込とブクマは別々のワーカーで処理しますが、キャッシュが暖気処理を別ワーカーで行っているため再起動戦略は「失敗したイベントの中にあるすべての子プロセスを再起動」（ <code>one_for_all</code> ）にしてあります。再起動戦略の詳細は「<a href=\"https://elixirschool.com/ja/lessons/advanced/otp-supervisors/\" target=\"_blank\" rel=\"noopener noreferrer\">OTPスーパバイザ · Elixir School</a>」を参照下さい。</p>\n<p data-sourcepos=\"69:1-69:197\">下記のように <code>Supervisor.start_link</code> を <code>Keshikimi2.Application.start</code> に適用すると、アプリケーション開始（ <code>mix run</code> ）した時点で監視機構が起動されます。</p>\n<div class=\"code-block\" data-sourcepos=\"71:1-92:3\">\n<div class=\"code-filename\">\n<i class=\"fa fa-file-code-o\"></i>ex</div>\n<div class=\"highlight\"><pre class=\"highlight elixir\"><code><span class=\"no\">Supervisor</span><span class=\"o\">.</span><span class=\"n\">start_link</span><span class=\"p\">(</span>\n  <span class=\"p\">[</span>\n    <span class=\"ss\">:hackney_pool</span><span class=\"o\">.</span><span class=\"n\">child_spec</span><span class=\"p\">(</span><span class=\"ss\">:hatena_bookmark_pool</span><span class=\"p\">,</span> <span class=\"ss\">timeout:</span> <span class=\"mi\">15_000</span><span class=\"p\">,</span> <span class=\"ss\">max_connections:</span> <span class=\"mi\">100</span><span class=\"p\">),</span>\n    <span class=\"c1\"># @todo 当該ワーカーで暖気処理を行っていないので `one_for_one` にした場合、再起動時にほかに影響する</span>\n    <span class=\"n\">supervisor</span><span class=\"p\">(</span><span class=\"no\">Cachex</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"ss\">:feed</span><span class=\"p\">,</span> <span class=\"p\">[]]),</span>\n    <span class=\"n\">supervisor</span><span class=\"p\">(</span><span class=\"no\">Keshikimi2Feed</span><span class=\"o\">.</span><span class=\"no\">Registry</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">prefix</span><span class=\"p\">]),</span>\n\n    <span class=\"c1\"># フィード読込処理 (PubSub)</span>\n    <span class=\"n\">supervisor</span><span class=\"p\">(</span><span class=\"no\">Keshikimi2Feed</span><span class=\"o\">.</span><span class=\"no\">Subscriber</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">prefix</span><span class=\"p\">]),</span>\n    <span class=\"n\">worker</span><span class=\"p\">(</span><span class=\"no\">Keshikimi2Feed</span><span class=\"o\">.</span><span class=\"no\">Worker</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">prefix</span><span class=\"p\">]),</span>\n    <span class=\"n\">worker</span><span class=\"p\">(</span><span class=\"no\">Keshikimi2Feed</span><span class=\"o\">.</span><span class=\"no\">Publisher</span><span class=\"p\">,</span> <span class=\"p\">[[</span><span class=\"ss\">prefix:</span> <span class=\"n\">prefix</span><span class=\"p\">,</span> <span class=\"ss\">poll_interval:</span> <span class=\"mi\">3_000</span><span class=\"p\">]]),</span>\n\n    <span class=\"c1\"># ブクマ処理</span>\n    <span class=\"n\">worker</span><span class=\"p\">(</span><span class=\"no\">Keshikimi2</span><span class=\"o\">.</span><span class=\"no\">HatenaBookmark</span><span class=\"o\">.</span><span class=\"no\">AddEntry</span><span class=\"p\">,</span> <span class=\"p\">[</span>\n      <span class=\"p\">[</span><span class=\"ss\">prefix:</span> <span class=\"n\">prefix</span><span class=\"p\">,</span> <span class=\"ss\">poll_interval:</span> <span class=\"mi\">3_000</span><span class=\"p\">]</span>\n    <span class=\"p\">])</span>\n  <span class=\"p\">],</span>\n  <span class=\"ss\">strategy:</span> <span class=\"ss\">:one_for_all</span><span class=\"p\">,</span>\n  <span class=\"ss\">name:</span> <span class=\"n\">name</span><span class=\"p\">(</span><span class=\"n\">prefix</span><span class=\"p\">)</span>\n<span class=\"p\">)</span>\n</code></pre></div>\n</div>\n<h3 data-sourcepos=\"94:1-94:37\" id=\"2-2-2\" name=\"2-2-2\">\n<a class=\"anchor\" id=\"非同期処理 Task.async_stream\" name=\"%E9%9D%9E%E5%90%8C%E6%9C%9F%E5%87%A6%E7%90%86%20Task.async_stream\" href=\"#%E9%9D%9E%E5%90%8C%E6%9C%9F%E5%87%A6%E7%90%86%20Task.async_stream\" data-position=\"2-2-2\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"非同期処理 Task.async_stream\"> &gt; 非同期処理 Task.async_stream</span></a>非同期処理 Task.async_stream</h3>\n<p data-sourcepos=\"95:1-95:461\">次に、Task.async_stream。配列を引き回すリクエスト処理は <code>Task.async_stream</code> がうってつけです。下記ではキャッシュからブクマ対象になるフィードリンクを取り出し、除外処理、校正処理を加えて、ブクマのリクエストを出すという流れを組んでいます。Elixirでは、流れをひとまとめにして視覚的にわかりやすく非同期処理してくことができます。</p>\n<div class=\"code-block\" data-sourcepos=\"97:1-139:3\">\n<div class=\"code-filename\">\n<i class=\"fa fa-file-code-o\"></i>ex</div>\n<div class=\"highlight\"><pre class=\"highlight elixir\"><code><span class=\"no\">Cachex</span><span class=\"o\">.</span><span class=\"n\">keys!</span><span class=\"p\">(</span><span class=\"ss\">:feed</span><span class=\"p\">)</span>\n<span class=\"o\">|&gt;</span> <span class=\"no\">Enum</span><span class=\"o\">.</span><span class=\"n\">reject</span><span class=\"p\">(</span><span class=\"k\">fn</span> <span class=\"n\">key</span> <span class=\"o\">-&gt;</span>\n  <span class=\"n\">key</span> <span class=\"ow\">in</span> <span class=\"p\">[</span>\n    <span class=\"s2\">\"excluded_links\"</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"excluded_titles\"</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"corrected_links\"</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"redirected_links\"</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"feed_group\"</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"archived_links\"</span>\n  <span class=\"p\">]</span>\n<span class=\"k\">end</span><span class=\"p\">)</span>\n<span class=\"o\">|&gt;</span> <span class=\"no\">Task</span><span class=\"o\">.</span><span class=\"n\">async_stream</span><span class=\"p\">(</span>\n  <span class=\"k\">fn</span> <span class=\"n\">item_link</span> <span class=\"o\">-&gt;</span>\n    <span class=\"n\">with</span> <span class=\"p\">{</span><span class=\"ss\">:ok</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">item_title</span><span class=\"p\">,</span> <span class=\"n\">feed_tags</span><span class=\"p\">]}</span> <span class=\"o\">&lt;-</span> <span class=\"no\">Cachex</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"ss\">:feed</span><span class=\"p\">,</span> <span class=\"n\">item_link</span><span class=\"p\">),</span>\n         <span class=\"ss\">:ok</span> <span class=\"o\">&lt;-</span> <span class=\"n\">validate_all</span><span class=\"p\">(</span><span class=\"n\">item_link</span><span class=\"p\">,</span> <span class=\"n\">item_title</span><span class=\"p\">),</span>\n         <span class=\"n\">corrected_link</span> <span class=\"o\">&lt;-</span> <span class=\"n\">correct_all</span><span class=\"p\">(</span><span class=\"n\">item_link</span><span class=\"p\">),</span>\n         <span class=\"p\">{</span><span class=\"ss\">:ok</span><span class=\"p\">,</span> <span class=\"n\">payload</span><span class=\"p\">}</span> <span class=\"o\">&lt;-</span>\n           <span class=\"no\">FormData</span><span class=\"o\">.</span><span class=\"n\">create</span><span class=\"p\">(</span>\n             <span class=\"p\">%{</span>\n               <span class=\"ss\">url:</span> <span class=\"n\">corrected_link</span><span class=\"p\">,</span>\n               <span class=\"ss\">comment:</span> <span class=\"n\">feed_tags</span> <span class=\"o\">|&gt;</span> <span class=\"no\">Enum</span><span class=\"o\">.</span><span class=\"n\">map_join</span><span class=\"p\">(</span><span class=\"k\">fn</span> <span class=\"n\">tag</span> <span class=\"o\">-&gt;</span> <span class=\"s2\">\"[</span><span class=\"si\">#{</span><span class=\"n\">tag</span><span class=\"si\">}</span><span class=\"s2\">]\"</span> <span class=\"k\">end</span><span class=\"p\">),</span>\n               <span class=\"ss\">rks:</span> <span class=\"no\">System</span><span class=\"o\">.</span><span class=\"n\">get_env</span><span class=\"p\">(</span><span class=\"s2\">\"HATENA_BOOKMARK_RKS\"</span><span class=\"p\">),</span>\n               <span class=\"ss\">private:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n               <span class=\"ss\">keep_original_url:</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n               <span class=\"ss\">with_status_op:</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n               <span class=\"ss\">from:</span> <span class=\"s2\">\"inplace\"</span><span class=\"p\">,</span>\n               <span class=\"ss\">post_twitter:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n               <span class=\"ss\">post_evernote:</span> <span class=\"mi\">0</span>\n             <span class=\"p\">},</span>\n             <span class=\"ss\">:url_encoded</span><span class=\"p\">,</span>\n             <span class=\"ss\">get:</span> <span class=\"no\">false</span>\n           <span class=\"p\">)</span> <span class=\"k\">do</span>\n      <span class=\"n\">do_add_entries_to_hb</span><span class=\"p\">(</span><span class=\"n\">payload</span><span class=\"p\">)</span>\n      <span class=\"no\">Logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s2\">\"add entry: </span><span class=\"si\">#{</span><span class=\"n\">item_link</span><span class=\"si\">}</span><span class=\"s2\">\"</span><span class=\"p\">)</span>\n    <span class=\"k\">end</span>\n\n    <span class=\"n\">archive_link</span><span class=\"p\">(</span><span class=\"n\">item_link</span><span class=\"p\">)</span>\n  <span class=\"k\">end</span><span class=\"p\">,</span>\n  <span class=\"ss\">timeout:</span> <span class=\"mi\">15_000</span>\n<span class=\"p\">)</span>\n<span class=\"o\">|&gt;</span> <span class=\"no\">Stream</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">()</span>\n</code></pre></div>\n</div>\n<h1 data-sourcepos=\"141:1-141:8\" id=\"3-0-0\" name=\"3-0-0\">\n<a class=\"anchor\" id=\"WRAPUP\" name=\"WRAPUP\" href=\"#WRAPUP\" data-position=\"3-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"WRAPUP\"> &gt; WRAPUP</span></a>WRAPUP</h1>\n<p data-sourcepos=\"142:1-142:216\">Elixirの非同期処理を使うことではてなブックマークの運用がとても快適になりました。はてなブックマークとの今後の付き合い方は下記のように考えています。</p>\n<ul data-sourcepos=\"144:1-146:0\">\n<li data-sourcepos=\"144:1-144:65\">\n<strong>手動でブクマ:</strong> 気になった記事があるごとに</li>\n<li data-sourcepos=\"145:1-146:0\">\n<strong>ブクマの確認:</strong> 気になるタグごとにまとめて確認</li>\n</ul>\n<p data-sourcepos=\"147:1-147:239\">ブクマの確認については、例えば、CIでデプロイしている間に最近のGitHubの動向を確認したい場合は「<a href=\"http://b.hatena.ne.jp/nabinno/github\" target=\"_blank\" rel=\"noopener noreferrer\">nabinno/github</a>」をみる、という感じの運用です。</p>\n<p data-sourcepos=\"149:1-149:111\">融通が利かない点で途中運用が難しくなる気もしますが、しばらく回してみます。</p>\n","tags":["elixir","hatena-bookmark"],"updated_at":"2021-01-16T01:12:01+09:00","childPublishedDate":{"published_on":"2019-01-01T00:00:00.000Z"},"updated_by":{"name":"なびの👷","screen_name":"nabinno","icon":"https://img.esa.io/uploads/production/members/94286/icon/thumb_m_ef5f024307008aa399b91f87fa5f64e8.jpg"}},"relatedPosts":{"edges":[{"node":{"number":91,"relative_category":"blog/backend","fields":{"title":"Hardware-Accelerated GPU Scheduling機能を使ったWSL2はどのくらいパフォーマンスが向上するか","excerpt":"新しいPC端末を購入したところ「Hardware-Accerlarated GPU Scheduling」機能があることに気づきました。使用したところ気持ち速くなったように感じたのでどのくらいパフォーマンスが向上したか調べてみました。   > PROBLEMPROBLEM \n\n- システム設定で「Hardware-Accerlarated GPU Scheduling（HAGS）」機能を使ったところWSL2のパフォーマンスが体感的に速くなったように感じた 他の端末にもHAGSを展開していきたいので実際にどのらくらいパフォーマンスが向上するか検証したい \n- 他の端末にもHAGSを展開していきたいので実際にどのらくらいパフォーマンスが向上するか検証したい  > SOLUTIONSOLUTION \n\nと言うわけで、以前Phoronixによって書かれた「WSLとWSL2とのベンチマーク比較の記事」を参考にPhoronix Test SuiteでHAGSのオン・オフのベンチマーク比較を行います。  > 検証端末の環境検証端末の環境    Item Content     Processor AMD Ryzen 9 5900X 12-Core (12 Cores / 24 Threads)   Memory 52 GB   Disk 2 x 275GB Virtual Disk   OS Ubuntu 20.04   Kernel 5.4.72-microsoft-standard-WSL2 (x86_64)   Display Server X Server   Compiler GCC 9.3.0   File System ext4   System Layer wsl     > Phoronix Test SuiteをインストールするPhoronix Test Suiteをインストールする sh\n\nbrew install phoronix-test-suite sudo apt install php php-gd php-xml php-curl   > 実行するベンチマークテストを選定する実行するベンチマークテストを選定する \n\nまず実行可能なテストとテストスーツを確認します、テストスーツは関連テストのグループになります。 sh\n\nphoronix-test-suite list-available-tests phoronix-test-suite list-available-suite  \n\n今回は開発する際に関係がある下記のテストを選定しました。テストスーツは数時間では完了しないケースがあったので今回の対象から外しています。 \n\n- pts/build-gcc\n- pts/compress-gzip\n- pts/system-decompress-gzip\n- pts/gnupg\n- pts/mutex\n- pts/openssl\n- pts/git\n- pts/pybench\n- pts/nginx\n- pts/node-web-tooling  > ベンチマーク結果ベンチマーク結果    Item HAGSオン HAGSオフ     pts/build-gcc 717.39 sec 715.56 sec   pts/compress-gzip 29.10 sec 29.36 sec   pts/system-decompress-gzip 2.397 sec 2.427 sec   pts/mutex Lock Shared 15.2 sec 15.2 sec   pts/mutex Unlock spinlock 33.1 sec 33.4 sec   pts/mutex Unlock std::mutex 14.8 sec 14.7 sec   pts/mutex Semaphore Release And Acquire 8.44 sec 8.36 sec   pts/mutex Unlock pthread_mutex 8.45 sec 8.34 sec   pts/openssl 3704.3 sign/sec 3694 sign/sec   pts/git 39.01 sec 38.85 sec   pts/pybench 869 msec 877 msec   pts/nginx 70124.29 req/sec 71919.70 req/sec   pts/node-web-tooling 16.71 sec 17.01 sec     > WRAPUPWRAPUP \n\n残念ながらベンチマーク結果からHAGSのオンとオフの間に大きなパフォーマンスの変化は見られませんでした。通常の開発の場合はほぼ恩恵を受けられないと言って問題ないでしょう。 \n\n結論として、他の端末へのHAGSの展開はお薦めしません。不具合等の口コミも散見されるので使用端末との相性を見ながら導入するのが良さそうです。個人的にはChromeのハードウェアアクセラレーション機能との相性を見つつしばらく運用しようと思います。"},"name":"[2021-08-01]Hardware-Accelerated GPU Scheduling機能を使ったWSL2はどのくらいパフォーマンスが向上するか","tags":["wsl2","hags","windows-10"],"childPublishedDate":{"published_on":"2021-08-01T00:00:00.000Z","published_on_unix":1627776000}}},{"node":{"number":93,"relative_category":"blog/backend","fields":{"title":"AWS CloudTrail用のコスパの良いSIEMを探す","excerpt":"IT統制において証跡管理の充実という観点から、また、ゼロトラストの強化という観点からSIEMの導入が必要になってきた。今回はAWS CloudTrail用のSIEMについてざっと調べました。   > PROBLEMPROBLEM \n\n- AWS CloudTrailのログをセキュリティアカウントに集約しているが、深く監視しきれていない 可能ならアカウントが不審な操作をした場合にアラートを飛ばしたい 可能ならCloudTrail以外のIaaSリソースを監視対象にしたい NewRelicのように人のコストをかけずに管理したい \n- 可能ならアカウントが不審な操作をした場合にアラートを飛ばしたい\n- 可能ならCloudTrail以外のIaaSリソースを監視対象にしたい NewRelicのように人のコストをかけずに管理したい \n- NewRelicのように人のコストをかけずに管理したい  > SOLUTIONSOLUTION \n\nと言うわけで、コスパが良いと噂のSumo LogicとAzure Sentinelを比較評価します。  > Azure SentinelAzure Sentinel  > 料金料金 \n\n- Azure Sentinel の価格 | Microsoft Azure\n- 価格 - Azure Monitor | Microsoft Azure  > SIEMからCloudTrailへの接続方法SIEMからCloudTrailへの接続方法 \n\n1. 下記設定でLog Analyticsワークスペースを作成 サブスクリプション 無料試用版 リソース グループ production 名前 prod-sentinel 地域 東日本 \n2. サブスクリプション 無料試用版\n3. リソース グループ production\n4. 名前 prod-sentinel\n5. 地域 東日本\n6. [ワークスペースprod-sentinel - データコネクタ] にて [アマゾンウェブサービス] コネクタページを開く\n7. [AWSアカウント - IAM - ロール] にて下記設定で [別のAWSアカウント] を作成 アカウントID {Microsoft account ID} オプション 外部IDが必要 をチェック 外部ID {外部ID (ワークスペースID)} パーミッションポリシーを適用 AWSCloudTrailReadOnlyAccess ロール名 AzureSentinel ※ Cf. AWS CloudTrail を Azure Sentinel に接続する | Microsoft Docs アマゾン ウェブ サービス (AWS) のための MCAS と Azure Sentinel - Azure Solution Ideas | Microsoft Docs Security-JAWS 第21回レポート #secjaws #secjaws21 #jawsug | DevelopersIO \n8. アカウントID {Microsoft account ID}\n9. オプション 外部IDが必要 をチェック 外部ID {外部ID (ワークスペースID)} \n10. 外部IDが必要 をチェック\n11. 外部ID {外部ID (ワークスペースID)}\n12. パーミッションポリシーを適用 AWSCloudTrailReadOnlyAccess\n13. ロール名 AzureSentinel\n14. ※ Cf. AWS CloudTrail を Azure Sentinel に接続する | Microsoft Docs アマゾン ウェブ サービス (AWS) のための MCAS と Azure Sentinel - Azure Solution Ideas | Microsoft Docs Security-JAWS 第21回レポート #secjaws #secjaws21 #jawsug | DevelopersIO \n15. AWS CloudTrail を Azure Sentinel に接続する | Microsoft Docs\n16. アマゾン ウェブ サービス (AWS) のための MCAS と Azure Sentinel - Azure Solution Ideas | Microsoft Docs\n17. Security-JAWS 第21回レポート #secjaws #secjaws21 #jawsug | DevelopersIO  > SIEM機能 (AWS CloudTrail)SIEM機能 (AWS CloudTrail) \n\n- デフォルト監視対象 時間経過に伴うイベントアラート 悪意ある可能性があるイベント 最近のインシデント データソースの異常 \n- 時間経過に伴うイベントアラート\n- 悪意ある可能性があるイベント\n- 最近のインシデント\n- データソースの異常\n- ログクエリ Audit Network Security \n- Audit\n- Network\n- Security\n- 脅威管理 インシデント ブック ... 簡易な分析情報を提供 AWSネットワークアクティビティ ... SG、ネットワークACL、IGW、ELB、VPC、サブネット、NIの作成・更新・削除など、AWS ネットワーク関連のリソースアクティビティに関する分析情報を得ます。 AWSユーザーアクティビティ ... 失敗したサインイン試行、IP アドレス、リージョン、ユーザー エージェント、ID の種類、また想定されたロールを持つ悪意のある可能性があるユーザー アクティビティなど、AWS ユーザー アクティビティに関する分析情報を得ます。 ハンティング ... 脅威判定となるログクエリを提供 Changes made to AWS IAM policy Tracking Privileged Account Rare Activity Exploit and Pentest Framework User Agent IAM Privilege Escalation by Instance Profile attachment Privileged role attached to Instance Suspicious credential token access of valid IAM Roles Unused or Unsupported Cloud Regions ノートブック ... Jupyter Notebookによる分析を提供 \n- インシデント\n- ブック ... 簡易な分析情報を提供 AWSネットワークアクティビティ ... SG、ネットワークACL、IGW、ELB、VPC、サブネット、NIの作成・更新・削除など、AWS ネットワーク関連のリソースアクティビティに関する分析情報を得ます。 AWSユーザーアクティビティ ... 失敗したサインイン試行、IP アドレス、リージョン、ユーザー エージェント、ID の種類、また想定されたロールを持つ悪意のある可能性があるユーザー アクティビティなど、AWS ユーザー アクティビティに関する分析情報を得ます。 \n- AWSネットワークアクティビティ ... SG、ネットワークACL、IGW、ELB、VPC、サブネット、NIの作成・更新・削除など、AWS ネットワーク関連のリソースアクティビティに関する分析情報を得ます。\n- AWSユーザーアクティビティ ... 失敗したサインイン試行、IP アドレス、リージョン、ユーザー エージェント、ID の種類、また想定されたロールを持つ悪意のある可能性があるユーザー アクティビティなど、AWS ユーザー アクティビティに関する分析情報を得ます。\n- ハンティング ... 脅威判定となるログクエリを提供 Changes made to AWS IAM policy Tracking Privileged Account Rare Activity Exploit and Pentest Framework User Agent IAM Privilege Escalation by Instance Profile attachment Privileged role attached to Instance Suspicious credential token access of valid IAM Roles Unused or Unsupported Cloud Regions \n- Changes made to AWS IAM policy\n- Tracking Privileged Account Rare Activity\n- Exploit and Pentest Framework User Agent\n- IAM Privilege Escalation by Instance Profile attachment\n- Privileged role attached to Instance\n- Suspicious credential token access of valid IAM Roles\n- Unused or Unsupported Cloud Regions\n- ノートブック ... Jupyter Notebookによる分析を提供\n- ソリューション ... 外部のエンドポイントセキュリティツールと連携することが可能 Trend Micro Apex One McAfee Network Security Platform \n- Trend Micro Apex One\n- McAfee Network Security Platform  > Sumo LogicSumo Logic  > 料金料金 \n\n- Sumo Logic 料金表  > SIEMからCloudTrailへの接続方法SIEMからCloudTrailへの接続方法 \n\n1. [AWSアカウントSecurity - S3] にてバケット cloudtrail-accumulativelogs-{account-id} を下記設定にて作成 パブリックアクセスをすべてブロック オフ バケットポリシー json{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"AWSCloudTrailAclCheck20150319\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"s3:GetBucketAcl\", \"Resource\": \"arn:aws:s3:::cloudtrail-accumulativelogs-{account-id}\" }, { \"Sid\": \"AWSCloudTrailWrite20150319\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"s3:PutObject\", \"Resource\": \"arn:aws:s3:::cloudtrail-accumulativelogs-{account-id}/AWSLogs/{organization-id}/*\", \"Condition\": { \"StringEquals\": { \"s3:x-amz-acl\": \"bucket-owner-full-control\" } } } ] } \n2. パブリックアクセスをすべてブロック オフ\n3. バケットポリシー json{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"AWSCloudTrailAclCheck20150319\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"s3:GetBucketAcl\", \"Resource\": \"arn:aws:s3:::cloudtrail-accumulativelogs-{account-id}\" }, { \"Sid\": \"AWSCloudTrailWrite20150319\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"s3:PutObject\", \"Resource\": \"arn:aws:s3:::cloudtrail-accumulativelogs-{account-id}/AWSLogs/{organization-id}/*\", \"Condition\": { \"StringEquals\": { \"s3:x-amz-acl\": \"bucket-owner-full-control\" } } } ] } \n4. [親AWSアカウント - KMS] にて下記設定でKSMを作成 キーのタイプ 対称 キーマテリアルオリジン KMS リージョンごと 単一リージョン エイリアス名 cloudtrail-kms キーポリシー json{ \"Version\": \"2012-10-17\", \"Id\": \"Key policy created by CloudTrail\", \"Statement\": [ { \"Sid\": \"Enable IAM User Permissions\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": \"kms:*\", \"Resource\": \"*\" }, { \"Sid\": \"Allow CloudTrail to encrypt logs\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"kms:GenerateDataKey*\", \"Resource\": \"*\", \"Condition\": { \"StringLike\": { \"kms:EncryptionContext:aws:cloudtrail:arn\": \"arn:aws:cloudtrail:*:{account-id}:trail/*\" } } }, { \"Sid\": \"Allow CloudTrail to describe key\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"kms:DescribeKey\", \"Resource\": \"*\" }, { \"Sid\": \"Allow principals in the account to decrypt log files\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": [ \"kms:Decrypt\", \"kms:ReEncryptFrom\" ], \"Resource\": \"*\", \"Condition\": { \"StringEquals\": { \"kms:CallerAccount\": \"{account-id}\" }, \"StringLike\": { \"kms:EncryptionContext:aws:cloudtrail:arn\": \"arn:aws:cloudtrail:*:{account-id}:trail/*\" } } }, { \"Sid\": \"Allow alias creation during setup\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": \"kms:CreateAlias\", \"Resource\": \"*\", \"Condition\": { \"StringEquals\": { \"kms:CallerAccount\": \"{account-id}\", \"kms:ViaService\": \"ec2.ap-northeast-1.amazonaws.com\" } } }, { \"Sid\": \"Enable cross account log decryption\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": [ \"kms:Decrypt\", \"kms:ReEncryptFrom\" ], \"Resource\": \"*\", \"Condition\": { \"StringEquals\": { \"kms:CallerAccount\": \"{account-id}\" }, \"StringLike\": { \"kms:EncryptionContext:aws:cloudtrail:arn\": \"arn:aws:cloudtrail:*:{account-id}:trail/*\" } } } ] } \n5. キーのタイプ 対称\n6. キーマテリアルオリジン KMS\n7. リージョンごと 単一リージョン\n8. エイリアス名 cloudtrail-kms\n9. キーポリシー json{ \"Version\": \"2012-10-17\", \"Id\": \"Key policy created by CloudTrail\", \"Statement\": [ { \"Sid\": \"Enable IAM User Permissions\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": \"kms:*\", \"Resource\": \"*\" }, { \"Sid\": \"Allow CloudTrail to encrypt logs\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"kms:GenerateDataKey*\", \"Resource\": \"*\", \"Condition\": { \"StringLike\": { \"kms:EncryptionContext:aws:cloudtrail:arn\": \"arn:aws:cloudtrail:*:{account-id}:trail/*\" } } }, { \"Sid\": \"Allow CloudTrail to describe key\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudtrail.amazonaws.com\" }, \"Action\": \"kms:DescribeKey\", \"Resource\": \"*\" }, { \"Sid\": \"Allow principals in the account to decrypt log files\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": [ \"kms:Decrypt\", \"kms:ReEncryptFrom\" ], \"Resource\": \"*\", \"Condition\": { \"StringEquals\": { \"kms:CallerAccount\": \"{account-id}\" }, \"StringLike\": { \"kms:EncryptionContext:aws:cloudtrail:arn\": \"arn:aws:cloudtrail:*:{account-id}:trail/*\" } } }, { \"Sid\": \"Allow alias creation during setup\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": \"kms:CreateAlias\", \"Resource\": \"*\", \"Condition\": { \"StringEquals\": { \"kms:CallerAccount\": \"{account-id}\", \"kms:ViaService\": \"ec2.ap-northeast-1.amazonaws.com\" } } }, { \"Sid\": \"Enable cross account log decryption\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"*\" }, \"Action\": [ \"kms:Decrypt\", \"kms:ReEncryptFrom\" ], \"Resource\": \"*\", \"Condition\": { \"StringEquals\": { \"kms:CallerAccount\": \"{account-id}\" }, \"StringLike\": { \"kms:EncryptionContext:aws:cloudtrail:arn\": \"arn:aws:cloudtrail:*:{account-id}:trail/*\" } } } ] } \n10. [親AWSアカウント - CloudTrail] にて下記設定で証跡を作成 全般的な詳細 証跡名 cloudtrail-logs 組織に証跡を適用 はい ストレージの場所 既存のS3バケットを使用する 証跡ログバケット名 cloudtrail-accumulativelogs-{account-id} ログファイルのSSE-KMS暗号化 有効 カスタマー管理のAWS KMSキー 新規 AWS KMSエイリアス arn:aws:kms:{region}:{account-id}:key/{kms-id} ログファイルの検証 有効 管理イベント APIアクティビティ すべて \n11. 全般的な詳細 証跡名 cloudtrail-logs 組織に証跡を適用 はい ストレージの場所 既存のS3バケットを使用する 証跡ログバケット名 cloudtrail-accumulativelogs-{account-id} ログファイルのSSE-KMS暗号化 有効 カスタマー管理のAWS KMSキー 新規 AWS KMSエイリアス arn:aws:kms:{region}:{account-id}:key/{kms-id} ログファイルの検証 有効 \n12. 証跡名 cloudtrail-logs\n13. 組織に証跡を適用 はい\n14. ストレージの場所 既存のS3バケットを使用する\n15. 証跡ログバケット名 cloudtrail-accumulativelogs-{account-id}\n16. ログファイルのSSE-KMS暗号化 有効\n17. カスタマー管理のAWS KMSキー 新規\n18. AWS KMSエイリアス arn:aws:kms:{region}:{account-id}:key/{kms-id}\n19. ログファイルの検証 有効\n20. 管理イベント APIアクティビティ すべて \n21. APIアクティビティ すべて\n22. [Sumo Logic - Setup Wizard - Start streaming data to Sumo Logic - CloudTrail] にて下記設定でCloudTrailデータタイプを作成 Source Category aws/cloudtrail S3 Bucket S3 Bucket Name cloudtrail-accumulativelogs-{account-id} Path Expression AWSLogs/{organization-id}/* S3 Region Asia Pacific (Tokyo) How do you want the user to access the S3 Bucket? Role-based access 指定されたCFnテンプレートでIAMロールを作成 \n23. Source Category aws/cloudtrail\n24. S3 Bucket S3 Bucket Name cloudtrail-accumulativelogs-{account-id} Path Expression AWSLogs/{organization-id}/* S3 Region Asia Pacific (Tokyo) How do you want the user to access the S3 Bucket? Role-based access 指定されたCFnテンプレートでIAMロールを作成 \n25. S3 Bucket Name cloudtrail-accumulativelogs-{account-id}\n26. Path Expression AWSLogs/{organization-id}/*\n27. S3 Region Asia Pacific (Tokyo)\n28. How do you want the user to access the S3 Bucket? Role-based access 指定されたCFnテンプレートでIAMロールを作成 \n29. 指定されたCFnテンプレートでIAMロールを作成  > SIEM機能 (AWS CloudTrail)SIEM機能 (AWS CloudTrail) \n\nデフォルト監視対象 \n\n- Console Logins Geo Location of All Users Login Events By User Logins Over Time Logins from Multiple IP Logins from Outside the USA Outlier - Success Login Outlier - Failed Login Login Results - One Day Time Comparison Logins without MFA \n- Geo Location of All Users\n- Login Events By User\n- Logins Over Time\n- Logins from Multiple IP\n- Logins from Outside the USA\n- Outlier - Success Login\n- Outlier - Failed Login\n- Login Results - One Day Time Comparison\n- Logins without MFA\n- Network and Security Authorization Failures from All Countries Network and Security Events Over Time Authorization Failures Over Time Network ACL with All Allowed Ingress/Egress Recent Authorization Failures Recent Security Group and Network ACL Changes Created and Deleted Network and Security Events Short Lived Critical Operations \n- Authorization Failures from All Countries\n- Network and Security Events Over Time\n- Authorization Failures Over Time\n- Network ACL with All Allowed Ingress/Egress\n- Recent Authorization Failures\n- Recent Security Group and Network ACL Changes\n- Created and Deleted Network and Security Events\n- Short Lived Critical Operations\n- Operations Action Events Requested AWS Services Over Time Events by AWS Region Recent Elastic IP Address Operations Created Resources Over Time Deleted Resources Over Time \n- Action Events\n- Requested AWS Services Over Time\n- Events by AWS Region\n- Recent Elastic IP Address Operations\n- Created Resources Over Time\n- Deleted Resources Over Time\n- Overview Geo Location of All Users Created Resources Deleted Resources Over Time Top 10 Users Failed Logins Created and Deleted Network and Security Events \n- Geo Location of All Users\n- Created Resources\n- Deleted Resources Over Time\n- Top 10 Users\n- Failed Logins\n- Created and Deleted Network and Security Events\n- S3 Public Objects and Buckets New Public Objects New Public Object by Object-Bucket New Public Objects Table Public Buckets Public Buckets Table Modified Public Objects Modified Public Objects by Object-Buket Modified Public Objects Table \n- New Public Objects\n- New Public Object by Object-Bucket\n- New Public Objects Table\n- Public Buckets\n- Public Buckets Table\n- Modified Public Objects\n- Modified Public Objects by Object-Buket\n- Modified Public Objects Table\n- User Monitoring Geo Location of All Users Top 10 Users Launched and Terminated Instances by User Administrative Activities Over Time Top 10 Activities by Administrative User Recent Activity by Administrative Users \n- Geo Location of All Users\n- Top 10 Users\n- Launched and Terminated Instances by User\n- Administrative Activities Over Time\n- Top 10 Activities by Administrative User\n- Recent Activity by Administrative Users  > 総評総評  > 使用コスト使用コスト \n\n初期導入の段階ではSumo LogicよりAzure Sentinelの方が倍のコストがかかります。    ログ取込量/日 Azure Sentinel月額 Sumo Logic月額     100MB 2,396 JPY 0 USD   500MB 11,978 JPY 0 USD   3GB 71,870 JPY 332 USD    \n\n※ Azure Sentinelの内訳は「 ((GB当たりのAzure Sentinel取込量347.20円) + (GB当たりのLog Analytics取込量451.36円) * 取込量GB 」  > 導入コスト導入コスト \n\n一度の設定で完了するSumo Logicの方が導入コストが低いです。Azure SentinelはIAMロールのみで済むという点で導入は楽ですがAWSアカウントごとに設定する必要があるので手離れが悪いです。  > SIEM機能SIEM機能 \n\nAzure Sentinelの方が分析機能が充実しています。Sumo Logicが大まかな脅威をログクエリからしか拾えないのに対し、Azure Sentinelは細かな脅威判定をログクエリで提供しているのに加え、Jupyter Notebookや外部のエンドポイントセキュリティツールを提供しています。また、デフォルトの監視対象も時間経過に伴うイベントアラート、悪意ある可能性があるイベント、最近のインシデント等必要十分な情報を提供しています。 \n\nまた、対象のデータソースはAzure SentinelがAWS CloudTrail、Google Workspace、Office 365、Azure AD等と幅広く用意しているのに対し、Sumo LogicはSIEMという観点では実質AWS CloudTrail専用のツールに落ち着いています。  > WRAPUPWRAPUP \n\nメインプロダクトがまだ2-3しかない状況でSIEMをAWSだけに限定する場合はSumo Logicで十分でしょう。使用コスト、導入コストともに低く抑えることができるので、しばらくはSumo Logicで運用し、プロダクトがスケールする段階でAzure Sentinelを移行するのが現実的だと思いました。"},"name":"[2021-08-15]AWS CloudTrail用のコスパの良いSIEMを探す","tags":["siem","aws-cloudtrail","azure-sentinel","sumo-logic"],"childPublishedDate":{"published_on":"2021-08-15T00:00:00.000Z","published_on_unix":1628985600}}},{"node":{"number":89,"relative_category":"blog/backend","fields":{"title":"imi-enrichment-addressは住所のバリデーションチェックでどの程度使えるか","excerpt":"コロナ禍であらゆる流通がオンラインに移行する中、正しい住所を使うことはいっそう求められています。ユーザーが配送用に住所を入力する時そのデータが正しいとどうやって判定するのでしょうか。今回はOSSライブラリimi-enrichment-addressが住所のバリデーションチェックでどの程度使えるか検証してみました。   > PROBLEMPROBLEM \n\n- 住所の不備が至るところで起きている 特に町名番地の抜けもれや不備が多くこの点をどうにか拾いたい 可能ならユーザーの入力時点でFEあるいはBE側でバリデーションチェックしたい まずはOSSのライブラリで検証したい \n- 特に町名番地の抜けもれや不備が多くこの点をどうにか拾いたい\n- 可能ならユーザーの入力時点でFEあるいはBE側でバリデーションチェックしたい まずはOSSのライブラリで検証したい \n- まずはOSSのライブラリで検証したい  > SOLUTIONSOLUTION \n\nというわけで、昨年（2020年）経産省IMI（情報共有基盤）から公開された住所変換コンポーネント「IMI-Tool-Project/imi-enrichment-address」がバリデーションチェックでどの程度使えるか検証します。  > imi-enrichment-addressとはimi-enrichment-addressとは \n\n経産省IMIツールプロジェクトで公開された住所変換コンポーネントです。CLIとサーバーが用意されていますが、今回はCLIを見ていきます。 \n\nヘルプを見ると住所を引数として渡すことで処理されることが分かります。 sh\n\n$ npm install -g https://info.gbiz.go.jp/tools/imi_tools/resource/imi-enrichment-address/imi-enrichment-address-2.0.0.tgz $ imi-enrichment-address --help imi-enrichment-address 住所文字列をもとに住所型・場所型の情報を補完します オプション -h, --help このヘルプを表示します -f, --file file 変換対象とする JSON ファイル -s, --string string 変換対象とする住所文字列 -i, --indent number 出力する JSON のインデント (default 2) 実行例 ヘルプの表示 $ imi-enrichment-address -h 文字列の処理 $ imi-enrichment-address -s 霞が関2 ファイルの処理 $ imi-enrichment-address input.json 標準入力の処理 $ cat input.json | imi-enrichment-address  \n\n実行すると正確な住所を渡したときと不正確な住所を渡したときで異なった結果を返すことが分かります。今回はこの正確・不正確の異なった結果を利用して検証していこうと思います。 sh\n\n$ imi-enrichment-address -s 長野県長野市大字長野旭町1108 { \"@context\": \"https://imi.go.jp/ns/core/context.jsonld\", \"@type\": \"場所型\", \"住所\": { \"@type\": \"住所型\", \"表記\": \"長野県長野市大字長野旭町1108\", \"都道府県\": \"長野県\", \"都道府県コード\": \"http://data.e-stat.go.jp/lod/sac/C20000\", \"市区町村\": \"長野市\", \"市区町村コード\": \"http://data.e-stat.go.jp/lod/sac/C20201\", \"町名\": \"大字長野\" }, \"地理座標\": { \"@type\": \"座標型\", \"緯度\": \"36.674892\", \"経度\": \"138.178449\" } } $ imi-enrichment-address -s 長野県長野市旭町1108 { \"@context\": \"https://imi.go.jp/ns/core/context.jsonld\", \"@type\": \"場所型\", \"住所\": { \"@type\": \"住所型\", \"表記\": \"長野県長野市旭町1108\", \"都道府県\": \"長野県\", \"都道府県コード\": \"http://data.e-stat.go.jp/lod/sac/C20000\", \"市区町村\": \"長野市\", \"市区町村コード\": \"http://data.e-stat.go.jp/lod/sac/C20201\" }, \"メタデータ\": { \"@type\": \"文書型\", \"説明\": \"該当する町名が見つかりません\" } }  \n\nなお、GitHubコードを見るとimi-enrichment-addressは街区レベル位置参照情報を利用して実装しています。このことを考えるとバリデーションチェックで積極的につかうのは難しく、ユースケースとしては下記2点に落ち着くと考えます。 \n\n- ユーザーに住所の再確認を促す\n- 入力後の住所不備について人が目検で確認する前段階で利用  > 検証用データ検証用データ \n\nさて、検証に進みましょう。imi-enrichment-addressで検証するデータは簡易に使える住所.jp、その中の事業所住所22402件を使います。他にも検証データはありますが、コストもそれほどかけられないのでコマンドだけで完結するものを選んでいます。 sh\n\n$ curl -sSL http://jusyo.jp/downloads/new/csv/csv_zenkoku.zip -o csv_zenkoku.zip $ unzip csv_zenkoku.zip $ go get github.com/mithrandie/csvq $ csvq -f CSV \"SELECT COUNT(*) FROM zenkoku WHERE 事業所住所 IS NOT NULL\" COUNT(*) 22402   > imi-enrichment-addressで検証用データを確認するimi-enrichment-addressで検証用データを確認する \n\n今回実行したCLIはNodeJSであることと数時間で処理できるという点で逐次で済ませました。 sh\n\n$ for i in $( csvq -f CSV \"SELECT 都道府県,市区町村,事業所住所 FROM zenkoku WHERE 事業所住所 IS NOT NULL\" \\ | sed 's/,//g' \\ | tail +2 \\ ); do imi-enrichment-address -s $i \\ | jq -r ' [ .[\"住所\"][\"表記\"], ( if .[\"地理座標\"] != null then true else false end ), .[\"メタデータ\"][\"説明\"] ] | @csv ' >>output.csv; done &   > バリデーションチェックの結果を確認するバリデーションチェックの結果を確認する \n\nimi-enrichment-addressの出力結果を確認したところ全国で9.25%が無効、下記の通り町名番地の表記揺れに弱いことが分かりました。特に町字（まちあざ）省略によるバリデーションエラーの比率が高く、青森、長野、沖縄等複数の県の住所が実用に耐えない結果となりました。 \n\nバリデーションエラーになった原因 \n\n- 各地方の字・大字の省略\n- 京都の通り上る・下るの表記\n- 北海道の条、線の表記揺れ\n- 茨城、岐阜等の町名省略\n- 茨城、神奈川、岐阜、石川等の区画整理地    都道府県 無効割合（%） 備考     青森県 54.42 字省略により無効   長野県 44.28 字省略により無効   沖縄県 43.55 字省略により無効   大分県 38.96 字省略により無効   京都府 36.86 字省略、通りにより無効   佐賀県 33.33 字省略により無効   奈良県 29.94 字省略により無効   福島県 29.18 字省略により無効   宮崎県 27.71 字省略により無効   埼玉県 23.08 字省略により無効   山口県 22.65 字省略により無効   和歌山県 17.78 字省略により無効   群馬県 17.08 字省略、ノ町により無効   茨城県 15.51 字省略、町名省略、区画整理により無効   熊本県 14.89 字省略により無効   山形県 14.38 字省略により無効   北海道 13.76 字省略、条、線により無効   栃木県 13.6 字省略により無効   新潟県 13.19 字省略により無効   鳥取県 9.57 字省略により無効   全国 9.25    福岡県 9 字省略により無効   三重県 7.74 字省略により無効   愛知県 7.4 字省略により無効   鹿児島県 7.09 字省略により無効   山梨県 6.8 字省略により無効   宮城県 6.37 字省略により無効   岩手県 6.28 字省略により無効   岐阜県 5.67 字省略、町名省略、区画整理により無効   香川県 4.71 字省略により無効   石川県 4.7 字省略、区画整理により無効   愛媛県 4.39 字省略により無効   秋田県 4.17 字省略により無効   滋賀県 3.76 字省略により無効   広島県 3.74 字省略により無効   高知県 3.38 字省略により無効   大阪府 3.28 字省略により無効   兵庫県 2.71 字省略により無効   島根県 2.04 字省略により無効   岡山県 1.81 字省略により無効   神奈川県 1.72 字省略、区画整理により無効   徳島県 1.64 字省略により無効   富山県 1.14 字省略により無効   静岡県 1.06 字省略、町名省略、区画整理により無効   東京都 0.89 字省略により無効   福井県 0.71 字省略により無効   千葉県 0.64 字省略により無効   長崎県 0      > WRAPUPWRAPUP \n\nimi-enrichment-addressは町名番地の判定に素の街区レベル位置参照情報を使用しているため、町字（まちあざ）の省略に弱いことが分かりました。 \n\n- ユーザーに住所の再確認を促す\n- 入力後の住所不備について人が目検で確認する前段階で利用 \n\nまず、想定したユースケースの内1つ「ユーザーに住所の再確認を促す」については、配送で使う住所の場合「町字の省略は影響ない」ので機能として適切ではありません。ユーザーが東京に集中している場合は関係ないですが、「町字が存在するさいたま市、川崎市、名古屋市、広島市、北九州市、福岡市、熊本市等の政令指定都市」や長野市のように住所が町字の組み合わせで2つ以上存在する都市の場合、使い勝手の悪い機能となります。 \n\n次に「入力後の住所不備について人が目検で確認する前段階で利用」については多少は有効に機能するでしょう。ただし、町字が多い地域では上記同様に使い勝手が悪くなります。 \n\n今回の検証の結果、現状の仕様ではimi-enrichment-addressを使うケースは限定せざるを得ず、一旦使用を見送りとします。とは言え、街区レベル位置参照情報にある町名番地から町字を除けば活用範囲が広がる可能性も確認できました。幸いなことにライブラリはMITライセンスで公開されています。"},"name":"[2021-07-24]imi-enrichment-addressは住所のバリデーションチェックでどの程度使えるか","tags":["imi-enrichment-address","mlit-isj"],"childPublishedDate":{"published_on":"2021-07-24T00:00:00.000Z","published_on_unix":1627084800}}}]}},"pageContext":{"number":62}},"staticQueryHashes":[]}