{"componentChunkName":"component---src-templates-post-tsx","path":"/posts/90","result":{"data":{"esaPost":{"number":90,"relative_category":"blog/backend","fields":{"title":"yubinbango-dataをどうやって生成するか","excerpt":"郵便番号から住所を補完するライブラリ「yubinbango」を継続的に利用するにあたり、当該ライブラリが参照している郵便データ「yubinbango-data」を自前でメンテナンスできるか確認します。   > PROBLEMPROBLEM \n\n- 「yubinbango/yubinbango」を利用するにあたり「yubinbango/yubinbango-data」の更新が継続的に行われるかサービス継続性の懸念がある そこで自前でメンテナンスをする場合の対処方法を事前に知っておきたい \n- そこで自前でメンテナンスをする場合の対処方法を事前に知っておきたい  > SOLUTIONSOLUTION \n\nというわけで、yubinbango-dataの中身であるken_all.csvとjigyosyo.csvを安定して変換する方法を確認します。  > ken_all.csvを正規化するken_all.csvを正規化する \n\nyubinbango-dataのken_all.csvの部分はアイビスが提供しているzipcloudを参照しているようなので、そちらに合わせて利用します。 sh\n\nsudo apt install nkf { curl -sSL \"http://zipcloud.ibsnet.co.jp/zipcodedata/download?di=1625040649647\" -o ./x_ken_all.zip; unzip -p x_ken_all.zip | nkf -w; rm x_ken_all.zip } >ken_all.csv  \n\nzipcloudを使うことに抵抗がある場合はgokenallもありますが、正規化によって一つの郵便番号に複数の町名番地が存在するため郵便番号をキーとするyubinbango-dataに変換する際には工夫が必要です。 sh\n\ngo get github.com/oirik/gokenall/cmd/kenall { kenall download -x | kenall normalize } >ken_all.csv   > jigyosyo.csvを取得するjigyosyo.csvを取得する \n\njigyosyo.csvは特に正規化は必要ないです。 sh\n\n{ curl -sSL https://www.post.japanpost.jp/zipcode/dl/jigyosyo/zip/jigyosyo.zip -o ./jigyosyo.zip; unzip -p jigyosyo.zip | nkf -w; rm jigyosyo.zip } >jigyosyo.csv   > yubinbango-dataを生成するyubinbango-dataを生成する \n\nken_all.csvとjigyosyo.csvをUNIONしてjqで郵便番号をキーとしたオブジェクトに変換します。一部buildingカラムがnullを持っておりyubinbango-dataと異なる部分はありますが、大凡同等の状態にまで持っていくことが出来ました。 sh\n\nbrew install noborus/tap/trdsql for i in {001..999}; do trdsql -ojson \" SELECT * FROM ( SELECT c3 zip, c8 city, c9 town, NULL building FROM ken_all.csv UNION SELECT c8 zip, c5 city, c6 town, c7 building FROM jigyosyo.csv ) WHERE SUBSTRING(zip,0,4) = '$i' ORDER BY zip ASC \" \\ | jq --compact-output ' . | to_entries | map({ (.value.zip): [1, .value.city, .value.town, .value.building] }) | add ' \\ | sed -E 's/(.+?)/$yubin(\\1);/g' \\ >$i.js; done   > WRAPUPWRAPUP \n\n昔から何かと話題に上がるken_all.csvですが、正規化のサービスに加えCSV用SQLクライアントとjqの登場により思った以上に簡単に変換することができました。","thumbnail":"https://img.esa.io/uploads/production/attachments/16651/2021/07/25/97367/d69e2c83-0aae-4409-804a-7f7ee0ce456c.png"},"wip":false,"body_md":"郵便番号から住所を補完するライブラリ「yubinbango」を継続的に利用するにあたり、当該ライブラリが参照している郵便データ「yubinbango-data」を自前でメンテナンスできるか確認します。\r\n\r\n<img width=\"710\" alt=\"thumbnail\" src=\"https://img.esa.io/uploads/production/attachments/16651/2021/07/25/97367/d69e2c83-0aae-4409-804a-7f7ee0ce456c.png\">\r\n\r\n# PROBLEM\r\n- 「[yubinbango/yubinbango](https://github.com/yubinbango/yubinbango)」を利用するにあたり「[yubinbango/yubinbango-data](https://github.com/yubinbango/yubinbango-data)」の更新が継続的に行われるかサービス継続性の懸念がある\r\n    - そこで自前でメンテナンスをする場合の対処方法を事前に知っておきたい\r\n\r\n# SOLUTION\r\nというわけで、yubinbango-dataの中身である[ken_all.csvとjigyosyo.csv](https://www.post.japanpost.jp/zipcode/download.html)を安定して変換する方法を確認します。\r\n\r\n## ken_all.csvを正規化する\r\nyubinbango-dataのken_all.csvの部分はアイビスが提供している[zipcloud](http://zipcloud.ibsnet.co.jp)を参照しているようなので、そちらに合わせて利用します。\r\n```sh\r\nsudo apt install nkf\r\n{ \r\n  curl -sSL \"http://zipcloud.ibsnet.co.jp/zipcodedata/download?di=1625040649647\" -o ./x_ken_all.zip;\r\n  unzip -p x_ken_all.zip | nkf -w;\r\n  rm x_ken_all.zip\r\n} >ken_all.csv\r\n```\r\n\r\nzipcloudを使うことに抵抗がある場合は[gokenall](https://github.com/oirik/gokenall)もありますが、正規化によって一つの郵便番号に複数の町名番地が存在するため郵便番号をキーとするyubinbango-dataに変換する際には工夫が必要です。\r\n\r\n```sh\r\ngo get github.com/oirik/gokenall/cmd/kenall\r\n{ kenall download -x | kenall normalize } >ken_all.csv\r\n```\r\n\r\n## jigyosyo.csvを取得する\r\njigyosyo.csvは特に正規化は必要ないです。\r\n\r\n```sh\r\n{ \r\n  curl -sSL https://www.post.japanpost.jp/zipcode/dl/jigyosyo/zip/jigyosyo.zip -o ./jigyosyo.zip;\r\n  unzip -p jigyosyo.zip | nkf -w;\r\n  rm jigyosyo.zip\r\n} >jigyosyo.csv\r\n```\r\n\r\n## yubinbango-dataを生成する\r\nken_all.csvとjigyosyo.csvをUNIONしてjqで郵便番号をキーとしたオブジェクトに変換します。一部buildingカラムがnullを持っておりyubinbango-dataと異なる部分はありますが、大凡同等の状態にまで持っていくことが出来ました。\r\n\r\n```sh\r\nbrew install noborus/tap/trdsql\r\nfor i in {001..999}; do\r\n  trdsql -ojson \"\r\n    SELECT *\r\n    FROM (\r\n      SELECT c3 zip, c8 city, c9 town, NULL building FROM ken_all.csv\r\n      UNION SELECT c8 zip, c5 city, c6 town, c7 building FROM jigyosyo.csv\r\n    )\r\n    WHERE SUBSTRING(zip,0,4) = '$i'\r\n    ORDER BY zip ASC\r\n  \" \\\r\n  | jq --compact-output '\r\n    .\r\n    | to_entries\r\n    | map({ (.value.zip): [1, .value.city, .value.town, .value.building] })\r\n    | add\r\n  ' \\\r\n  | sed -E 's/(.+?)/$yubin(\\1);/g' \\\r\n  >$i.js;\r\ndone\r\n```\r\n\r\n# WRAPUP\r\n昔から何かと話題に上がるken_all.csvですが、正規化のサービスに加えCSV用SQLクライアントとjqの登場により思った以上に簡単に変換することができました。","body_html":"<p data-sourcepos=\"1:1-1:250\">郵便番号から住所を補完するライブラリ「yubinbango」を継続的に利用するにあたり、当該ライブラリが参照している郵便データ「yubinbango-data」を自前でメンテナンスできるか確認します。</p>\n<a href=\"https://img.esa.io/uploads/production/attachments/16651/2021/07/25/97367/d69e2c83-0aae-4409-804a-7f7ee0ce456c.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img width=\"710\" alt=\"thumbnail\" src=\"https://img.esa.io/uploads/production/attachments/16651/2021/07/25/97367/d69e2c83-0aae-4409-804a-7f7ee0ce456c.png\"></a>\n<h1 data-sourcepos=\"5:1-5:9\" id=\"1-0-0\" name=\"1-0-0\"><a class=\"anchor\" id=\"PROBLEM\" name=\"PROBLEM\" href=\"#PROBLEM\" data-position=\"1-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"PROBLEM\"> &gt; PROBLEM</span></a>PROBLEM</h1>\n<ul data-sourcepos=\"6:1-8:0\">\n<li data-sourcepos=\"6:1-8:0\">「<a href=\"https://github.com/yubinbango/yubinbango\" target=\"_blank\" rel=\"noopener noreferrer\">yubinbango/yubinbango</a>」を利用するにあたり「<a href=\"https://github.com/yubinbango/yubinbango-data\" target=\"_blank\" rel=\"noopener noreferrer\">yubinbango/yubinbango-data</a>」の更新が継続的に行われるかサービス継続性の懸念がある\n<ul data-sourcepos=\"7:5-8:0\">\n<li data-sourcepos=\"7:5-8:0\">そこで自前でメンテナンスをする場合の対処方法を事前に知っておきたい</li>\n</ul></li>\n</ul>\n<h1 data-sourcepos=\"9:1-9:10\" id=\"2-0-0\" name=\"2-0-0\"><a class=\"anchor\" id=\"SOLUTION\" name=\"SOLUTION\" href=\"#SOLUTION\" data-position=\"2-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"SOLUTION\"> &gt; SOLUTION</span></a>SOLUTION</h1>\n<p data-sourcepos=\"10:1-10:189\">というわけで、yubinbango-dataの中身である<a href=\"https://www.post.japanpost.jp/zipcode/download.html\" target=\"_blank\" rel=\"noopener noreferrer\">ken_all.csvとjigyosyo.csv</a>を安定して変換する方法を確認します。</p>\n<h2 data-sourcepos=\"12:1-12:32\" id=\"2-1-0\" name=\"2-1-0\"><a class=\"anchor\" id=\"ken_all.csvを正規化する\" name=\"ken_all.csvを正規化する\" href=\"#ken_all.csvを正規化する\" data-position=\"2-1-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"ken_all.csvを正規化する\"> &gt; ken_all.csvを正規化する</span></a>ken_all.csvを正規化する</h2>\n<p data-sourcepos=\"13:1-13:195\">yubinbango-dataのken_all.csvの部分はアイビスが提供している<a href=\"http://zipcloud.ibsnet.co.jp\" target=\"_blank\" rel=\"noopener noreferrer\">zipcloud</a>を参照しているようなので、そちらに合わせて利用します。</p>\n<div class=\"code-block\" data-sourcepos=\"14:1-21:3\"><div class=\"code-filename\"><i class=\"fa fa-file-code-o\"></i>sh</div><div class=\"highlight\"><pre class=\"highlight shell\"><code><span class=\"nb\">sudo </span>apt <span class=\"nb\">install </span>nkf\n<span class=\"o\">{</span> \n  curl <span class=\"nt\">-sSL</span> <span class=\"s2\">\"http://zipcloud.ibsnet.co.jp/zipcodedata/download?di=1625040649647\"</span> <span class=\"nt\">-o</span> ./x_ken_all.zip<span class=\"p\">;</span>\n  unzip <span class=\"nt\">-p</span> x_ken_all.zip | nkf <span class=\"nt\">-w</span><span class=\"p\">;</span>\n  <span class=\"nb\">rm </span>x_ken_all.zip\n<span class=\"o\">}</span> <span class=\"o\">&gt;</span>ken_all.csv\n</code></pre></div></div>\n<p data-sourcepos=\"23:1-23:296\">zipcloudを使うことに抵抗がある場合は<a href=\"https://github.com/oirik/gokenall\" target=\"_blank\" rel=\"noopener noreferrer\">gokenall</a>もありますが、正規化によって一つの郵便番号に複数の町名番地が存在するため郵便番号をキーとするyubinbango-dataに変換する際には工夫が必要です。</p>\n<div class=\"code-block\" data-sourcepos=\"25:1-28:3\"><div class=\"code-filename\"><i class=\"fa fa-file-code-o\"></i>sh</div><div class=\"highlight\"><pre class=\"highlight shell\"><code>go get github.com/oirik/gokenall/cmd/kenall\n<span class=\"o\">{</span> kenall download <span class=\"nt\">-x</span> | kenall normalize <span class=\"o\">}</span> <span class=\"o\">&gt;</span>ken_all.csv\n</code></pre></div></div>\n<h2 data-sourcepos=\"30:1-30:30\" id=\"2-2-0\" name=\"2-2-0\"><a class=\"anchor\" id=\"jigyosyo.csvを取得する\" name=\"jigyosyo.csvを取得する\" href=\"#jigyosyo.csvを取得する\" data-position=\"2-2-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"jigyosyo.csvを取得する\"> &gt; jigyosyo.csvを取得する</span></a>jigyosyo.csvを取得する</h2>\n<p data-sourcepos=\"31:1-31:54\">jigyosyo.csvは特に正規化は必要ないです。</p>\n<div class=\"code-block\" data-sourcepos=\"33:1-39:3\"><div class=\"code-filename\"><i class=\"fa fa-file-code-o\"></i>sh</div><div class=\"highlight\"><pre class=\"highlight shell\"><code><span class=\"o\">{</span> \n  curl <span class=\"nt\">-sSL</span> https://www.post.japanpost.jp/zipcode/dl/jigyosyo/zip/jigyosyo.zip <span class=\"nt\">-o</span> ./jigyosyo.zip<span class=\"p\">;</span>\n  unzip <span class=\"nt\">-p</span> jigyosyo.zip | nkf <span class=\"nt\">-w</span><span class=\"p\">;</span>\n  <span class=\"nb\">rm </span>jigyosyo.zip\n<span class=\"o\">}</span> <span class=\"o\">&gt;</span>jigyosyo.csv\n</code></pre></div></div>\n<h2 data-sourcepos=\"41:1-41:33\" id=\"2-3-0\" name=\"2-3-0\"><a class=\"anchor\" id=\"yubinbango-dataを生成する\" name=\"yubinbango-dataを生成する\" href=\"#yubinbango-dataを生成する\" data-position=\"2-3-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"yubinbango-dataを生成する\"> &gt; yubinbango-dataを生成する</span></a>yubinbango-dataを生成する</h2>\n<p data-sourcepos=\"42:1-42:288\">ken_all.csvとjigyosyo.csvをUNIONしてjqで郵便番号をキーとしたオブジェクトに変換します。一部buildingカラムがnullを持っておりyubinbango-dataと異なる部分はありますが、大凡同等の状態にまで持っていくことが出来ました。</p>\n<div class=\"code-block\" data-sourcepos=\"44:1-65:3\"><div class=\"code-filename\"><i class=\"fa fa-file-code-o\"></i>sh</div><div class=\"highlight\"><pre class=\"highlight shell\"><code>brew <span class=\"nb\">install </span>noborus/tap/trdsql\n<span class=\"k\">for </span>i <span class=\"k\">in</span> <span class=\"o\">{</span>001..999<span class=\"o\">}</span><span class=\"p\">;</span> <span class=\"k\">do\n  </span>trdsql <span class=\"nt\">-ojson</span> <span class=\"s2\">\"\n    SELECT *\n    FROM (\n      SELECT c3 zip, c8 city, c9 town, NULL building FROM ken_all.csv\n      UNION SELECT c8 zip, c5 city, c6 town, c7 building FROM jigyosyo.csv\n    )\n    WHERE SUBSTRING(zip,0,4) = '</span><span class=\"nv\">$i</span><span class=\"s2\">'\n    ORDER BY zip ASC\n  \"</span> <span class=\"se\">\\</span>\n  | jq <span class=\"nt\">--compact-output</span> <span class=\"s1\">'\n    .\n    | to_entries\n    | map({ (.value.zip): [1, .value.city, .value.town, .value.building] })\n    | add\n  '</span> <span class=\"se\">\\</span>\n  | <span class=\"nb\">sed</span> <span class=\"nt\">-E</span> <span class=\"s1\">'s/(.+?)/$yubin(\\1);/g'</span> <span class=\"se\">\\</span>\n  <span class=\"o\">&gt;</span><span class=\"nv\">$i</span>.js<span class=\"p\">;</span>\n<span class=\"k\">done</span>\n</code></pre></div></div>\n<h1 data-sourcepos=\"67:1-67:8\" id=\"3-0-0\" name=\"3-0-0\"><a class=\"anchor\" id=\"WRAPUP\" name=\"WRAPUP\" href=\"#WRAPUP\" data-position=\"3-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"WRAPUP\"> &gt; WRAPUP</span></a>WRAPUP</h1>\n<p data-sourcepos=\"68:1-68:208\">昔から何かと話題に上がるken_all.csvですが、正規化のサービスに加えCSV用SQLクライアントとjqの登場により思った以上に簡単に変換することができました。</p>\n","tags":["yubinbango","ken_all.csv","jq","trdsql"],"updated_at":"2021-07-25T12:07:20+09:00","childPublishedDate":{"published_on":"2021-07-25T00:00:00.000Z"},"updated_by":{"name":"なびの👷","screen_name":"nabinno","icon":"https://img.esa.io/uploads/production/members/94286/icon/thumb_m_7b757a0db07cde6a337af7df901ab0c5.jpg"}},"relatedPosts":{"edges":[{"node":{"number":140,"relative_category":"blog/backend","fields":{"title":"提供していない決済方法を業務で取り扱う際に気をつけること","excerpt":"ECプロダクトを扱っている際にどうしても出てくる銀行振込。プロダクト立ち上げ時は、銀行振込が第一にあるターゲット層を除いて、コストの高い銀行振込は実装せずに裏メニューとして扱うのが通例だと思います。今回は、当該ケースの課題を取り上げて、その解決策を示します。単純な話なのですが、時間が経つにつれて業務が硬直化してスケーリングに影響してくるので事前に手を打っておくと良いと思います。   > PROBLEMPROBLEM \n\n- 銀行振込を通常決済方法でしか提供していないケースの場合 人力でトランザクションをはる必要があり、その処理の隙間で想定外の支払い、あるいは、二重決済が行われる可能性がある また、不整合処理を実施するCSあるいはそれに付随する担当に権限が集中しすぎ、統制上難しい運用になる \n- 人力でトランザクションをはる必要があり、その処理の隙間で想定外の支払い、あるいは、二重決済が行われる可能性がある\n- また、不整合処理を実施するCSあるいはそれに付随する担当に権限が集中しすぎ、統制上難しい運用になる  > 通常のケース通常のケース \n\n  > 不整合が起きるケース「銀行振込と通常決済が同時に実行」不整合が起きるケース「銀行振込と通常決済が同時に実行」 \n\n  > SOLUTIONSOLUTION \n\nと言うわけで、解決方法を整理してみました。答えは単純で銀行振込の決済ロックをシステム側に実装するというだけの話です。ただ、振込確認を人力で行っている場合は、銀行振込を決済方法として表側に出すのは難しいので問い合わせタイミングでロックできるよう問い合わせ窓口を工夫する必要があります。プロダクトのUXに関わってくる話なので簡単に実装するだけで済まないのが悩ましいところですが、粘り強く進めるしかないです。 \n\n  > WRAPUPWRAPUP \n\nECプロダクトがスケールしてくると決済方法が増え、業務処理が複雑になってきます。決済の適正性は統制上重要になってくるので決済の処理量に応じて、リスクアセスメントで拾い上げ適切な実装にしていきたいものですね。"},"name":"提供していない決済方法を業務で取り扱う際に気をつけること","tags":["payment-service"],"childPublishedDate":{"published_on":"2022-05-01T15:27:13.000Z","published_on_unix":1651418833}}},{"node":{"number":139,"relative_category":"blog/backend","fields":{"title":"ヘルステック界隈のエンジニアが気をつけるべき個人情報の扱い","excerpt":"ヘルステックでエンジニアをしている方であればデータの扱いには苦労していることと思います。CISOがつくったデータセグメンテーションがどういう意図で成り立っているのか、整理されていない現場だと読み解きに時間がかかります。現場に入って早々 何も知らないエンジニアとしては、緩めな方針よりは保守的に設計していく方が後々のトラブルが少なく安全です。   > PROBLEMPROBLEM \n\n- 要配慮個人情報について、厚労省医政局発「医療情報システムの安全管理に関するガイドライン」1を見ると「 医療・健康情報を[..]医師等以外の者が分析等を実施することは許されるものではない 」と書かれている ここでいう「 医療・健康情報 」は要配慮個人情報の中の具体的に何を指しているのか分かりづらい 「 医師等 」の「 等 」が何を指すのか分かりづらい 厚労省医政局の発令0912001号「診療情報の提供等に関する指針」2から推察するに、「 医療・健康情報 」は診療録、「 医師等 」は医療系有資格者を指している 医療系有資格者については、個人情報保護法の関連で出された医療・介護分野用「医療・介護関係事業者における個人情報の適切な取扱いのためのガイダンス」に掲載されている守秘義務対象 \n- ここでいう「 医療・健康情報 」は要配慮個人情報の中の具体的に何を指しているのか分かりづらい\n- 「 医師等 」の「 等 」が何を指すのか分かりづらい\n- 厚労省医政局の発令0912001号「診療情報の提供等に関する指針」2から推察するに、「 医療・健康情報 」は診療録、「 医師等 」は医療系有資格者を指している 医療系有資格者については、個人情報保護法の関連で出された医療・介護分野用「医療・介護関係事業者における個人情報の適切な取扱いのためのガイダンス」に掲載されている守秘義務対象 \n- 医療系有資格者については、個人情報保護法の関連で出された医療・介護分野用「医療・介護関係事業者における個人情報の適切な取扱いのためのガイダンス」に掲載されている守秘義務対象\n- また、データアクセス対象を緩めると、教育が不十分な人が故意に流出させ刑法上の秘密漏示罪3に問われる可能性がある 秘密漏示罪は身分犯ではあるが歯科医師のように解釈の余地もあり範囲が不透明 \n- 秘密漏示罪は身分犯ではあるが歯科医師のように解釈の余地もあり範囲が不透明  > SOLUTIONSOLUTION \n\nというわけで、ヘルステックに関わる個人情報の扱いを整理してみました。 \n\n課題は上記の通りで、時代の流れとともに医療情報の整備が進んでいる状況です。善管注意の責務を負ったエンジニアとしては医療系有資格者以外への診療録の情報提供は、例え、同僚であっても連結可能匿名（仮名加工）ではなく匿名加工で対応すべきでしょう。ゆくゆくは会社として次世代医療基盤法4を適用し、医療分野の研究開発に資するよう体制を構築することが望ましいと考えています。  > 加工なし加工なし \n\n学術研究等をのぞき第三者提供は本人同意が必要となるため、ユースケースは限定されます。各々の個人情報の種類によりアクセス出来る人が変わってきます。また、守秘義務が課せられる範囲が広く、行為によっては秘密漏示罪や不正アクセス禁止法5の罰則の対象になります。     診療録 診療録を除いた要配慮個人情報 要配慮個人情報を除いた個人情報     使用場所 社内 (医療関連有資格者) 社内 社内, 社外   利用目的の必要性 (公表有無) 必要 必要 必要   利用目的の必要性 (変更可否) 関連性を有する合理的な範囲 関連性を有する合理的な範囲 関連性を有する合理的な範囲   目的外利用 不可 不可 不可   第三者提供 (可否) 可 可 可   第三者提供 (本人同意) 必要 (オプトインのみ) 必要 (オプトインのみ) 必要 (オプトアウト)   個人の開示請求 応じる 応じる 応じる   漏洩時の報告 必須 必須 必須     > 仮名加工仮名加工 \n\n診療録に関する規定は次世代医療基盤法でまとめられているので、あえて規定が曖昧な仮名加工（連結可能匿名）をつかうのは望ましくありません。ユースケースとして要配慮個人情報を除いた個人情報の統計分析に限られるでしょう。     診療録を除いた要配慮個人情報 要配慮個人情報を除いた個人情報     使用場所 社内 社内   利用目的の必要性 (公表有無) 必要 必要   利用目的の必要性 (変更可否) 際限なく変更可能 際限なく変更可能   目的外利用 不可 不可   第三者提供 (可否) 不可 不可   個人の開示請求 応じない 応じない   漏洩時の報告 なし なし     > 匿名加工匿名加工 \n\n診療録は本人のオプトアウトありですが、基本本人同意なしで利用可能です。ただ、診療録は可変長文字列の上、特異な記述として最も気をつける対象になります。データマスキングの実装は手厚く行っていく必要があります。     診療録を含んだ要配慮個人情報 要配慮個人情報を除いた個人情報     使用場所 社内, 社外 社内, 社外   利用目的の必要性 (公表有無) 不要 不要   第三者提供 (可否) 可 可   第三者提供 (本人同意) 不要 (オプトアウトあり) 不要   個人の開示請求 応じない 応じない   漏洩時の報告 なし なし     > WRAPUPWRAPUP \n\nポイントをかいつまんでまとめてみました。エンジニア視点のため、考慮漏れの箇所があるかも知れませんが、フィードバックや各種レギュレーションの経過を元に更新していければと思います。  \n\n1. https://www.mhlw.go.jp/stf/shingi/0000516275.html ↩ \n2. https://www.mhlw.go.jp/web/t_doc?dataId=00tb3403&dataType=1&page%20No=1 ↩ \n3. https://elaws.e-gov.go.jp/document?lawid=140AC0000000045 ↩ \n4. https://elaws.e-gov.go.jp/document?lawid=429AC0000000028 ↩ \n5. https://elaws.e-gov.go.jp/document?lawid=411AC0000000128 ↩"},"name":"[2022-04-24]ヘルステック界隈のエンジニアが気をつけるべき個人情報の扱い","tags":["privacy","data-masking","data-engineering","health-informatics"],"childPublishedDate":{"published_on":"2022-04-24T00:00:00.000Z","published_on_unix":1650758400}}},{"node":{"number":137,"relative_category":"blog/backend","fields":{"title":"G Suite無償版停止に伴い、MXレコード等のドメイン管理を整理した","excerpt":"今回は10年以上利用していたG Suite無償版が2022年8月に停止されるとのことで、メールアドレスの管理をどうするか検討しました。メール管理は別のGMailアカウントを使っていたので、転送できれば良いのですが、これを機にドメイン管理をAWSにまとめていくことを思いつきました。   > PROBLEMPROBLEM \n\n- 10年以上利用していたG Suite無償版が2022年8月に停止され、メールアドレスの管理をどうしようか Google Workspaceにアップグレードしても良いけどBusiness Starterプランにしても面白みがないので別の方法を探したい G Suiteはメールしか利用しておらず、メール管理は別のGMailアカウントを使っていたのでメール転送機能で代替できそう \n- Google Workspaceにアップグレードしても良いけどBusiness Starterプランにしても面白みがないので別の方法を探したい G Suiteはメールしか利用しておらず、メール管理は別のGMailアカウントを使っていたのでメール転送機能で代替できそう \n- G Suiteはメールしか利用しておらず、メール管理は別のGMailアカウントを使っていたのでメール転送機能で代替できそう  > SOLUTIONSOLUTION \n\nと言うわけで、今回はG Suiteアカウントの利用を止めて、MXレコード周りを整理することにしました。個人利用なのでドメイン管理は既存のままで良かったのですが、証跡管理のない状況に耐えられずAWSに移管。メール転送機能はPOBOX以外はサブアドレス対応していなかったのですが、キャッチオール対応できるのでまずは良しとしています。現時点での構成は下記の通り。 \n\nなお、複数人数で必要になった場合は、サブアドレスとグループアドレスが対応可能なAmazon Workmailに移管する予定ですが、これでもGoogle Workspaceを利用するよりコストは半分程で済みます。  > 構成構成  > beforebefore \n\n- ドメイン管理 バリュードメイン\n- NSレコード Cloudflare DNS\n- MXレコード G Suite\n- SMTP G Suite  > afterafter \n\n- ドメイン管理 Amazon Route 53\n- NSレコード Amazon Route 53\n- MXレコード Cloudflare Email Routing\n- SMTP Amazon SES  > 手順手順 \n\n方針が決まるまでいくつかメールサービスを検討したのですが、決まってしまえばやることは単純です。  > 1. ドメイン管理を整理する1. ドメイン管理を整理する \n\n基本はドメイン移管申請ですが、G Suiteを後ほど削除することを考慮してMXレコードをCloudflare Email Routingに変更。本来はこの処理の前にG Suiteに紐付いている各サービスの設定変更が必要になります。 \n\n1. 移管元にてWHOIS情報公開代行の解除\n2. 移管元にてドメインロックの解除\n3. 移管元にて認証鍵 (Auth-Code) を確認\n4. 移管先にてホストゾーンの作成、各レコードの内容を移管元に合わせる\n5. Cloudflare Email Routingにて転送先メールアドレスを検証する\n6. 移管先にてMXレコードをCloudflare Email Routingのものを設定する\n7. 移管元のNSレコードを移管先に変更\n8. 移管先にて認証鍵をつかい移管申請を行う\n9. 移管元に対して移管申請を行った旨をメールにて連携する \n\nCf. \n\n- ドメインの他社への移管 | バリュードメイン ユーザーガイド\n- ドメイン登録の Amazon Route 53 への移管 - Amazon Route 53\n- Easily creating and routing email addresses with Cloudflare Email Routing  > 2. SMTPを設定する2. SMTPを設定する \n\n最近はセキュリティ対策のためGMailのSMTPが使いづらくなっているので、今回はAmazon SESを利用しました。サンドボックス解除のため下記の通りサポートに依頼しました。 txt\n\n# メールタイプ 通例の取引がメインとなる予定です # ユースケース ## メールを送信する頻度 週に1-2回 ## 受信者リストのメンテナンス方法 四半期に一度の棚卸し ## バウンス対応 当該メールアドレスの削除 ## 申し立て対応 当該メールアドレスへのフラグ管理 ## 解除申請の管理方法 メールでの受付 ## 送信予定のメールサンプル {{宛先名}}様 お世話になっております。 表題の件につきまして1点問い合わせします。 {{問い合わせ内容}} ご不明な点等ございましたらお気軽にお問い合わせ下さい。 どうぞ、よろしくお願い致します。   > 3. G Suiteを退会する3. G Suiteを退会する \n\nG Suiteに依存しているサービスがないか確認し、退会します。  > WRAPUPWRAPUP \n\n以前からドメイン管理をAWSに移管したかったのですが、積極的な理由がないためなおざりになっていました。今回のG Suite無償版の期限切れに伴い整理できすっきりしたので、これを機にいろいろ整理していきたいですね。  > 後日談後日談 \n\nCloudflare DNSからAmazon Route 53に設定を変更した数日後、Cloudflare Email Routingが使用できなくなりました。転送機能としてドメイン管理から切り離されていると思ったのですがそうではなかったようです。ドメイン管理は厳しめに証跡を取っていきたいところなので、Amazon Route 53による管理は譲れません。 \n\nまた、Amazon SESによる転送機能も検討したのですが、送信元すべてに対してドメイン検証が必要なため現実的ではありませんでした。AWSにはメール転送の種類が2つあって、送信元を転送者に置き換える「転送」と送信元をそのまま利用する「リダイレクト」があります。「転送」だと元の送信元とコミュニケーションが取りづらくなる一方、「リダイレクト」だとすべての送信元のドメイン検証が必要となります。ここでは融通が利かないと判断するのではなく、セキュリティを考慮された実装と捉え、AWSが提供しているWorkMailを素直に使うことにしました。慣れればたいしたことはありません。下記が結果になります。  > beforebefore \n\n- ドメイン管理 Amazon Route 53\n- NSレコード Amazon Route 53\n- MXレコード Cloudflare Email Routing\n- SMTP Amazon SES  > afterafter \n\n- ドメイン管理 Amazon Route 53\n- NSレコード Amazon Route 53\n- MXレコード Amazon WorkMail\n- SMTP Amazon WorkMail"},"name":"[2022-04-12]G Suite無償版停止に伴い、MXレコード等のドメイン管理を整理した","tags":["gsuite","google-workspace","cloudflare","amazon-ses","amazon-workmail"],"childPublishedDate":{"published_on":"2022-04-12T00:00:00.000Z","published_on_unix":1649721600}}}]}},"pageContext":{"number":90}},"staticQueryHashes":[]}