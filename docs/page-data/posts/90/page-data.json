{"componentChunkName":"component---src-templates-post-tsx","path":"/posts/90","result":{"data":{"esaPost":{"number":90,"relative_category":"blog/backend","fields":{"title":"yubinbango-dataをどうやって生成するか","excerpt":"郵便番号から住所を補完するライブラリ「yubinbango」を継続的に利用するにあたり、当該ライブラリが参照している郵便データ「yubinbango-data」を自前でメンテナンスできるか確認します。   > PROBLEMPROBLEM \n\n- 「yubinbango/yubinbango」を利用するにあたり「yubinbango/yubinbango-data」の更新が継続的に行われるかサービス継続性の懸念がある そこで自前でメンテナンスをする場合の対処方法を事前に知っておきたい \n- そこで自前でメンテナンスをする場合の対処方法を事前に知っておきたい  > SOLUTIONSOLUTION \n\nというわけで、yubinbango-dataの中身であるken_all.csvとjigyosyo.csvを安定して変換する方法を確認します。  > ken_all.csvを正規化するken_all.csvを正規化する \n\nyubinbango-dataのken_all.csvの部分はアイビスが提供しているzipcloudを参照しているようなので、そちらに合わせて利用します。 sh\n\nsudo apt install nkf { curl -sSL \"http://zipcloud.ibsnet.co.jp/zipcodedata/download?di=1625040649647\" -o ./x_ken_all.zip; unzip -p x_ken_all.zip | nkf -w; rm x_ken_all.zip } >ken_all.csv  \n\nzipcloudを使うことに抵抗がある場合はgokenallもありますが、正規化によって一つの郵便番号に複数の町名番地が存在するため郵便番号をキーとするyubinbango-dataに変換する際には工夫が必要です。 sh\n\ngo get github.com/oirik/gokenall/cmd/kenall { kenall download -x | kenall normalize } >ken_all.csv   > jigyosyo.csvを取得するjigyosyo.csvを取得する \n\njigyosyo.csvは特に正規化は必要ないです。 sh\n\n{ curl -sSL https://www.post.japanpost.jp/zipcode/dl/jigyosyo/zip/jigyosyo.zip -o ./jigyosyo.zip; unzip -p jigyosyo.zip | nkf -w; rm jigyosyo.zip } >jigyosyo.csv   > yubinbango-dataを生成するyubinbango-dataを生成する \n\nken_all.csvとjigyosyo.csvをUNIONしてjqで郵便番号をキーとしたオブジェクトに変換します。一部buildingカラムがnullを持っておりyubinbango-dataと異なる部分はありますが、大凡同等の状態にまで持っていくことが出来ました。 sh\n\nbrew install noborus/tap/trdsql for i in {001..999}; do trdsql -ojson \" SELECT * FROM ( SELECT c3 zip, c8 city, c9 town, NULL building FROM ken_all.csv UNION SELECT c8 zip, c5 city, c6 town, c7 building FROM jigyosyo.csv ) WHERE SUBSTRING(zip,0,4) = '$i' ORDER BY zip ASC \" \\ | jq --compact-output ' . | to_entries | map({ (.value.zip): [1, .value.city, .value.town, .value.building] }) | add ' \\ | sed -E 's/(.+?)/$yubin(\\1);/g' \\ >$i.js; done   > WRAPUPWRAPUP \n\n昔から何かと話題に上がるken_all.csvですが、正規化のサービスに加えCSV用SQLクライアントとjqの登場により思った以上に簡単に変換することができました。","thumbnail":"https://img.esa.io/uploads/production/attachments/16651/2023/08/16/97367/321d0e29-bf15-42f9-8651-2052ccf256cb.png"},"wip":false,"body_md":"郵便番号から住所を補完するライブラリ「yubinbango」を継続的に利用するにあたり、当該ライブラリが参照している郵便データ「yubinbango-data」を自前でメンテナンスできるか確認します。\r\n\r\n<img alt=\"thumbnail\" src=\"https://img.esa.io/uploads/production/attachments/16651/2023/08/16/97367/321d0e29-bf15-42f9-8651-2052ccf256cb.png\">\r\n\r\n# PROBLEM\r\n- 「[yubinbango/yubinbango](https://github.com/yubinbango/yubinbango)」を利用するにあたり「[yubinbango/yubinbango-data](https://github.com/yubinbango/yubinbango-data)」の更新が継続的に行われるかサービス継続性の懸念がある\r\n    - そこで自前でメンテナンスをする場合の対処方法を事前に知っておきたい\r\n\r\n# SOLUTION\r\nというわけで、yubinbango-dataの中身である[ken_all.csvとjigyosyo.csv](https://www.post.japanpost.jp/zipcode/download.html)を安定して変換する方法を確認します。\r\n\r\n## ken_all.csvを正規化する\r\nyubinbango-dataのken_all.csvの部分はアイビスが提供している[zipcloud](http://zipcloud.ibsnet.co.jp)を参照しているようなので、そちらに合わせて利用します。\r\n```sh\r\nsudo apt install nkf\r\n{ \r\n  curl -sSL \"http://zipcloud.ibsnet.co.jp/zipcodedata/download?di=1625040649647\" -o ./x_ken_all.zip;\r\n  unzip -p x_ken_all.zip | nkf -w;\r\n  rm x_ken_all.zip\r\n} >ken_all.csv\r\n```\r\n\r\nzipcloudを使うことに抵抗がある場合は[gokenall](https://github.com/oirik/gokenall)もありますが、正規化によって一つの郵便番号に複数の町名番地が存在するため郵便番号をキーとするyubinbango-dataに変換する際には工夫が必要です。\r\n\r\n```sh\r\ngo get github.com/oirik/gokenall/cmd/kenall\r\n{ kenall download -x | kenall normalize } >ken_all.csv\r\n```\r\n\r\n## jigyosyo.csvを取得する\r\njigyosyo.csvは特に正規化は必要ないです。\r\n\r\n```sh\r\n{ \r\n  curl -sSL https://www.post.japanpost.jp/zipcode/dl/jigyosyo/zip/jigyosyo.zip -o ./jigyosyo.zip;\r\n  unzip -p jigyosyo.zip | nkf -w;\r\n  rm jigyosyo.zip\r\n} >jigyosyo.csv\r\n```\r\n\r\n## yubinbango-dataを生成する\r\nken_all.csvとjigyosyo.csvをUNIONしてjqで郵便番号をキーとしたオブジェクトに変換します。一部buildingカラムがnullを持っておりyubinbango-dataと異なる部分はありますが、大凡同等の状態にまで持っていくことが出来ました。\r\n\r\n```sh\r\nbrew install noborus/tap/trdsql\r\nfor i in {001..999}; do\r\n  trdsql -ojson \"\r\n    SELECT *\r\n    FROM (\r\n      SELECT c3 zip, c8 city, c9 town, NULL building FROM ken_all.csv\r\n      UNION SELECT c8 zip, c5 city, c6 town, c7 building FROM jigyosyo.csv\r\n    )\r\n    WHERE SUBSTRING(zip,0,4) = '$i'\r\n    ORDER BY zip ASC\r\n  \" \\\r\n  | jq --compact-output '\r\n    .\r\n    | to_entries\r\n    | map({ (.value.zip): [1, .value.city, .value.town, .value.building] })\r\n    | add\r\n  ' \\\r\n  | sed -E 's/(.+?)/$yubin(\\1);/g' \\\r\n  >$i.js;\r\ndone\r\n```\r\n\r\n# WRAPUP\r\n昔から何かと話題に上がるken_all.csvですが、正規化のサービスに加えCSV用SQLクライアントとjqの登場により思った以上に簡単に変換することができました。","body_html":"<p data-sourcepos=\"1:1-1:250\">郵便番号から住所を補完するライブラリ「yubinbango」を継続的に利用するにあたり、当該ライブラリが参照している郵便データ「yubinbango-data」を自前でメンテナンスできるか確認します。</p>\n<a href=\"https://img.esa.io/uploads/production/attachments/16651/2023/08/16/97367/321d0e29-bf15-42f9-8651-2052ccf256cb.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img alt=\"thumbnail\" src=\"https://img.esa.io/uploads/production/attachments/16651/2023/08/16/97367/321d0e29-bf15-42f9-8651-2052ccf256cb.png\"></a>\n<h1 data-sourcepos=\"5:1-5:9\" id=\"1-0-0\" name=\"1-0-0\"><a class=\"anchor\" id=\"PROBLEM\" name=\"PROBLEM\" href=\"#PROBLEM\" data-position=\"1-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"PROBLEM\"> &gt; PROBLEM</span></a>PROBLEM</h1>\n<ul data-sourcepos=\"6:1-8:0\">\n<li data-sourcepos=\"6:1-8:0\">「<a href=\"https://github.com/yubinbango/yubinbango\" target=\"_blank\" rel=\"noopener noreferrer\">yubinbango/yubinbango</a>」を利用するにあたり「<a href=\"https://github.com/yubinbango/yubinbango-data\" target=\"_blank\" rel=\"noopener noreferrer\">yubinbango/yubinbango-data</a>」の更新が継続的に行われるかサービス継続性の懸念がある\n<ul data-sourcepos=\"7:5-8:0\">\n<li data-sourcepos=\"7:5-8:0\">そこで自前でメンテナンスをする場合の対処方法を事前に知っておきたい</li>\n</ul></li>\n</ul>\n<h1 data-sourcepos=\"9:1-9:10\" id=\"2-0-0\" name=\"2-0-0\"><a class=\"anchor\" id=\"SOLUTION\" name=\"SOLUTION\" href=\"#SOLUTION\" data-position=\"2-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"SOLUTION\"> &gt; SOLUTION</span></a>SOLUTION</h1>\n<p data-sourcepos=\"10:1-10:189\">というわけで、yubinbango-dataの中身である<a href=\"https://www.post.japanpost.jp/zipcode/download.html\" target=\"_blank\" rel=\"noopener noreferrer\">ken_all.csvとjigyosyo.csv</a>を安定して変換する方法を確認します。</p>\n<h2 data-sourcepos=\"12:1-12:32\" id=\"2-1-0\" name=\"2-1-0\"><a class=\"anchor\" id=\"ken_all.csvを正規化する\" name=\"ken_all.csvを正規化する\" href=\"#ken_all.csvを正規化する\" data-position=\"2-1-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"ken_all.csvを正規化する\"> &gt; ken_all.csvを正規化する</span></a>ken_all.csvを正規化する</h2>\n<p data-sourcepos=\"13:1-13:195\">yubinbango-dataのken_all.csvの部分はアイビスが提供している<a href=\"http://zipcloud.ibsnet.co.jp\" target=\"_blank\" rel=\"noopener noreferrer\">zipcloud</a>を参照しているようなので、そちらに合わせて利用します。</p>\n<div class=\"code-block\" data-sourcepos=\"14:1-21:3\"><div class=\"code-filename\"><i class=\"fa fa-file-code-o\"></i>sh</div><div class=\"highlight\"><pre class=\"highlight shell\"><code><span class=\"nb\">sudo </span>apt <span class=\"nb\">install </span>nkf\n<span class=\"o\">{</span> \n  curl <span class=\"nt\">-sSL</span> <span class=\"s2\">\"http://zipcloud.ibsnet.co.jp/zipcodedata/download?di=1625040649647\"</span> <span class=\"nt\">-o</span> ./x_ken_all.zip<span class=\"p\">;</span>\n  unzip <span class=\"nt\">-p</span> x_ken_all.zip | nkf <span class=\"nt\">-w</span><span class=\"p\">;</span>\n  <span class=\"nb\">rm </span>x_ken_all.zip\n<span class=\"o\">}</span> <span class=\"o\">&gt;</span>ken_all.csv\n</code></pre></div></div>\n<p data-sourcepos=\"23:1-23:296\">zipcloudを使うことに抵抗がある場合は<a href=\"https://github.com/oirik/gokenall\" target=\"_blank\" rel=\"noopener noreferrer\">gokenall</a>もありますが、正規化によって一つの郵便番号に複数の町名番地が存在するため郵便番号をキーとするyubinbango-dataに変換する際には工夫が必要です。</p>\n<div class=\"code-block\" data-sourcepos=\"25:1-28:3\"><div class=\"code-filename\"><i class=\"fa fa-file-code-o\"></i>sh</div><div class=\"highlight\"><pre class=\"highlight shell\"><code>go get github.com/oirik/gokenall/cmd/kenall\n<span class=\"o\">{</span> kenall download <span class=\"nt\">-x</span> | kenall normalize <span class=\"o\">}</span> <span class=\"o\">&gt;</span>ken_all.csv\n</code></pre></div></div>\n<h2 data-sourcepos=\"30:1-30:30\" id=\"2-2-0\" name=\"2-2-0\"><a class=\"anchor\" id=\"jigyosyo.csvを取得する\" name=\"jigyosyo.csvを取得する\" href=\"#jigyosyo.csvを取得する\" data-position=\"2-2-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"jigyosyo.csvを取得する\"> &gt; jigyosyo.csvを取得する</span></a>jigyosyo.csvを取得する</h2>\n<p data-sourcepos=\"31:1-31:54\">jigyosyo.csvは特に正規化は必要ないです。</p>\n<div class=\"code-block\" data-sourcepos=\"33:1-39:3\"><div class=\"code-filename\"><i class=\"fa fa-file-code-o\"></i>sh</div><div class=\"highlight\"><pre class=\"highlight shell\"><code><span class=\"o\">{</span> \n  curl <span class=\"nt\">-sSL</span> https://www.post.japanpost.jp/zipcode/dl/jigyosyo/zip/jigyosyo.zip <span class=\"nt\">-o</span> ./jigyosyo.zip<span class=\"p\">;</span>\n  unzip <span class=\"nt\">-p</span> jigyosyo.zip | nkf <span class=\"nt\">-w</span><span class=\"p\">;</span>\n  <span class=\"nb\">rm </span>jigyosyo.zip\n<span class=\"o\">}</span> <span class=\"o\">&gt;</span>jigyosyo.csv\n</code></pre></div></div>\n<h2 data-sourcepos=\"41:1-41:33\" id=\"2-3-0\" name=\"2-3-0\"><a class=\"anchor\" id=\"yubinbango-dataを生成する\" name=\"yubinbango-dataを生成する\" href=\"#yubinbango-dataを生成する\" data-position=\"2-3-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"yubinbango-dataを生成する\"> &gt; yubinbango-dataを生成する</span></a>yubinbango-dataを生成する</h2>\n<p data-sourcepos=\"42:1-42:288\">ken_all.csvとjigyosyo.csvをUNIONしてjqで郵便番号をキーとしたオブジェクトに変換します。一部buildingカラムがnullを持っておりyubinbango-dataと異なる部分はありますが、大凡同等の状態にまで持っていくことが出来ました。</p>\n<div class=\"code-block\" data-sourcepos=\"44:1-65:3\"><div class=\"code-filename\"><i class=\"fa fa-file-code-o\"></i>sh</div><div class=\"highlight\"><pre class=\"highlight shell\"><code>brew <span class=\"nb\">install </span>noborus/tap/trdsql\n<span class=\"k\">for </span>i <span class=\"k\">in</span> <span class=\"o\">{</span>001..999<span class=\"o\">}</span><span class=\"p\">;</span> <span class=\"k\">do\n  </span>trdsql <span class=\"nt\">-ojson</span> <span class=\"s2\">\"\n    SELECT *\n    FROM (\n      SELECT c3 zip, c8 city, c9 town, NULL building FROM ken_all.csv\n      UNION SELECT c8 zip, c5 city, c6 town, c7 building FROM jigyosyo.csv\n    )\n    WHERE SUBSTRING(zip,0,4) = '</span><span class=\"nv\">$i</span><span class=\"s2\">'\n    ORDER BY zip ASC\n  \"</span> <span class=\"se\">\\</span>\n  | jq <span class=\"nt\">--compact-output</span> <span class=\"s1\">'\n    .\n    | to_entries\n    | map({ (.value.zip): [1, .value.city, .value.town, .value.building] })\n    | add\n  '</span> <span class=\"se\">\\</span>\n  | <span class=\"nb\">sed</span> <span class=\"nt\">-E</span> <span class=\"s1\">'s/(.+?)/$yubin(\\1);/g'</span> <span class=\"se\">\\</span>\n  <span class=\"o\">&gt;</span><span class=\"nv\">$i</span>.js<span class=\"p\">;</span>\n<span class=\"k\">done</span>\n</code></pre></div></div>\n<h1 data-sourcepos=\"67:1-67:8\" id=\"3-0-0\" name=\"3-0-0\"><a class=\"anchor\" id=\"WRAPUP\" name=\"WRAPUP\" href=\"#WRAPUP\" data-position=\"3-0-0\"><i class=\"fa fa-link\"></i><span class=\"hidden\" data-text=\"WRAPUP\"> &gt; WRAPUP</span></a>WRAPUP</h1>\n<p data-sourcepos=\"68:1-68:208\">昔から何かと話題に上がるken_all.csvですが、正規化のサービスに加えCSV用SQLクライアントとjqの登場により思った以上に簡単に変換することができました。</p>\n","tags":["yubinbango","ken_all.csv","jq","trdsql"],"updated_at":"2023-08-16T00:40:12+09:00","childPublishedDate":{"published_on":"2021-07-25T00:00:00.000Z"},"updated_by":{"name":"なびの👷","screen_name":"nabinno","icon":"https://img.esa.io/uploads/production/members/94286/icon/thumb_m_7b757a0db07cde6a337af7df901ab0c5.jpg"}},"relatedPosts":{"edges":[{"node":{"number":70,"relative_category":"blog/market","fields":{"title":"就職氷河期とは何だったのか","excerpt":"私はいわゆる就職氷河期世代です。周囲から時折漏れ聞こえる不平のような言葉がありますが、それを単なる不平として片付けるのはもったいない気がします。できれば、その中に新しい視点を見つけ、次のチャンスへ繋げたいと思っています。   > PROBLEMPROBLEM \n\n- リセッション（景気後退）に直面した若者たちは、就職に関する不満や不平を抱えている\n- 周囲から聞こえてくる否定的な声が、彼らの意欲や展望を損ねている可能性がある\n- 経済の不安定性や求人の減少などの要因により、採用マーケットが厳しい状況にある\n- 若者たちが持つ可能性や才能が、現状の困難な状況によって十分に引き出されていない  > SOLUTIONSOLUTION \n\nそこで、リセッションと大卒の就職率の関係について、また、就職氷河期が単なる経済後退だけではなかったのか、その歴史をじっくりと解き明かしてみたいと思います。  > そもそもリセッションとは何か、どのタイミングで起きるのかそもそもリセッションとは何か、どのタイミングで起きるのか \n\nリセッションとは、経済の景気が一時的に悪化し、生産や雇用が減少する現象を指します。これは通常、国内総生産（GDP）が連続する2つの四半期でマイナス成長する状態になることで定義されます。リセッションはさまざまな要因によって引き起こされ、金融危機や需要減少などが主な原因とされています。  > 新卒採用マーケットについて新卒採用マーケットについて \n\n新卒採用マーケットとは、新卒学生が卒業後に就職を選ぶ際に選択できる求人の数や質を指します。景気の好悪や産業の動向などが影響を及ぼし、景気が良い時には多くの求人が出てくる一方、景気が悪化すると求人数が減少し、競争も激化します。  > リセッションと大卒の就職率の関係とその歴史リセッションと大卒の就職率の関係とその歴史 \n\n統計局の「学校基本調査 年次統計総括表 5 就職率（1950年～）」 から得られたデータに基づくチャートを見ると、リセッションが大卒の就職率にどのような影響を与えたのかがはっきりと分かります。     年 イベント 翌々年大卒の就職率 内閣     1987 ブラックマンデー 79.6% 中曽根/竹下   1997 アジア通貨危機 60.1% 橋本内閣   2000-2004 就職氷河期 55.8% 小渕/森内閣   2008 リーマンショック 60.8% 福田内閣   2020 コロナクラッシュ ??? 安倍/管内閣    \n\n1987年のブラックマンデーに起因するリセッションでは、大卒の就職率が79.6%まで落ち込みました。その後もアジア通貨危機やリーマンショック、そして最近のコロナクラッシュによって、大卒の就職率は変動しています。特に2000年から2004年にかけての就職氷河期では、大卒の就職率が55.8%にまで低下しました。  > アジア通貨危機はなぜ尾を引いていたのかアジア通貨危機はなぜ尾を引いていたのか \n\nアジア通貨危機は、1997年にアジア諸国で発生した経済危機であり、その影響は就職氷河期世代にも長期間にわたって影響を及ぼしました。この危機が尾を引いた理由は以下の点にあります。 \n\n1. 金融システムの崩壊: アジア通貨危機は、一部のアジア諸国で急激な通貨の暴落や金融システムの崩壊を引き起こしました。このため、企業や金融機関が多額の損失を被り、経済全体が深刻な打撃を受けました。経済基盤の崩壊は、就職機会の減少や企業の採用停止などをもたらしました。 \n2. 経済の停滞: アジア諸国の経済は通貨危機後、停滞期に入りました。このため、企業の業績が悪化し、新卒採用の余裕がなくなりました。経済の停滞は、若者たちの就職機会を減少させる一因となりました。 \n3. 信用の低下: 通貨危機により多くの企業が経営危機に陥り、信用が低下しました。これによって、企業が採用活動を控える傾向が生まれ、新卒の求人数が減少しました。就職氷河期世代は、この信用の低下によって求人市場が厳しさを増した現実を直面しました。 \n4. 失業率の上昇: アジア通貨危機により多くの企業が倒産し、失業率が上昇しました。失業者が増加する状況は、求職者同士の競争を激化させ、新卒の就職活動を難しくしました。この影響は就職氷河期世代にも及びました。  \n\nこれらの要因により、アジア通貨危機は長期的な影響をもたらし、若者たちの就職機会やキャリア形成に深刻な影響を与えました。しかし、この困難な状況に対して克服の道を見つけ、自己成長と前向きな姿勢を持つことが、就職氷河期世代の未来への道を切り拓く鍵となったのです。  > WRAPUPWRAPUP \n\n今回は、リセッションの歴史とその背後にある要因について深く考察してみました。リセッションと新卒採用マーケットの動向が、大卒の就職率にどのような影響を与えるかを理解することは、今後のキャリアにおいて重要です。常に社会経済の変動に柔軟に対応し、新たな視点を持って未来を切り開いていくことが大切です。"},"name":"[2021-01-23]就職氷河期とは何だったのか","tags":["labor-economics","recession","employment-ice-age"],"childPublishedDate":{"published_on":"2021-01-23T00:00:00.000Z","published_on_unix":1611360000}}},{"node":{"number":67,"relative_category":"blog/frontend","fields":{"title":"esaをHeadless CMSとして使う","excerpt":"最近仕事の同僚からHeadless CMS という言葉を聞いていて「自分には関係ないな」と距離を取っていたのですが、なぜか回り回って自分からHeadless CMSを作ることになりました。世の中何が起きるか分からないですね。   > PROBLEMPROBLEM \n\n- ブログを普段書かない人なのだが、よそ向けに情報発信する必要が出てきた とは言っても、今までMarkdownをJekyllで管理していたので画像を貼り付けるのが手間でモチベーションが大きく下がっていた さらにPlantUMLを出力するのも手間、試行錯誤した末にいずれも付け焼き刃で、esaの操作感に勝てるものはなかった \n- とは言っても、今までMarkdownをJekyllで管理していたので画像を貼り付けるのが手間でモチベーションが大きく下がっていた さらにPlantUMLを出力するのも手間、試行錯誤した末にいずれも付け焼き刃で、esaの操作感に勝てるものはなかった \n- さらにPlantUMLを出力するのも手間、試行錯誤した末にいずれも付け焼き刃で、esaの操作感に勝てるものはなかった  > SOLUTIONSOLUTION \n\nというわけで、esaをHeadless CMSとして使うことにしました。 \n\nやってることは昔のMovableTypeそのもので懐かしかったです。コンテンツを別システムで管理しビルドサーバーに当該コンテンツを流し込みリビルド、最後にホストサーバーにアップロードというワークフロー。今はJAMStackの文脈で語られているようです。 \n\nこのHeadless CMSが昔と違うのはコンテンツ作成に集中できること。CI周りが発達したので一度ワークフローを組み立てれば後は自動でコンテンツを生成できます。  > やり方やり方 \n\n- esa.io でゆるふわ情報共有 - Middleman Blog への Export サンプル付き #esa_io - Qiita\n- 技術ブログを支える技術（Gatsby + esaio） - mottox2 blog\n- Next.jsとesaを使った個人サイト構築 | corocn.dev \n\nそれほど時間をかけられなかったので、上記3記事の中で手軽さを考慮しmottox2さんのソースコードを拝借しました。ありがとうございます。 \n\n- 作ったレポジトリ：nabinno/nabinno.github.io: On Blahfe - Nab's Github Pages  > シークエンス図シークエンス図 \n\n私が手を入れたのはコンポーネントを削りGatsby Blog Starterに寄せたのと、デプロイ方法を使い慣れたCircleCIに変えたくらいです。 \n\nGitHub PagesにはVercelのような便利なWebhookがないので、esaで実装されたGitHub Webhook連携を使いそれをトリガーにCircleCIジョブを走らせています。 \n\n  > CircleCIジョブCircleCIジョブ \n\nまた、CircleCIジョブは何の変哲もないもので、NodeJSを叩いてGitプッシュしているくらいです。先ほどのGitHub Webhookと似た感じの泥臭いワークフローは [skip ci] コメントの追加があります。当該コメントを入れないとジョブが再帰的に走り続けるので出口で明示してあります。 yml\n\nversion: 2.1 jobs: build_deploy: docker: - image: circleci/node:12.4 steps: - checkout - run: name: Install NPM command: npm install - run: name: Build command: npm run clean && npm run build - add_ssh_keys: fingerprints: - \"{foo}\" - deploy: name: Deploy command: | git config --global user.email \"nab+circleci@blahfe.com\" git config --global user.name \"nabinno+circleci\" git add . git commit -m \"[skip ci]Run npm run clean && npm run build.\" git push origin master workflows: build_deploy: jobs: - build_deploy: filters: branches: only: master   > WRAPUPWRAPUP \n\nとまあ大した作業内容ではないのですが、久しぶりに昔懐かしのMovableTypeのリビルドを思い出しつつ、副産物として全く縁遠かったNetlifyとVercelの位置づけを薄らと感じ取れました。"},"name":"[2021-01-18]esaをHeadless CMSとして使う","tags":["gatsby","esa","headless-cms","cms"],"childPublishedDate":{"published_on":"2021-01-18T00:00:00.000Z","published_on_unix":1610928000}}},{"node":{"number":63,"relative_category":"blog/frontend","fields":{"title":"イケてるしヤバい言語REBOLの後継Redでクライアントソフトをつくった話","excerpt":"Redという言語はご存じでしょうか。可読性が高いシンタックスを持ち、ワンバイナリーをクロスコンパイルでき、かつ、クライアント用のUIコンポーネントを標準ライブラリに備えたプログラミング言語です。その野心的な挑戦にすぐに虜になりました。新年早々の恋です。   > PROBLEMPROBLEM \n\n- クロスプラットフォーム用のクライアントソフトをつくるにあたり 重たいフレームワークが多い 汎用的な言語をつかってるものが多く、そのためライブラリー等の依存関係が多くなりやすい \n- 重たいフレームワークが多い\n- 汎用的な言語をつかってるものが多く、そのためライブラリー等の依存関係が多くなりやすい  > SOLUTIONSOLUTION \n\nというわけで、年明け見つけたRedがシンプルだったので使ってみました。題材は以前つくったEmacsライブラリ「esa.el」の移植です。 \n\n- 今回作ったコード https://github.com/nabinno/esa.red  > やったことやったこと  > エディターエディター \n\n構文がすなおなので特にエディタは関係なさそうでしたが、慣れ親しんでるEmacsに「Skrylar/red.el」を適用しました。その際、 red-font-lock-keywords と red-indent-line に足りない箇所があったのでオーバーライドしました。  > 糖衣構文の適用糖衣構文の適用 \n\nRedはコマンドラインREPLがつかえるので、 docs.red-lang.org とRed by Exampleをみながらひとつひとつ挙動を確認しました。その中でどうしても慣れない表現が2つあったので糖衣構文を実装しました。 \n\n- 実装した糖衣構文 nabinno/red-elixir \n\n1. compose \n\nブロック内の変数を評価しブロックとして返す関数 compose は、VIDのフェイス更新によく使われます。HTML/JavaScripでいうところDOM更新にあたるものといえば分かるでしょうか。頻繁に「 compose [foo (bar)] 」のような表現がつづくとほかの変数や関数とまざり可読性がおちるので、Elixirのシジルを参考に compose 関数を省略しました。こんな感じです。 \n\n;-- before compose [foo (bar)] ;-- after ~c[foo (bar)]  \n\n2. 関数の入れ子 \n\n素のRedはイテレーター構文なので、関数の入れ子による可読性低下をおさえるため変数定義をよく使います。個人的には変数は意味のあるものだけ使いたい派なので、パイプを導入しました。といっても、フロントエンドの場合、データ加工はあまりやらないのでつかうケースはほぼありませんでした。あってもこのくらいです。 red\n\n;-- before rejoin collect [ foreach d data [ keep rejoin [d \" \"] ] ] ;-- after data .[ |> Series/map 'd [rejoin [d \" \"]] |> rejoin ]   > タスクランナーの用意タスクランナーの用意 \n\n今回は上で実装したライブラリ「red-elixir」のほかにHTTPリクエスト・JSONパーサーライブラリを使っています。ライブラリパッケージはインストールはgit submodulesで良いですが、呼び出しも考えると実装が冗長的になるのでパッケージ管理とタスクランナーをあわせて用意しました（nabinno/hot、nabinno/mods）。 \n\nタスクランナーインストール後、パッケージのインストールから呼び出しまでの流れ \n\nRedはGoとおなじくワンバイナリーなので、wgetやcurlだけでインストールが完了します。 sh\n\n> mkdir -p ~/.local/bin > wget https://github.com/nabinno/hot/releases/download/0.0.3/hot-linux -O ~/.local/bin/hot > chmod 744 ~/.local/bin/hot  \n\nパッケージ管理はElixirのmixを参考にタスクランナー管理ファイル内に定義します。 sh\n\n> hot cmd/install https://raw.githubusercontent.com/nabinno/mods/master/mods.red > cat hots.red Red [] hots: context [ mods: [ red-elixir #(init: %init.red git: https://github.com/nabinno/red-elixir) json #(init: %json.red git: https://github.com/rebolek/red-tools) http-tools #(init: %http-tools.red git: https://github.com/rebolek/red-tools) ] ] > hot mods/get  \n\nビルド時は #include をつかうのでパッケージ呼び出し機能は使えないですが、コマンドラインREPLで挙動確認している際は do/args %require を使います。 sh\n\n> red >> do/args %require [red-elixir] >> 1 .. 10 .[ |> Series/map 'i [i * 2] |> Series/map 'i [i + 1] ] == [3 5 7 9 11 13 15 17 19 21]   > WRAPUPWRAPUP \n\nクライアントソフトを作る中で感じたことは、この1点です。Redは既存のフレームワークと比べるとまだまだ機能不足感が拭えませんが、それを補えるだけの表現力を持っていました。手触りが本当に良い言語でした。"},"name":"[2019-03-31]イケてるしヤバい言語REBOLの後継Redでクライアントソフトをつくった話","tags":["red","esa"],"childPublishedDate":{"published_on":"2019-03-31T00:00:00.000Z","published_on_unix":1553990400}}}]}},"pageContext":{"number":90}},"staticQueryHashes":[]}